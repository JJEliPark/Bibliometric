eid,doi,pii,pubmed_id,title,subtype,subtypeDescription,creator,afid,affilname,affiliation_city,affiliation_country,author_count,author_names,author_ids,author_afids,coverDate,coverDisplayDate,publicationName,issn,source_id,eIssn,aggregationType,volume,issueIdentifier,article_number,pageRange,description,authkeywords,citedby_count,openaccess,freetoread,freetoreadLabel,fund_acr,fund_no,fund_sponsor,origin_ref
2-s2.0-0030354250,,,,Novel application of theory refinement to student modeling,cp,Conference Paper,Baffes P.,60092463,"SciComp Inc., Texas",Austin,United States,2,"Baffes, Paul T.;Mooney, Raymond J.",6508335676;7102791999,60092463;60092463,1996-12-01,1996,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,1,,,403-408,Theory refinement systems developed in machine learning automatically modify a knowledge base to render it consistent with a set of classified training examples. We illustrate a novel application of these techniques to the problem of constructing a student model for an intelligent tutoring system (ITS). Our approach is implemented in an ITS authoring system called ASSERT which uses theory refinement to introduce errors into an initially correct knowledge base so that it models incorrect student behavior. The efficacy of the approach has been demonstrated by evaluating a tutor developed with ASSERT with 75 students tested on a classification task covering concepts from an introductory course on the C++ programming language. The system produced reasonably accurate models and students who received feedback based on these models performed significantly better on a post test than students who received simple reteaching.,,24,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-0029736257,,,,Algorithm for multicast tree generation in networks with asymmetric links,cp,Conference Paper,Ramanathan S.,60011761,BBN Technologies,Cambridge,United States,1,"Ramanathan, S.",7102449182,60011761,1996-01-01,1996,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,1,,,337-344,"We formulate the problem of multicast tree generation in asymmetric networks as one of computing a directed Steiner tree of minimal cost. We present a new polynomial-time algorithm that provides for trade-off selection, using a single parameter κ, between the tree-cost (Steiner cost) and the runtime efficiency. Using theoretical analysis, we (1) show that it is highly unlikely that there exists a polynomial-time algorithm with a performance guarantee of constant times optimum cost, (2) introduce metrics for measuring the asymmetry of graphs, and (3) show that the worst-case cost of the tree produced by our algorithm is bounded in proportion to the graph asymmetry for two of the metrics. For a class of graphs whose asymmetry is upper bounded by a constant, this gives constant times optimum performance guarantee and is significant in light of (1). We also show that three well-known algorithms for (undirected) Steiner trees are but particular cases of our algorithm. Our experimental study shows that operating at a low κ gives nearly best possible average tree cost while maintaining acceptable runtime efficiency.",,13,0,,,,undefined,,INFOCOM Networking
2-s2.0-85088074507,10.1145/238721.238734,,,Automatic compiler-inserted I/O prefetching for out-of-core applications,cp,Conference Paper,Mowry T.C.,60016849,University of Toronto,Toronto,Canada,3,"Mowry, Tödd C.;Demke, Angela K.;Krieger, Orran",7003819429;57212549974;57207594975,60016849;60016849;60016849,1996-01-01,1996,"2nd USENIX Symposium on Operating Systems Design and Implementation, OSDI 1996",,21100940296,,Conference Proceeding,,,,,"Current operating systems offer poor performance when a numeric application's working set does not fit in main memory. As a result, programmers who wish to solve ""out-of-core"" problems efficiently are typically faced with the onerous task of rewriting an application to use explicit I/O operations (e.g., read/write). In this paper, we propose and evaluate a fully-automatic technique which liberates the programmer from this task, provides high performance, and requires only minimal changes to current operating systems. In our scheme, the compiler provides the crucial information on future access patterns without burdening the programmer, the operating system supports non-binding prefetch and release hints for managing I/O , and the operating system cooperates with a run-time layer to accelerate performance by adapting to dynamic behavior and minimizing prefetch overhead. This approach maintains the abstraction of unlimited virtual memory for the programmer, gives the compiler the flexibility to aggressively move prefetches back ahead of references, and gives the operating system the flexi bility to arbitrate between the competing resource demands of multiple applications. We have implemented our scheme using the SUIF compiler and the Hurricane operating system. Our experiment a l results demonstrate that our fully-automatic scheme effectively hides the I/O latency in out-ofcore versions of the entire NAS Parallel benchmark suite, thus resulting in speedups of roughly twofold for five of the eight applications, with two applications speeding up by threefold or more..",,135,0,,,,undefined,,OSDI Operating Systems
2-s2.0-85085698525,10.1145/233013.233019,,,Exploiting process lifetime distributions for dynamic load balancing,cp,Conference Paper,Harchol-Balter M.,60025038,"University of California, Berkeley",Berkeley,United States,2,"Harchol-Balter, Mor;Downey, Allen B.",6701569542;35858860300,60025038;60025038,1996-05-15,15 May 1996,SIGMETRICS 1996 - Proceedings of the 1996 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems,,21101098721,,Conference Proceeding,,,,13-24,"We measure the distribution of lifetimes for UNIX processes and propose a functional form that fits this distribution well. We use this functional form to derive a policy for preemptive migration, and then use a trace-driven simulator to compare our proposed policy with other preemptive migration policies, and with a non-preemptive load balancing strategy. We find that, contrary to previous reports, the performance benefits of preemptive migration are significantly greater than those of non-preemptive migration, even when the memory-transfer cost is high. Using a model of migration costs representative of current systems, we find that preemptive migration reduces the mean delay (queueing and migration) by 35 - 50%, compared to non-preemptive migration.",,19,1,publisherfree2read,Bronze,NSF,DMW-891 9074,National Science Foundation,SIGMETRICS Performance
2-s2.0-0028447023,10.1145/191843.191925,,,Fast Subsequence Matching in Time-Series Databases,ar,Article,Faloutsos C.,60078684,A. James Clark School of Engineering,College Park,United States,3,"Faloutsos, Christos;Ranganathan, M.;Manolopoulos, Yannis",7006005166;57515940000;54397260800,60078684;60078684;60078684,1994-05-24,24 May 1994,ACM SIGMOD Record,01635808,13622,,Journal,23,2,,419-429,"We present an efficient indexing method to locate 1-dimensional subsequences within a collection of sequences, such that the subsequences match a given 1994 pattern within a specified tolerance. The idea is to map each data sequences into a small set of multidimensional rectangles in feature space. Then, these rectangles can be readily indexed using traditional spatial access methods, like the R*-tree [9]. In more detail, we use a sliding window over the data sequence and extract its features; the result is a trail in feature space. We propose an efficient and effective algorithm to divide such trails into sub-trails, which are subsequently represented by their Minimum Bounding Rectangles (MBRs). We also examine queries of varying lengths, and we show how to handle each case efficiently. We implemented our method and carried out experiments on synthetic and real data (stock price movements). We compared the method to sequential scanning, which is the only obvious competitor. The results were excellent: our method accelerated the search time from 3 times up to 100 times. © 1994, ACM. All rights reserved.",,1472,1,repositoryam,Green,,undefined,,SIGMOD Databases
2-s2.0-0030157475,10.1145/235968.233333,,,Implementing Data Cubes Efficiently,ar,Article,Harinarayan V.,60012708,Stanford University,Stanford,United States,3,"Harinarayan, Venky;Rajaraman, Anand;Ullman, Jeffrey D.",6506991255;7003282591;7004490091,60012708;60012708;60012708,1996-01-01,June 1996,SIGMOD Record (ACM Special Interest Group on Management of Data),01635808,13622,,Journal,25,2,,205-216,"Decision support applications involve complex queries on very large databases. Since response times should be small, query optimization is critical. Users typically view the data as multidimensional data cubes. Each cell of the data cube is a view consisting of an aggregation of interest, like total sales. The values of many of these cells are dependent on the values of other cells in the data cube. A common and powerful query optimization technique is to materialize some or all of these cells rather than compute them from raw data each time. Commercial systems differ mainly in their approach to materializing the data cube. In this paper, we investigate the issue of which cells (views) to materialize when it is too expensive to materialize all views. A lattice framework is used to express dependencies among views. We present greedy algorithms that work off this lattice and determine a good set of views to materialize. The greedy algorithm performs within a small constant factor of optimal under a variety of models. We then consider the most common case of the hypercube lattice and examine the choice of materialized views for hypercubes in detail, giving some good tradeoffs between the space used and the average time to answer a query.",,990,0,,,,undefined,,SIGMOD Databases
2-s2.0-0030386118,,,,Indigo: a local propagation algorithm for inequality constraints,cp,Conference Paper,Borning A.,60015481,University of Washington,Seattle,United States,3,"Borning, Alan;Anderson, Richard;Freeman-Benson, Bjorn",6603681982;7406489612;6603208634,60015481;60015481;60015481,1996-12-01,1996,UIST (User Interface Software and Technology): Proceedings of the ACM Symposium,,82223,,Conference Proceeding,,,,129-136,"Inequality constraints are useful for specifying various aspects of user interfaces, such as constraints that one window is to the left of another, or that an object is contained within a rectangle. However, current local propagation constraint solvers can't handle inequality constraints. We present Indigo, an efficient local propagation algorithm for satisfying acyclic constraint hierarchies, including inequality constraints.",,25,0,,,,undefined,,UIST User Interface
2-s2.0-0030352389,,,,"Pushing the envelope: Planning, propositional logic, and stochastic search",cp,Conference Paper,Kautz H.,60014300,AT&amp;T Inc.,San Antonio,United States,2,"Kautz, Henry;Selman, Bart",7005697997;7005516690,60014300;60014300,1996-12-01,1996,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,2,,,1194-1201,"Planning is a notoriously hard combinatorial search problem. In many interesting domains, current planning algorithms fail to scale up gracefully. By combining a general, stochastic search algorithm and appropriate problem encodings based on propositional logic, we are able to solve hard planning problems many times faster than the best current planning systems. Although stochastic methods have been shown to be very effective on a wide range of scheduling problems, this is the first demonstration of its power on truly challenging classical planning instances. This work also provides a new perspective on representational issues in planning.",,531,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-0030379111,10.1145/243199.243208,,,Retrieving spoken documents by combining multiple index sources,cp,Conference Paper,Jones G.J.F.,60031101,University of Cambridge,Cambridge,United Kingdom,4,"Jones, G. J.F.;Foote, J. T.;Jones, K. Sparck;Young, S. J.",9133183900;7101965325;7404727909;7404515229,60031101;60031101;60031101;60031101,1996-01-01,1996,SIGIR Forum (ACM Special Interest Group on Information Retrieval),01635840,15745,,Conference Proceeding,,,,30-39,"This paper presents domain-independent methods of spoken document retrieval. Both a continuous-speech large vocabulary recognition system, and a phone-lattice word spotter, are used to locate index units within an experimental corpus of voice messages. Possible index terms are nearly unconstrained; terms not in a 20,000 word recognition system vocabulary can be identified by the word spotter at search time. Though either system alone can yield respectable retrieval performance, the two methods are complementary and work best in combination. Different ways of combining them are investigated, and it is shown that the best of these can increase retrieval average precision for a speaker-independent retrieval system to 85% of that achieved for full-text transcriptions of the test documents.",,71,1,publisherfree2read,Bronze,,undefined,,SIGIR Information Retrieval
2-s2.0-84884330227,10.1145/233013.233047,,,Supporting Stored Video: Reducing Rate Variability and End-to-End Resource Requirements through Optimal Smoothing,cp,Conference Paper,Salehi J.D.,60152130,Manning College of Information &amp; Computer Sciences,Amherst,United States,4,"Salehi, James D.;Zhang, Zhi Li;Kurose, James F.;Towsley, Don",7004652783;35197549700;57205296035;7101832058,60152130;60152130;60152130;60152130,1996-05-15,15 May 1996,SIGMETRICS 1996 - Proceedings of the 1996 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems,,21101098721,,Conference Proceeding,,,,222-231,"VBR compressed video is known to exhibit significant, multiple-time-scale bit rate variability. In this paper, we consider the transmission of stored video from a server to a client across a high speed network, and explore how the client buffer space can be used most effectively toward reducing the variability of the transmitted bit rate.We present two basic results. First, we present an optimal smoothing algorithm for achieving the greatest possible reduction in rate variability when transmitting stored video to a client with given buffer size. We provide a formal proof of optimality, and demonstrate the performance of the algorithm on a set of long MPEG-1 encoded video traces. Second, we evaluate the impact of optimal smoothing on the network resources needed for video transport, under two network service models: Deterministic Guaranteed service [1, 9] and Renegotiated CBR (RCBR) service [8, 7]. Under both models, we find the impact of optimal smoothing to be dramatic.",,62,0,,,NSF,F-19628-92-C-0089,National Science Foundation,SIGMETRICS Performance
2-s2.0-0030365653,,,,Verification of knowledge bases based on containment checking,cp,Conference Paper,Levy A.,60014300,AT&amp;T Inc.,San Antonio,United States,2,"Levy, Alon Y.;Rousset, Marie Christine",7401905693;7005980183,60014300;60014300,1996-12-01,1996,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,1,,,585-591,"Building complex knowledge based applications requires encoding large amounts of domain knowledge. After acquiring knowledge from domain experts, much of the effort in building a knowledge base goes into verifying that the knowledge is encoded correctly. We consider the problem of verifying hybrid knowledge bases that contain both Horn rules and a terminology in a description logic. Our approach to the verification problem is based on showing a close relationship to the problem of query containment. Our first contribution, based on this relationship, is presenting a thorough analysis of the decidability and complexity of the verification problem, for knowledge bases containing recursive rules and the interpreted predicates =, ≤, < and ≠. Second, we show that important new classes of constraints on correct inputs and outputs can be expressed in a hybrid setting, in which a description logic class hierarchy is also considered, and we present the first complete algorithm for verifying such hybrid knowledge bases.",,5,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-0031366907,,,,Practical algorithm for finding optimal triangulations,cp,Conference Paper,Shoikhet K.,60022403,Technion - Israel Institute of Technology,Haifa,Israel,2,"Shoikhet, Kirill;Geiger, Dan",6507589642;7101746213,60022403;60022403,1997-12-01,1997,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,,,,185-190,An algorithm called QUICK TREE is developed for finding a triangulation T of a given undirected graph G such that the size of T's maximal clique is minimum and such that no other triangulation of G is a subgraph of T. We have tested QUICKTREE on graphs of up to 100 nodes for which the maximum clique in an optimal triangulation is of size 11. This is the first algorithm that can optimally triangulate graphs of such size in a reasonable time frame. This algorithm is useful for constraint satisfaction problems and for Bayesian inference through the clique tree inference algorithm.,,53,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-85101511266,,,,Analysis and Visualization of Classifier Performance: Comparison under Imprecise Class and Cost Distributions,cp,Conference Paper,Provost F.,60013155,Verizon Communications,New York,United States,2,"Provost, Foster;Fawcett, Tom",7004026629;7006446454,60013155;60013155,1997-01-01,1997,"Proceedings - 3rd International Conference on Knowledge Discovery and Data Mining, KDD 1997",,21101179280,,Conference Proceeding,,,,43-48,"Applications of inductive learning algorithms to real-world data mining problems have shown repeatedly that using accuracy to compare classifiers is not adequate because the underlying assumptions rarely hold. We present a method for the comparison of classifier performance that is robust to imprecise class distributions and misclassification costs. The ROC convex hull method combines techniques from ROC analysis, decision analysis and computational geometry, and adapts them to the particulars of analyzing learned classifiers. The method is efficient and incremental, minimizes the management of classifier performance data, and allows for clear visual comparisons and sensitivity analyses.",,551,0,,,,undefined,,KDD Data Mining
2-s2.0-0043159619,,,,Applications of the situation calculus to formalizing control and strategic information: The prolog cut operator,cp,Conference Paper,Lin F.,60008592,Hong Kong University of Science and Technology,Hong Kong,Hong Kong,1,"Lin, Fangzhen",7402777607,60008592,1997-12-01,1997,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2,,,1412-1418,"We argue that the situation calculus is a natural formalism for representing and reasoning about control and strategic information. As a case study, in this paper we provide a situation calculus semantics for the Prolog cut operator, the central search control operator in Prolog. We show that our semantics is well-behaved when the programs are properly stratified. We also show that according to this semantics, the conventional implementation of the negation-as-failure operator using cut is provably correct with respect to the stable model semantics.",,6,0,,,,DAG96/97,,IJCAI Artificial Intelligence
2-s2.0-0031380188,,,,Building concept representations from reusable components,cp,Conference Paper,Clark P.,60030821,Boeing Corporation,Chicago,United States,2,"Clark, Peter;Porter, Bruce",7402579556;7201565374,60030821;60030821,1997-12-01,1997,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,,,,369-376,"Our goal is to build knowledge-based systems capable of answering a wide variety of questions, including questions that are unanticipated when the knowledge base is built. For systems to achieve this level of competence and generality, they require the ability to dynamically construct new concept representations, and to do so in response to the questions and tasks posed to them. Our approach to meeting this requirement is to build knowledge bases of generalized, representational components, and to develop methods for automatically composing components on demand. This work extends the normal inheritance approach used in frame-based systems, and imports ideas from several different areas of AI, in particular compositional modeling, terminological reasoning, and ontological engineering. The contribution of this work is a novel integration of these methods that improves the efficiency of building knowledge bases and the robustness of using them.",,41,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-0031270220,10.1145/265924.265925,,,Continuous Profiling: Where Have All the Cycles Gone?,ar,Article,Anderson J.M.,60076047;60020536,Adobe Inc.;Hewlett-Packard Inc.,San Jose;Palo Alto,United States;United States,10,"Anderson, Jennifer M.;Berc, Lance M.;Dean, Jeffrey;Ghemawat, Sanjay;Henzinger, Monika R.;Leung, Shun Tak A.;Sites, Richard L.;Vandevoorde, Mark T.;Waldspurger, Carl A.;Weihl, William E.",55497545500;6505980232;16427311000;6507434941;55910682000;7202044829;57212823650;6602229206;6602227147;35567718400,60020536;60020536;60020536;60020536;60020536;60020536;60076047;60020536;60020536;60020536,1997-01-01,November 1997,ACM Transactions on Computer Systems,07342071,12213,,Journal,15,4,,357-390,"This article describes the Digital Continuous Profiling Infrastructure, a sampling-based profiling system designed to run continuously on production systems. The system supports multiprocessors, works on unmodified executables, and collects profiles for entire systems, including user programs, shared libraries, and the operating system kernel. Samples are collected at a high rate (over 5200 samples/sec. per 333MHz processor), yet with low overhead (1-3% slowdown for most workloads). Analysis tools supplied with the profiling system use the sample data to produce a precise and accurate accounting, down to the level of pipeline stalls incurred by individual instructions, of where time is being spent. When instructions incur stalls, the tools identify possible reasons, such as cache misses, branch mispredictions, and functional unit contention. The fine-grained instruction-level analysis guides users and automated optimizers to the causes of performance problems and provides important insights for fixing them.",C.4 [Computer Systems Organization]: Performance of Systems | D.2.2 [Software Engineering]: Tools and Techniques - profiling tools | D.2.6 [Programming Languages]: Programming Environments - performance monitoring | D.4 [Operating Systems]: General,174,1,publisherfree2read,Bronze,,undefined,,SOSP Operating Systems
2-s2.0-0031269854,10.1145/265924.265930,,,Disco: Running Commodity Operating Systems on Scalable Multiprocessors,ar,Article,Bugnion E.,60012708,Stanford University,Stanford,United States,4,"Bugnion, Edouard;Devine, Scott;Govil, Kinshuk;Rosenblum, Mendel",6602775973;35957786100;7004115970;7202183719,60012708;60012708;60012708;60012708,1997-01-01,November 1997,ACM Transactions on Computer Systems,07342071,12213,,Journal,15,4,,412-447,"In this article we examine the problem of extending modern operating systems to run efficiently on large-scale shared-memory multiprocessors without a large implementation effort. Our approach brings back an idea popular in the 1970s: virtual machine monitors. We use virtual machines to run multiple commodity operating systems on a scalable multiprocessor. This solution addresses many of the challenges facing the system software for these machines. We demonstrate our approach with a prototype called Disco that runs multiple copies of Silicon Graphics' IRIX operating system on a multiprocessor. Our experience shows that the overheads of the monitor are small and that the approach provides scalability as well as the ability to deal with the nonuniform memory access time of these systems. To reduce the memory overheads associated with running multiple operating systems, virtual machines transparently share major data structures such as the program code and the file system buffer cache. We use the distributed-system support of modern operating systems to export a partial single system image to the users. The overall solution achieves most of the benefits of operating systems customized for scalable multiprocessors, yet it can be achieved with a significantly smaller implementation effort.",C.1.2 [Computer Systems Organization]: Multiple Data Stream Architectures -parallel processors | D.4.7 [Software]: Operating Systems - organization and design | Design | Experimentation | Performance | Scalable multiprocessors | Virtual machines,164,1,publisherfree2read,Bronze,,undefined,,SOSP Operating Systems
2-s2.0-0031272525,10.1145/265924.265927,,,Eraser: A Dynamic Data Race Detector for Multithreaded Programs,ar,Article,Savage S.,60028661;60025038;60020536,"UW College of Engineering;University of California, Berkeley;Hewlett-Packard Inc.",Seattle;Berkeley;Palo Alto,United States;United States;United States,5,"Savage, Stefan;Burrows, Michael;Nelson, Greg;Sobalvarro, Patrick;Anderson, Thomas",7103218472;7103139604;57211183192;6506489883;35560665700,60028661;60020536;60020536;60020536;60025038-60028661,1997-01-01,November 1997,ACM Transactions on Computer Systems,07342071,12213,,Journal,15,4,,391-411,"Multithreaded programming is difficult and error prone. It is easy to make a mistake in synchronization that produces a data race, yet it can be extremely hard to locate this mistake during debugging. This article describes a new tool, called Eraser, for dynamically detecting data races in lock-based multithreaded programs. Eraser uses binary rewriting techniques to monitor every shared-memory reference and verify that consistent locking behavior is observed. We present several case studies, including undergraduate coursework and a multithreaded Web search engine, that demonstrate the effectiveness of this approach.",D.1.3 [Programming Techniques]: Concurrent Programming - parallel programming | D.2.5 [Software Engineering]: Testing and Debugging - debugging aids | D.4.1 [Operating Systems]: Process Management -concurrency | Deadlock | Monitors | Tracing,1007,1,repositoryam,Green,,undefined,,SOSP Operating Systems
2-s2.0-0031358372,,,,Fast context switching in real-time propositional reasoning,cp,Conference Paper,Pandurang Nayak P.,60004179,NASA Ames Research Center,Moffett Field,United States,2,"Pandurang Nayak, P.;Williams, Brian C.",6507804145;7404502203,60004179;60004179,1997-12-01,1997,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,,,,50-56,"The trend to increasingly capable and affordable control processors has generated an explosion of embedded real-time gadgets that serve almost every function imaginable. The daunting task of programming these gadgets is greatly alleviated with real-time deductive engines that perform all execution and monitoring functions from a single core model. Fast response times are achieved using an incremental propositional deductive database (an LTMS). Ideally the cost of an LTMS's incremental update should be linear in the number of labels that change between successive contexts. Unfortunately an LTMS can expend a significant percentage of its time working on labels that remain constant between contexts. This is caused by the LTMS's conservative approach: a context switch first removes all consequences of deleted clauses, whether or not those consequences hold in the new context. This paper presents a more aggressive incremental TMS, called the ITMS, that avoids processing a significant number of these consequences that are unchanged. Our empirical evaluation for spacecraft control shows that the overhead of processing unchanged consequences can be reduced by a factor of seven.",,18,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-0031168920,10.1145/253262.253263,,,Fast Parallel Similarity Search in Multimedia Databases,ar,Article,Berchtold S.,,,,,5,"Berchtold, Stefan;Böhm, Christian;Braunmüller, Bernhard;Keim, Daniel A.;Kriegel, Hans Peter",55927089600;57960334300;6506360065;34769953100;7005718994,,1997-01-01,June 1997,SIGMOD Record (ACM Special Interest Group on Management of Data),01635808,13622,,Journal,26,2,,1-12,"Most similarity search techniques map the data objects into some high-dimensional feature space. The similarity search then corresponds to a nearest-neighbor search in the feature space which is computationally very intensive. In this paper, we present a new parallel method for fast nearest-neighbor search in high-dimensional feature spaces. The core problem of designing a parallel nearest-neighbor algorithm is to find an adequate distribution of the data onto the disks. Unfortunately, the known declustering methods do not perform well for high-dimensional nearest-neighbor search. In contrast, our method has been optimized based on the special properties of high-dimensional spaces and therefore provides a near-optimal distribution of the data items among the disks. The basic idea of our data declustering technique is to assign the buckets corresponding to different quadrants of the data space to different disks. We show that our technique - in contrast to other declustering methods - guarantees that all buckets corresponding to neighboring quadrants are assigned to different disks. We evaluate our method using large amounts of real data (up to 40 MBytes) and compare it with the best known data declustering method, the Hilbert curve. Our experiments show that our method provides an almost linear speed-up and a constant scale-up. Additionally, it outperforms the Hilbert approach by a factor of up to 5.",,125,1,repositoryam,Green,,undefined,,SIGMOD Databases
2-s2.0-0030651099,10.1145/278459.258537,,,"Feature selection, perceptron learning, and a usability case study for text categorization",ar,Article,Ng H.T.,60078606;60003196,"Ministry of Defence, Government of Singapore;DSO National Laboratories",Singapore City;Singapore City,Singapore;Singapore,3,"Ng, Hwee Tou;Goh, Wei Boon;Low, Kok Leong",47061923200;7005651406;7102180140,60003196;60078606;60078606,1997-01-01,1997,SIGIR Forum (ACM Special Interest Group on Information Retrieval),01635840,15745,,Journal,31,1 SPEC. ISS.,,67-73,"In this paper, we describe an automated learning approach to text categorization based on perceptron learning and a new feature selection metric, called correlation coefficient. Our approach has been tested on the standard Reuters text categorization collection. Empirical results indicate that our approach outperforms the best published results on this Reuters collection. In particular, our new feature selection method yields considerable improvement. We also investigate the usability of our automated learning approach by actually developing a system that categorizes texts into a tree of categories. We compare the accuracy of our learning approach to a rule-based, expert system approach that uses a text categorization shell built by Carnegie Group. Although our automated learning approach still gives a lower accuracy, by appropriately incorporating a set of manually chosen words to use as features, the combined, semi-automated approach yields accuracy close to the rule-based approach. Copyright 1997 ACM.",,361,0,,,,undefined,,SIGIR Information Retrieval
2-s2.0-84994097468,,,,Integrating reliable memory in databases,cp,Conference Paper,Ng W.T.,60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,2,"Ng, Wee Teck;Chen, Peter M.",7401613463;7408356226,60025778;60025778,1997-01-01,1997,"Proceedings of the 23rd International Conference on Very Large Databases, VLDB 1997",,21100784255,,Conference Proceeding,,,,76-85,"Recent results in the Rio project at the University of Michigan show that it is possible to create an area of main memory that is as safe as disk from operating system crashes. This paper explores how to integrate the reliable memory provided by the Rio file cache into a database system. We pro pose three designs for integrating reliable memory into databases: non-persistent database buffer cache, persistent database buffer cache, and per sistent database buffer cache with protection. Non-persistent buffer caches use an I/O interface to reliable memory and require the fewest modifications to existing databases. However, they waste memory capacity and bandwidth due to double buffering. Persistent buffer caches use a memory interface to reliable memory by mapping it into the database address space. This places reliable memory under complete database control and eliminates double buffering, but it may expose the buffer cache to database errors. Our third design reduces this exposure by write protecting the buffer pages. Extensive fault tests show that mapping reliable memory into the data base address space does not significantly hurt reliability. This is because wild stores rarely touch dirty, committed pages written by previous transactions. As a result, we believe that data bases should use a memory interface to reliable memory.",,17,0,,,,undefined,,VLDB Databases
2-s2.0-84880696541,,,,Object identification in a Bayesian context,cp,Conference Paper,Huang T.,60025038,"University of California, Berkeley",Berkeley,United States,2,"Huang, Timothy;Russell, Stuart",7404962745;7401538237,60025038;60025038,1997-12-01,1997,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2,,,1276-1282,"Object identification - the task of deciding that two observed objects are in fact one and the same object - is a fundamental requirement for any situated agent that reasons about individuals. Object identity, as represented by the equality operator between two terms in predicate calculus, is essentially a first-order concept. Raw sensory observations, on the other hand, are essentially propositional - especially when formulated as evidence in standard probability theory. This paper describes patterns of reasoning that allow identity sentences to be grounded in sensory observations, thereby bridging the gap. We begin by defining a physical event space over which probabilities are defined. We then introduce an identity criterion, which selects those events that correspond to identity between observed objects. From this, we are able to compute the probability that any two objects are the same, given a stream of observations of many objects. We show that the appearance probability, which defines how an object can be expected to appear at subsequent observations given its current appearance, is a natural model for this type of reasoning. We apply the theory to the task of recognizing cars observed by cameras at widely separated sites in a freeway network, with new heuristics to handle the inevitable complexity of matching large numbers of objects and with online learning of appearance probability models. Despite extremely noisy observations, we are able to achieve high levels of performance.",,143,0,,,ONR,NOO014-97-1-0941,Office of Naval Research,IJCAI Artificial Intelligence
2-s2.0-0030642883,,,,On the complexity of database queries,cp,Conference Paper,Papadimitriou C.,60025038,"University of California, Berkeley",Berkeley,United States,2,"Papadimitriou, Christos H.;Yannakakis, Mihalis",35597590700;35560952800,60025038;60025038,1997-01-01,1997,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems - PODS,,81931,,Conference Proceeding,,,,12-19,"We revisit the issue of the complexity of database queries, in the light of the recent parametric refinement of complexity theory. We show that, if the query size (or the number of variables in the query) is considered as a parameter, then the relational calculus and its fragments (conjunctive queries, positive queries) are classified at appropriate levels of the so-called W hierarchy of Downey and Fellows. These results strongly suggest that the query size is inherently in the exponent of the data complexity of any query evaluation algorithm, with the implication becoming stronger as the expressibility of the query language increases. For recursive languages (fixpoint logic, Datalog) this is provably the case. On the positive side, we show that this exponential dependence can be avoided for the extension of acyclic queries with ≠ (but not <) inequalities.",,55,0,,,,undefined,,PODS Databases
2-s2.0-0031366914,,,,Statistical parsing with a context-free grammar and word statistics,cp,Conference Paper,Charniak E.,60011460,Brown University,Providence,United States,1,"Charniak, Eugene",6604061532,60011460,1997-12-01,1997,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,,,,598-603,"We describe a parsing system based upon a language model for English that is, in turn, based upon assigning probabilities to possible parses for a sentence. This model is used in a parsing system by finding the parse for the sentence with the highest probability. This system outperforms previous schemes. As this is the third in a series of parsers by different authors that are similar enough to invite detailed comparisons but different enough to give rise to different levels of performance, we also report on some experiments designed to identify what aspects of these systems best explain their relative performance.",,243,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-0032131696,10.1016/s0004-3702(98)00063-0,S0004370298000630,,Translingual information retrieval: Learning from bilingual corpora,ar,Article,Yang Y.,60136640,School of Computer Science,Pittsburgh,United States,4,"Yang, Yiming;Carbonell, Jaime G.;Brown, Ralf D.;Frederking, Robert E.",35231480000;35609950300;7406357692;7006610694,60136640;60136640;60136640;60136640,1998-01-01,August 1998,Artificial Intelligence,00043702,23675,,Journal,103,1-2,,323-345,"Translingual information retrieval (TLIR) consists of providing a query in one language and searching document collections in one or more different languages. This paper introduces new TLIR methods and reports on comparative TLIR experiments with these new methods and with previously reported ones in a realistic setting. Methods fall into two categories: query translation and statistical-IR approaches establishing translingual associations. The results show that using bilingual corpora for automated extraction of term equivalences in context outperforms dictionary-based methods. Translingual versions of the Generalized Vector Space Model (GVSM) and Latent Semantic Indexing (LSI) perform well, as does translingual pseudo-relevance feedback (PRF) and Example-Based Term-in-context translation (EBT). All showed relatively small performance loss between monolingual and translingual versions, ranging between 87-101% of monolingual IR performance. Query translation based on a general machine-readable bilingual dictionary -heretofore the most popular method - did not match the performance of other, more sophisticated methods. Also, the previous very high LSI results in the literature based on ""mate-finding"" were superseded by more realistic relevance-based evaluations; LSI performance proved comparable to that of other statistical corpus-based methods. © 1998 Elsevier Science B.V. All rights reserved.",Corpus-based methods | Cross-language IR | Generalized vector space model | Information retrieval | Statistical learning | Translingual IR,50,1,,,,undefined,,IJCAI Artificial Intelligence
2-s2.0-0031645234,,,,Lower bound theorem for indexing schemes and its application to multidimensional range queries,cp,Conference Paper,Samoladas V.,60013372,The University of Texas at Austin,Austin,United States,2,"Samoladas, Vasilis;Miranker, Daniel P.",22434227900;6603742192,60013372;60013372,1998-01-01,1998,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,44-51,"Indexing schemes were proposed by Hellerstein, Koutsoupias and Papadimitriou to model data indexing on external memory. Using indexing schemes, the complexity of indexing is quantified by two parameters: storage redundancy and access overhead. There is a tradeoff between these two parameters, in the sense that for some problems it is not possible for both of these to be low. In this paper we derive a lower-bounds theorem for arbitrary indexing schemes. We apply our theorem to the particular problem of d-dimensional range queries. We first resolve the open problem of [7] for a tight lower bound for 2-dimensional range queries and extend our lower bound to d-dimensional range queries. We then show, how, the construction in our lower-bounds proof may be exploited to derive indexing schemes for d-dimensional range queries, whose asymptotic complexity matches our lower bounds.",,22,0,,,,undefined,,PODS Databases
2-s2.0-84953783005,10.1145/290941.290948,,,A Theory of Term Weighting Based on Exploratory Data Analysis,cp,Conference Paper,Greiff W.R.,60152130,Manning College of Information &amp; Computer Sciences,Amherst,United States,1,"Greiff, Warren R.",6603118355,60152130,1998-08-01,1 August 1998,SIGIR 1998 - Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,,21101164806,,Conference Proceeding,,,,11-19,"Techniques of exploratory data analysis are used to study the weight of evidence that the occurrence of a query term provides in support of the hypothesis that a document is relevant to an information need. In particular, the relationship between the document frequency and the weight of evidence is investigated. A correlation between document frequency normalized by collection size and the mutual information between relevance and term occurrence is uncovered. This correlation is found to be robust across a variety of query sets and document collections. Based on this relationship, a theoretical explanation of the efficacy of inverse document frequency for term weighting is developed which differs in both style and content from theories previously put forth. The theory predicts that a ""flattening""of idf at both low and high frequency should result in improved retrieval performance. This altered idf formulation is tested on all TREC query sets. Retrieval results corroborate the prediction of improved retrieval performance. In conclusion, we argue that exploratory data analysis can be a valuable tool for research whose goal is the development of an explanatory theory of information retrieval.",,3,1,publisherfree2read,Bronze,NSF,D468,National Science Foundation,SIGIR Information Retrieval
2-s2.0-0031645255,,,,Acceleration methods for numeric CSPs,cp,Conference Paper,Lebbah Y.,60110235,IMT Atlantique,Nantes,France,2,"Lebbah, Yahia;Lhomme, Olivier",8842159400;55893637000,60110235;60110235,1998-01-01,1998,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,,,,19-24,"This paper introduces a new way of accelerating the convergence of numeric CSP filtering algorithms, through the use of extrapolation methods. Extrapolation methods are used in numerical analysis to accelerate the convergence of real number sequences. We will show how to use them for solving numeric CSPs, leading to drastic improvement in efficiency.",,4,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-0031648634,,,,Effective bandwidths in wireless networks with multiuser receivers,cp,Conference Paper,Tse D.,60025038,"University of California, Berkeley",Berkeley,United States,2,"Tse, David;Hanly, Stephen",7101916524;7003858493,60025038;60025038,1998-01-01,1998,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,1,,,35-42,"To meet the increasing capacity demand on wireless networks, there have been intense efforts in the past decade on developing multi-user receiver structures which mitigate the interference between users in spread-spectrum and antenna array systems. While much of the research is performed at the physical layer, the capacity of networks with multi-user receivers and the associated resource allocation problems are less well-understood. In this paper, we show that under some conditions, the capacity of a single cell for several important receivers can be very simply characterized via a notion of effective bandwidth: the QoS requirements of all the users can be met if and only if the sum of the effective bandwidths of the users is less than the total number of degrees of freedom in the system. The number of degrees of freedom is the processing gain in a spread-spectrum system and the number of antenna elements in an antenna array. The effective bandwidth of a user depends only on its own QoS requirement, expressed in terms of the desired signal-to-interference ratio. It is hoped that such an abstraction of resource requirement will help in bridging the resource allocation problems at the networking layer and multi-user techniques at the physical layer.",,13,0,,,,undefined,,INFOCOM Networking
2-s2.0-0032094072,10.1145/276305.276345,,,Efficient transparent application recovery in client-server information systems,ar,Article,Lomet D.,60021726,Microsoft Research,Redmond,United States,2,"Lomet, David;Weikum, Gerhard",7004130161;56270327600,60021726;60021726,1998-01-01,June 1998,SIGMOD Record,01635808,13622,,Journal,27,2,,460-471,"Database systems recover persistent data, providing high database availability. However, database applications, typically residing on client or ""middle-tier"" application-server machines, may lose work because of a server failure. This prevents the masking of server failures from the human user and substantially degrades application availability. This paper aims to enable high application availability with an integrated method for database server recovery and transparent application recovery in a client-server system. The approach, based on application message logging, is similar to earlier work on distributed system fault tolerance. However, we exploit advanced database logging and recovery techniques and request/reply messaging properties to significantly improve efficiency. Forced log I/Os, frequently required by other methods, are usually avoided. Restart time, for both failed server and failed client, is reduced by checkpointing and log truncation. Our method ensures that a server can recover independently of clients. A client may reduce logging overhead in return for dependency on server availability during client restart. © 1998 ACM.",,36,0,,,,undefined,,SIGMOD Databases
2-s2.0-0031630373,10.1145/275487.275489,,,Expressiveness of structured document query languages based on attribute grammars,cp,Conference Paper,Neven F.,60010413,Universiteit Hasselt,Hasselt,Belgium,2,"Neven, Frank;Van den Bussche, Jan",6701415938;7004243631,60010413;60010413,1998-01-01,1998,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,11-17,"Structured document databases can be naturally viewed as derivation trees of a context-free grammar. Under this view, the classical formalism of attribute grammars becomes a formalism for structured document query languages. From this perspective, we study the expressive power of BAGs: Boolean-valued attribute grammars with propositional logic formulas as semantic rules, and RAGs: relation-valued attribute grammars with first-order logic formulas as semantic rules. BAGs can express only unary queries; RAGs can express queries of any arity. We first show that the (unary) queries expressible by BAGs are precisely those definable in monadic second-order logic. We then show that the queries expressible by RAGs are precisely those definable by first-order inductions of linear depth, or, equivalently, those computable in linear time on a parallel machine with polynomially many processors. We finally show that RAGs are more powerful than monadic second-order logic for queries of any arity.",,18,0,repositoryam,Green,,undefined,,PODS Databases
2-s2.0-0032094477,10.1145/276305.276335,,,Integrating association rule mining with relational database systems: Alternatives and implications,ar,Article,Sarawagi S.,60154244;60009253,Herbert Wertheim College of Engineering;IBM Research - Almaden,Gainesville;San Jose,United States;United States,3,"Sarawagi, Sunita;Thomas, Shiby;Agrawal, Rakesh",55968663300;8899662800;7201475122,60009253;60009253-60154244;60009253,1998-01-01,June 1998,SIGMOD Record,01635808,13622,,Journal,27,2,,343-354,"Data mining on large data warehouses is becoming increasingly important. In support of this trend, we consider a spectrum of architectural alternatives for coupling mining with database systems. These alternatives include: loose-coupling through a SQL cursor interface; encapsulation of a mining algorithm in a stored procedure; caching the data to a file system on-the-fly and mining; tight-coupling using primarily user-defined functions; and SQL implementations for processing in the DBMS. We comprehensively study the option of expressing the mining algorithm in the form of SQL queries using Association rule mining as a case in point. We consider four options in SQL-92 and six options in SQL enhanced with object-relational extensions (SQL-OR). Our evaluation of the different architectural alternatives shows that from a performance perspective, the Cache-Mine option is superior, although the performance of the SQL-OR option is within a factor of two. Both the Cache-Mine and the SQL-OR approaches incur a higher storage penalty than the loose-coupling approach which performance-wise is a factor of 3 to 4 worse than Cache-Mine. The SQL-92 implementations were too slow to qualify as a competitive option. We also compare these alternatives on the basis of qualitative factors like automatic parallelization, development ease, portability and inter-operability. © 1998 ACM.",,236,1,publisherfree2read,Bronze,,undefined,,SIGMOD Databases
2-s2.0-0031625420,,,,Learning evaluation functions for global optimization and Boolean satisfiability,cp,Conference Paper,Boyan J.,60027950,Carnegie Mellon University,Pittsburgh,United States,2,"Boyan, Justin A.;Moore, Andrew W.",6602621170;55860696200,60027950;60027950,1998-01-01,1998,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,,,,3-10,"This paper describes STAGE, a learning approach to automatically improving search performance on optimization problems. STAGE learns an evaluation function which predicts the outcome of a local search algorithm, such as hillclimbing or WALKSAT, as a function of state features along its search trajectories. The learned evaluation function is used to bias future search trajectories toward better optima. We present positive results on six large-scale optimization domains.",,45,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-85166350822,,,,Occam's Two Razors: The Sharp and the Blunt,cp,Conference Paper,Domingos P.,60004956,Instituto Superior Técnico,Lisbon,Portugal,1,"Domingos, Pedro",7003565655,60004956,1998-01-01,1998,"Proceedings of the 4th International Conference on Knowledge Discovery and Data Mining, KDD 1998",,21101169004,,Conference Proceeding,,,,37-43,"Occam's razor has been the subject of much controversy. This paper argues that this is partly because it has been interpreted in two quite different ways, the first of which (simplicity is a goal in itself) is essentially correct, while the second (simplicity leads to greater accuracy) is not. The paper reviews the large variety of theoretical arguments and empirical evidence for and against the ""second razor,"" and concludes that the balance is strongly against it. In particular, it builds on the case of (Schaffer, 1993) and (Webb, 1996) by considering additional theoretical arguments and recent empirical evidence that the second razor fails in most domains. A version of the first razor more appropriate to K D D is proposed, and we argue that continuing to apply the second razor risks causing significant opportunities to be missed.",,62,0,,,,undefined,,KDD Data Mining
2-s2.0-0032310190,,,,Self-calibration and metric reconstruction in spite of varying and unknown internal camera parameters,cp,Conference Paper,Pollefeys M.,60025063,KU Leuven,Leuven,Belgium,3,"Pollefeys, Marc;Koch, Reinhard;Van Gool, Luc",7004040532;7403189785;22735702300,60025063;60025063;60025063,1998-12-01,1998,Proceedings of the IEEE International Conference on Computer Vision,,110561,,Conference Proceeding,,,,90-95,In this paper the feasibility of self-calibration in the presence of varying internal camera parameters is under investigation. A self-calibration method is presented which efficiently deals with all kinds of constraints on the internal camera parameters. Within this framework a practical method is proposed which can retrieve metric reconstruction from image sequences obtained with uncalibrated zooming/focusing cameras. The feasibility of the approach is illustrated on real and synthetic examples.,,386,0,,,,undefined,,ICCV Computer Vision
2-s2.0-20444402327,10.1016/s0169-7552(98)00119-6,S0169755298001196,,The Interactive Multimedia Jukebox (IMJ): A new paradigm for the on-demand delivery of audio/video,ar,Article,Almeroth K.C.,60142701,UC Santa Barbara College of Engineering,Santa Barbara,United States,1,"Almeroth, Kevin C.",7004637915,60142701,1998-01-01,1998,Computer Networks,13891286,26811,,Journal,30,1-7,,431-441,"Straightforward, one-way delivery of video programming through television sets has existed for many decades. In the 1980s, new services like Pay-Per-View and Video-on-Demand were touted as the ""killer application"" for next-generation Internet and TV services. However, the hype has quickly died away leaving only hard technical problems and costly systems. As an alternative, and what we propose, is a new paradigm offering flexibility in how programs are requested and scheduled for playout, ranging from complete viewer control (true VoD), to complete service provider control (traditional broadcast or cable TV). In this paper, we describe our proposed jukebox paradigm and relate it to other on-demand paradigms. Our new paradigm presents some challenges of its own, including how to best schedule viewer requests, how to provide VCR-style interactive functions, and how to track viewer usage patterns. In addition to addressing these issues we also present our implementation of a jukebox-based service called the Interactive Multimedia Jukebox (IMJ). The IMJ provides scheduling via the World Wide Web (WWW) and content delivery via the Multicast Backbone (MBone). We discuss the challenges of building a functioning system and our ongoing efforts to improve the jukebox paradigm. © 1998 Published by Elsevier Science B.V. All rights reserved.",MBone | Multicast | Video-on-demand | WWW,8,0,,,,undefined,,WWW World Wide Web
2-s2.0-0031636472,,,,Interactive museum tour-guide robot,cp,Conference Paper,Burgard W.,60007493,Universität Bonn,Bonn,Germany,8,"Burgard, Wolfram;Cremers, Armin B.;Fox, Dieter;Haehnel, Dirk;Lakemeyer, Gerhard;Schulz, Dirk;Steiner, Walter;Thrun, Sebastian",7003610380;7006727752;7402074129;6602520023;6603571701;7201870956;8734465600;7005996507,60007493;60007493;60007493;60007493;60007493;60007493;60007493;60007493,1998-01-01,1998,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,,,,11-18,"This paper describes the software architecture of an autonomous tour-guide/tutor robot. This robot was recently deployed in the `Deutsches Museum Bonn', were it guided hundreds of visitors through the museum during a six-day deployment period. The robot's control software integrates low-level probabilistic reasoning with high-level problem solving embedded in first order logic. A collection of software innovations, described in this paper, enabled the robot to navigate at high speeds through dense crowds, while reliably avoiding collisions with obstacles - some of which could not even be perceived. Also described in this paper is a user interface tailored towards non-expert users, which was essential for the robot's success in the museum. Based on these experiences, this paper argues that time is ripe for the development of AI-based commercial service robots that assist people in everyday life.",,354,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-0032597866,10.1023/A:1008140928553,,,Problem of degeneracy in structure and motion recovery from uncalibrated image sequences,ar,Article,Torr P.H.S.,60021726,Microsoft Research,Redmond,United States,3,"Torr, Philip H.S.;Fitzgibbon, Andrew W.;Zisserman, Andrew",56821543600;56355070900;7006619672,60021726;;,1999-01-01,1999,International Journal of Computer Vision,09205691,72242,,Journal,32,1,,27-44,"The aim of this work is the recovery of 3D structure and camera projection matrices for each frame of an uncalibrated image sequence. In order to achieve this, correspondences are required throughout the sequence. A significant and successful mechanism for automatically establishing these correspondences is by the use of geometric constraints arising from scene rigidity. However, problems arise with such geometry guided matching if general viewpoint and general structure are assumed whilst frames in the sequence and/or scene structure do not conform to these assumptions. Such cases are termed degenerate. In this paper we describe two important cases of degeneracy and their effects on geometry guided matching. The cases are a motion degeneracy where the camera does not translate between frames, and a structure degeneracy where the viewed scene structure is planar. The effects include the loss of correspondences due to under or over fitting of geometric models estimated from image data, leading to the failure of the tracking method. These degeneracies are not a theoretical curiosity, but commonly occur in real sequences where models are statistically estimated from image points with measurement error. We investigate two strategies for tackling such degeneracies: the first uses a statistical model selection test to identify when degeneracies occur; the second uses multiple motion models to overcome the degeneracies. The strategies are evaluated on real sequences varying in motion, scene type, and length from 13 to 120 frames.",,119,0,,,,undefined,,ICCV Computer Vision
2-s2.0-84880670016,,,,A distributed case-based reasoning application for engineering sales support,cp,Conference Paper,Watson I.,60008250;101719464,University of Salford;Western Air Ltd.,Salford;Fremantle,United Kingdom;Australia,2,"Watson, Ian;Gardingen, Dan",54973431000;6506535513,60008250;101719464,1999-12-01,1999,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,1,,,600-605,"This paper describes the implementation of a distributed case-based reasoning application that supports engineering sales staff. The application operates on the world wide web and uses the XML standard as a communications protocol between client and server side Java applets. The paper describes the distributed architecture of the application, the two case retrieval techniques used, its implementation, trial, roll-out and subsequent improvements to its architecture and retrieval techniques using introspective reasoning to improve retrieval efficiency. The benefits it has provided to the company are detailed.",,42,0,,,,undefined,,IJCAI Artificial Intelligence
2-s2.0-0033284492,,,,Theory of shape by space carving,cp,Conference Paper,Kutulakos K.N.,60027165,University of Rochester,Rochester,United States,2,"Kutulakos, Kiriakos N.;Seitz, Steven M.",6701920248;7004774929,60027165;60027165,1999-01-01,1999,Proceedings of the IEEE International Conference on Computer Vision,15505499,110561,,Conference Proceeding,1,,,307-314,"In this paper we consider the problem of computing the 3D shape of an unknown, arbitrarily-shaped scene from multiple photographs taken at known but arbitrarily-distributed viewpoints. By studying the equivalence class of all 3D shapes that reproduce the input photographs, we prove the existence of a special member of this class, the photo hull, that (1) can be computed directly from photographs of the scene, and (2) subsumes all other members of this class. We then give a probably-correct algorithm, called Space Carving, for computing this shape and present experimental results on complex real-world scenes. The approach is designed to (1) build photorealistic shapes that accurately model scene appearance from a wide range of viewpoints, and (2) account for the complex interactions between occlusion, parallax, shading, and their effects on arbitrary views of a 3D scene.",,199,0,,,,undefined,,ICCV Computer Vision
2-s2.0-0032669768,10.1109/INFCOM.1999.752159,,,Bandwidth sharing: Objectives and algorithms,cp,Conference Paper,Massoulie L.,60104081,Orange Labs,Issy-les-Moulineaux,France,2,"Massoulie, L.;Roberts, J.",6603753137;57199185875,60104081;60104081,1999-12-01,1999,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,3,,752159,1395-1403,"This paper concerns the design of distributed algorithms for sharing network bandwidth resources among contending flows. The classical fairness notion is the so-called max-min fairness; Kelly (see Europ. Trans. Telecom. vol.8 p.33-37, 1997) has previously introduced the alternative proportional fairness criterion; we introduce a third criterion, which is naturally interpreted in terms of the delays experienced by ongoing transfers. We prove that fixed size window control can achieve fair bandwidth sharing according to any of these criteria, provided scheduling at each link is performed in an appropriate manner. We next consider a distributed random scheme where each traffic source varies its sending rate randomly, based on binary feedback information from the network. We show how to select the source behaviour so as to achieve an equilibrium distribution concentrated around the considered fair rate allocations. This stochastic analysis is then used to assess the asymptotic behaviour of deterministic rate adoption procedures. © 1999 IEEE.",,279,0,,,,undefined,,INFOCOM Networking
2-s2.0-84978416965,10.1145/319151.319162,,,Cellular Disco: Resource management using virtual clusters on shared-memory multiprocessors,cp,Conference Paper,Govil K.,60141508;60010574,Stanford Engineering;Hewlett Packard Laboratories,Stanford;Palo Alto,United States;United States,4,"Govil, Kinshuk;Teodosiu, Dan;Huang, Yongqiang;Rosenblum, Mendel",7004115970;6507145017;37862620800;7202183719,60141508;60010574;60141508;60141508,1999-12-12,12 December 1999,"Proceedings of the 17th ACM Symposium on Operating Systems Principles, SOSP 1999",,21100830160,,Conference Proceeding,,,,154-169,"Despite the fact that large-scale shared-memory multiprocessors have been commercially available for several years, system software that fully utilizes all their features is still not available, mostly due to the complexity and cost of making the required changes to the operating system. A recently proposed approach, called Disco, substantially reduces this development cost by using a virtual machine monitor that leverages the existing operating system technology. In this paper we present a system called Cellular Disco that extends the Disco work to provide all the advantages of the hardware partitioning and scalable operating system approaches. We argue that Cellular Disco can achieve these benefits at only a small fraction of the development cost of modifying the operating system. Cellular Disco effectively turns a large-scale shared-memory multiprocessor into a virtual cluster that supports fault containment and heterogeneity, while avoiding operating system scalability bottlenecks. Yet at the same time, Cellular Disco preserves the benefits of a shared-memory multiprocessor by implementing dynamic, fine-grained resource sharing, and by allowing users to overcommit resources such as processors and memory. This hybrid approach requires a scalable resource manager that makes local decisions with limited information while still providing good global performance and fault containmenL In this paper we describe our experience with a Cellular Disco prototype on a 32-processor SGI Origin 2000 system. We show that the execution time penalty for this approach is low, typically within 10% of the best available commercial operating system for most workloads, and that it can manage the CPU and memory resources of the machine significantly better than the hardware partitioning approach.",,22,1,publisherfree2read,Bronze,DARPA,DABT63-94-C-0054,Defense Advanced Research Projects Agency,SOSP Operating Systems
2-s2.0-85011998214,10.1145/312624.312656,,,Cross-language information retrieval based on parallel texts and automatic mining of parallel texts from the Web,cp,Conference Paper,Nie J.Y.,60009507,University of Montreal,Montreal,Canada,4,"Nie, Jian Yun;Simard, Michel;Isabelle, Pierre;Durand, Richard",7102234213;7005681326;6508292115;57195629292,60009507;60009507;60009507;60009507,1999-08-01,1 August 1999,"Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 1999",,21100830409,,Conference Proceeding,,,,74-81,"This paper describes the use of a probabilistic translation model to cross-language IR (CLIR). The performance of this approach is compared with that using machine translation (MT). It is shown that using a probabilistic model, we are able to obtain performances close to those using an MT system. In addition, we also investigated the possibility of automatically gather parallel texts from the Web in an attempt to construct a reasonable training corpus. The result is very encouraging. We showed that in several tests, such a training corpus is as good as a manually constructed one for CLIR purposes.",Cross-language information retrieval | Probabilistic translation model | Text mining,239,0,,,,undefined,,SIGIR Information Retrieval
2-s2.0-85134330708,10.1145/304182.304215,,,DynaMat: A Dynamic View Management System for Data Warehouses,cp,Conference Paper,Kotidis Y.,60020304,"University of Maryland, College Park",College Park,United States,2,"Kotidis, Yannis;Roussopoulos, Nick",6602471641;7003496227,60020304;60020304,1999-06-01,1 June 1999,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,371-382,"Pre-computation and materialization of views with aggregate functions is a common technique in Data Warehouses. Due to the complex structure of the warehouse and the different profiles of the users who submit queries, there is need for tools that will automate the selection and management of the materialized data. In this paper we present DynaMat, a system that dynamically materializes information at multiple levels of granularity in order to match the demand (workload) but also takes into account the maintenance restrictions for the warehouse, such as down time to update the views and space availability. DynaMat unifies the view selection and the view maintenance problems under a single framework using a novel ""goodness""measure for the materialized views. DynaMat constantly monitors incoming queries and materializes the best set of views subject to the space constraints. During updates, DynaMat reconciles the current materialized view selection and refreshes the most beneficial subset of it within a given maintenance window. We compare DynaMat against a system that is given all queries in advance and the pre-computed optimal static view selection. The comparison is made based on a new metric, the Detailed Cost Savings Ratio introduced for quantifying the benefits of view materialization against incoming queries. These experiments show that DynaMat's dynamic view selection outperforms the optimal static view selection and thus, any sub-optimal static algorithm that has appeared in the literature.",,5,0,,,NASA,CG9815,National Aeronautics and Space Administration,SIGMOD Databases
2-s2.0-0033283979,10.1109/iccv.1999.790300,,,Euclidean reconstruction and reprojection up to subgroups,cp,Conference Paper,Ma Y.,60025038,"University of California, Berkeley",Berkeley,United States,4,"Ma, Yi;Soatto, Stefano;Kosecka, Jana;Sastry, Shankar",35196583100;7004080670;7003985685;56111601700,60025038;60025038;60025038;60025038,1999-01-01,1999,Proceedings of the IEEE International Conference on Computer Vision,15505499,110561,,Conference Proceeding,2,,,773-780,"The necessary and sufficient conditions for being able to estimate scene structure, motion and camera calibration from a sequence of images are very rarely satisfied in practice. What exactly can be estimated in sequences of practical importance, when such conditions are not satisfied? In this paper we give a complete answer to this question. For every camera motion that fails to meet the conditions, we give explicit formulas for the ambiguities in the reconstructed scene, motion and calibration. Such a characterization is crucial both for designing robust estimation algorithms (that do not try to recover parameters that cannot be recovered), and for generating novel views of the scene by controlling the vantage point. To this end, we characterize explicitly all the vantage points that give rise to a valid Euclidean reprojection regardless of the ambiguity in the reconstruction. We also characterize vantage points that generate views that are altogether invariant to the ambiguity. All the results are presented using simple notation that involves no tensors nor complex projective geometry, and should be accessible with basic background in linear algebra.",,13,0,repositoryam,Green,,undefined,,ICCV Computer Vision
2-s2.0-0032688729,10.1145/303976.303987,,,Exact and approximate aggregation in constraint query languages,ar,Article,Benedikt M.,60021378,Nokia Bell Labs,Murray,United States,2,"Benedikt, Michael;Libkin, Leonid",7003883643;57203256125,60021378;60021378,1999-01-01,1999,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,102-113,"We investigate the problem of how to extend constraint query languages with aggregate operators. We deal with standard relational aggregation, and also with aggregates specific to spatial data, such as volume. We study several approaches, including the addition of a new class of approximate aggregate operators which allow an error tolerance in the computation. We show how techniques based on VC-dimension can be used to give languages with approximation operators, but also show that these languages have a number of shortcomings. We then give a set of results showing that it is impossible to get constraint-based languages that admit definable aggregation operators, both for exact operators and for approximate ones. These results are quite robust, in that they show that closure under aggregation is problematic even when the class of functions permitted in constraints is expanded. This motivates a different approach to the aggregation problem. We introduce a language FO+POLY+SUM, which permits standard discrete aggregation operators to be applied to the outputs of range-restricted constraint queries. We show that this language has a number of attractive closure and expressivity properties, and that it can compute volumes of linear-constraint databases. We also show, using techniques from machine learning, that a small extension of FO+POLY+SUM can probabilistically find approximations of volumes for polynomial-constraint databases.",,11,1,publisherfree2read,Bronze,,undefined,,PODS Databases
2-s2.0-0033294474,10.1016/S1389-1286(99)00052-3,S1389128699000523,,Focused crawling: A new approach to topic-specific Web resource discovery,ar,Article,Chakrabarti S.,60027200;60014153;60009253,FX Palo Alto Laboratory;Indian Institute of Technology Bombay;IBM Research - Almaden,Palo Alto;Mumbai;San Jose,United States;India;United States,3,"Chakrabarti, Soumen;Van Den Berg, Martin;Dom, Byron",58570163200;36777128700;6701388386,60014153;60027200;60009253,1999-05-17,17 May 1999,Computer Networks,13891286,26811,,Journal,31,11,,1623-1640,"The rapid growth of the World-Wide Web poses unprecedented scaling challenges for general-purpose crawlers and search engines. In this paper we describe a new hypertext resource discovery system called a Focused Crawler. The goal of a focused crawler is to selectively seek out pages that are relevant to a pre-defined set of topics. The topics are specified not using keywords, but using exemplary documents. Rather than collecting and indexing all accessible Web documents to be able to answer all possible ad-hoc queries, a focused crawler analyzes its crawl boundary to find the links that are likely to be most relevant for the crawl, and avoids irrelevant regions of the Web. This leads to significant savings in hardware and network resources, and helps keep the crawl more up-to-date. To achieve such goal-directed crawling, we designed two hypertext mining programs that guide our crawler: a classifier that evaluates the relevance of a hypertext document with respect to the focus topics, and a distiller that identifies hypertext nodes that are great access points to many relevant pages within a few links. We report on extensive focused-crawling experiments using several topics at different levels of specificity. Focused crawling acquires relevant pages steadily while standard crawling quickly loses its way, even though they are started from the same root set. Focused crawling is robust against large perturbations in the starting set of URLs. It discovers largely overlapping sets of resources in spite of these perturbations. It is also capable of exploring out and discovering valuable resources that are dozens of links away from the start set, while carefully pruning the millions of pages that may lie within this same radius. Our anecdotes suggest that focused crawling is very effective for building high-quality collections of Web documents on specific topics, using modest desktop hardware.",,752,0,repositoryvor,Green,,undefined,,WWW World Wide Web
2-s2.0-0002943256,10.1145/332799.332895,,,IO-Lite: A unified I/O buffering and caching system,ar,Article,Pai V.S.,60148288,George R. Brown School of Engineering,Houston,United States,3,"Pai, Vivek S.;Druschel, Peter;Zwaenepoel, Willy",7101768250;6701688597;55955749000,60148288;60148288;60148288,2000-01-01,February 2000,ACM Transactions on Computer Systems,07342071,12213,,Journal,18,1,,37-66,"This article presents the design, implementation, and evaluation of IO-Lite, a unified I/O buffering and caching system for general-purpose operating systems. IO-Lite unifies all buffering and caching in the system, to the extent permitted by the hardware. In particular, it allows applications, the interprocess communication system, the file system, the file cache, and the network subsystem to safely and concurrently share a single physical copy of the data. Protection and security are maintained through a combination of access control and read-only sharing. IO-Lite eliminates all copying and multiple buffering of I/O data, and enables various cross-subsystem optimizations. Experiments with a Web server show performance improvements between 40 and 80% on real workloads as a result of IO-Lite.",Caching | D.4.4 [Operating Systems]: Communications Management | D.4.8 [Operating Systems]: Performance | I/O buffering | Management | Networking | Performance | Zero-copy,104,1,repositoryvor,Green,,undefined,,OSDI Operating Systems
2-s2.0-84968338392,,,,A Learning Approach to Shallow Parsing,cp,Conference Paper,Muñoz M.,60158506,The Grainger College of Engineering,Urbana,United States,4,"Muñoz, Marcia;Punyakanok, Vasin;Roth, Dan;Zimak, Dav",55118470500;10244902700;7401669040;55803740000,60158506;60158506;60158506;60158506,1999-01-01,1999,"Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, EMNLP 1999",,21101073936,,Conference Proceeding,,,,168-178,"A SNoW based learning approach to shallow parsing tasks is presented and studied experimentally. The approach learns to identify syntactic patterns by combining simple predictors to produce a coherent inference. Two instantiations of this approach are studied and experimental results for Noun-Phrases (NP) and Subject-Verb (SV) phrases that compare favorably with the best published results are presented. In doing that, we compare two ways of modeling the problem of learning to recognize patterns and suggest that shallow parsing patterns are better learned using open/close predictors than using inside/outside predictors.",,45,0,,,NSF,CCR-9502540,National Science Foundation,IJCAI Artificial Intelligence
2-s2.0-0036832950,10.1023/A:1017936530646,,,Technical update: Least-squares temporal difference learning,ar,Article,Boyan J.A.,60099633,ITA Software,Cambridge,United States,1,"Boyan, Justin A.",6602621170,60099633,2002-11-01,November 2002,Machine Learning,08856125,24775,,Journal,49,2-3,,233-246,"TD(λ) is a popular family of algorithms for approximate policy evaluation in large MDPs. TD(λ) works by incrementally updating the value function after each observed transition. It has two major drawbacks: it may make inefficient use of data, and it requires the user to manually tune a stepsize schedule for good performance. For the case of linear value function approximations and λ = 0, the Least-Squares TD (LSTD) algorithm of Bradtke and Barto (1996, Machine learning, 22:1-3,33-57) eliminates all stepsize parameters and improves data efficiency. This paper updates Bradtke and Barto's work in three significant ways. First, it presents a simpler derivation of the LSTD algorithm. Second, it generalizes from λ = 0 to arbitrary values of λ at the extreme of λ = 1, the resulting new algorithm is shown to be a practical, incremental formation of supervised linear regression. Third, it presents a novel and intuitive interpretation of LSTD as a model-based reinforcement learning technique.",Linear least-squares methods | Reinforcement learning | Temporal difference learning | Value function approximation,243,1,publisherfree2read,Bronze,NASA,undefined,National Aeronautics and Space Administration,ICML Machine Learning
2-s2.0-84958805788,10.1145/319151.319152,,,"Manageability, availability and performance in Porcupine: A highly scalable, cluster-based mail service",cp,Conference Paper,Saito Y.,60015481,University of Washington,Seattle,United States,3,"Saito, Yasushi;Bershad, Brian N.;Levy, Henry M.",55466440400;6701383953;7201665633,60015481;60015481;60015481,1999-12-12,12 December 1999,"Proceedings of the 17th ACM Symposium on Operating Systems Principles, SOSP 1999",,21100830160,,Conference Proceeding,,,,1-15,"This paper describes the motivation, design, and performance of Porcupine, a scalable mail server. The goal of Porcupine is to provide a highly available and scalable electronic mail service using a large cluster of commodity PCs. We designed Porcupine to be easy to manage by emphasizing dynamic load balancing, automatic configuration, and graceful degradation in the presence of failures. Key to the system's manageability, availability, and performance is that sessions, data, and underlying services are distributed homogeneously and dynamically across nodes in a cluster.",,27,0,,,NSF,EIA-9870740,National Science Foundation,SOSP Operating Systems
2-s2.0-0032596402,,,,PROVERB: the probabilistic cruciverbalist,ar,Article,Keim G.,60008724,Duke University,Durham,United States,10,"Keim, Greg A.;Shazeer, Noam M.;Littman, Michael L.;Agarwal, Sushant;Cheves, Catherine M.;Fitzgerald, Joseph;Grosland, Jason;Jiang, Fan;Pollard, Shannon;Weinmeister, Karl",6603930115;6505939767;7006510438;55452913300;8743938900;7402450884;7801476499;36866244500;7101930690;6603010161,60008724;60008724;60008724;60008724;60008724;60008724;60008724;60008724;60008724;60008724,1999-01-01,1999,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,,,,710-717,"We attacked the problem of solving crossword puzzles by computer: given a set of clues and a crossword grid, try to maximize the number of words correctly filled in. In our system, 'expert modules' specialize in solving specific types of clues, drawing on ideas from information retrieval, database search, and machine learning. Each expert module generates a (possibly empty) candidate list for each clue, and the lists are merged together and placed into the grid by a centralized solver. We used a probabilistic representation throughout the system as a common interchange language between subsystems and to drive the search for an optimal solution. PROVERB, the complete system, averages 95.3% words correct and 98.1% letters correct in under 15 minutes per puzzle on a sample of 370 puzzles taken from the New York Times and several other puzzle sources. This corresponds to missing roughly 3 words or 4 letters on a daily 15 × 15 puzzle, making PROVERB a better-than-average cruciverbalist (crossword solver).",,26,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-84905381461,10.1145/319151.319167,,,Soft timers: Efficient microsecond software timer support for network processing,cp,Conference Paper,Aron M.,60148288,George R. Brown School of Engineering,Houston,United States,2,"Aron, Mohit;Druschel, Peter",7006799191;6701688597,60148288;60148288,1999-12-12,12 December 1999,"Proceedings of the 17th ACM Symposium on Operating Systems Principles, SOSP 1999",,21100830160,,Conference Proceeding,,,,232-246,"This paper proposes and evaluates soft timers, a new operating system facility that allows the efficient scheduling of software events at a granularity down to tens of microseconds. Soft timers can be used to avoid interrupts and reduce context switches associated with network processing without sacrificing low communication delays. More specifically, soft timers enable transport protocols like TCP to efficiently perform rate-based clocking of packet transmissions. Experiments show that rate-based clocking can improve HTTP response time over connections with high bandwidth-delay products by up to 89% and that soft timers allow a server to employ rate-based clocking with little CPU overhead (2-6%) at high aggregate bandwidths. Soft timers can also be used to perform network polling, which eliminates network interrupts and increases the memory access locality of the network subsystem without sacrificing delay. Experiments show that this technique can improve the throughput of a Web server by up to 25%.",,12,0,,,NSF,ATP Grant0 03604,National Science Foundation,SOSP Operating Systems
2-s2.0-84943563498,10.1145/319151.319166,,,The Click modular router,cp,Conference Paper,Morris R.,60006320,MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge,United States,4,"Morris, Robert;Kohler, Eddie;Jannotti, John;Kaashoek, M. Frans",7404059170;9133554700;16038997700;57207515364,60006320;60006320;60006320;60006320,1999-12-12,12 December 1999,"Proceedings of the 17th ACM Symposium on Operating Systems Principles, SOSP 1999",,21100830160,,Conference Proceeding,,,,217-231,"Click is a new software architecture for building flexible and configurable routers. A Click router is assembled from packet processing modules called elements. Individual elements implement simple router functions like packet classification, queueing, scheduling, and interfacing with network devices. Complete configurations are built by connecting elements into a graph; packets flow along the graph's edges. Several features make individual elements more powerful and complex configurations easier to write, including pull processing, which models packet flow driven by transmitting interfaces, and flow-based router context, which helps an element locate other interesting elements. We demonstrate several working configurations, including an IP router and an Ethernet bridge. These configurations are modular-the IP router has 16 elements on the forwarding path-and easy to extend by adding additional elements, which we demonstrate with augmented configurations. On commodity PC hardware running Linux, the Click 1P router can forward 64-byte packets at 73,000 packets per second, just 10% slower than Linux alone.",,55,1,publisherfree2read,Bronze,DARPA,undefined,Defense Advanced Research Projects Agency,SOSP Operating Systems
2-s2.0-0032681069,10.1145/301618.301678,,,Whole program paths,ar,Article,Larus J.R.,60021726,Microsoft Research,Redmond,United States,1,"Larus, James R.",7003695813,60021726,1999-01-01,1999,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,259-269,"Whole program paths (WPP) are a new approach to capturing and representing a program's dynamic - actually executed - control flow. Unlike other path profiling techniques, which record intraprocedural or acyclic paths, WPPs produce a single, compact description of a program's entire control flow, including loop iteration and interprocedural paths. This paper explains how to collect and represent WPPs. It also shows how to use WPPs to find hot subpaths, which are the heavily executed sequences of code that should be the focus of performance tuning and compiler optimization.",,220,1,publisherfree2read,Bronze,,undefined,,PLDI Programming Languages
2-s2.0-0033699997,10.1145/335168.335210,,,Auditing Boolean attributes,cp,Conference Paper,Kleinberg J.,60007776,Cornell University,Ithaca,United States,3,"Kleinberg, Jon;Papadimitriou, Christos;Raghavan, Prabhakar",7005755823;35597590700;7006894026,60007776;60007776;60007776,2000-01-01,2000,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,86-91,"We study the problem of auditing databases which support statistical sum queries to protect the security of sensitive information; we focus on the special case in which the sensitive information is Boolean. Principles and techniques developed for the security of statistical databases in the case of continuous attributes do not apply here. We prove certain strong complexity results suggesting that there is no general efficient solution for the auditing problem in this case. We propose two efficient algorithms: The first is applicable when the sum queries are one-dimensional range queries (we prove that the problem is NP-hard even in the two-dimensional case). The second is an approximate algorithm that maintains security, although it may be too restrictive. Finally, we consider a `dual' variant, with continuous data but an aggregate function that is combinatorial in nature. Specifically, we provide algorithms for two natural definitions of the auditing condition when the aggregate function is MAX.",,52,0,,,,undefined,,PODS Databases
2-s2.0-85158130086,,,,Automatic Invention of Integer Sequences,cp,Conference Paper,Colton S.,60027272;60016418,The University of Edinburgh;University of York,Edinburgh;York,United Kingdom;United Kingdom,3,"Colton, Simon;Bundy, Alan;Walsh, Toby",24922689800;7007000097;55806690200,60027272;60027272;60016418,2000-01-01,2000,"Proceedings of the 17th National Conference on Artificial Intelligence and 12th Conference on Innovative Applications of Artificial Intelligence, AAAI 2000",,21101150669,,Conference Proceeding,,,,558-563,"We report on the application of the HR program (Colton, Bundy, & Walsh 1999) to the problem of automatically inventing integer sequences. Seventeen sequences invented by HR are interesting enough to have been accepted into the Encyclopedia of Integer Sequences (Sloane 2000) and all were supplied with interesting conjectures about their nature, also discovered by HR. By extending HR, we have enabled it to perform a two stage process of invention and investigation. This involves generating both the definition and terms of a new sequence, relating it to sequences already in the Encyclopedia and pruning the output to help identify the most surprising and interesting results.",,25,0,,,EPSRC,GR/M98012,Engineering and Physical Sciences Research Council,AAAI Artificial Intelligence
2-s2.0-84975277890,,,,"Checking system rules using system-specific, programmer-written compiler extensions",cp,Conference Paper,Engler D.,60012708,Stanford University,Stanford,United States,4,"Engler, Dawson;Chelf, Benjamin;Chou, Andy;Hallem, Seth",7006155582;7801343597;35941130500;6505998747,60012708;60012708;60012708;60012708,2000-10-22,22 October 2000,"Proceedings of the 4th Conference on Symposium on Operating System Design and Implementation, OSDI 2000",,21100830427,,Conference Proceeding,,,,,"Systems software such as OS kernels, embedded systems, and libraries must obey many rules for both correctness and performance. Common examples include ""accesses to variable A must be guarded by lock B,"" ""system calls must check user pointers for validity before using them,"" and ""message handlers should free their buffers as quickly as possible to allow greater parallelism."" Unfortunately, adherence to these rules is largely unchecked. This paper attacks this problem by showing how system implementors can use meta-level compilation (MC) to write simple, system-specific compiler extensions that automatically check their code for rule violations. By melding domain-specific knowledge with the automatic machinery of compilers, MC brings the benefits of language-level checking and optimizing to the higher, ""meta"" level of the systems implemented in these languages. This paper demonstrates the effectiveness of the MC approach by applying it to four complex, real systems: Linux, OpenBSD, the Xok exokernel, and the FLASH machine's embedded software. MC extensions found roughly 500 errors in these systems and led to numerous kernel patches. Most extensions were less than a hundred lines of code and written by implementors who had a limited understanding of the systems checked.",,378,0,,,,undefined,,OSDI Operating Systems
2-s2.0-0034449842,,,,Dynamo: A transparent dynamic optimization system,cp,Conference Paper,Bala V.,100663769,InCert Corporation,Cambridge (ex Galt),United States,3,"Bala, V.;Duesterwald, E.;Banerjia, S.",56344010300;6602576903;6603130242,100663769;100663769;100663769,2000-12-01,2000,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,1-12,"We describe the design and implementation of Dynamo, a software dynamic optimization system that is capable of transparently improving the performance of a native instruction stream as it executes on the processor. The input native instruction stream to Dynamo can be dynamically generated (by a JIT for example), or it can come from the execution of a statically compiled native binary. This paper evaluates the Dynamo system in the latter, more challenging situation, in order to emphasize the limits, rather than the potential, of the system. Our experiments demonstrate that even statically optimized native binaries can be accelerated Dynamo, and often by a significant degree. For example, the average performance of -O optimized SpecInt95 benchmark binaries created by the HP product C compiler is improved to a level comparable to their -O4 optimized version running without Dynamo. Dynamo achieves this by focusing its efforts on optimization opportunities that tend to manifest only at runtime, and hence opportunities that might be difficult for a static compiler to exploit. Dynamo's operation is transparent in the sense that it does not depend on any user annotations or binary instrumentation, and does not require multiple runs, or any special compiler, operating system or hardware support. The Dynamo prototype presented here is a realistic implementation running on and HP PA-8000 workstation under the HPUX 10.20 operating system.",,522,0,,,,undefined,,PLDI Programming Languages
2-s2.0-0033721503,10.1016/S1389-1286(00)00083-9,S1389128600000839,,Graph structure in the Web,ar,Article,Broder A.,60020536;60009253;115064980,Hewlett-Packard Inc.;IBM Research - Almaden;AltaVista Company,Palo Alto;San Jose;San Mateo,United States;United States;United States,8,"Broder, Andrei;Kumar, Ravi;Maghoul, Farzin;Raghavan, Prabhakar;Rajagopalan, Sridhar;Stata, Raymie;Tomkins, Andrew;Wiener, Janet",7006812501;7406018609;56556777500;7006894026;43661666500;6603609507;7103063275;7201514044,115064980;60009253;115064980;60009253;60009253;60020536;60009253;60020536,2000-01-01,June 2000,Computer Networks,13891286,26811,,Journal,33,1,,309-320,"The study of the Web as a graph is not only fascinating in its own right, but also yields valuable insight into Web algorithms for crawling, searching and community discovery, and the sociological phenomena which characterize its evolution. We report on experiments on local and global properties of the Web graph using two Alta Vista crawls each with over 200 million pages and 1.5 billion links. Our study indicates that the macroscopic structure of the Web is considerably more intricate than suggested by earlier experiments on a smaller scale.",,1928,0,,,,undefined,,WWW World Wide Web
2-s2.0-0034592773,,,,Hancock: A language for extracting signatures from data streams,cp,Conference Paper,Cortes C.,60008383,AT&amp;T Laboratories Florham Park,Florham Park,United States,5,"Cortes, Corinna;Fisher, Kathleen;Pregibon, Daryl;Rogers, Anne;Smith, Frederick",8850433300;57214548612;6602175600;16029397000;55574194465,60008383;60008383;60008383;60008383;60008383,2000-12-01,2000,Proceeding of the Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,120063,,Conference Proceeding,,,,9-17,"Massive transaction streams present a number of opportunities for data mining techniques. Transactions might represent calls on a telephone network, commercial credit card purchases, stock market trades, or HTTP requests to a web server. While historically such data have been collected for billing or security purposes, they are now being used to discover how customers or their intermediaries (called transactors) use the underlying services. For several years, we have computed evolving profiles (called signatures) of the transactors in large data streams using handwritten C code. The signature for each transactor captures the salient features of his transactions through time. Programs for processing signatures must be highly optimized because of the size of the data stream (several gigabytes per day) and the number of signatures to maintain (hundreds of millions). C programs to compute signatures often sacrificed readability for performance. Consequently, they are difficult to verify and maintain. Hancock is a domain-specific language created to express computationally efficient signature programs cleanly. In this paper, we describe the obstacles to computing signatures from massive streams and explain how Hancock addresses these problems. For expository purposes, we present Hancock using a running example from the telecommunications industry; however, the language itself is general and applies equally well to other data sources.",,126,0,,,,undefined,,KDD Data Mining
2-s2.0-0033645041,,,,IR evaluation methods for retrieving highly relevant documents,ar,Article,Jarvelin K.,60011170,Tampere University,Tampere,Finland,2,"Jarvelin, Kalervo;Kekalainen, Jaana",7003932928;6508128789,60011170;60011170,2000-12-11,2000,SIGIR Forum (ACM Special Interest Group on Information Retrieval),01635840,15745,,Journal,,,,41-48,"This paper proposes evaluation methods based on the use of non-dichotomous relevance judgements in IR experiments. It is argued that evaluation methods should credit IR methods for their ability to retrieve highly relevant documents. This is desirable from the user point of view in modern large IR environments. The proposed methods are (1) a novel application of P-R curves and average precision computations based on separate recall bases for documents of different degrees of relevance, and (2) two novel measures computing the cumulative gain the user obtains by examining the retrieval result up to a given ranked position. We then demonstrate the use of these evaluation methods in a case study on the effectiveness of query types, based on combinations of query structures and expansion, in retrieving documents of various degrees of relevance. The test was run with a best match retrieval system (In-Query) in a text database consisting of newspaper articles. The results indicate that the tested strong query structures are most effective in retrieving highly relevant documents. The differences between the query types are practically essential and statistically significant. More generally, the novel evaluation methods and the case demonstrate that non-dichotomous relevance assessments are applicable in IR experiments, may reveal interesting phenomena, and allow harder testing of IR methods.",,1174,0,,,,undefined,,SIGIR Information Retrieval
2-s2.0-0001183866,,,,Local Search Characteristics of Incomplete SAT Procedures,cp,Conference Paper,Schuurmans D.,60000463,David R. Cheriton School of Computer Science,Waterloo,Canada,2,"Schuurmans, Dale;Southey, Finnegan",57204335408;10241539900,60000463;60000463,2000-01-01,2000,"Proceedings of the 17th National Conference on Artificial Intelligence and 12th Conference on Innovative Applications of Artificial Intelligence, AAAI 2000",,21101150669,,Conference Proceeding,,,,297-302,"Effective local search methods for finding satisfying assignments of CNF formulae exhibit several systematic characteristics in their search. We identify a series of measurable characteristics of local search behavior that are predictive of problem solving efficiency. These measures are shown to be useful for diagnosing inefficiencies in given search procedures, tuning parameters, and predicting the value of innovations to existing strategies. We then introduce a new local search method, SDF (“smoothed descent and flood”), that builds upon the intuitions gained by our study. SDF works by greedily descending in an informative objective (that considers how strongly clauses are satisfied, in addition to counting the number of unsatisfied clauses) and, once trapped in a local minima, “floods” this minima by re-weighting unsatisfied clauses to create a new descent direction. The resulting procedure exhibits superior local search characteristics under our measures. We then show that our method is competitive with the state of the art techniques, and typically reduces the number of search steps by a significant factor.",,39,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-0033682434,10.1109/CVPR.2000.854761,,,Real-time tracking of non-rigid objects using mean shift,cp,Conference Paper,Comaniciu D.,60120688;60084261,Department of Electrical and Computer Engineering;Siemens USA,Piscataway;New York,United States;United States,3,"Comaniciu, Dorin;Ramesh, Visvanathan;Meer, Peter",7003476440;57192658294;7006570387,60084261;60084261;60120688,2000-01-01,2000,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Journal,2,,,142-149,"A new method for real-time tracking of non-rigid objects seen from a moving camera is proposed. The central computational module is based on the mean shift iterations and finds the most probable target position in the current frame. The dissimilarity between the target model (its color distribution) and the target candidates is expressed by a metric derived from the Bhattacharyya coefficient. The theoretical analysis of the approach shows that it relates to the Bayesian framework while providing a practical, fast and efficient solution. The capability of the tracker to handle in real-time partial occlusions, significant clutter, and target scale variations, is demonstrated for several image sequences.",,2788,0,,,,undefined,,CVPR Computer Vision
2-s2.0-0034440437,10.1145/354401.354417,,,Sensing techniques for mobile interaction,cp,Conference Paper,Hinckley K.,60021726,Microsoft Research,Redmond,United States,4,"Hinckley, K.;Pierce, J.;Sinclair, M.;Horvitz, E.",7003730318;7402398320;7202410378;6701318945,60021726;60021726;60021726;60021726,2000-01-01,2000,UIST (User Interface Software and Technology): Proceedings of the ACM Symposium,,82223,,Conference Proceeding,,,,91-100,"We describe sensing techniques motivated by unique aspects of human-computer interaction with handheld devices in mobile settings. Special features of mobile interaction include changing orientation and position, changing venues, the use of computing as auxiliary to ongoing, real-world activities like talking to a colleague, and the general intimacy of use for such devices. We introduce and integrate a set of sensors into a handheld device, and demonstrate several new functionalities engendered by the sensors, such as recording memos when the device is held like a cell phone, switching between portrait and landscape display modes by holding the device in the desired orientation, automatically powering up the device when the user picks it up the device to start using it, and scrolling the display using tilt. We present an informal experiment, initial usability testing results, and user reactions to these techniques.",Context-awareness | Input devices | Interaction techniques | Mobile devices | Mobile interaction | Sensing | Sensors,389,1,repositoryam,Green,,undefined,,UIST User Interface
2-s2.0-10644277499,,,,Statistics-Based Summarization - Step One: Sentence Compression,cp,Conference Paper,Knight K.,60015400,Information Sciences Institute,Marina del Rey,United States,2,"Knight, Kevin;Marcu, Daniel",7202745471;6701627574,60015400;60015400,2000-01-01,2000,"Proceedings of the 17th National Conference on Artificial Intelligence and 12th Conference on Innovative Applications of Artificial Intelligence, AAAI 2000",,21101150669,,Conference Proceeding,,,,703-710,"When humans produce summaries of documents, they do not simply extract sentences and concatenate them. Rather, they create new sentences that are grammatical, that cohere with one another, and that capture the most salient pieces of information in the original document. Given that large collections of text/abstract pairs are available online, it is now possible to envision algorithms that are trained to mimic this process. In this paper, we focus on sentence compression, a simpler version of this larger challenge. We aim to achieve two goals simultaneously: our compressions should be grammatical, and they should retain the most important pieces of information. These two goals can conflict. We devise both noisy-channel and decision-tree approaches to the problem, and we evaluate results against manual compressions and a simple baseline.",,261,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-0033884567,,,,Chaotic nature of TCP congestion control,cp,Conference Paper,Veres A.,60080668,Ericsson Hungary Ltd.,Budapest,Hungary,1,"Veres, Andras",7004467318,60080668,2000-01-01,2000,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,3,,,1715-1723,"In his paper we demonstrate how TCP congestion control can show chaotic behavior. We demonstrate the major features of chaotic systems in TCP/IP networks with examples. These features include unpredictability, extreme sensitivity to initial conditions and odd periodicity. Previous work has shown the fractal nature of aggregate TCP/IP traffic and one explanation to this phenomenon was that traffic can be approximated by a large number of ON/OFF sources where the random ON and/or OFF periods are of length described by a heavy tailed distribution. In this paper we show that this argument is not necessary to explain self-similarity, neither randomness is required. Rather, TCP itself as a deterministic process creates chaos, which generates self-similarity. This property is inherent in todays TCP/IP networks and it is independent of higher layer applications or protocols. The two causes: heavy tailed ON/OFF and chaotic TCP together contribute to the phenomena, called fractal nature of Internet traffic.",,253,0,,,,undefined,,INFOCOM Networking
2-s2.0-85158171964,,,,The Game of Hex: An Automatic Theorem Proving Approach to Game Programming,cp,Conference Paper,Anshelevich V.V.,129650834,Vanshel Consulting,Richardson,United States,1,"Anshelevich, Vadim V.",57506513500,129650834,2000-01-01,2000,"Proceedings of the 17th National Conference on Artificial Intelligence and 12th Conference on Innovative Applications of Artificial Intelligence, AAAI 2000",,21101150669,,Conference Proceeding,,,,189-194,"The game of Hex is a two-player game with simple rules, a deep underlying mathematical beauty, and a strategic complexity comparable to that of Chess and Go. The massive game-tree search techniques developed mostly for Chess, and successfully used for Checkers, Othello, and a number of other games, become less useful for games with large branching factors like Go and Hex. We offer a new approach, which results in superior playing strength. This approach emphasizes deep analysis of relatively few game positions. In order to reach this goal, we develop an automatic theorem proving technique for topological analysis of Hex positions. We also discuss in detail an idea of modeling Hex positions with electrical resistor circuits. We explain how this approach is implemented in Hexy - the strongest known Hex-playing computer program, able to compete with best human players.",,22,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-85134757949,10.1145/342009.335405,,,XMill: an Efficient Compressor for XML Data,cp,Conference Paper,Liefke H.,60014300;60006297,AT&amp;T Inc.;University of Pennsylvania,San Antonio;Philadelphia,United States;United States,2,"Liefke, Hartmut;Suciu, Dan",6508135575;57190803598,60006297;60014300,2000-01-01,2000,SIGMOD 2000 - Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data,,21101097209,,Conference Proceeding,,,,153-164,"We describe a tool for compressing XML data, with applications in data exchange and archiving, which usually achiev es about twice the compression ratio of gzip at roughly the same speed. The compressor, called XMill, incorporates and combines existing compressors in order to apply them to heterogeneous XML data: it uses zlib, the library function for gzip, a collection of datat ype specific compressors for simple data types, and, possibly, user defined compressors for application specific data types.",,4,0,,,,undefined,,SIGMOD Databases
2-s2.0-0036036816,10.1145/502059.502037,,,BASE: Using abstraction to improve fault tolerance,ar,Article,Rodrigues R.,60098463;60006320,Microsoft Research Cambridge;MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge;Cambridge,United Kingdom;United States,3,"Rodrigues, Rodrigo;Castro, Miguel;Liskov, Barbara",13008425200;57189717671;7003295036,60006320;60098463;60006320,2001-12-01,December 2001,Operating Systems Review (ACM),01635980,19829,,Conference Proceeding,35,5,,15-28,"Software errors are a major cause of outages and they are increasingly exploited in malicious attacks. Byzantine fault tolerance allows replicated systems to mask some software errors but it is expensive to deploy. This paper describes a replication technique, BASE, which uses abstraction to reduce the cost of Byzantine fault tolerance and to improve its ability to mask software errors. BASE reduces cost because it enables reuse of off-the-shelf service implementations. It improves availability because each replica can be repaired periodically using an abstract view of the state stored by correct replicas, and because each replica can run distinct or non-deterministic service implementations, which reduces the probability of common mode failures. We built an NFS service where each replica can run a different off-the-shelf file system implementation, and an object-oriented database where the replicas ran the same, non-deterministic implementation. These examples suggest that our technique can be used in practice - in both cases, the implementation required only a modest amount of new code, and our performance results indicate that the replicated services perform comparably to the implementations that they reuse.",,74,0,,,,undefined,,SOSP Operating Systems
2-s2.0-0012317475,,,,Complexity results for structure-based causality,cp,Conference Paper,Eiter T.,60018163,Technische Universität Wien,Vienna,Austria,2,"Eiter, Thomas;Lukasiewicz, Thomas",7005085805;7004581222,60018163;60018163,2001-12-01,2001,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,35-40,"We analyze the computational complexity of causal relationships in Pearl's structural models, where we focus on causality between variables, event causality, and probabilistic causality. In particular, we analyze the complexity of the sophisticated notions of weak and actual causality by Halpern and Pearl. In the course of this, we also prove an open conjecture by Halpern and Pearl, and establish other semantic results. To our knowledge, no complexity aspects of causal relationships have been considered so far, and our results shed light on this issue.",,7,0,,,EC,N Z29-INF,European Commission,IJCAI Artificial Intelligence
2-s2.0-84880493935,10.1145/371920.371935,,,Engineering server-driven consistency for large scale dynamic web services,cp,Conference Paper,Yin J.,60150459;60017366,Department of Computer Science;IBM Thomas J. Watson Research Center,Austin;Yorktown Heights,United States;United States,4,"Yin, Jian;Alvisi, Lorenzo;Dahlin, Mike;Iyengar, Arun",55242880300;6603768937;7003483638;7005401000,60150459;60150459;60150459;60017366,2001-04-01,1 April 2001,"Proceedings of the 10th International Conference on World Wide Web, WWW 2001",,21100877166,,Conference Proceeding,,,,45-57,"Many researchers have shown that server-driven consistency protocols can potentially reduce read latency. Server-driven consistency protocols are particularly attractive for large-scale dynamic web workloads because dynamically gener- A ted data can change rapidly and unpredictably. However, there have been no reports on engineering server-driven con-sistency for such a workload. This paper reports our experi-ence in engineering server-driven consistency for a Sporting and Event web site hosted by IBM, one of the most popu-lar web sites on the Internet for the duration of the event. Our study focuses on scalability and cachability of dynamic content. To assess scalability, we measure both the amount of state that a server needs to maintain to ensure consis-tency and the bursts of load that a server sustains to send out invalidation messages when a popular object is modified. We find that it is possible to limit the size of the server's state without significant performance costs and that bursts of load can be smoothed out with minimal impact on the consistency guarantees. To improve performance, we sys-tematically investigate several design issues for which prior research has suggested widely different solutions, including how long servers should send invalidations to idle clients. Finally, we quantify the performance impact of caching dy-namic data with server-driven consistency protocols and find that it can reduce read latency by more than 10%. We have implemented a prototype of a server-driven consistency pro-tocol based on our findings on top of the popular Squid cache.",Dynamic content | Performance | Scala-bility | Volume lease | Web cache consistency,34,0,,,,undefined,,WWW World Wide Web
2-s2.0-1242310001,10.1016/j.artint.2003.06.001,S0004370203001723,,Fast and optimal decoding for machine translation,ar,Article,Germann U.,60141508;60015400,Stanford Engineering;Information Sciences Institute,Stanford;Marina del Rey,United States;United States,5,"Germann, Ulrich;Jahr, Michael;Knight, Kevin;Marcu, Daniel;Yamada, Kenji",7005251202;55550576400;7202745471;6701627574;55190519800,60015400;60141508;60015400;60015400;60015400,2004-04-01,April 2004,Artificial Intelligence,00043702,23675,,Journal,154,1-2,,127-143,"A good decoding algorithm is critical to the success of any statistical machine translation system. The decoder's job is to find the translation that is most likely according to a set of previously learned parameters (and a formula for combining them). Since the space of possible translations is extremely large, typical decoding algorithms are only able to examine a portion of it, thus risking to miss good solutions. Unfortunately, examining more of the space leads to unacceptably slow decodings. In this paper, we compare the speed and output quality of a traditional stack-based decoding algorithm with two new decoders: a fast but non-optimal greedy decoder and a slow but optimal decoder that treats decoding as an integer-programming optimization problem. © 2003 Elsevier B.V. All rights reserved.",Decoding | Machine translation | MT | SMT | Statistical machine translation,31,1,repositoryvor,Green,,N66001-00-1-9814,,ACL Natural Language Processing
2-s2.0-0034832364,10.1145/375663.375680,,,Locally adaptive dimensionality reduction for indexing large time series databases,cp,Conference Paper,Keogh E.,60007278,"University of California, Irvine",Irvine,United States,4,"Keogh, E.;Chakrabarti, K.;Mehrotra, S.;Pazzani, M.",7006166198;7004916223;7102264434;7004099223,60007278;60007278;60007278;60007278,2001-01-01,2001,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,151-162,"Similarity search in large time series databases has attracted much research interest recently. It is a difficult problem because of the typically high dimensionality of the data.. The most promising solutions involve performing dimensionality reduction on the data, then indexing the reduced data with a multidimensional index structure. Many dimensionality reduction techniques have been proposed, including Singular Value Decomposition (SVD), the Discrete Fourier transform (DFT), and the Discrete Wavelet Transform (DWT). In this work we introduce a new dimensionality reduction technique which we call Adaptive Piecewise Constant Approximation (APCA). While previous techniques (e.g., SVD, DFT and DWT) choose a common representation for all the items in the database that minimizes the global reconstruction error, APCA approximates each time series by a set of constant value segments of varying lengths such that their individual reconstruction errors are minimal. We show how APCA can be indexed using a multid imensional index structure. We propose two distance measures in the indexed space that exploit the high fidelity of APCA for fast searching: a lower bounding Euclidean distance approximation, and a non-lower bounding, but very tight Euclidean distance approximation and show how they can support fast exact searching, and even faster approximate searching on the same index structure. We theoretically and empirically compare APCA to all the other techniques and demonstrate its superiority.",Content-based retrieval | Dimensionality reduction | Indexing,361,0,repositoryam,Green,,undefined,,SIGMOD Databases
2-s2.0-0035017228,,,,Mobility increases the capacity of ad-hoc wireless networks,ar,Article,Grossglauser M.,60025038;60008383,"University of California, Berkeley;AT&amp;T Laboratories Florham Park",Berkeley;Florham Park,United States;United States,2,"Grossglauser, Matthias;Tse, David N.C.",7004602473;7101916524,60008383;60025038,2001-01-01,2001,Proceedings - IEEE INFOCOM,0743166X,18204,,Journal,3,,,1360-1369,"The capacity of ad-hoc wireless networks is constrained by the mutual interference of concurrent transmissions between nodes. We study a model of an ad-hoc network where n nodes communicate in random source-destination pairs. These nodes are assumed to be mobile. We examine the per-session throughput for applications with loose delay constraints, such that the topology changes over the time-scale of packet delivery. Under this assumption, the per-user throughput can increase dramatically when nodes are mobile rather than fixed. This improvement can be achieved by exploiting node mobility as a type of multi-user diversity.",,714,0,,,,undefined,,INFOCOM Networking
2-s2.0-0035693930,,,,Morphable 3D models from video,cp,Conference Paper,Brand M.,60003398,Mitsubishi Electric Research Laboratories,Cambridge,United States,1,"Brand, Matthew",7202584113,60003398,2001-12-01,2001,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,2,,,,"Nonrigid 3D structure-from-motion and 2D optical flow can both be formulated as tensor factorization problems. The two problems can be made equivalent through a noisy affine transform, yielding a combined nonrigid structure-from-intensities problem that we solve via structured matrix decompositions. Often the preconditions for this factorization are violated by image noise and deficiencies of the data vis-a-vis the sample complexity of the problem. Both issues are remediated with careful use of rank constraints, norm constraints, and integration over uncertainty in the intensity values, yielding novel solutions for SVD under uncertainty, factorization under uncertainty, nonrigid factorization, and subspace optical flow. The resulting integrated algorithm can track and 3D-reconstruct nonrigid surfaces that have very little texture, for example the smooth parts of the face. Working with low-resolution low-texture ""found video,"" these methods produce good tracking and 3D reconstruction results where prior algorithms fail.",,177,0,,,,undefined,,CVPR Computer Vision
2-s2.0-0034819889,10.1145/375551.375567,,,Optimal aggregation algorithms for middleware,cp,Conference Paper,Fagin R.,60009253,IBM Research - Almaden,San Jose,United States,3,"Fagin, R.;Lotem, A.;Naor, M.",7005757964;7003924963;7005831405,60009253;60009253;60009253,2001-01-01,2001,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,102-113,"Assume that each object in a database has m grades, or scores, one for each of m attributes. For example, an object can have a color grade, that tells how red it is, and a shape grade, that tells how round it is. For each attribute, there is a sorted list, which lists each object and its grade under that attribute, sorted by grade (highest grade first). There is some monotone aggregation function, or combining rule, such as min or average, that combines the individual grades to obtain an overall grade. To determine objects that have the best overall grades, the naive algorithm must access every object in the database, to find its grade under each attribute. Fagin has given an algorithm (""Fagin's Algorithm"", or FA) that is much more efficient. For some distributions on grades, and for some monotone aggregation functions, FA is optimal in a high-probability sense. We analyze an elegant and remarkably simple algorithm (""the threshold algorithm"", or TA) that is optimal in a much stronger sense than FA. We show that TA is essentially optimal, not just for some monotone aggregation functions, but for all of them, and not just in a high-probability sense, but over every database. Unlike FA, which requires large buffers (whose size may grow unboundedly as the database size grows), TA requires only a small, constant-size buffer. We distinguish two types of access: sorted access (where the middleware system obtains the grade of an object in some sorted list by proceeding through the list sequentially from the top), and random access (where the middleware system requests the grade of object in a list, and obtains it in one step). We consider the scenarios where random access is either impossible, or expensive relative to sorted access, and provide algorithms that are essentially optimal for these cases as well.",Competitive analysis | Instance optimality | Middleware,812,0,repository,Green,,undefined,,PODS Databases
2-s2.0-0035757745,,,,Phidgets: Easy development of physical interfaces through physical widgets,cp,Conference Paper,Greenberg S.,60002306,University of Calgary,Calgary,Canada,2,"Greenberg, Saul;Fitchett, Chester",7402294419;6603333280,60002306;60002306,2001-12-01,2001,UIST (User Interface Software and Technology): Proceedings of the ACM Symposium,,82223,,Conference Proceeding,,,,209-218,"Physical widgets or phidgets are to physical user interfaces what widgets are to graphical user interfaces. Similar to widgets, phidgets abstract and package input and output devices: They hide implementation and construction details, they expose functionality through a well-defined API, and they have an (optional) on-screen interactive interface for displaying and controlling device state. Unlike widgets, phidgets also require: A connection manager to track how devices appear on-line; a way to link a software phidget with its physical counterpart; and a simulation mode to allow the programmer to develop, debug and test a physical interface even when no physical device is present. Our evaluation shows that everyday programmers using phidgets can rapidly develop physical interfaces.",,431,0,,,,undefined,,UIST User Interface
2-s2.0-0034857374,,,,Probabilistic tracking in a metric space,cp,Conference Paper,Toyama K.,60021726,Microsoft Research,Redmond,United States,2,"Toyama, K.;Blake, A.",7201530533;7201402207,60021726;60021726,2001-01-01,2001,Proceedings of the IEEE International Conference on Computer Vision,,110561,,Conference Proceeding,2,,,50-57,"A new, exemplar-based, probabilistic paradigm for visual tracking is presented. Probabilistic mechanisms are attractive because they handle fusion of information, especially temporal fusion, in a principled manner. Exemplars are selected representatives of raw training data, used here to represent probabilistic mixture distributions of object configurations. Their use avoids tedious hand-construction of object models and problems with changes of topology. Using exemplars in place of a parameterized model poses several challenges, addressed here with what we call the ""Metric Mixture"" (M2) approach. The M2 model has several valuable properties. Principally, it provides alternatives to standard learning algorithms by allowing the use of metrics that are not embedded in a vector space. Secondly, it uses a noise model that is learned from training data. Lastly, it eliminates any need for an assumption of probabilistic pixelwise independence. Experiments demonstrate the effectiveness of the M2 model in two domains: tracking walking people using chamfer distances on binary edge images and tracking mouth movements by means of a shuffle distance.",,171,0,,,,undefined,,ICCV Computer Vision
2-s2.0-0035789577,10.1145/502512.502532,,,Robust space transformations for distance-based operations,cp,Conference Paper,Knorr E.M.,60010365,The University of British Columbia,Vancouver,Canada,3,"Knorr, Edwin M.;Ng, Raymond T.;Zamar, Ruben H.",6701607164;7102153783;7004311906,60010365;60010365;60010365,2001-01-01,2001,Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,74893,,Conference Proceeding,,,,126-135,"For many KDD operations, such as nearest neighbor search, distance-based clustering, and outlier detection, there is an underlying k-D data space in which each tuple/object is represented as a point in the space. In the presence of differing scales, variability, correlation, and/or outliers, we may get unintuitive results if an inappropriate space is used. The fundamental question that this paper addresses is: ""What then is an appropriate space?"" We propose using a robust space transformation called the Donoho-Stahel estimator. In the first half of the paper, we show the key properties of the estimator. Of particular importance to KDD applications involving databases is the stability property, which says that in spite of frequent updates, the estimator does not: (a) change much, (b) lose its usefulness, or (c) require re-computation. In the second half, we focus on the computation of the estimator for high-dimensional databases. We develop randomized algorithms and evaluate how well they perform empirically. The novel algorithm we develop called the Hybrid-random algorithm is, in most cases, at least an order of magnitude faster than the Fixed-angle and Subsampling algorithms.",Data Mining | Distance-based Operations | Outliers | Robust Estimators | Robust Statistics | Space Transformations,31,0,,,,undefined,,KDD Data Mining
2-s2.0-0034849127,,,,The space of all stereo images,cp,Conference Paper,Seitz S.M.,60028661,UW College of Engineering,Seattle,United States,1,"Seitz, S. M.",7004774929,60028661,2001-01-01,2001,Proceedings of the IEEE International Conference on Computer Vision,,110561,,Conference Proceeding,1,,,26-33,"A theory of stereo image formation is presented that enables a complete classification of all possible stereo views, including non-perspective varieties. Towards this end, the notion of epipolar geometry is generalized to apply to multiperspective images. It is shown that any stereo pair must consist of rays lying on one of three varieties of quadric surfaces. A unified representation is developed to model all classes of stereo views, based on the concept of a quadric view. The benefits include a unified treatment of projection and triangulation operations for all stereo views. The framework is applied to derive new types of stereo image representations with unusual and useful properties.",,59,0,,,,undefined,,ICCV Computer Vision
2-s2.0-0036036793,10.1145/502059.502036,,,Untrusted hosts and confidentiality: Secure program partitioning,ar,Article,Zdancewic S.,,,,,4,"Zdancewic, Steve;Zheng, Lantian;Nystrom, Nathaniel;Myers, Andrew C.",57293474600;7403406427;6603621095;7202743179,,2001-12-01,December 2001,Operating Systems Review (ACM),01635980,19829,,Conference Proceeding,35,5,,1-14,"This paper presents secure program partitioning, a language-based technique for protecting confidential data during computation in distributed systems containing mutually untrusted hosts. Confidentiality and integrity policies can be expressed by annotating programs with security types that constrain information flow; these programs can then be partitioned automatically to run securely on heterogeneously trusted hosts. The resulting communicating subprograms collectively implement the original program, yet the system as a whole satisfies the security requirements of participating principals without requiring a universally trusted host machine. The experience in applying this methodology and the performance of the resulting distributed code suggest that this is a promising way to obtain secure distributed computation.",,57,0,,,,undefined,,SOSP Operating Systems
2-s2.0-84944324889,,,,Weaving relations for cache performance,cp,Conference Paper,Ailamaki A.,60032179;60027950,University of Wisconsin-Madison;Carnegie Mellon University,Madison;Pittsburgh,United States;United States,4,"Ailamaki, Anastassia;DeWitt, David J.;Hill, Mark D.;Skounakis, Marios",56216343500;57203070346;7404448079;55806343700,60027950;60032179;60032179;60032179,2001-01-01,2001,VLDB 2001 - Proceedings of 27th International Conference on Very Large Data Bases,,21100416476,,Conference Proceeding,,,,169-180,"Relational database systems have traditionally optimzed for I/O performance and organized records sequentially on disk pages using the N-ary Storage Model (NSM) (a.k.a., slotted pages). Recent research, however, indicates that cache utilization and performance is becoming increasingly important on modern platforms. In this paper, we first demonstrate that in-page data placement is the key to high cache performance and that NSM exhibits low cache utilization on modern platforms. Next, we propose a new data organization model called PAX (Partition Attributes Across), that significantly improves cache performance by grouping together all values of each attribute within each page. Because PAX only affects layout inside the pages, it incurs no storage penalty and does not affect I/O behavior. According to our experimental results, when compared to NSM (a) PAX exhibits superior cache and memory bandwidth utilization, saving at least 75% of NSM's stall time due to data cache accesses, (b) range selection queries and updates on memoryresident relations execute 17-25% faster, and (c) TPC-H queries involving I/O execute 11-48% faster.",,253,0,,,,undefined,,VLDB Databases
2-s2.0-0036964534,,,,A dichotomy theorem for constraints on a three-element set,cp,Conference Paper,Bulatov A.,60026851,University of Oxford,Oxford,United Kingdom,1,"Bulatov, Andrei A.",57204255801,60026851,2002-12-01,2002,Annual Symposium on Foundations of Computer Science - Proceedings,02725428,22882,,Conference Proceeding,,,,649-658,"The Constraint Satisfaction Problem (CSP) provides a common framework for many combinatorial problems. The general CSP is known to be NP-complete; however, certain restrictions on the possible form of constraints may affect the complexity, and lead to tractable problem classes. There is, therefore, a fundamental research direction, aiming to separate those subclasses of the CSP which are tractable, from those which remain NP-complete. In 1978 Schaefer gave an exhaustive solution of this problem for the CSP on a 2-element domain. In this paper we generalise this result to a classification of the complexity of CSPs on a 3-element domain. The main result states that every subclass of the CSP defined by a set of allowed constraints is either tractable or NP-complete, and the criterion separating them is that conjectured in [6, 8]. We also exhibit a polynomial time algorithm which, for a given set of allowed constraints, determines whether if this set gives rise to a tractable problem class. To obtain the main result and the algorithm we extensively use the algebraic technique for the CSP developed in [17] and [6, 8].",,128,0,,,,undefined,,FOCS Theory
2-s2.0-77953069969,10.1145/511446.511498,,,Abstracting application-level web security,cp,Conference Paper,Scott D.,105762923;105201324,Computer Laboratory;Engineering Laboratory,Cambridge;Cambridge,United Kingdom;United Kingdom,2,"Scott, David;Sharp, Richard",55636956700;57190393932,105201324;105762923,2002-12-01,2002,"Proceedings of the 11th International Conference on World Wide Web, WWW '02",,19700174700,,Conference Proceeding,,,,396-407,"Application-level web security refers to vulnerabilities inherent in the code of a web-application itself (irrespective of the technologies in which it is implemented or the security of the web-server/back-end database on which it is built). In the last few months application-level vulnerabilities have been exploited with serious consequences: hackers have tricked e-commerce sites into shipping goods for no charge, user-names and passwords have been harvested and condential information (such as addresses and credit-card numbers) has been leaked.In this paper we investigate new tools and techniques which address the problem of application-level web security. We (i) describe a scalable structuring mechanism facilitating the abstraction of security policies from large web-applications developed in heterogenous multi-platform environments; (ii) present a tool which assists programmers develop secure applications which are resilient to a wide range of common attacks; and (iii) report results and experience arising from our implementation of these techniques.",Application-level web security | Component-based design | Security policy description language,137,0,,,,undefined,,WWW World Wide Web
2-s2.0-0037967638,10.1145/571998.571999,,,Clothing manipulation,cp,Conference Paper,Igarashi T.,60280409;60025272,Department of Computer Science;The University of Tokyo,Providence;Tokyo,United States;Japan,2,"Igarashi, Takeo;Hughes, John F.",7403250321;9737706300,60025272;60280409,2002-01-01,2002,UIST (User Interface Software and Technology): Proceedings of the ACM Symposium,,82223,,Conference Proceeding,,,,91-100,"This paper presents interaction techniques (and the underlying implementations) for putting clothes on a 3D character and manipulating them The user paints freeform marks on the clothes and corresponding marks on the 3D character; the system then puts the clothes around the body so that corresponding marks match. Internally, the system grows the clothes on the body surface around the marks while maintaining basic cloth constraints via simple relaxation steps. The entire computation takes a few seconds. After that, the user can adjust the placement of the clothes by an enhanced dragging operation. Unlike standard dragging where the user moves a set of vertices in a single direction in 3D space, our dragging operation moves the cloth along the body surface to make possible more flexible operations. The user can apply pushpins to fix certain cloth points during dragging. The techniques are ideal for specifying an initial cloth configuration before applying a more sophisticated cloth simulation.",Clothing | User Interface,53,0,,,,undefined,,UIST User Interface
2-s2.0-0036949106,,,,Constant-round coin-tossing with a man in the middle or realizing the shared random string model,cp,Conference Paper,Barak B.,60017563,Weizmann Institute of Science Israel,Rehovot,Israel,1,"Barak, Boaz",55909951700,60017563,2002-12-01,2002,Annual Symposium on Foundations of Computer Science - Proceedings,02725428,22882,,Conference Proceeding,,,,345-355,"We present the first constant-round non-malleable commitment scheme and the first constant-round non-malleable zero-knowledge argument system, as defined by Dolev, Dwork and Naor. Previous constructions either used a non-constant number of rounds, or were only secure under stronger setup assumptions. An example of such an assumption is the shared random string model where we assume all parties have access to a reference string that was chosen uniformly at random by a trusted dealer. We obtain these results by defining an adequate notion of non-malleable coin-tossing, and presenting a constant-round protocol that satisfies it. This protocol allows us to transform protocols that are non-malleable in (a modified notion of) the shared random string model into protocols that are non-malleable in the plain model (without any trusted dealer or setup assumptions). Observing that known constructions of a non-interactive non-malleable zero-knowledge argument systems in the shared random string model (De Santis et. al., 2001) are in fact non-malleable in the modified model, and combining them with our coin-tossing protocol we obtain the results mentioned above. The techniques we use are different from those used in previous constructions of non-malleable protocols. In particular our protocol uses diagonalization and a non-black-box proof of security (in a sense similar to Barak's zero-knowledge argument).",,107,0,,,,undefined,,FOCS Theory
2-s2.0-85101305674,,,,Discriminative training and maximum entropy models for statistical machine translation,cp,Conference Paper,Och F.J.,60016653,Rheinisch-Westfälische Technische Hochschule Aachen,Aachen,Germany,2,"Och, Franz Josef;Ney, Hermann",6602894021;7006360226,60016653;60016653,2002-01-01,2002,Proceedings of the Annual Meeting of the Association for Computational Linguistics,0736587X,21101138302,,Conference Proceeding,2002-July,,,295-302,"We present a framework for statistical machine translation of natural languages based on direct maximum entropy models, which contains the widely used source-channel approach as a special case. All knowledge sources are treated as feature functions, which depend on the source language sentence, the target language sentence and possible hidden variables. This approach allows a baseline machine translation system to be extended easily by adding new feature functions. We show that a baseline statistical machine translation system is significantly improved using this approach.",,780,0,,,,undefined,,ACL Natural Language Processing
2-s2.0-0037672303,10.1145/587051.587053,,,Isolating cause-effect chains from computer programs,cp,Conference Paper,Zeller A.,60033241,Universität des Saarlandes,Saarbrucken,Germany,1,"Zeller, Andreas",7007015864,60033241,2002-01-01,2002,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21101010898,,Conference Proceeding,,,,1-10,"Consider the execution of a failing program as a sequence of program states. Each state induces the following state, up to the failure. Which variables and values of a program state are relevant for the failure? We show how the Delta Debugging algorithm isolates the relevant variables and values by systematically narrowing the state difference between a passing run and a failing run - by assessing the outcome of altered executions to determine wether a change in the program state makes a difference in the test outcome. Applying Delta Debugging to multiple states of the program automatically reveals the cause-effect chain of the failure - that is, the variables and values that caused the failure. In a case study, our prototype implementation successfully isolated the cause-effect chain for a failure of the GNU C compiler: ""Initially, the C program to be compiled contained an addition of 1.0; this caused an addition operator in the intermediate RTL representation; this caused a cycle in the RTL tree - and this caused the compiler to crash"".",Automated debugging | Program comprehension | Testing | Tracing,417,0,,,,undefined,,FSE Software Engineering
2-s2.0-84978382687,10.1145/844128.844146,,,Memory resource management in VMware ESX server,cp,Conference Paper,Waldspurger C.A.,60103987,"VMware, Inc",Palo Alto,United States,1,"Waldspurger, Carl A.",6602227147,60103987,2002-12-31,31 December 2002,Operating Systems Review (ACM),01635980,19829,,Conference Proceeding,36,Special Issue,,181-194,VMware ESX Server is a thin software layer designed to multiplex hardware resources efficiently among virtual machines running unmodified commodity operating systems. This paper introduces several novel ESX Server mechanisms and policies for managing memory. A ballooning technique reclaims the pages considered least valuable by the operating system running in a virtual machine. An idle memory tax achieves efficient memory utilization while maintaining performance isolation guarantees. Content-based page sharing and hot I/0 page remapping exploit transparent page remapping to eliminate redundancy and reduce copying overheads. These techniques are combined to efficiently support virtual machine workloads that overcommit memory.,,735,0,,,,undefined,,OSDI Operating Systems
2-s2.0-0036948872,,,,Minimizing congestion in general networks,cp,Conference Paper,Räcke H.,60020238,Universität Paderborn,Paderborn,Germany,1,"Räcke, Harald",6602081824,60020238,2002-12-01,2002,Annual Symposium on Foundations of Computer Science - Proceedings,02725428,22882,,Conference Proceeding,,,,43-52,"A principle task in parallel and distributed systems is to reduce the communication load in the interconnection network, as this is usually the major bottleneck for the performance of distributed applications. In this paper we introduce a framework for solving on-line problems that aim to minimize the congestion (i.e. the maximum load of a network link) in general topology networks. We apply this framework to the problem of on-line routing of virtual circuits and to a dynamic data management problem. For both scenarios we achieve a competitive ratio of O(log3n) with respect to the congestion of the network links. Our on-line algorithm for the routing problem has the remarkable property that it is oblivious, i.e., the path chosen for a virtual circuit is independent of the current network load. Oblivious routing strategies can easily be implemented in distributed environments and have therefore been intensively studied for certain network topologies as e.g. meshes, tori and hypercubic networks. This is the first oblivious path selection algorithm that achieves a polylogarithmic competitive ratio in general networks.",,194,0,,,,undefined,,FOCS Theory
2-s2.0-0036041423,10.1145/543613.543617,,,Monadic datalog and the expressive power of languages for Web information extraction,cp,Conference Paper,Gottlob G.,60018163,Technische Universität Wien,Vienna,Austria,2,"Gottlob, Georg;Koch, Christoph",7005068491;56353512400,60018163;60018163,2002-01-01,2002,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,17-28,"Research on information extraction from Web pages (wrapping) has been much activity in recent times (particularly systems implementations), but little work has been done on formally studying the expressiveness of the formalisms proposed or on the theoretical foundations of wrapping. In this paper, we first study monadic datalog as a wrapping language (over ranked or unranked tree structures). Using previous work by Neven and Schwentick, we show that this simple language is equivalent to full monadic second order logic (MSO) in its ability to specify wrappers. We believe that MSO has the right expressiveness required for Web information extraction and thus propose MSO as a yardstick for evaluating and comparing wrappers. Using the above result, we study the kernel fragment Elog- of the Elog wrapping language used in the Lixto system (a visual wrapper generator). The striking fact here is that Elog- exactly captures MSO, yet is easier to use. Indeed, programs in this language can be entirely visually specified. We also formally compare Elog to other wrapping languages proposed in the literature.",,34,0,repositoryam,Green,,undefined,,PODS Databases
2-s2.0-0036989637,,,,Novelty and redundancy detection in adaptive filtering,cp,Conference Paper,Yi Z.,60136640;60027950,School of Computer Science;Carnegie Mellon University,Pittsburgh;Pittsburgh,United States;United States,3,"Yi, Zhang;Callan, Jamie;Minka, Thomas",57056558500;35588436200;6603659884,60136640;60136640;60027950,2002-12-01,2002,SIGIR Forum (ACM Special Interest Group on Information Retrieval),01635840,15745,,Journal,,,,81-88,This paper addresses the problem of extending an adaptive information filtering system to make decisions about the novelty and redundancy of relevant documents. It argues that relevance and redundance should each be modelled explicitly and separately. A set of five redundancy measures are proposed and evaluated in experiments with and without redundancy thresholds. The experimental results demonstrate that the cosine similarity metric and a redundancy measure based on a mixture of language models are both effective for identifying redundant documents.,Algorithm | Design | Experimentation,324,0,,,,undefined,,SIGIR Information Retrieval
2-s2.0-0036932138,,,,On computing all abductive explanations,cp,Conference Paper,Eiter T.,60024322;60018163,Osaka University;Technische Universität Wien,Suita;Vienna,Japan;Austria,2,"Eiter, Thomas;Makino, Kazuhisa",7005085805;7202528105,60018163;60024322,2002-12-01,2002,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,,,,62-67,"We consider the computation of all respectively a polynomial subset of the explanations of an abductive query from a Horn theory, and pay particular attention to whether the query is a positive or negative letter, the explanation is based on literals from an assumption set, and the Horn theory is represented in terms of formulas or characteristic models. We derive tractability results, one of which refutes a conjecture by Selman and Levesque, as well as intractability results, and furthermore also semi-tractability results in terms of solvability in quasi-polynomial time. Our results complement previous results in the literature, and elucidate the computational complexity of generating the set of explanations.",,35,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-0242456820,10.1145/775069.775070,,,Pattern discovery in sequences under a Markov assumption,cp,Conference Paper,Chudova D.,60142654,Donald Bren School of Information &amp; Computer Sciences,Irvine,United States,2,"Chudova, Darya;Smyth, Padhraic",6506983413;7006933675,60142654;60142654,2002-01-01,2002,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,101510,,Conference Proceeding,,,,153-162,"In this paper we investigate the general problem of discovering recurrent patterns that are embedded in categorical sequences. An important real-world problem of this nature is motif discovery in DNA sequences. We investigate the fundamental aspects of this data mining problem that can make discovery ""easy"" or ""hard."" We present a general framework for characterizing learning in this context by deriving the Bayes error rate for this problem under a Markov assumption. The Bayes error framework demonstrates why certain patterns are much harder to discover than others. It also explains the role of different parameters such as pattern length and pattern frequency in sequential discovery. We demonstrate how the Bayes error can be used to calibrate existing discovery algorithms, providing a lower bound on achievable performance. We discuss a number of fundamental issues that characterize sequential pattern discovery in this context, present a variety of empirical results to complement and verify the theoretical analysis, and apply our methodology to real-world motif-discovery problems in computational biology.",,26,0,,,,undefined,,KDD Data Mining
2-s2.0-0036346349,,,,Priority service and max-min fairness,cp,Conference Paper,Marbach P.,60016849,University of Toronto,Toronto,Canada,1,"Marbach, Peter",7006520314,60016849,2002-01-01,2002,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,1,,,266-275,"We study a pricing scheme for networks which use priorities to provide differentiated quality of service. We consider the situation where users are free to choose the priority of their traffic, but are charged accordingly. We model this situation as a non-cooperative game, where users behave in a selfish manner and choose an allocation of priorities to packets to optimize their own net benefit. We show that there exists an unique equilibrium for this game and the bandwidth allocation in equilibrium is weighted max-min fair.",,68,0,,,,undefined,,INFOCOM Networking
2-s2.0-1542286887,10.1145/940085.940086,,,A Family of Test Adequacy Criteria for Database-Driven Applications,cp,Conference Paper,Kapfhammer G.M.,60159156,Department of Computer Science,Pittsburgh,United States,2,"Kapfhammer, Gregory M.;Soffa, Mary Lou",12752631400;7003864328,60159156;60159156,2003-01-01,2003,Proceedings of the Joint European Software Engineering Conference (ESEC) and SIGSOFT Symposium on the Foundations of Software Engineering (FSE-11),,21100986306,,Conference Proceeding,,,,98-107,"Although a software application always executes within a particular environment, current testing methods have largely ignored these environmental factors. Many applications execute in an environment that contains a database. In this paper, we propose a family of test adequacy criteria that can be used to assess the quality of test suites for database-driven applications. Our test adequacy criteria use dataflow information that is associated with the entities in a relational database. Furthermore, we develop a unique representation of a database-driven application that facilitates the enumeration of database interaction associations. These associations can reflect an application's definition and use of database entities at multiple levels of granularity. The usage of a tool to calculate intraprocedural database interaction associations for two case study applications indicates that our adequacy criteria can be computed with an acceptable time and space overhead.",Database-driven applications | Test adequacy criteria,54,0,,,,undefined,,FSE Software Engineering
2-s2.0-85146417759,,,,Accurate unlexicalized parsing,cp,Conference Paper,Klein D.,60141508,Stanford Engineering,Stanford,United States,2,"Klein, Dan;Manning, Christopher D.",23009040500;35280197500,60141508;60141508,2003-01-01,2003,Proceedings of the Annual Meeting of the Association for Computational Linguistics,0736587X,21101138302,,Conference Proceeding,2003-July,,,,"We demonstrate that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar. Indeed, its performance of 86.36% (LP/LR F1) is better than that of early lexicalized PCFG models, and surprisingly close to the current state-of-the-art. This result has potential uses beyond establishing a strong lower bound on the maximum possible accuracy of unlexicalized models: an unlexicalized PCFG is much more compact, easier to replicate, and easier to interpret than more complex lexical models, and the parsing algorithms are simpler, more widely understood, of lower asymptotic complexity, and easier to optimize.",,2144,0,,,NSF,IIS-0085896,National Science Foundation,ACL Natural Language Processing
2-s2.0-1142287643,10.1145/773153.773155,,,An Information-Theoretic Approach to Normal Forms for Relational and XML Data,cp,Conference Paper,Arenas M.,60016849,University of Toronto,Toronto,Canada,2,"Arenas, Marcelo;Libkin, Leonid",7005937486;57203256125,60016849;60016849,2003-01-01,2003,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,22,,,15-26,"Normalization as a way of producing good database designs is a well-understood topic. However, the same problem of distinguishing well-designed databases from poorly designed ones arises in other data models, in particular, XML. While in the relational world the criteria for being well-designed are usually very intuitive and clear to state, they become more obscure when one moves to more complex data models. Our goal is to provide a set of tools for testing when a condition on a database design, specified by a normal form, corresponds to a good design. We use techniques of information theory, and define a measure of information content of elements in a database with respect to a set of constraints. We first test this measure in the relational context, providing information-theoretic justification for familiar normal forms such as BCNF, 4NF, PJ/NF, 5NFR, DK/NF. We then show that the same measure applies in the XML context, which gives us a characterization of a recently introduced XML normal form called XNF. Finally, we look at information-theoretic criteria for justifying normalization algorithms.",,30,0,,,,undefined,,PODS Databases
2-s2.0-84880840280,,,,Approximating game-theoretic optimal strategies for full-scale poker,cp,Conference Paper,Billings D.,60030835,University of Alberta,Edmonton,Canada,7,"Billings, D.;Burch, N.;Davidson, A.;Holte, R.;Schaeffer, J.;Schauenberg, T.;Szafron, D.",7006129689;36080490300;7402000832;6701843136;57203215676;14016621800;7003311854,60030835;60030835;60030835;60030835;60030835;60030835;60030835,2003-12-01,2003,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,661-668,"The computation of the first complete approximations of game-theoretic optimal strategies for full-scale poker is addressed. Several abstraction techniques are combined to represent the game of 2-player Texas Hold'em, having size O(1018), using closely related models each having size 0(1O 7). Despite the reduction in size by a factor of 100 billion, the resulting models retain the key properties and structure of the real game. Linear programming solutions to the abstracted game are used to create substantially improved poker-playing programs, able to defeat strong human players and be competitive against world-class opponents.",,185,0,,,,undefined,,IJCAI Artificial Intelligence
2-s2.0-0038039859,10.1145/781131.781156,,,Automatically proving the correctness of compiler optimizations,cp,Conference Paper,Lerner S.,60015481,University of Washington,Seattle,United States,3,"Lerner, Sorin;Millstein, Todd;Chambers, Craig",23134870200;57207585055;7101706202,60015481;60015481;60015481,2003-01-01,2003,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,220-231,"We describe a technique for automatically proving compiler optimizations sound, meaning that their transformations are always semantics-preserving. We first present a domain-specific language, called Cobalt, for implementing optimizations as guarded rewrite rules. Cobalt optimizations operate over a C-like intermediate representation including unstructured control flow, pointers to local variables and dynamically allocated memory, and recursive procedures. Then we describe a technique for automatically proving the soundness of Cobalt optimizations. Our technique requires an automatic theorem prover to discharge a small set of simple, optimization-specific proof obligations for each optimization. We have written a variety of forward and backward intraprocedural dataflow optimizations in Cobalt, including constant propagation and folding, branch folding, full and partial redundancy elimination, full and partial dead assignment elimination, and simple forms of points-to analysis. We implemented our soundness-checking strategy using the Simplify automatic theorem prover, and we have used this implementation to automatically prove our optimizations correct. Our checker found many subtle bugs during the course of developing our optimizations. We also implemented an execution engine for Cobalt optimizations as part of the Whirlwind compiler infrastructure.",Automated correctness proofs | Compiler optimization,69,0,,,,undefined,,PLDI Programming Languages
2-s2.0-21644490164,10.1145/1165389.945467,,,Backtracking intrusions,cp,Conference Paper,King S.T.,60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,2,"King, Samuel T.;Chen, Peter M.",8627038400;7408356226,60025778;60025778,2003-01-01,2003,Operating Systems Review (ACM),01635980,19829,,Conference Proceeding,37,5,,223-236,"Analyzing intrusions today is an arduous, largely manual task because system administrators lack the information and tools needed to understand easily the sequence of steps that occurred in an attack. The goal of BackTracker is to identify automatically potential sequences of steps that occurred in an intrusion. Starting with a single detection point (e.g., a suspicious file), BackTracker identifies files and processes that could have affected that detection point and displays chains of events in a dependency graph. We use BackTracker to analyze several real attacks against computers that we set up as honeypots. In each case, BackTracker is able to highlight effectively the entry point used to gain access to the system and the sequence of steps from that entry point to the point at which we noticed the intrusion. The logging required to support BackTracker added 9% overhead in running time and generated 1.2 GB per day of log data for an operating-system intensive workload. Copyright 2003 ACM.",Computer forensics | Information flow | Intrusion analysis,244,0,,,,undefined,,SOSP Operating Systems
2-s2.0-0038107689,10.1145/780591.780595,,,Derandomizing polynomial identity tests means proving circuit lower bounds,cp,Conference Paper,Kabanets V.,60121653,Department of Computer Science and Engineering,La Jolla,United States,2,"Kabanets, Valentine;Impagliazzo, Russell",8533022100;7005754624,60121653;60121653,2003-01-01,2003,Conference Proceedings of the Annual ACM Symposium on Theory of Computing,07349025,20568,,Conference Proceeding,,,,355-364,"We show that derandomizing Polynomial Identity Testing is, essentially, equivalent to proving circuit lower bounds for NEXP. More precisely, we prove that if one can test in polynomial time (or, even, nondeterministic subexponential time, infinitely often) whether a given arithmetic circuit over integers computes an identically zero polynomial, then either (i) NEXP ¢. P/poly or (ii) Permanent is not computable by polynomial-size arithmetic circuits. We also prove a (partial) converse: If Permanent requires superpolynomial-size arithmetic circuits, then one can test in subexponential time whether a given arithmetic formula computes an identically zero polynomial. Since Polynomial Identity Testing is a coRP problem, we obtain the following corollary: If RP = P (or, even, coRP ⊆ ∩ε>0NTIME(2nε), infinitely often), then NEXP is not computable by polynomial-size arithmetic circuits. Thus, establishing that RP = coRP or BPP = P would require proving superpolynomial lower bounds for Boolean or arithmetic circuits. We also show that any derandomization of RNC would yield new circuit lower bounds for a language in NEXP.",BPP | Circuit lower bounds | Derandomization | NEXP | Polynomial identity testing,77,0,,,,undefined,,STOC Theory
2-s2.0-0344983340,10.1109/iccv.2003.1238422,,,Detecting pedestrians using patterns of motion and appearance,cp,Conference Paper,Viola P.,60021726;60003398,Microsoft Research;Mitsubishi Electric Research Laboratories,Redmond;Cambridge,United States;United States,3,"Viola, Paul;Jones, Michael J.;Snow, Daniel",7006336559;55700793100;7103259209,60021726;60003398;60003398,2003-01-01,2003,Proceedings of the IEEE International Conference on Computer Vision,15505499,110561,,Conference Proceeding,2,,,734-741,"This paper describes a pedestrian detection system that integrates image intensity information with motion information. We use a detection style algorithm that scans a detector over two consecutive frames of a video sequence. The detector is trained (using AdaBoost) to take advantage of both motion and appearance information to detect a walking person. Past approaches have built detectors based on motion information or detectors based on appearance information, but ours is the first to combine both sources of information in a single detector. The implementation described runs at about 4 frames/second, detects pedestrians at very small scales (as small as 20×15 pixels), and has a very low false positive rate. Our approach builds on the detection work of Viola and Jones. Novel contributions of this paper include: i) development of a representation of image motion which is extremely efficient, and ii) implementation of a state of the art pedestrian detection system which operates on low resolution images under difficult conditions (such as rain and snow).",,1105,0,,,,undefined,,ICCV Computer Vision
2-s2.0-77954517211,10.1145/940071.940104,,,"Eliminating redundancies with a ""composition with adaptation"" meta-programming technique",cp,Conference Paper,Jarzabek S.,60018308;60017161,Xi'an Jiaotong University;National University of Singapore,Xi'an;Singapore City,China;Singapore,2,"Jarzabek, Stan;Shubiao, Li",7004229564;6504795141,60017161;60018308,2003-12-01,2003,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,85109,,Conference Proceeding,,,,237-246,"Redundant code obstructs program understanding and contributes to high maintenance costs. While most experts agree on that, opinions - on how serious the problem of redundancies really is and how to tackle it - differ. In this paper, we present the study of redundancies in the Java Buffer library, JDK 1.4.1, which was recently released by Sun. We found that at least 68% of code in the Buffer library is redundant in the sense that it recurs in many classes in the same or slightly modified form. We effectively eliminated that 68% of code at the meta-level using a technique based on ""composition with adaptation"" called XVCL. We argue that such a program solution is easier to maintain than buffer classes with redundant code. In this experiment, we have designed our meta-representation so that we could produce buffer classes in exactly the same form as they appear in the original Buffer library. While we have been tempted to re-design the buffer classes, we chose not to do so, in order to allow for the seamless integration of the XVCL solution into contemporary programming methodologies and systems. This decision has not affected the essential results reported in this paper. © 2003 ACM.",class libraries | generative programming | meta-programming | object-oriented methods,35,0,,,,undefined,,FSE Software Engineering
2-s2.0-0344120328,,,,"Image parsing: Unifying segmentation, detection, and recognition",cp,Conference Paper,Tu Z.,60027550,"University of California, Los Angeles",Los Angeles,United States,4,"Tu, Zhuowen;Chen, Xiangrong;Yuille, Alan L.;Zhu, Song Chun",7102010636;55739144700;7006372632;22236080700,60027550;60027550;60027550;60027550,2003-12-02,2003,Proceedings of the IEEE International Conference on Computer Vision,,110561,,Conference Proceeding,1,,,18-25,"We propose a general framework for parsing images into regions and objects. In this framework, the detection and recognition of objects proceed simultaneously with image segmentation in a competitive and cooperative manner. We illustrate our approach on natural images of complex, city scenes where the objects of primary interest are faces and text. This method makes use of bottom-up proposals combined with top-down generative models using the Data Driven Markov Chain Monte Carlo (DDMCMC) algorithm which is guaranteed to converge to the optimal estimate asymptotically. More precisely, we define generative models s or faces, text, and generic regions-e.g. shading, texture, and clutter. These models are activated by bottom-up proposals. The proposals for faces and text are learnt using a probabilistic version of AdaBoosi. The DDMCMC combines reversible jump and diffusion dynamics to enable the generative models to explain the input images in a competitive and cooperative manner. Our experiments illustrate the advantages and importance of combining bottom-up and top-down models and of performing segmentation and object detection/recognition simultaneously.",,106,0,,,,undefined,,ICCV Computer Vision
2-s2.0-0344983275,10.1109/iccv.2003.1238625,,,Image-based rendering using image-based priors,cp,Conference Paper,Fitzgibbon A.,60026851;60017563,University of Oxford;Weizmann Institute of Science Israel,Oxford;Rehovot,United Kingdom;Israel,3,"Fitzgibbon, Andrew;Wexler, Yonatan;Zisserman, Andrew",56355070900;6602545985;7006619672,60026851;60017563;60026851,2003-01-01,2003,Proceedings of the IEEE International Conference on Computer Vision,15505499,110561,,Conference Proceeding,2,,,1176-1183,"Given a set of images acquired from known viewpoints, we describe a method for synthesizing the image which would be seen from a new viewpoint. In contrast to existing techniques, which explicitly reconstruct the 3D geometry of the scene, we transform the problem to the reconstruction of colour rather than depth. This retains the benefits of geometric constraints, but projects out the ambiguities in depth estimation which occur in textureless regions. On the other hand, regularization is still needed in order to generate high-quality images. The paper's second contribution is to constrain the generated views to lie in the space of images whose texture statistics are those of the input images. This amounts to a image-based prior on the reconstruction which regularizes the solution, yielding realistic synthetic views. Examples are given of new view generation for cameras interpolated between the acquisition viewpoints-which enables synthetic steadicam stabilisation of a sequence with a high level of realism.",,116,0,,,,undefined,,ICCV Computer Vision
2-s2.0-21644451622,10.1145/1165389.945466,,,Improving the reliability of commodity operating systems,cp,Conference Paper,Swift M.M.,60028661,UW College of Engineering,Seattle,United States,3,"Swift, Michael M.;Bershad, Brian N.;Levy, Henry M.",57209111762;6701383953;7201665633,60028661;60028661;60028661,2003-01-01,2003,Operating Systems Review (ACM),01635980,19829,,Conference Proceeding,37,5,,207-222,"Despite decades of research in extensible operating system technology, extensions such as device drivers remain a significant cause of system failures. In Windows XP, for example, drivers account for 85% of recently reported failures. This paper describes Nooks, a reliability subsystem that seeks to greatly enhance OS reliability by isolating the OS from driver failures. The Nooks approach is practical: rather than guaranteeing complete fault tolerance through a new (and incompatible) OS or driver architecture, our goal is to prevent the vast majority of driver-caused crashes with little or no change to existing driver and system code. To achieve this, Nooks isolates drivers within lightweight protection domains inside the kernel address space, where hardware and software prevent them from corrupting the kernel. Nooks also tracks a driver's use of kernel resources to hasten automatic clean-up during recovery. To prove the viability of our approach, we implemented Nooks in the Linux operating system and used it to fault-isolate several device drivers. Our results show that Nooks offers a substantial increase in the reliability of operating systems, catching and quickly recovering from many faults that would otherwise crash the system. In a series of 2000 fault-injection tests, Nooks recovered automatically from 99% of the faults that caused Linux to crash. While Nooks was designed for drivers, our techniques generalize to other kernel extensions, as well. We demonstrate this by isolating a kernel-mode file system and an in-kernel Internet service. Overall, because Nooks supports existing C-language extensions, runs on a commodity operating system and hardware, and enables automated recovery, it represents a substantial step beyond the specialized architectures and type-safe languages required by previous efforts directed at safe extensibility. Copyright 2003 ACM.",Device Drivers | I/O | Protection | Recovery | Virtual Memory,219,0,repositoryam,Green,,undefined,,SOSP Operating Systems
2-s2.0-33747172362,10.1145/956750.956769,,,Maximizing the spread of influence through a social network,cp,Conference Paper,Kempe D.,60278093,Cornell Ann S. Bowers College of Computing and Information Science,Ithaca,United States,3,"Kempe, David;Kleinberg, Jon;Tardos, Éva",6701573509;7005755823;7003499326,60278093;60278093;60278093,2003-12-01,2003,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,101510,,Conference Proceeding,,,,137-146,"Models for the processes by which ideas and influence propagate through a social network have been studied in a number of domains, including the diffusion of medical and technological innovations, the sudden and widespread adoption of various strategies in game-theoretic settings, and the effects of ""word of mouth"" in the promotion of new products. Recently, motivated by the design of viral marketing strategies, Domingos and Richardson posed a fundamental algorithmic problem for such social network processes: if we can try to convince a subset of individuals to adopt a new product or innovation, and the goal is to trigger a large cascade of further adoptions, which set of individuals should we target?We consider this problem in several of the most widely studied models in social network analysis. The optimization problem of selecting the most influential nodes is NP-hard here, and we provide the first provable approximation guarantees for efficient algorithms. Using an analysis framework based on submodular functions, we show that a natural greedy strategy obtains a solution that is provably within 63% of optimal for several classes of models; our framework suggests a general approach for reasoning about the performance guarantees of algorithms for these types of influence problems in social networks.We also provide computational experiments on large collaboration networks, showing that in addition to their provable guarantees, our approximation algorithms significantly out-perform node-selection heuristics based on the well-studied notions of degree centrality and distance centrality from the field of social networks. Copyright 2003 ACM.",Approximation algorithms | Diffusion of innovations | Social networks | Viral marketing,6351,0,repositoryvor,Green,,undefined,,KDD Data Mining
2-s2.0-0038601527,10.1109/icse.2003.1201217,,,Modular verification of software components in C,cp,Conference Paper,Chaki S.,60027950;60018163,Carnegie Mellon University;Technische Universität Wien,Pittsburgh;Vienna,United States;Austria,5,"Chaki, Sagar;Clarke, Edmund;Groce, Alex;Jha, Somesh;Veith, Helmut",56206720500;56962714000;57204255530;7202728236;7004074558,60027950;60027950;60027950;;60018163,2003-01-01,2003,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,385-395,"We present a new methodology for automatic verification of C programs against finite state machine specifications. Our approach is compositional, naturally enabling us to decompose the verification of large software systems into subproblems of manageable complexity. The decomposition reflects the modularity in the software design. We use weak simulation as the notion of conformance between the program and its specification. Following the abstract-verify-refine paradigm, our tool MAGIC first extracts a finite model from C source code using predicate abstraction and theorem proving. Subsequently, simulation is checked via a reduction to Boolean satisfiability. MAGIC is able to interface with several publicly available theorem provers and SAT solvers. We report experimental results with procedures from the Linux kernel and the OpenSSL toolkit.",,194,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-0037770045,10.1145/780601.780603,,,New lattice based cryptographic constructions,cp,Conference Paper,Regev O.,60027485,Institute for Advanced Study,Princeton,United States,1,"Regev, Oded",7006498283,60027485,2003-01-01,2003,Conference Proceedings of the Annual ACM Symposium on Theory of Computing,07349025,20568,,Conference Proceeding,,,,407-416,"We introduce the use of Fourier analysis on lattices as an integral part of a lattice based construction. The tools we develop provide an elegant description of certain Gaussian distributions around lattice points. Our results include two cryptographic constructions which are based on the worst-case hardness of the unique shortest vector problem. The main result is a new public key cryptosystem whose security guarantee is considerably stronger than previous results (O(n1.5) instead of O(n7)). This provides the first alternative to Ajtai and Dwork's original 1996 cryptosystem. Our second result is a collision resistant hash function which, apart from improving the security in terms of the unique shortest vector problem, is also the first example of an analysis which is not based on Ajtai's iterative step. Surprisingly, the two results are derived from the same tool which presents two indistinguishable distributions on the segment [0,1). It seems that this tool can have further applications and as an example we mention how it can be used to solve an open problem related to quantum computation.",Average-case hardness | Cryptography | Lattices | Public key encryption | Quantum computing,64,0,,,CISE,9987845,Directorate for Computer and Information Science and Engineering,STOC Theory
2-s2.0-0041940256,,,,Object class recognition by unsupervised scale-invariant learning,cp,Conference Paper,Fergus R.,60143898;60026851,California Institute of Technology Division of Engineering and Applied Science;University of Oxford,Pasadena;Oxford,United States;United Kingdom,3,"Fergus, R.;Perona, P.;Zisserman, A.",14821791600;7006384933;7006619672,60026851;60143898;60026851,2003-01-01,2003,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,2,,,,"We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals).",,1677,0,,,,undefined,,CVPR Computer Vision
2-s2.0-0345412664,,,,On the impossibility of dimension reduction in ℓ<inf>1</inf>,cp,Conference Paper,Brinkman B.,60003269,Princeton University,Princeton,United States,2,"Brinkman, Bo;Charikar, Moses",22936694700;7004385858,60003269;60003269,2003-12-02,2003,Annual Symposium on Foundations of Computer Science - Proceedings,02725428,22882,,Conference Proceeding,,,,514-523,"The Johnson-Lindenstrauss Lemma shows that any n points in Euclidean space (with distances measured by the ℓ2 norm) may be mapped down to O((log n)/ε2) dimensions such that no pairwise distance is distorted by more than a (1 + ε) factor. Determining whether such dimension reduction is possible in ℓ1 has been an intriguing open question. We show strong lower bounds for general dimension reduction in ℓ1. We give an explicit family of n points in ℓ1 such that any embedding with distortion δ requires nΩ(1/δ2) dimensions. This proves that there is no analog of the Johnson-Lindenstrauss Lemma for ℓ1; in fact embedding with any constant distortion requires nΩ(1) dimensions. Further, embedding the points into ℓ1 with 1 + ε distortion requires n1/2-O(εlog(1/ε)) dimensions. Our proof establishes this lower bound for shortest path metrics of series-parallel graphs. We make extensive use of linear programming and duality in devising our bounds. We expect that the tools and techniques we develop will be useful for future investigations of embeddings into ℓ1.",,23,0,,,,undefined,,FOCS Theory
2-s2.0-4544387556,10.1145/964696.964717,,,Perceptually-supported image editing of text and graphics,cp,Conference Paper,Saund E.,60028487,Palo Alto Research Center Incorporated,Palo Alto,United States,4,"Saund, Eric;Fleet, David;Larner, Daniel;Mahoney, James",6602158708;57206712712;8416795500;36724837900,60028487;60028487;60028487;60028487,2003-01-01,2003,UIST: Proceedings of the Annual ACM Symposium on User Interface Softaware and Technology,,21101006571,,Conference Proceeding,,,,183-192,"This paper presents a novel image editing program emphasizing easy selection and manipulation of material found in informal, casual documents such as sketches, handwritten notes, whiteboard images, screen snapshots, and scanned documents. The program, called ScanScribe, offers four significant advances. First, it presents a new, intuitive model for maintaining image objects and groups, along with underlying logic for updating these in the course of an editing session. Second, ScanScribe takes advantage of newly developed image processing algorithms to separate foreground markings from a white or light background, and thus can automatically render the background transparent so that image material can be rearranged without occlusion by background pixels. Third, ScanScribe introduces new interface techniques for selecting image objects with a pointing device without resorting to a palette of tool modes. Fourth, ScanScribe presents a platform for exploiting image analysis and recognition methods to make perceptually significant structure readily available to the user. As a research prototype, ScanScribe has proven useful in the work of members of our laboratory, and has been released on a limited basis for user testing and evaluation. © 2003 ACM.",Bitmap image | Foreground/background | Lattice grouping | Perceptual document editing | Rough document | ScanScribe | WYPIWYG,59,0,repositoryam,Green,,undefined,,UIST User Interface
2-s2.0-0038262825,,,,Precise dynamic slicing algorithms,cp,Conference Paper,Zhang X.,60156414;60150072,Erik Jonsson School of Engineering and Computer Science;Department of Computer Science,Richardson;Tucson,United States;United States,3,"Zhang, Xiangyu;Gupta, Rajiv;Zhang, Youtao",56336433500;57222315761;16231855600,60150072;60150072;60156414,2003-07-21,2003,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,319-329,"Dynamic slicing algorithms can greatly reduce the debugging effort by focusing the attention of the user on a relevant subset of program statements. In this paper we present the design and evaluation of three precise dynamic slicing algorithms called the full preprocessing (FP), no preprocessing (NP) and limited preprocessing (LP) algorithms. The algorithms differ in the relative timing of constructing the dynamic data dependence graph and its traversal for computing requested dynamic slices. Our experiments show that the LP algorithm is a fast and practical precise slicing algorithm. In fact we show that while precise slices can be orders of magnitude smaller than imprecise dynamic slices, for small number of slicing requests, the LP algorithm is faster than an imprecise dynamic slicing algorithm proposed by Agrawal and Morgan.",,168,0,,,,undefined,,ICSE Software Engineering
2-s2.0-1542286879,10.1145/940108.940110,,,Predicting Problems Caused by Component Upgrades,cp,Conference Paper,McCamant S.,60006320,MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge,United States,2,"McCamant, Stephen;Ernst, Michael D.",6603114025;36916423000,60006320;60006320,2003-01-01,2003,Proceedings of the Joint European Software Engineering Conference (ESEC) and SIGSOFT Symposium on the Foundations of Software Engineering (FSE-11),,78315,,Conference Proceeding,,,,287-296,"We present a new, automatic technique to assess whether replacing a component of a software system by a purportedly compatible component may change the behavior of the system. The technique operates before integrating the new component into the system or running system tests, permitting quicker and cheaper identification of problems. It takes into account the system's use of the component, because a particular component upgrade may be desirable in one context but undesirable in another. No formal specifications are required, permitting detection of problems due either to errors in the component or to errors in the system. Both external and internal behaviors can be compared, enabling detection of problems that are not immediately reflected in the output. The technique generates an operational abstraction for the old component in the context of the system and generates an operational abstraction for the new component in the context of its test suite; an operational abstraction is a set of program properties that generalizes over observed run-time behavior. If automated logical comparison indicates that the new component does not make all the guarantees that the old one did, then the upgrade may affect system behavior and should not be performed without further scrutiny. In case studies, the technique identified several incompatibilities among software components.",Software components | Software upgrades | Specification matching,37,0,,,,undefined,,FSE Software Engineering
2-s2.0-21644485107,10.1145/1165389.945451,,,Preserving peer replicas by rate-limited sampled voting,cp,Conference Paper,Maniatis P.,60074754;60012708;60010574;60009982,Intel Research Laboratories;Stanford University;Hewlett Packard Laboratories;Harvard University,Santa Clara;Stanford;Palo Alto;Cambridge,United States;United States;United States;United States,6,"Maniatis, Petros;Rosenthal, David S.H.;Roussopoulos, Mema;Baker, Mary;Giuli, T. J.;Muliadi, Yanto",36022707400;35101007400;13906276100;7403074477;15058544100;8507395700,60012708-60074754;60012708;60012708-60009982;60012708-60010574;60012708;60012708,2003-01-01,2003,Operating Systems Review (ACM),01635980,19829,,Conference Proceeding,37,5,,44-59,"The LOCKSS project has developed and deployed in a worldwide test a peer-to-peer system for preserving access to journals and other archival information published on the Web. It consists of a large number of independent, low-cost, persistent web caches that cooperate to detect and repair damage to their content by voting in ""opinion polls."" Based on this experience, we present a design for and simulations of a novel protocol for voting in systems of this kind. It incorporates rate limitation and intrusion detection to ensure that even some very powerful adversaries attacking over many years have only a small probability of causing irrecoverable damage before being detected. Copyright 2003 ACM.",Digital preservation | Rate limiting | Replicated storage,44,0,repositoryam,Green,,undefined,,SOSP Operating Systems
2-s2.0-1542377532,10.1145/860472.860475,,,Re-examining the Potential Effectiveness of Interactive Query Expansion,cp,Conference Paper,Ruthven I.,60024724,University of Strathclyde,Glasgow,United Kingdom,1,"Ruthven, Ian",6603708900,60024724,2003-01-01,2003,SIGIR Forum (ACM Special Interest Group on Information Retrieval),01635840,15745,,Journal,,SPEC. ISS.,,213-220,"Much attention has been paid to the relative effectiveness of interactive query expansion versus automatic query expansion. Although interactive query expansion has the potential to be an effective means of improving a search, in this paper we show that, on average, human searchers are less likely than systems to make good expansion decisions. To enable good expansion decisions, searchers must have adequate instructions on how to use interactive query expansion functionalities. We show that simple instructions on using interactive query expansion do not necessarily help searchers make good expansion decisions and discuss difficulties found in making query expansion decisions.",Evaluation | Query expansion,150,0,repositoryam,Green,,undefined,,SIGIR Information Retrieval
2-s2.0-80053438862,10.1145/775152.775191,,,Scaling personalized web search,cp,Conference Paper,Jeh G.,60012708,Stanford University,Stanford,United States,2,"Jeh, Glen;Widom, Jennifer",6508061042;7006676535,60012708;60012708,2003-12-01,2003,"Proceedings of the 12th International Conference on World Wide Web, WWW 2003",,21100245912,,Conference Proceeding,,,,271-279,"Recent web search techniques augment traditional text matching with a global notion of ""importance"" based on the linkage structure of the web, such as in Google's PageRank algorithm. For more refined searches, this global notion of importance can be specialized to create personalized views of importance - for example, importance scores can be biased according to a user-specified set of initially-interesting pages. Computing and storing all possible personalized views in advance is impractical, as is computing personalized views at query time, since the computation of each view requires an iterative computation over the web graph. We present new graph-theoretical results, and a new technique based on these results, that encode personalized views as partial vectors. Partial vectors are shared across multiple personalized views, and their computation and storage costs scale well with the number of views. Our approach enables incremental computation, so that the construction of personalized views from partial vectors is practical at query time. We present efficient dynamic programming algorithms for computing partial vectors, an algorithm for constructing personalized views from partial vectors, and experimental results demonstrating the effectiveness and scalability of our techniques.",PageRank | web search,830,0,,,NSF,IIS-9817799,National Science Foundation,WWW World Wide Web
2-s2.0-29344454459,10.1145/775152.775178,,,SemTag and seeker: Bootstrapping the semantic web via automated semantic annotation,cp,Conference Paper,Dill S.,60009253,IBM Research - Almaden,San Jose,United States,11,"Dill, Stephen;Eiron, Nadav;Gibson, David;Gruhl, Daniel;Guha, R.;Jhingran, Anant;Kanungo, Tapas;Rajagopalan, Sridhar;Tomkins, Andrew;Tomlin, John A.;Zien, Jason Y.",56122552900;6602376245;7401626295;6603111677;8380044400;7003418795;7003566049;43661666500;57200940123;7003275173;6602728014,60009253;60009253;60009253;60009253;60009253;60009253;60009253;60009253;60009253;60009253;60009253,2003-12-01,2003,"Proceedings of the 12th International Conference on World Wide Web, WWW 2003",,21100245912,,Conference Proceeding,,,,178-186,"This paper describes Seeker, a platform for large-scale text analytics, and SemTag, an application written on the platform to perform automated semantic tagging of large corpora. We apply SemTag to a collection of approximately 264 million web pages, and generate approximately 434 million automatically disambiguated semantic tags, published to the web as a label bureau providing metadata regarding the 434 million annotations. To our knowledge, this is the largest scale semantic tagging effort to date.We describe the Seeker platform, discuss the architecture of the SemTag application, describe a new disambiguation algorithm specialized to support ontological disambiguation of large-scale data, evaluate the algorithm, and present our final results with information about acquiring and making use of the semantic tags. We argue that automated large scale semantic tagging of ambiguous content can bootstrap and accelerate the creation of the semantic web.",automated semantic tagging | data mining | information retrieval | large text datasets | text analytics,332,0,,,,undefined,,WWW World Wide Web
2-s2.0-1142291603,10.1145/872766.872767,,,Spreadsheets in RDBMS for OLAP,cp,Conference Paper,Witkowski A.,,,,,8,"Witkowski, Andrew;Bellamkonda, Srikanth;Bozkaya, Tolga;Dorman, Gregory;Folkert, Nathan;Gupta, Abhinav;Shen, Lei;Subramanian, Sankar",7005762600;6505998246;6602294122;7004277664;8542114400;55574223476;7401704045;36857840500,,2003-01-01,2003,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,52-63,"One of the critical deficiencies of SQL is lack of support for n-dimensional array-based computations which are frequent in OLAP environments. Relational OLAP (ROLAP) applications have to emulate them using joins, recently introduced SQL Window Functions and complex and inefficient CASE expressions. The designated place in SQL for specifying calculations is the SELECT clause, which is extremely limiting and forces the user to generate queries using nested views, subqueries and complex joins. Furthermore, SQL-query optimizer is pre-occupied with determining efficient join orders and choosing optimal access methods and largely disregards optimization of complex numerical formulas. Execution methods concentrated on efficient computation of a cube rather than on random access structures for inter-row calculations. This has created a gap that has been filled by spreadsheets and specialized MOLAP engines, which are good at formulas for mathematical modeling but lack the formalism of the relational model, are difficult to manage, and exhibit scalability problems. This paper presents SQL extensions involving array based calculations for complex modeling. In addition, we present optimizations, access structures and execution models for processing them efficiently.",,50,0,,,,undefined,,SIGMOD Databases
2-s2.0-84880794510,,,,Thin junction tree filters for simultaneous localization and mapping,cp,Conference Paper,Paskin M.,60025038,"University of California, Berkeley",Berkeley,United States,1,"Paskin, Mark A.",6506017431,60025038,2003-12-01,2003,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,1157-1164,"Simultaneous Localization and Mapping (SLAM) is a fundamental problem in mobile robotics: while a robot navigates in an unknown environment, it must incrementally build a map of its surroundings and, at the same time, localize itself within that map. One popular solution is to treat SLAM as an estimation problem and apply the Kalman filter; this approach is elegant, but it does not scale well: the size of the belief state and the time complexity of the filter update both grow quadratically in the number of landmarks in the map. This paper presents a filtering technique that maintains a tractable approximation of the belief state as a thin junction tree. The junction tree grows under filter updates and is periodically ""thinned"" via efficient maximum likelihood projections so inference remains tractable. When applied to the SLAM problem, these thin junction tree filters have a linearspace belief state and a linear-time filtering operation. Further approximation yields a filtering operation that is often constant-time. Experiments on a suite of SLAM problems validate the approach.",,131,0,,,,undefined,Intel Corporation,IJCAI Artificial Intelligence
2-s2.0-84872694394,,,,Towards a model of face-to-face grounding,cp,Conference Paper,Nakano Y.I.,60015682;60002243,Japan Science and Technology Agency;MIT Media Lab,Kawaguchi;Cambridge,Japan;United States,4,"Nakano, Yukiko I.;Reinstein, Gabe;Stocky, Tom;Cassell, Justine",57210545823;58122101400;36922877300;7005656578,60002243-60015682;60002243;60002243;60002243,2003-01-01,2003,Proceedings of the Annual Meeting of the Association for Computational Linguistics,0736587X,21101138302,,Conference Proceeding,2003-July,,,,"We investigate the verbal and nonverbal means for grounding, and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction. We analyzed eye gaze, head nods and attentional focus in the context of a direction-giving task. The distribution of nonverbal behaviors differed depending on the type of dialogue move being grounded, and the overall pattern reflected a monitoring of lack of negative feedback. Based on these results, we present an ECA that uses verbal and nonverbal grounding acts to update dialogue state.",,165,0,,,,undefined,University of Tokyo,ACL Natural Language Processing
2-s2.0-0042475172,,,,User-level performance of channel-aware scheduling algorithms in wireless data networks,cp,Conference Paper,Borst S.,60032882;60021378;60011575,Technische Universiteit Eindhoven;Nokia Bell Labs;Centrum Wiskunde &amp; Informatica,Eindhoven;Murray;Amsterdam,Netherlands;United States;Netherlands,1,"Borst, Sem",7005829058,60021378-60011575-60032882,2003-09-01,2003,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,1,,,321-331,"Channel-aware scheduling strategies, such as the Proportional Fair algorithm for the CDMA 1xEV-DO system, provide an effective mechanism for improving throughput performance in wireless data networks by exploiting channel fluctuations. The performance of channel-aware scheduling algorithms has mostly been explored at the packet level for a static user population, often assuming infinite backlogs. In the present paper, we focus on the performance at the flow level in a dynamic setting with random finite-size service demands. We show that in certain cases the user-level performance may be evaluated by means of a multi-class Processor-Sharing model where the total service rate varies with the total number of users. The latter model provides explicit formulas for the distribution of the number of active users of the various classes, the mean response times, the blocking probabilities, and the mean throughput In addition we show that, in the presence of channel variations, greedy, myopic strategies which maximize throughput in a static scenario, may result in sub-optimal throughput performance for a dynamic user configuration and cause potential instability effects.",Channel-aware scheduling | Elastic traffic | Insensitivity | Processor Sharing | Proportional Fair scheduling | Response time | Stability | Throughput optimization | Wireless data networks,261,0,,,,undefined,,INFOCOM Networking
2-s2.0-20344393644,10.1145/1041685.1029917,,,A classification system and analysis for aspect-oriented programs,cp,Conference Paper,Rinard M.,60022195,Massachusetts Institute of Technology,Cambridge,United States,3,"Rinard, Martin;Sǎlcianu, Alexandru;Bugrara, Suhabe",7003321126;6505898305;23017950000,60022195;60022195;60022195,2004-01-01,2004,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100989386,,Conference Proceeding,,,,147-158,"We present a new classification system for aspect-oriented programs. This system characterizes the interactions between aspects and methods and identifies classes of interactions that enable modular reasoning about the crosscut program. We argue that this system can help developers structure their understanding of aspect-oriented programs and promotes their ability to reason productively about the consequences of crosscutting a program with a given aspect. We have designed and implemented a program analysis system that automatically classifies interactions between aspects and methods and have applied this analysis to a set of benchmark programs. We found that our analysis is able to 1) identify interactions with desirable properties (such as lack of interference), 2) identify potentially problematic interactions (such as interference caused by the aspect and the method both writing the same field), and 3) direct the developer's attention to the causes of such interactions. Copyright 2004 ACM.",Aspect oriented programming | Program analysis,119,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-8644248346,10.1145/1008992.1009004,,,A formal study of information retrieval heuristics,cp,Conference Paper,Fang H.,60000745,University of Illinois Urbana-Champaign,Urbana,United States,3,"Fang, Hui;Tao, Tao;Zhai, Cheng Xiang",55316817500;55286088800;35232046000,60000745;60000745;60000745,2004-01-01,2004,Proceedings of Sheffield SIGIR - Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,,21100988486,,Conference Proceeding,,,,49-56,"Empirical studies of information retrieval methods show that good retrieval performance is closely related to the use of various retrieval heuristics, such as TF-IDF weighting. One basic research question is thus what exactly are these ""necessary"" heuristics that seem to cause good retrieval performance. In this paper, we present a formal study of retrieval heuristics. We formally define a set of basic desirable constraints that any reasonable retrieval function should satisfy, and check these constraints on a variety of representative retrieval functions. We find that none of these retrieval functions satisfies all the constraints unconditionally. Empirical results show that when a constraint is not satisfied, it often indicates non-optimality of the method, and when a constraint is satisfied only for a certain range of parameter values, its performance tends to be poor when the parameter is out of the range. In general, we find that the empirical performance of a retrieval formula is tightly related to how well it satisfies these constraints. Thus the proposed constraints provide a good explanation of many empirical observations and make it possible to evaluate any existing or new retrieval formula analytically.",Constraints | Formal models | Retrieval heuristics | TF-IDF weighting,255,0,,,,undefined,,SIGIR Information Retrieval
2-s2.0-4544236510,,,,A tool for writing and debugging algebraic specifications,cp,Conference Paper,Henkel J.,,,,,2,"Henkel, Johannes;Diwan, Amer",7007090134;7005769796,,2004-09-29,2004,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,26,,,449-458,"Despite their benefits, programmers rarely use formal specifications, because they are difficult to write and they require an up front investment in time. To address these issues, we present a tool that helps programmers write and debug algebraic specifications. Given an algebraic specification, our tool instantiates a prototype that can be used just like any regular Java class. The tool can also modify an existing application to use the prototype generated by the interpreter instead of a hand-coded implementation. The tool improves the usability of algebraic specifications in the following ways: (i) A programmer can ""run"" an algebraic specification to study its behavior. The tool reports in which way a specification is incomplete for a client application. (ii) The tool can check whether a specification and a hand-coded implementation behave the same for a particular run of a client application. (iii) A prototype can be used when a hand-coded implementation is not yet available. Two case studies demonstrate how to use the tool.",,20,0,,,,undefined,,ICSE Software Engineering
2-s2.0-12244300524,10.1145/1014052.1014062,,,A probabilistic framework for semi-supervised clustering,cp,Conference Paper,Basu S.,60150459,Department of Computer Science,Austin,United States,3,"Basu, Sugato;Bilenko, Mikhail;Mooney, Raymond J.",7403655931;7006143034;7102791999,60150459;60150459;60150459,2004-01-01,2004,KDD-2004 - Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,120062,,Conference Proceeding,,,,59-68,"Unsupervised clustering can be significantly improved using supervision in the form of pairwise constraints, i.e., pairs of instances labeled as belonging to same or different clusters. In recent years, a number of algorithms have been proposed for enhancing clustering quality by employing such supervision. Such methods use the constraints to either modify the objective function, or to learn the distance measure. We propose a probabilistic model for semi-supervised clustering based on Hidden Markov Random Fields (HMRFs) that provides a principled framework for incorporating supervision into prototype-based clustering. The model generalizes a previous approach that combines constraints and Euclidean distance learning, and allows the use of a broad range of clustering distortion measures, including Bregman divergences (e.g., Euclidean distance and I-divergence) and directional similarity measures (e.g., cosine similarity). We present an algorithm that performs partitional semi-supervised clustering of data by minimizing an objective function derived from the posterior energy of the HMRF model. Experimental results on several text data sets demonstrate the advantages of the proposed framework.",Distance Metric Learning | Hidden Markov Random Fields | Semi-supervised Clustering,653,0,,,,undefined,,KDD Data Mining
2-s2.0-4544225763,,,,An empirical study of software reuse vs. defect-density and stability,cp,Conference Paper,Mohagheghi P.,60013141;60000645;100721306,Norges Teknisk-Naturvitenskapelige Universitet;Simula Research Laboratory;Ericsson Norway-Grimstad,Trondheim;Barum;Grimstad,Norway;Norway;Norway,4,"Mohagheghi, Parastoo;Conradi, Reidar;Killi, Ole M.;Schwarz, Henrik",12645532100;35606380100;6504108007;57549042000,100721306-60013141-60000645;60013141-60000645;60013141;60013141,2004-09-29,2004,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,26,,,282-291,"The paper describes results of an empirical study, where some hypotheses about the impact of reuse on defect-density and stability, and about the impact of component size on defects and defect-density in the context of reuse are assessed, using historical data (""data mining"") on defects, modification rate, and software size of a large-scale telecom system developed by Ericsson. The analysis showed that reused components have lower defect-density than non-reused ones. Reused components have more defects with highest severity than the total distribution, but less defects after delivery, which shows that that these are given higher priority to fix. There are an increasing number of defects with component size for non-reused components, but not for reused components. Reused components were less modified (more stable) than non-reused ones between successive releases, even if reused components must incorporate evolving requirements from several application products. The study furthermore revealed inconsistencies and weaknesses in the existing defect reporting system, by analyzing data that was hardly treated systematically before.",,112,0,,,,undefined,,ICSE Software Engineering
2-s2.0-18744380220,10.1145/988672.988732,,,Automatic detection of fragments in dynamically generated web pages,cp,Conference Paper,Ramaswamy L.,60097290;60017366,College of Computing;IBM Thomas J. Watson Research Center,Atlanta;Yorktown Heights,United States;United States,4,"Ramaswamy, Lakshmish;Iyengar, Arun;Liu, Ling;Douglis, Fred",16069392500;7005401000;55628583368;57204492266,60097290;60017366;60097290;60017366,2004-01-01,2004,"Thirteenth International World Wide Web Conference Proceedings, WWW2004",,21101013114,,Conference Proceeding,,,,443-454,"Dividing web pages into fragments has been shown to provide significant benefits for both content generation and caching. In order for a web site to use fragment-based content generation, however, good methods are needed for dividing web pages into fragments. Manual fragmentation of web pages is expensive, error prone, and unscalable. This paper proposes a novel scheme to automatically detect and flag fragments that are cost-effective cache units in web sites serving dynamic content. We consider the fragments to be interesting if they are shared among multiple documents or they have different lifetime or personalization characteristics. Our approach has three unique features. First, we propose a hierarchical and fragment-aware model of the dynamic web pages and a data structure that is compact and effective for fragment detection. Second, we present an efficient algorithm to detect maximal fragments that are shared among multiple documents. Third, we develop a practical algorithm that effectively detects fragments based on their lifetime and personalization characteristics. We evaluate the proposed scheme through a series of experiments, showing the benefits and costs of the algorithms. We also study the impact of adopting the fragments detected by our system on disk space utilization and network bandwidth consumption.",Dynamic content caching | Fragment detection | Fragment-based caching | L-P fragments | Shared fragments,51,0,,,,undefined,,WWW World Wide Web
2-s2.0-8344251741,10.1145/996841.996859,,,Cloning-based context-sensitive pointer alias analysis using binary decision diagrams,cp,Conference Paper,Whaley J.,60141508,Stanford Engineering,Stanford,United States,2,"Whaley, John;Lam, Monica S.",56212539300;7202630166,60141508;60141508,2004-01-01,2004,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,1,,,131-144,"This paper presents the first scalable context-sensitive, inclusion-based pointer alias analysis for Java programs. Our approach to context sensitivity is to create a clone of a method for every context of interest, and run a context-insensitive algorithm over the expanded call graph to get context-sensitive results. For precision, we generate a clone for every acyclic path through a program's call graph, treating methods in a strongly connected component as a single node. Normally, this formulation is hopelessly intractable as a call graph often has 1014 acyclic paths or more. We show that these exponential relations can be computed efficiently using binary decision diagrams (BDDs). Key to the scalability of the technique is a context numbering scheme that exposes the commonalities across contexts. We applied our algorithm to the most popular applications available on Sourceforge, and found that the largest programs, with hundreds of thousands of Java bytecodes, can be analyzed in under 20 minutes. This paper shows that pointer analysis, and many other queries and algorithms, can be described succinctly and declaratively using Datalog, a logic programming language. We have developed a system called bddbddb that automatically translates Datalog programs into highly efficient BDD implementations. We used this approach to develop a variety of context-sensitive algorithms including side effect analysis, type analysis, and escape analysis.",Binary decision diagrams | Cloning | Context-sensitive | Datalog | Inclusion-based | Java | Logic programming | Pointer analysis | Program analysis | Scalable,278,0,repositoryam,Green,,undefined,,PLDI Programming Languages
2-s2.0-3142685198,10.1145/1055558.1055562,,,"Conditional XPath, the first order complete XPath dialect",cp,Conference Paper,Marx M.,60002483,Universiteit van Amsterdam,Amsterdam,Netherlands,1,"Marx, Maarten",7202187622,60002483,2004-01-01,2004,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,23,,,13-22,"XPath is the W3C-standard node addressing language for XML documents. XPath is still under development and its technical aspects are intensively studied. What is missing at present is a clear characterization of the expressive power of XPath, be it either semantical or with reference to some well established existing (logical) formalism. Core XPath (the logical core of XPath 1.0 defined by Gottlob et al.) cannot express queries with conditional paths as exemplified by ""do a child step, while test is true at the resulting node."" In a first-order complete extension of Core XPath, such queries are expressible. We add conditional axis relations to Core XPath and show that the resulting language, called conditional XPath, is equally expressive as first-order logic when interpreted on ordered trees. Both the result, the extended XPath language, and the proof are closely related to temporal logic. Specifically, while Core XPath may be viewed as a simple temporal logic, conditional XPath extends this with (counterparts of) the since and until operators.",,37,0,,,,undefined,,PODS Databases
2-s2.0-20344394454,,,,CrossY: A crossing-based drawing application,cp,Conference Paper,Apitz G.,60151568,Department of Computer Science,College Park,United States,2,"Apitz, Georg;Guimbretiére, François",8229785100;6508204254,60151568;60151568,2004-12-01,2004,UIST: Proceedings of the Annual ACM Symposium on User Interface Softaware and Technology,,21100524244,,Conference Proceeding,,,,3-12,"We introduce CrossY, a simple drawing application developed as a benchmark to demonstrate the feasibility of goal crossing as the basis for a graphical user interface. We show that crossing is not only as expressive as the current point-and-click interface, but also offers more flexibility in interaction design. In particular, crossing encourages the fluid composition of commands which supports the development of more fluid interfaces. While crossing was previously identified as a potential substitute for the classic point-and-click interaction, this work is the first to report on the practical aspects of implementing an interface based on goal crossing as the fundamental building block. Copyright © 2004 ACM.",Command composition | Crossing based interfaces | Fluid interaction | Pen-computing,119,0,,,,undefined,,UIST User Interface
2-s2.0-77955319555,10.1007/978-3-642-14165-2_14,,,From secrecy to soundness: Efficient verification via secure computation,cp,Conference Paper,Applebaum B.,60027550;60022403;60017563,"University of California, Los Angeles;Technion - Israel Institute of Technology;Weizmann Institute of Science Israel",Los Angeles;Haifa;Rehovot,United States;Israel;Israel,3,"Applebaum, Benny;Ishai, Yuval;Kushilevitz, Eyal",9133797100;6701668717;7005357536,60017563;60022403-60027550;60022403,2010-08-12,2010,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),03029743,25674,16113349,Book Series,6198 LNCS,PART 1,,152-163,"We study the problem of verifiable computation (VC) in which a computationally weak client wishes to delegate the computation of a function f on an input x to a computationally strong but untrusted server. We present new general approaches for constructing VC protocols, as well as solving the related problems of program checking and self-correcting. The new approaches reduce the task of verifiable computation to suitable variants of secure multiparty computation (MPC) protocols. In particular, we show how to efficiently convert the secrecy property of MPC protocols into soundness of a VC protocol via the use of a message authentication code (MAC). The new connections allow us to apply results from the area of MPC towards simplifying, unifying, and improving over previous results on VC and related problems. In particular, we obtain the following concrete applications: (1) The first VC protocols for arithmetic computations which only make a black-box use of the underlying field or ring; (2) a non-interactive VC protocol for boolean circuits in the preprocessing model, conceptually simplifying and improving the online complexity of a recent protocol of Gennaro et al. (Cryptology ePrint Archive: Report 2009/547); (3) NC0 self-correctors for complete languages in the complexity class NC1 and various log-space classes, strengthening previous AC 0 correctors of Goldwasser et al. (STOC 2008). © 2010 Springer-Verlag Berlin Heidelberg.",,137,0,,,,undefined,,FOCS Theory
2-s2.0-18744403708,10.1145/1031171.1031210,,,Discovering frequently changing structures from historical structural deltas of unordered XML,cp,Conference Paper,Zhao Q.,60011001;60005510;60003329,Kyoto University;Nanyang Technological University;IBM Research - India,Kyoto;Singapore City;Bengaluru,Japan;Singapore;India,4,"Zhao, Qiankun;Bhowmick, Sourav S.;Mghania, Mukesh;Kambayashi, Yahiko",8730385600;7006796096;8419442100;35577315600,60005510;60005510;60003329;60011001,2004-01-01,2004,"International Conference on Information and Knowledge Management, Proceedings",,55826,,Conference Proceeding,,,,188-197,"Recently, a large amount of work has been done in XML data mining. However, we observed that most of the existing works focus on the snapshot XML data, while XML data is dynamic in real applications. To the best of our knowledge, none of the existing works has addressed the issue of mining the history of changes to XML documents. Such mining results can be useful in many applications such as XML change detection, XML indexing, association rule mining, and classification etc. In this paper, we propose a novel approach to discover the frequently changing structures from the sequence of historical structural deltas of unordered XML. To make the structure discovering process efficient, an expressive and compact data model, Historical-Document Object Model (H-DOM), is proposed. Using this model, two basic algorithms, which can discover all the frequently changing structures with only two scans of the XML sequence, are presented. Experimental results show that our algorithms, together with the optimization techniques, are efficient and scalable. Copyright 2004 ACM.",Data mining | XML,11,0,,,,undefined,,CIKM Knowledge Management
2-s2.0-4544250512,10.1145/1007352.1007355,,,"Expander flows, geometric embeddings and graph partitioning",cp,Conference Paper,Arora S.,60141284;60025038,"School of Engineering and Applied Science;University of California, Berkeley",Princeton;Berkeley,United States;United States,3,"Arora, Sanjeev;Rao, Satish;Vazirani, Umesh",7202419160;7404174770;7003318617,60141284;60025038;60025038,2004-01-01,2004,Conference Proceedings of the Annual ACM Symposium on Theory of Computing,07349025,20568,,Conference Proceeding,,,,222-231,"We give a O(√log n)-approximation algorithm for SPARS-EST CUT, BALANCED SEPARATOR, and GRAPH CONDUCTANCE problems. This improves the O(log n)-approximation of Leighton and Rao (1988). We use a well-known semidefinite relaxation with triangle inequality constraints. Central to our analysis is a geometric theorem about projections of point sets in ℜd, whose proof makes essential use of a phenomenon called measure concentration. We also describe an interesting and natural ""certificate"" for a graph's expansion, by embedding an n-node expander in it with appropriate dilation and congestion. We call this an expander flow.",Approximation algorithms | Clustering | Conductance | Eigenvalues | Embedding | Expander | Graph partitioning | Normalized cuts | Semidefinite programming | Sparsest cuts | Spectral methods,239,0,repositoryam,Green,,undefined,,STOC Theory
2-s2.0-4544347694,,,,Extending the REpresentational State Transfer (REST) architectural style for decentralized systems,cp,Conference Paper,Khare R.,60007278,"University of California, Irvine",Irvine,United States,2,"Khare, Rohit;Taylor, Richard N.",7006838425;57202910394,60007278;60007278,2004-09-29,2004,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,26,,,428-437,"Because it takes time and trust to establish agreement, traditional consensus-based architectural styles cannot safely accommodate resources that change faster than it takes to transmit notification of that change, nor resources that must be shared across independent agencies. The alternative is decentralization: permitting independent agencies to make their own decisions. Our definition contrasts with that of distribution, in which several agents share control of a single decision. Ultimately, the physical limits of network latency and the social limits of independent agency call for solutions that can accommodate multiple values for the same variable. Our approach to this challenge is architectural: proposing constraints on the configuration of components and connectors to induce particular desired properties of the whole application. Specifically, we present, implement, and evaluate variations of the World Wide Web's REpresentational State Transfer (REST) architectural style that support distributed and decentralized systems.",,65,0,,,,undefined,,ICSE Software Engineering
2-s2.0-85149116612,,,,Finding predominant word senses in untagged text,cp,Conference Paper,McCarthy D.,60017317,University of Sussex,Brighton,United Kingdom,4,"McCarthy, Diana;Koeling, Rob;Weeds, Julie;Carroll, John",15056218400;22734282200;13405645700;35301562500,60017317;60017317;60017317;60017317,2004-01-01,2004,Proceedings of the Annual Meeting of the Association for Computational Linguistics,0736587X,21101138302,,Conference Proceeding,,,,279-286,"In word sense disambiguation (WSD), the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed. The problem with using the predominant, or first sense heuristic, aside from the fact that it does not take surrounding context into account, is that it assumes some quantity of hand-tagged data. Whilst there are a few hand-tagged corpora available for some languages, one would expect the frequency distribution of the senses of words, particularly topical words, to depend on the genre and domain of the text under consideration. We present work on the use of a thesaurus acquired from raw textual corpora and the WordNet similarity package to find predominant noun senses automatically. The acquired predominant senses give a precision of 64% on the nouns of the SENSEVAL-2 English all-words task. This is a very promising result given that our method does not require any hand-tagged text, such as SemCor. Furthermore, we demonstrate that our method discovers appropriate predominant senses for words from two domain-specific corpora.",,246,0,,,,undefined,,ACL Natural Language Processing
2-s2.0-17744386194,,,,Hardness of approximating the shortest vector problem in lattices,cp,Conference Paper,Khot S.,60027485;60019647,Institute for Advanced Study;Georgia Institute of Technology,Princeton;Atlanta,United States;United States,1,"Khot, Subhash",6701814147,60027485-60019647,2004-12-01,2004,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,,,,126-135,"Let p > 1 be any fixed real. We show that assuming NP ⊂ RP, it is hard to approximate the Shortest Vector Problem (SVP) in l p norm within an arbitrarily large constant factor. Under the stronger assumption NP ⊂ RTIME(2 poly((lop n)), we show that the problem is hard to approximate within factor 2(log n) 1/2-ε where n is the dimension of the lattice and ε > 0 is an arbitrarily small constant. This greatly improves all previous results in p norms with 1 < p < ∞. The best results so far gave only a constant factor hardness, namely, 2 1/p - ε by Micciancio [27] and 1/ε in high l p norms by Knot [20]. We first give a new (randomized) reduction from Closest Vector Problem (CVP) to SVP that achieves some constant factor hardness. The reduction is based on BCH Codes. Its advantage is that the SVP instances produced by the reduction behave well under the augmented tensor product, a new variant of tensor product that we introduce. This enables us to boost the hardness factor to 2(log n) 1/2-ε. © 2004 IEEE.",,36,0,,,,undefined,,FOCS Theory
2-s2.0-3142777878,10.1145/1007568.1007636,,,Indexing spatio-temporal trajectories with Chebyshev polynomials,cp,Conference Paper,Cai Y.,60010365,The University of British Columbia,Vancouver,Canada,2,"Cai, Yuhan;Ng, Raymond",10739321100;7102153783,60010365;60010365,2004-01-01,2004,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,599-610,"In this paper, we attempt to approximate and index a d-dimensional (d ≥ 1) spatio-temporal trajectory with a low order continuous polynomial. There are many possible ways to choose the polynomial, including (continuous) Fourier transforms, splines, non-linear regression, etc. Some of these possibilities have indeed been studied before. We hypothesize that one of the best possibilities is the polynomial that minimizes the maximum deviation from the true value, which is called the minimax polynomial. Minimax approximation is particularly meaningful for indexing because in a branch-and-bound search (i.e., for finding nearest neighbours), the smaller the maximum deviation, the more pruning opportunities there exist. However, in general, among all the polynomials of the same degree, the optimal minimax polynomial is very hard to compute. However, it has been shown that the Chebyshev approximation is almost identical to the optimal minimax polynomial, and is easy to compute. Thus, in this paper, we explore how to use the Chebyshev polynomials as a basis for approximating and indexing d-dimensional trajectories. The key analytic result of this paper is the Lower Bounding Lemma. That is, we show that the Euclidean distance between two d-dimensional trajectories is lower bounded by the weighted Euclidean distance between the two vectors of Chebyshev coefficients. This lemma is not trivial to show, and it ensures that indexing with Chebyshev coefficients admits no false negatives. To complement the analytic result, we conducted comprehensive experimental evaluation with real and generated 1-dimensional to 4-dimensional data sets. We compared the proposed scheme with the Adaptive Piece-wise Constant Approximation (APCA) scheme. Our preliminary results indicate that in all situations we tested, Chebyshev indexing dominates APCA in pruning power, I/O and CPU costs.",,256,0,repositoryam,Green,,undefined,,SIGMOD Databases
2-s2.0-9444284310,,,,Learning and inferring transportation routines,cp,Conference Paper,Liao L.,60028661,UW College of Engineering,Seattle,United States,3,"Liao, Lin;Fox, Dieter;Kautz, Henry",18836557000;7402074129;7005697997,60028661;60028661;60028661,2004-12-09,2004,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,,,,348-353,This paper introduces a hierarchical Markov model that can learn and infer a user's daily movements through the community. The model uses multiple levels of abstraction in order to bridge the gap between raw GPS sensor measurements and high level information such as a user's mode of transportation or her goal. We apply Rao-Blackwellised particle filters for efficient inference both at the low level and at the higher levels of the hierarchy. Significant locations such as goals or locations where the user frequently changes mode of transportation are learned from GPS data logs without requiring any manual labeling. We show how to detect abnormal behaviors (e.g. taking a wrong bus) by concurrently tracking his activities with a trained and a prior model. Experiments show that our model is able to accurately predict the goals of a person and to recognize situations in which the user performs unknown activities.,,175,0,,,NSF,IIS-0093406,National Science Foundation,AAAI Artificial Intelligence
2-s2.0-77954442172,10.1016/B978-012088469-8.50053-X,,,Model-Driven Data Acquisition in Sensor Networks,ch,Book Chapter,Deshpande A.,60074754;60025038;60022195,"Intel Research Laboratories;University of California, Berkeley;Massachusetts Institute of Technology",Santa Clara;Berkeley;Cambridge,United States;United States;United States,5,"Deshpande, Amol;Hellerstein, Joseph M.;Guestrin, Carlos;Madden, Samuel R.;Hong, Wei",9734842400;35561994000;57195906692;7007132780;57210548753,60025038;60025038-60074754;60074754;60074754-60022195;60074754,2004-01-01,1 January 2004,Proceedings 2004 VLDB Conference: The 30th International Conference on Very Large Databases (VLDB),,21101101256,,Book,,,,588-599,"This chapter presents an interactive sensor querying with statistical modeling techniques. Declarative queries are proving to be an attractive paradigm for interacting with networks of wireless sensors. The metaphor that “the sensomet is a database” is problematic, however, because sensors do not exhaustively represent the data in the real world. In order to map the raw sensor readings onto physical reality, a model of that reality is required to complement the readings. The chapter analyzes that such models can help provide solutions that are both more meaningful, and, by introducing approximations with probabilistic confidences, significantly more efficient to compute in both time and energy. The chapter describes an exponential time algorithm for finding the optimal solution to the optimization problem, and a polynomial-time heuristic for identifying solutions that perform well in practice. It evaluates the approach on several real-world sensor-network data sets, taking into account the real measured data and communication quality. The chapter concludes that this model-based approach provides a high-fidelity representation of the real phenomena and leads to significant performance gains in comparison to traditional data acquisition techniques.",,828,0,repositoryam,Green,,undefined,,VLDB Databases
2-s2.0-20344395152,10.1145/1029632.1029644,,,Multi-finger gestural interaction with 3D volumetric displays,cp,Conference Paper,Grossman T.,60016849,University of Toronto,Toronto,Canada,3,"Grossman, Tovi;Wigdor, Daniel;Balakrishnan, Ravin",7003520062;6507569914;7006221860,60016849;60016849;60016849,2004-01-01,2004,UIST: Proceedings of the Annual ACM Symposium on User Interface Softaware and Technology,,21101006687,,Conference Proceeding,,,,61-70,"Volumetric displays provide interesting opportunities and challenges for 3D interaction and visualization, particularly when used in a highly interactive manner. We explore this area through the design and implementation of techniques for interactive direct manipulation of objects with a 3D volumetric display. Motion tracking of the user's fingers provides for direct gestural interaction with the virtual objects, through manipulations on and around the display's hemispheric enclosure. Our techniques leverage the unique features of volumetric displays, including a 360° viewing volume that enables manipulation from any viewpoint around the display, as well as natural and accurate perception of true depth information in the displayed 3D scene. We demonstrate our techniques within a prototype 3D geometric model building application. Copyright © 2004 ACM.",3D interaction | Multi-finger and two-handed gestural input | Volumetric display,153,0,repositoryam,Green,,undefined,,UIST User Interface
2-s2.0-4544258177,10.1145/1007352.1007353,,,Multi-linear formulas for permanent and determinant are of super-Polynomial size,cp,Conference Paper,Raz R.,60017563,Weizmann Institute of Science Israel,Rehovot,Israel,1,"Raz, Ran",7102829173,60017563,2004-01-01,2004,Conference Proceedings of the Annual ACM Symposium on Theory of Computing,07349025,20568,,Conference Proceeding,,,,633-641,"An arithmetic formula is multi-linear if the polynomial computed by each of its sub-formulas is multi-linear. We prove that any multi-linear arithmetic formula for the permanent or the determinant of an n × n matrix is of size super-polynomial in n. Previously, super-polynomial lower bounds were not known (for any explicit function) even for the special case of multi-linear formulas of constant depth.",Algebraic complexity | Arithmetic formulas | Circuit complexity | Computational complexity | Lower bounds,41,0,,,,undefined,,STOC Theory
2-s2.0-8344286433,10.1145/1012888.1005716,,,On performance bounds for the integration of elastic and adaptive streaming flows,cp,Conference Paper,Bonald T.,60104081,Orange Labs,Issy-les-Moulineaux,France,2,"Bonald, Thomas;Proutière, Alexandre",6603808064;6603905943,60104081;60104081,2004-01-01,2004,Performance Evaluation Review,01635999,26742,,Conference Proceeding,32,1,,235-245,"We consider a network model where bandwidth is fairly shared by a dynamic number of elastic and adaptive streaming flows. Elastic flows correspond to data transfers while adaptive streaming flows correspond to audio/video applications with variable rate codecs. In particular, the former are characterized by a fixed size (in bits) while the latter are characterized by a fixed duration. This flow-level model turns out to be intractable in general. In this paper, we give performance bounds for both elastic and streaming traffic by means of sample-path arguments. These bounds present the practical interest of being insensitive to traffic characteristics like the distributions of elastic flow size and streaming flow duration.",Adaptive streaming traffic | Elastic traffic | Flow-level analysis | Insensitive bounds | Multi-service network,40,0,repositoryam,Green,,undefined,,SIGMETRICS Performance
2-s2.0-5044222279,,,,Programmable imaging using a digital micromirror array,cp,Conference Paper,Nayar S.K.,60031321;60010265,The Fu Foundation School of Engineering and Applied Science;University of Colorado at Colorado Springs,New York;Colorado Springs,United States;United States,3,"Nayar, Shree K.;Branzoi, Vlad;Boult, Terry E.",35560595700;6701652508;35561535500,60031321;60031321;60010265,2004-10-19,2004,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,1,,,,"In this paper, we introduce the notion of a programmable imaging system. Such an imaging system provides a human user or a vision system significant control over the radiometric and geometric characteristics of the system. This flexibility is achieved using a programmable array of micro-mirrors. The orientations of the mirrors of the array can be controlled with high precision over space and time. This enables the system to select and modulate rays from the light field based on the needs of the application at hand. We have implemented a programmable imaging system that uses a digital micro-mirror device (DMD), which is used in digital light processing. Although the mirrors of this device can only be positioned in one of two states, we show that our system can be used to implement a wide variety of imaging functions, including, high dynamic range imaging, feature detection, and object recognition. We conclude with a discussion on how a micro-mirror array can be used to efficiently control field of view without the use of moving parts.",,104,0,,,,undefined,,CVPR Computer Vision
2-s2.0-20344363679,10.1145/1041685.1029905,,,Reasoning about partial goal satisfaction for requirements and design engineering,cp,Conference Paper,Letier E.,60000874,Université Catholique de Louvain,Louvain-la-Neuve,Belgium,2,"Letier, Emmanuel;Van Lamsweerde, Axel",57204376747;6701616373,60000874;60000874,2004-01-01,2004,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100988870,,Conference Proceeding,,,,53-62,"Exploring alternative options is at the heart of the requirements and design processes. Different alternatives contribute to different degrees of achievement of non-functional goals about system safety, security, performance, usability, and so forth. Such goals in general cannot be satisfied in an absolute, clear-cut sense. Various qualitative and quantitative frameworks have been proposed to support the assessment of alternatives for design decision making. In general they lead to limited conclusions due to the lack of accuracy and measurability of goal formulations and the lack of impact propagation rules along goal contribution links. The paper presents techniques for specifying partial degrees of goal satisfaction and for quantifying the impact of alternative system designs on the degree of goal satisfaction. The approach consists in enriching goal refinement models with a probabilistic layer for reasoning about partial satisfaction. Within such models, non-functional goals are specified in a precise, probabilistic way; their specification is interpreted in terms of application-specific measures; impact of alternative goal refinements is evaluated in terms of refinement equations over random variables involved in the system's functional goals. A systematic method is presented for guiding the elaboration of such models. The latter can then be used to assess the impact of alternative decisions on the degree of goal satisfaction or to derive quantitative, fine-grained requirements on the software to achieve the higher-level goals. Copyright 2004 ACM.",Goal-oriented requirements engineering | Non-functional requirements | Partial satisfaction of requirements | Probabilistic requirements modeling | Reasoning about design alternatives,216,0,,,,undefined,,FSE Software Engineering
2-s2.0-85077022007,,,,Recovering device drivers,cp,Conference Paper,Swift M.M.,60028661,UW College of Engineering,Seattle,United States,4,"Swift, Michael M.;Annamalai, Muthukaruppan;Bershad, Brian N.;Levy, Henry M.",57209111762;16021157800;6701383953;7201665633,60028661;60028661;60028661;60028661,2004-01-01,2004,OSDI 2004 - 6th Symposium on Operating Systems Design and Implementation,,21100962880,,Conference Proceeding,,,,1-15,"This paper presents a new mechanism that enables applications to run correctly when device drivers fail. Because device drivers are the principal failing component in most systems, reducing driver-induced failures greatly improves overall reliability. Earlier work has shown that an operating system can survive driver failures [33], but the applications that depend on them cannot. Thus, while operating system reliability was greatly improved, application reliability generally was not. To remedy this situation, we introduce a new operating system mechanism called a shadow driver. A shadow driver monitors device drivers and transparently recovers from driver failures. Moreover, it assumes the role of the failed driver during recovery. In this way, applications using the failed driver, as well as the kernel itself, continue to function as expected. We implemented shadow drivers for the Linux operating system and tested them on over a dozen device drivers. Our results show that applications and the OS can indeed survive the failure of a variety of device drivers. Moreover, shadow drivers impose minimal performance overhead. Lastly, they can be introduced with only modest changes to the OS kernel and with no changes at all to existing device drivers.",,108,0,,,NSF,CCR-0121341,National Science Foundation,OSDI Operating Systems
2-s2.0-4544254100,,,,SNIAFL: Towards a static non-interactive approach to feature location,cp,Conference Paper,Zhao W.,60014966,Peking University,Beijing,China,5,"Zhao, Wei;Zhang, Lu;Liu, Yin;Sun, Jiasu;Yang, Fuqing",55574199585;8421831300;7410228010;8401629400;8081516200,60014966;60014966;60014966;60014966;60014966,2004-09-29,2004,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,26,,,293-303,"To facilitate software maintenance and evolution, a helpful step is to locate features concerned in a particular maintenance task. In the literature, both dynamic and interactive approaches have been proposed for feature location. In this paper, we present a static and non-interactive method for achieving this objective. The main idea of our approach is to use the information retrieval (IR) technology to reveal the basic connections between features and computational units in source code. Due to the characteristics of the retrieved connections, we use a static representation of the source code named BRCG to further recover both the relevant and the specific computational units for each feature. Furthermore, we recover the relationships among the relevant units for each feature. A premise of our approach is that programmers should use meaningful names as identifiers. We perform an experimental study based on a GNU system to evaluate our approach. In the experimental study, we present the detailed quantitative experimental data and give the qualitative analytical results.",,49,0,,,,undefined,,ICSE Software Engineering
2-s2.0-4544280668,,,,Static checking of dynamically generated queries in database applications,cp,Conference Paper,Gould C.,60153736,College of Engineering,Davis,United States,3,"Gould, Carl;Su, Zhendong;Devanbu, Premkumar",7102089186;7402248744;35583833100,60153736;60153736;60153736,2004-09-29,2004,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,26,,,645-654,"Many data-intensive applications dynamically construct queries in response to client requests and execute them. Java servlets, e.g., can create string representations of SQL queries and then send the queries, using JDBC, to a database server for execution. The servlet programmer enjoys static checking via Java's strong type system. However, the Java type system does little to check for possible errors in the dynamically generated SQL query strings. Thus, a type error in a generated selection query (e.g., comparing a string attribute with an integer) can result in an SQL runtime exception. Currently, such defects must be rooted out through careful testing, or (worse) might be found by customers at runtime. In this paper, we present a sound, static, program analysis technique to verify the correctness of dynamically generated query strings. We describe our analysis technique and provide soundness results for our static analysis algorithm. We also describe the details of a prototype tool based on the algorithm and present several illustrative defects found in senior software-engineering student-team projects, online tutorial examples, and a real-world purchase order system written by one of the authors.",,136,0,,,,undefined,,ICSE Software Engineering
2-s2.0-4143112460,,,,Throughput-delay trade-off in wireless networks,cp,Conference Paper,El Gamal A.,60012708,Stanford University,Stanford,United States,4,"El Gamal, Abbas;Mammen, James;Prabhakar, Balaji;Shah, Devavrat",6602093177;6602468769;7102955788;7402371516,60012708;60012708;60012708;60012708,2004-11-22,2004,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,1,,,464-475,"Gupta and Kumar (2000) introduced a random network model for studying the way throughput scales in a wireless network when the nodes are fixed, and showed that the throughput per source-destination pair is Θ (1/√n log n). Grossglauser and Tse (2001) showed that when nodes are mobile it is possible to have a constant or Θ(1) throughput scaling per source-destination pair. The focus of this paper is on characterizing the delay and determining the throughput-delay trade-off in such fixed and mobile ad hoc networks. For the Gupta-Kumar fixed network model, we show that the optimal throughput-delay trade-off is given by D(n) = Θ(nT(n)), where T(n) and D(n) are the throughput and delay respectively. For the Grossglauser-Tse mobile network model, we show that the delay scales as Θ (n 1/2/v(n)), where v(n) is the velocity of the mobile nodes. We then describe a scheme that achieves the optimal order of delay for any given throughput. The scheme varies (i) the number of hops, (ii) the transmission range and (iii) the degree of node mobility to achieve the optimal throughput-delay trade-off. The scheme produces a range of models that capture the Gupta-Kumar model at one extreme and the Grossglauser-Tse model at the other. In the course of our work, we recover previous results of Gupta and Kumar, and Grossglauser and Tse using simpler techniques, which might be of a separate interest.",Combinatorics | Information theory | Statistics | Stochastic processes/Queueing theory,481,0,,,,undefined,,INFOCOM Networking
2-s2.0-85019620107,,,,Trickle: A self-regulating algorithm for code propagation and maintenance in wireless sensor networks,cp,Conference Paper,Levis P.,60074754;60033286;60025038,"Intel Research Laboratories;International Computer Science Institute;University of California, Berkeley",Santa Clara;Berkeley;Berkeley,United States;United States;United States,4,"Levis, Philip;Patel, Neil;Culler, David;Shenker, Scott",22835832700;57198804092;7004874505;35593393300,60025038-60074754;60025038;60025038-60074754;60025038-60033286,2004-01-01,2004,"1st Symposium on Networked Systems Design and Implementation, NSDI 2004",,21101024048,,Conference Proceeding,,,,,"We present Trickle, an algorithm for propagating and maintaining code updates in wireless sensor networks. Borrowing techniques from the epidemic/gossip, scalable multicast, and wireless broadcast literature, Trickle uses a “polite gossip” policy, where motes periodically broadcast a code summary to local neighbors but stay quiet if they have recently heard a summary identical to theirs. When a mote hears an older summary than its own, it broadcasts an update. Instead of flooding a network with packets, the algorithm controls the send rate so each mote hears a small trickle of packets, just enough to stay up to date. We show that with this simple mechanism, Trickle can scale to thousand-fold changes in network density, propagate new code in the order of seconds, and impose a maintenance cost on the order of a few sends an hour.",,595,0,,,NSF,0122599,National Science Foundation,NSDI Networking
2-s2.0-84885668018,,,,Using model checking to find serious file system errors,cp,Conference Paper,Yang J.,60021726;60012708,Microsoft Research;Stanford University,Redmond;Stanford,United States;United States,4,"Yang, Junfeng;Twohey, Paul;Engler, Dawson;Musuvathi, Madanlal",36676080800;15064617100;7006155582;11141222500,60012708;60012708;60012708;60021726,2004-01-01,2004,OSDI 2004 - 6th Symposium on Operating Systems Design and Implementation,,21100962880,,Conference Proceeding,,,,273-287,"This paper shows how to use model checking to find serious errors in file systems. Model checking is a formal verification technique tuned for finding corner-case errors by comprehensively exploring the state spaces defined by a system. File systems have two dynamics that make them attractive for such an approach. First, their errors are some of the most serious, since they can destroy persistent data and lead to unrecoverable corruption. Second, traditional testing needs an impractical, exponential number of test cases to check that the system will recover if it crashes at any point during execution. Model checking employs a variety of state-reducing techniques that allow it to explore such vast state spaces efficiently. We built a system, FiSC, for model checking file systems. We applied it to three widely-used, heavily-tested file systems: ext3 [13], JFS [21], and ReiserFS [27]. We found serious bugs in all of them, 32 in total. Most have led to patches within a day of diagnosis. For each file system, FiSC found demonstrable events leading to the unrecoverable destruction of metadata and entire directories, including the file system root directory “/”.",,155,0,,,NSF,CCR-0326227,National Science Foundation,OSDI Operating Systems
2-s2.0-84859893686,10.3115/1219840.1219873,,,A hierarchical phrase-based model for statistical machine translation,cp,Conference Paper,Chiang D.,60020304,"University of Maryland, College Park",College Park,United States,1,"Chiang, David",36004514600,60020304,2005-01-01,2005,"ACL-05 - 43rd Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference",,21100201003,,Conference Proceeding,,,,263-270,"We present a statistical phrase-based translation model that uses hierarchical phrases-phrases that contain subphrases. The model is formally a synchronous context-free grammar but is learned from a bitext without any syntactic information. Thus it can be seen as a shift to the formal machinery of syntaxbased translation systems without any linguistic commitment. In our experiments using BLEU as a metric, the hierarchical phrasebased model achieves a relative improvement of 7.5% over Pharaoh, a state-of-the-art phrase-based system. © 2005 Association for Computational Linguistics.",,833,1,repositoryam,Green,,undefined,,ACL Natural Language Processing
2-s2.0-84880742675,,,,A probabilistic model of redundancy in information extraction,cp,Conference Paper,Downey D.,60028661,UW College of Engineering,Seattle,United States,3,"Downey, Doug;Etzioni, Oren;Soderland, Stephen",35956201800;7004312379;6603651046,60028661;60028661;60028661,2005-12-01,2005,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,1034-1041,"Unsupervised Information Extraction (UIE) is the task of extracting knowledge from text without using hand-tagged training examples. A fundamental problem for both UIE and supervised IE is assessing the probability that extracted information is correct. In massive corpora such as the Web, the same extraction is found repeatedly in different documents. How does this redundancy impact the probability of correctness? This paper introduces a combinatorial ""balls-and-urns"" model that computes the impact of sample size, redundancy, and corroboration from multiple distinct extraction rules on the probability that an extraction is correct. We describe methods for estimating the model's parameters in practice and demonstrate experimentally that for UIE the model's log likelihoods are 15 times better, on average, than those obtained by Pointwise Mutual Information (PMI) and the noisy-or model used in previous work. For supervised IE, the model's performance is comparable to that of Support Vector Machines, and Logistic Regression.",,120,0,,,NSF,IIS-0312988,National Science Foundation,IJCAI Artificial Intelligence
2-s2.0-31844446804,10.1145/1102351.1102399,,,A Support Vector Method for multivariate performance measures,cp,Conference Paper,Joachims T.,60278093,Cornell Ann S. Bowers College of Computing and Information Science,Ithaca,United States,1,"Joachims, Thorsten",6602804136,60278093,2005-12-01,2005,ICML 2005 - Proceedings of the 22nd International Conference on Machine Learning,,3200147601,,Conference Proceeding,,,,377-384,"This paper presents a Support Vector Method for optimizing multivariate nonlinear performance measures like the F1-score. Taking a multivariate prediction approach, we give an algorithm with which such multivariate SVMs can be trained in polynomial time for large classes of potentially non-linear performance measures, in particular ROCArea and all measures that can be computed from the contingency table. The conventional classification SVM arises as a special case of our method.",,652,0,repositoryam,Green,,undefined,,ICML Machine Learning
2-s2.0-32344452628,10.1145/1081706.1081711,,,Automatic generation of suggestions for program investigation,cp,Conference Paper,Robillard M.P.,60002494,Université McGill,Montreal,Canada,1,"Robillard, Martin P.",7006311463,60002494,2005-01-01,2005,ESEC/FSE'05 - Proceedings of the Joint 10th European Software Engineering Conference (ESEC) and 13th ACM SIGSOFT Symposium on the Foundations of Software Engineering (FSE-13),,3300147602,,Conference Proceeding,,,,11-20,"Before performing a modification task, a developer usually has to investigate the source code of a system to understand how to carry out the task. Discovering the code relevant to a change task is costly because it is an inherently human activity whose success depends on a large number of unpredictable factors, such as intuition and luck. Although studies have shown that effective developers tend to explore a program by following structural dependencies, no methodology is available to guide their navigation through the typically hundreds of dependency paths found in a non-trivial program. In this paper, we propose a technique to automatically propose and rank program elements that are potentially interesting to a developer investigating source code. Our technique is based on an analysis of the topology of structural dependencies in a program. It takes as input a set of program elements of interest to a developer and produces a fuzzy set describing other elements of potential interest. Empirical evaluation of our technique indicates that it can help developers quickly select program elements worthy of investigation while avoiding less interesting ones. Copyright 2005 ACM.",Feature location | Static analysis | Structural program dependencies,115,0,,,,undefined,,FSE Software Engineering
2-s2.0-31844446709,,,,Automatic pool allocation: Improving performance by controlling data structure layout in the heap,cp,Conference Paper,Lattner C.,60000745,University of Illinois Urbana-Champaign,Urbana,United States,2,"Lattner, Chris;Adve, Vikram",7801365279;6701828487,60000745;60000745,2005-12-01,2005,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,129-142,"This paper describes Automatic Pool Allocation, a transformation framework that segregates distinct instances of heap-based data structures into seperate memory pools and allows heuristics to be used to partially control the internal layout of those data structures. The primary goal of this work is performance improvement, not automatic memory management, and the paper makes several new contributions. The key contribution is a new compiler algorithm for partitioning heap objects in imperative programs based on a context-sensitive pointer analysis, including a novel strategy for correct handling of indirect (and potentially unsafe) function calls. The transformation does not require type safe programs and works for the full generality of C and C++. Second, the paper describes several optimizations that exploit data structure partitioning to further improve program performance. Third, the paper evaluates how memory hierarchy behavior and overall program performance are impacted by the new transformations. Using a number of bench-marks and a few applications, we find that compilation times are extremely low, and overall running times for heap intensive programs speed up by 10-25% in many cases, about 2x in two cases, and more than 10x in two small benchmarks. Overall, we believe this work provides a new framework for optimizing pointer intensive programs by segregating and controlling the layout of heap-based data structures. Copyright 2005 ACM.","Cache, static analysis | Data layout | Pool allocation | Recursive data structure",119,0,,,,undefined,,PLDI Programming Languages
2-s2.0-33749570363,10.1145/1095034.1095062,,,Automation and customization of rendered Web pages,cp,Conference Paper,Bolin M.,60006320,MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge,United States,5,"Bolin, Michael;Webber, Matthew;Rha, Philip;Wilson, Tom;Miller, Robert C.",14830915200;35958344400;14831559400;57198875392;57216196948,60006320;60006320;60006320;60006320;60006320,2005-01-01,2005,UIST: Proceedings of the Annual ACM Symposium on User Interface Softaware and Technology,,21100527131,,Conference Proceeding,,,,163-172,"On the desktop, an application can expect to control its user interface down to the last pixel, but on the World Wide Web, a content provider has no control over how the client will view the page, once delivered to the browser. This creates an opportunity for end-users who want to automate and customize their web experiences, but the growing complexity of web pages and standards prevents most users from realizing this opportunity. We describe Chickenfoot, a programming system embedded in the Firefox web browser, which enables end-users to automate, customize, and integrate web applications without examining their source code. One way Chickenfoot addresses this goal is a novel technique for identifying page components by keyword pattern matching. We motivate this technique by studying how users name web page components, and present a heuristic keyword matching algorithm that identifies the desired component from the user's name. Copyright ACM.",Web automation | Web browsers,167,0,,,,undefined,,UIST User Interface
2-s2.0-84885635827,10.1145/1095810.1095816,,,BAR fault tolerance for cooperative services,cp,Conference Paper,Aiyer A.S.,60150459,Department of Computer Science,Austin,United States,6,"Aiyer, Amitanand S.;Alvisi, Lorenzo;Clement, Allen;Dahlin, Mike;Martin, Jean Philippe;Porth, Carl",13404887000;6603768937;23033773000;7003483638;57199282156;15136779600,60150459;60150459;60150459;60150459;60150459;60150459,2005-12-01,2005,"Proceedings of the 20th ACM Symposium on Operating Systems Principles, SOSP 2005",,21100261951,,Conference Proceeding,,,,45-58,"This paper describes a general approach to constructing cooperative services that span multiple administrative domains. In such environments, protocols must tolerate both Byzantine behaviors when broken, misconfigured, or malicious nodes arbitrarily deviate from their specification and rational behaviors when selfish nodes deviate from their specification to increase their local benefit. The paper makes three contributions: (1) It introduces the BAR (Byzantine, Altruistic, Rational) model as a foundation for reasoning about cooperative services; (2) It proposes a general three-level architecture to reduce the complexity of building services under the BAR model; and (3) It describes an implementation of BAR-B the first cooperative backup service to tolerate both Byzantine users and an unbounded number of rational users. At the core of BAR-B is an asynchronous replicated state machine that provides the customary safety and liveness guarantees despite nodes exhibiting both Byzantine and rational behaviors. Our prototype provides acceptable performance for our application: our BAR-tolerant state machine executes 15 requests per second, and our BAR-B backup service can back up 100MB of data in under 4 minutes. © 2005 ACM.",byzantine fault tolerance | game theory | peer to peer | reliable systems,92,0,repositoryvor,Green,NSF,0509338,National Science Foundation,SOSP Operating Systems
2-s2.0-32344447459,,,,CUTE: A concolic unit testing engine for C,cp,Conference Paper,Sen K.,60158506,The Grainger College of Engineering,Urbana,United States,3,"Sen, Koushik;Marinov, Darko;Agha, Gul",8226489200;8730036800;7003402631,60158506;60158506;60158506,2005-12-01,2005,ESEC/FSE'05 - Proceedings of the Joint 10th European Software Engineering Conference (ESEC) and 13th ACM SIGSOFT Symposium on the Foundations of Software Engineering (FSE-13),,3300147602,,Conference Proceeding,,,,263-272,"In unit testing, a program is decomposed into units which are collections of functions. A part of unit can be tested by generating inputs for a single entry function. The entry function may contain pointer arguments, in which case the inputs to the unit are memory graphs. The paper addresses the problem of automating unit testing with memory graphs as inputs. The approach used builds on previous work combining symbolic and concrete execution, and more specifically, using such a combination to generate test inputs to explore all feasible execution paths. The current work develops a method to represent and track constraints that capture the behavior of a symbolic execution of a unit with memory graphs as inputs. Moreover, an efficient constraint solver is proposed to facilitate incremental generation of such test inputs. Finally, CUTE, a tool implementing the method is described together with the results of applying CUTE to real-world examples of C code. Copyright 2005 ACM.",Concolic testing | Data structure testing | Explicit path model-checking | Random testing | Testing C programs | Unit testing,1441,0,,,,undefined,,FSE Software Engineering
2-s2.0-33745618206,,,,Cache-conscious frequent pattern mining on a modern processor,cp,Conference Paper,Ghoting A.,60149838;60033010,College of Engineering;Intel Corporation,Columbus;Santa Clara,United States;United States,7,"Ghoting, Amol;Buehrer, Gregory;Parthasarathy, Srinivasan;Kim, Daehyun;Nguyen, Anthony;Chen, Yen Kuang;Dubey, Pradeep",8352633900;55956991300;7101695336;55696740400;14029161300;7601437551;7102976269,60149838;60149838;60149838;60033010;60033010;60033010;60033010,2005-12-01,2005,VLDB 2005 - Proceedings of 31st International Conference on Very Large Data Bases,,4700152262,,Conference Proceeding,2,,,577-588,"In this paper, we examine the performance of frequent pattern mining algorithms on a modern processor. A detailed performance study reveals that even the best frequent pattern mining implementations, with highly e cient memory managers, still grossly under-utilize a modern processor. The primary performance bottlenecks are poor data locality and low instruction level parallelism (ILP). We propose a cache-conscious pre × tree to address this problem. The resulting tree improves spatial locality and also enhances the bene ts from hardware cache line prefetching. Furthermore, the design of this data structure allows the use of a novel tiling strategy to improve temporal locality. The result is an overall speedup of up to 3.2 when compared with state-of-the-art implementations. We then show how these algorithms can be improved further by realizing a non-naive thread-based decomposition that targets simultaneously multi-threaded processors. A key aspect of this decomposition is to ensure cache re-use between threads that are co-scheduled at a ne granularity. This optimization a ords an additional speedup of 50%, resulting in an overall speedup of up to 4.8. To the best of our knowledge, this e ort is the rst to target cache-conscious data mining.",,49,0,,,,undefined,,VLDB Databases
2-s2.0-32344440613,10.1145/1095430.1081728,,,Context- And path-sensitive memory leak detection,cp,Conference Paper,Xie Y.,60141508,Stanford Engineering,Stanford,United States,2,"Xie, Yichen;Aiken, Alex",7403959415;57203049517,60141508;60141508,2005-01-01,2005,ESEC/FSE'05 - Proceedings of the Joint 10th European Software Engineering Conference (ESEC) and 13th ACM SIGSOFT Symposium on the Foundations of Software Engineering (FSE-13),,21100984775,,Conference Proceeding,,,,115-125,"We present a context- and path-sensitive algorithm for detecting memory leaks in programs with explicit memory management. Our leak detection algorithm is based on an underlying escape analysis: any allocated location in a procedure P that is not deallocated in P and does not escape from P is leaked. We achieve very precise context- and path-sensitivity by expressing our analysis using boolean constraints. In experiments with six large open source projects our analysis produced 510 warnings of which 455 were unique memory leaks, a false positive rate of only 10.8%. A parallel implementation improves performance by over an order of magnitude on large projects; over five million lines of code in the Linux kernel is analyzed in 50 minutes. Copyright 2005 ACM.",Boolean satisfiability | Error detection | Memory leaks | Memory management | Program analysis,95,0,,,,undefined,,FSE Software Engineering
2-s2.0-33646831750,10.1109/SFCS.2005.29,,,Correcting errors beyond the Guruswami-Sudan radius in polynomial time,cp,Conference Paper,Parvaresh F.,60030612,"University of California, San Diego",La Jolla,United States,2,"Parvaresh, Farzad;Vardy, Alexander",6508099027;56254654200,60030612;60030612,2005-12-01,2005,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2005,,1530722,285-294,"We introduce a new family of error-correcting codes that have a polynomial-time encoder and a polynomial-time listdecoder, correcting a fraction of adversarial errors up to τ M = l - M+1√M MR M where R is the rate of the code and M ≥1 is an arbitrary integer parameter. This makes it possible to decode beyond the Guruswami-Sudan radius of 1 - √R for all rates less than 1/16. Stated another way, for any ε > 0, we can list-decode in polynomial time a fraction of errors up to 1 - ε with a code of length n and rate Ω(ε/log(1/ε)), defined over an alphabet of size n M = n O(log(1/ε)). Notably, this error-correction is achieved in the worst-case against adversarial errors: a probabilistic model for the error distribution is neither needed nor assumed. The best results so far for polynomial-time list-decoding of adversarial errors required a rate of of O(ε 2) to achieve the correction radius of 1 -ε. Our codes and list-decoders are based on two key ideas. The first is the transition from bivariate polynomial interpolation, pioneered by Sudan and Guruswami-Sudan [12,22], to multivariate interpolation decoding. The second idea is to pan ways with Reed-Solomon codes, for which numerous prior attempts [2,3,12,18] at breaking the O(ε 2) rate barrier in the worst-case were unsuccessful. Rather than devising a better list-decoder for Reed-Solomon codes, we devise better codes. Standard Reed-Solomon encoders view a message as a polynomial f (X) over a field double-stract F sign q, and produce the corresponding codeword by evaluating f (X) at n distinct elements of double-stract F sign q. Herein, given f (X), we first compute one or more related polynomials g 1 (X), g 2 (X),.. ./g M-1 (X) and produce the corresponding codeword by evaluating all these polynomials. Correlation between f (X) and g i (X), carefully designed into our encoder, then provides the additional information we need to recover the encoded message from the output of the multivariate interpolation process. © 2005 IEEE.",,140,0,,,,undefined,,FOCS Theory
2-s2.0-33244486355,10.1145/1071690.1064215,,,Coupon replication systems,cp,Conference Paper,Massoulié L.,60021726,Microsoft Research,Redmond,United States,2,"Massoulié, Laurent;Vojnović, Milan",6603753137;56978166000,60021726;60021726,2005-12-01,2005,Performance Evaluation Review,01635999,26742,01635999,Conference Proceeding,33,1,,2-13,"Motivated by the study of peer-to-peer file swarming systems à la BitTorrent, we introduce a probabilistic model of coupon replication systems. These systems consist of users, aiming to complete a collection of distinct coupons. Users are characterised by their current collection of coupons, and leave the system once they complete their coupon collection. The system evolution is then specified by describing how users of distinct types meet, and which coupons get replicated upon such encounters. For open systems, with exogenous user arrivals, we derive necessary and sufficient stability conditions in a layered scenario, where encounters are between users holding the same number of coupons. We also consider a system where encounters are between users chosen uniformly at random from the whole population. We show that performance, captured by sojourn time, is asymptotically optimal in both systems as the number of coupon types becomes large. We also consider closed systems with no exogenous user arrivals. In a special scenario where users have only one missing coupon, we evaluate the size of the population ultimately remaining in the system, as the initial number of users, N, goes to infinity. We show that this decreases geometrically with the number of coupons, K. In particular, when the ratio K/ log(N) is above a critical threshold, we prove that this number of left-overs is of order log(log(N)). These results suggest that performance of file swarming systems does not depend critically on either altruistic user behavior, or on load balancing strategies such as rarest first. Copyright 2005 ACM.",Content Distribution | File Swarming | Peer-to-peer,53,0,,,,undefined,,SIGMETRICS Performance
2-s2.0-33244493764,10.1109/ICSE.2005.1553560,,,Data structure repair using goal-directed reasoning,cp,Conference Paper,Demsky B.,60006320,MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge,United States,2,"Demsky, Brian;Rinard, Martin",6507879885;7003321126,60006320;60006320,2005-12-01,2005,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2005,,1553560,176-185,"Data structure repair is a promising technique for enabling programs to execute successfully in the presence of otherwise fatal data structure corruption errors. Previous research in this field relied on the developer to write a specification to explicitly translate model repairs into concrete data structure repairs, raising the possibility of 1) incorrect translations causing the supposedly repaired concrete data structures to be inconsistent, and 2) repaired models with no corresponding concrete data structure representation. We present a new repair algorithm that uses goal-directed reasoning to automatically translate model repairs into concrete data structure repairs. This new repair algorithm eliminates the possibility of incorrect translations and repaired models with no corresponding representation as concrete data structures. Copyright 2005 ACM.",Data structure invariants | Data structure repair,57,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-84969934542,10.1145/1054972.1055074,,,Designing the spectator experience,cp,Conference Paper,Reeves S.,60020650;60015138,University of Bristol;University of Nottingham,Bristol;Nottingham,United Kingdom;United Kingdom,4,"Reeves, Stuart;Benford, Steve;O'Malley, Claire;Fraser, Mike",7102635630;7006887786;57193989946;7201441361,60015138;60015138;60015138;60020650,2005-07-01,1 July 2005,Conference on Human Factors in Computing Systems - Proceedings,02749696,28664,,Conference Proceeding,,,,741-750,"Interaction is increasingly a public affair, taking place in our theatres, galleries, museums, exhibitions and on the city streets. This raises a new design challenge for HCI -how should spectators experience a performer's interaction with a computer? We classify public interfaces (including examples from art, performance and exhibition design) according to the extent to which a performer's manipulations of an interface and their resulting effects are hidden, partially revealed, fully revealed or even amplified for spectators. Our taxonomy uncovers four broad design strategies: 'secretive,' where manipulations and effects are largely hidden; 'expressive,' where they tend to be revealed enabling the spectator to fully appreciate the performer's interaction; 'magical,' where effects are revealed but the manipulations that caused them are hidden; and finally 'suspenseful,' where manipulations are apparent but effects are only revealed as the spectator takes their turn. Copyright 2005 ACM.",Art | Design framework | Expression | Galleries | Magic | Museums | Performance | Public experiences | Spectators,296,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84894553762,,,,Detecting BGP configuration faults with static analysis,cp,Conference Paper,Feamster N.,60006320,MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge,United States,2,"Feamster, Nick;Balakrishnan, Hari",6603252878;7006098113,60006320;60006320,2005-01-01,2005,"2nd Symposium on Networked Systems Design and Implementation, NSDI 2005",,21101024052,,Conference Proceeding,,,,43-56,"The Internet is composed of many independent autonomous systems (ASes) that exchange reachability information to destinations using the Border Gateway Protocol (BGP). Network operators in each AS configure BGP routers to control the routes that are learned, selected, and announced to other routers. Faults in BGP configuration can cause forwarding loops, packet loss, and unintended paths between hosts, each of which constitutes a failure of the Internet routing infrastructure. This paper describes the design and implementation of rcc, the router configuration checker, a tool that finds faults in BGP configurations using static analysis. rcc detects faults by checking constraints that are based on a high-level correctness specification. rcc detects two broad classes of faults: route validity faults, where routers may learn routes that do not correspond to usable paths, and path visibility faults, where routers may fail to learn routes for paths that exist in the network. rcc enables network operators to test and debug configurations before deploying them in an operational network, improving on the status quo where most faults are detected only during operation. rcc has been downloaded by more than sixty-five network operators to date, some of whom have shared their configurations with us. We analyze network-wide configurations from 17 different ASes to detect a wide variety of faults and use these findings to motivate improvements to the Internet routing infrastructure.",,244,0,,,NSF,ANI-0225660,National Science Foundation,NSDI Networking
2-s2.0-29244445934,,,,Eliciting design requirements for maintenance-oriented IDEs: A detailed study of corrective and perfective maintenance tasks,cp,Conference Paper,Ko A.J.,60136640,School of Computer Science,Pittsburgh,United States,3,"Ko, Andrew J.;Aung, Htet Htet;Myers, Brad A.",7007018374;8203400200;7202684451,60136640;60136640;60136640,2005-12-01,2005,"Proceedings - 27th International Conference on Software Engineering, ICSE05",,3700148006,,Conference Proceeding,,,,126-135,"Recently, several innovative tools have found their way into mainstream use in modem development environments. However, most of these tools have focused on creating and modifying code, despite evidence that most of programmers' time is spent understanding code as part of maintenance tasks. If new tools were designed to directly support these maintenance tasks, what types would be most helpful? To find out, a study of expert Java programmers using Eclipse was performed. The study suggests that maintenance work consists of three activities: (1) forming a working set of task-relevant code fragments; (2) navigating the dependencies within this working set; and (3) repairing or creating the necessary code. The study identified several trends in these activities, as well as many opportunities for new tools that could save programmers up to 35% of the time they currently spend on maintenance tasks. Copyright 2005 ACM.",Design | Human Factors,146,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84861296784,10.1145/1054972.1055018,,,Examining task engagement in sensor-based statistical models of human interruptibilïty,cp,Conference Paper,Fogarty J.,60136640,School of Computer Science,Pittsburgh,United States,6,"Fogarty, James;Ko, Andrew J.;Aung, Htet Htet;Golden, Elspeth;Tang, Karen P.;Hudson, Scott E.",7004668263;7007018374;8203400200;56275172200;36742145700;7201375469,60136640;60136640;60136640;60136640;60136640;60136640,2005-01-01,2005,Conference on Human Factors in Computing Systems - Proceedings,02749696,28664,,Conference Proceeding,,,,331-340,"The computer and communication systems that office workers currently use tend to interrupt at inappropriate times or unduly demand attention because they have no way to determine when an interruption is appropriate. Sensor-based statistical models of human interruptibility offer a potential solution to this problem. Prior work to examine such models has primarily reported results related to social engagement, but it seems that task engagement is also important. Using an approach developed in our prior work on sensor-based statistical models of human interruptibility, we examine task engagement by studying programmers working on a realistic programming task. After examining many potential sensors, we implement a system to log low-level input events in a development environment. We then automatically extract features from these low-level event logs and build a statistical model of interruptibility. By correctly identifying situations in which programmers are non-interruptible and minimizing cases where the model incorrectly estimates that a programmer is non-interruptible, we can support a reduction in costly interruptions while still allowing systems to convey notifications in a timely manner. Copyright 2005 ACM.",Context-aware computing | Interruptibility | Machine learning | Managing human attention | Sensor-based interfaces | Situationally appropriate interaction,73,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-33745842405,10.1109/ICCV.2005.109,,,Globally optimal estimates for geometric reconstruction problems,cp,Conference Paper,Kahl F.,60030612;60029170;60005830,"University of California, San Diego;Lunds Universitet;Laboratoire d'Analyse et d'Architecture des Systemes",La Jolla;Lund;Toulouse,United States;Sweden;France,2,"Kahl, Fredrik;Henrion, Didier",7003784974;7006323650,60030612-60029170;60005830,2005-12-01,2005,Proceedings of the IEEE International Conference on Computer Vision,,110561,,Conference Proceeding,II,,1544827,978-985,"We introduce a framework for computing statistically optimal estimates of geometric reconstruction problems. While traditional algorithms often suffer from either local minima or non-optimality - or a combination of both - we pursue the goal of achieving global solutions of the statistically optimal cost-function. Our approach is based on a hierarchy of convex relaxations to solve non-convex optimization problems with polynomials. These convex relaxations generate a monotone sequence of lower bounds and we show how one can detect whether the global optimum is attained at a given relaxation. The technique is applied to a number of classical vision problems: triangulation, camera pose, homography estimation and last, but not least, epipolar geometry estimation. Experimental validation on both synthetic and real data is provided. In practice, only a few relaxations are needed for attaining the global optimum. © 2005 IEEE.",,43,0,,,,undefined,,ICCV Computer Vision
2-s2.0-32344436210,10.1145/1081870.1081893,,,"Graphs over time: Densification laws, shrinking diameters and possible explanations",cp,Conference Paper,Leskovec J.,60027950;60007776,Carnegie Mellon University;Cornell University,Pittsburgh;Ithaca,United States;United States,3,"Leskovec, Jure;Kleinberg, Jon;Faloutsos, Christos",12241436100;7005755823;7006005166,60027950;60007776;60027950,2005-12-01,2005,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,101510,,Conference Proceeding,,,,177-187,"How do real graphs evolve over time? What are ""normal"" growth patterns in social, technological, and information networks? Many studies have discovered patterns in static graphs, identifying properties in a single snapshot of a large network, or in a very small number of snapshots; these include heavy tails for in- and out-degree distributions, communities, small-world phenomena, and others. However, given the lack of information about network evolution over long periods, it has been hard to convert these findings into statements about trends over time. Here we study a wide range of real graphs, and we observe some surprising phenomena. First, most of these graphs densify over time, with the number of edges growing super-linearly in the number of nodes. Second, the average distance between nodes often shrinks over time, in contrast to the conventional wisdom that such distance parameters should increase slowly as a function of the number of nodes (like O(log n) or O (log (log n)). Existing graph generation models do not exhibit these types of behavior, even at a qualitative level. We provide a new graph generator, based on a ""forest fire"" spreading process, that has a simple, intuitive justification, requires very few parameters (like the ""flammability"" of nodes), and produces graphs exhibiting the full range of properties observed both in prior work and in the present study. Copyright 2005 ACM.",Densification power laws | Graph generators | Graph mining | Heavy-tailed distributions | Small-world phenomena,1793,0,,,,undefined,,KDD Data Mining
2-s2.0-26044454396,10.1109/ICSE.2005.1553583,,,Is mutation an appropriate tool for testing experiments?,cp,Conference Paper,Andrews J.H.,60017592;60010884,Carleton University;Western University,Ottawa;London,Canada;Canada,3,"Andrews, J. H.;Briand, L. C.;Labiche, Y.",55468860000;7006613079;6602305217,60010884;60017592;60017592,2005-12-01,2005,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2005,,1553583,402-411,"The empirical assessment of test techniques plays an important role in software testing research. One common practice is to instrument faults, either manually or by using mutation operators. The latter allows the systematic, repeatable seeding of large numbers of faults; however, we do not know whether empirical results obtained this way lead to valid, representative conclusions. This paper investigates this important question based on a number of programs with comprehensive pools of test cases and known faults. It is concluded that, based on the data available thus far, the use of mutation operators is yielding trustworthy results (generated mutants are similar to real faults). Mutants appear however to be different from hand-seeded faults that seem to be harder to detect than real faults. Copyright 2005 ACM.",Hand-seeded faults | Mutants | Real faults,613,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84880722210,,,,Learning coordination classifiers,cp,Conference Paper,Guo Y.,60030835,University of Alberta,Edmonton,Canada,3,"Guo, Yuhong;Greiner, Russell;Schuurmans, Dale",10240222700;7102873710;57204335408,60030835;60030835;60030835,2005-12-01,2005,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,714-721,"We present a new approach to ensemble classification that requires learning only a single base classifier. The idea is to learn a classifier that simultaneously predicts pairs of test labels - as opposed to learning multiple predictors for single test labels - then coordinating the assignment of individual labels by propagating beliefs on a graph over the data. We argue that the approach is statistically well motivated, even for independent identically distributed (iid) data. In fact, we present experimental results that show improvements in classification accuracy over single-example classifiers, across a range of iid data sets and over a set of base classifiers. Like boosting, the technique increases representational capacity while controlling variance through a principled form of classifier combination.",,7,0,,,NSERC,undefined,Natural Sciences and Engineering Research Council of Canada,IJCAI Artificial Intelligence
2-s2.0-84885652948,10.1145/1076034.1076121,,,Learning to estimate query difficulty: Including applications to missing content detection and distributed information retrieval,cp,Conference Paper,Yom-Tov E.,60026303,IBM Research - Haifa,Haifa,Israel,4,"Yom-Tov, Elad;Fine, Shai;Carmel, David;Darlow, Adam",6602557629;57203054481;7003995138;6506270823,60026303;60026303;60026303;60026303,2005-12-01,2005,SIGIR 2005 - Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,,21100261928,,Conference Proceeding,,,,512-519,"In this article we present novel learning methods for estimating the quality of results returned by a search engine in response to a query. Estimation is based on the agreement between the top results of the full query and the top results of its sub-queries. We demonstrate the usefulness of quality estimation for several applications, among them improvement of retrieval, detecting queries for which no relevant content exists in the document collection, and distributed information retrieval. Experiments on TREC data demonstrate the robustness and the effectiveness of our learning algorithms. © 2005 ACM.",query difficulty estimation,158,0,,,,undefined,,SIGIR Information Retrieval
2-s2.0-80051470467,,,,Making space for stories: Ambiguity in the design of personal communication systems,cp,Conference Paper,Aoki P.M.,60074754;60028487,Intel Research Laboratories;Palo Alto Research Center Incorporated,Santa Clara;Palo Alto,United States;United States,2,"Aoki, Paul M.;Woodruff, Allison",6601984494;55181034600,60028487;60074754,2005-01-01,2005,Conference on Human Factors in Computing Systems - Proceedings,02749696,28664,,Conference Proceeding,,,,181-190,"Pervasive personal communication technologies offer the potential for important social benefits for individual users, but also the potential for significant social difficulties and costs. In research on face-to-face social interaction, ambiguity is often identified as an important resource for resolving social difficulties. In this paper, we discuss two design cases of personal communication systems, one based on fieldwork of a commercial system and another based on an unrealized design concept. The cases illustrate how user behavior concerning a particular social difficulty, unexplained unresponsiveness, can be influenced by technological issues that result in interactional ambiguity. The cases also highlight the need to balance the utility of ambiguity against the utility of usability and communicative clarity. Copyright 2005 ACM.",Ambiguity | Face-work | Leases | Mediated communication | Push-to-talk,96,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-33244473083,10.1145/1065167.1065178,,,On the complexity of division and set joins in the relational algebra,cp,Conference Paper,Leinders D.,60010413,Universiteit Hasselt,Hasselt,Belgium,2,"Leinders, Dirk;Van Den Bussche, Jan",8544914400;7004243631,60010413;60010413,2005-12-01,2005,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,76-83,"We show that any expression of the relational division operator in the relational algebra with union, difference, projection, selection, and equijoins, must produce intermediate results of quadratic size. To prove this result, we show a dichotomy theorem about intermediate sizes of relational algebra expressions (they are either all linear, or at least one is quadratic); we link linear relational algebra expressions to expressions using only semijoins instead of joins; and we link these semijoin algebra expressions to the guarded fragment of first-order logic. Copyright 2005 ACM.",,9,0,repositoryvor,Green,,undefined,,PODS Databases
2-s2.0-25644450392,,,,Perfect simulation and stationarity of a class of mobility models,cp,Conference Paper,Le Boudec J.Y.,60098463;60070536,Microsoft Research Cambridge;Ceramics Laboratory,Cambridge;Lausanne,United Kingdom;Switzerland,2,"Le Boudec, Jean Yves;Vojnović, Milan",7005325654;56978166000,60070536;60098463,2005-10-07,2005,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,4,,,2743-2754,"We define ""random trip"", a generic mobility model for independent mobiles that contains as special cases: the random way point on convex or non convex domains, random walk with reflection or wrapping, city section, space graph and other models. We use Palm calculus to study the model and give a necessary and sufficient condition for a stationary regime to exist. When this condition is satisfied, we compute the stationary regime and give an algorithm to start a simulation in steady state (perfect simulation). The algorithm does not require the knowledge of geometric constants. For the special case of random waypoint, we provide for the first time a proof and a sufficient and necessary condition of the existence of a stationary regime. Further, we extend its applicability to a broad class of non convex and multi-site examples, and provide a ready-to-use algorithm for perfect simulation. For the special case of random walks with reflection or wrapping, we show that, in the stationary regime, the mobile location is uniformly distributed and is independent of the speed vector, and that there is no speed decay. Our framework provides a rich set of well understood models that can be used to simulate mobile networks with independent node movements. Our perfect sampling is implemented to use with ns-2, and it is freely available to download from http://icalwww.epfl.ch/ RandomTrip. © 2005 IEEE.",,339,0,,,,undefined,,INFOCOM Networking
2-s2.0-31844442829,,,,Programming by sketching for bit-streaming programs,cp,Conference Paper,Solar-Lezama A.,60025038;60017366;60006320,"University of California, Berkeley;IBM Thomas J. Watson Research Center;MIT Computer Science &amp; Artificial Intelligence Laboratory",Berkeley;Yorktown Heights;Cambridge,United States;United States;United States,4,"Solar-Lezama, Armando;Rabbah, Rodric;Bodík, Rastislav;Ebcioǧlu, Kemal",12141220900;6505978737;6701821028;6701391069,60025038;60006320;60025038;60017366,2005-12-01,2005,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,281-294,"This paper introduces the concept of programming with sketches, an approach for the rapid development of high-performance applications. This approach allows a programmer to write clean and portable reference code, and then obtain a high-quality implementation by simply sketching the outlines of the desired implementation. Subsequently, a compiler automatically fills in the missing details while also ensuring that a completed sketch is faithful to the input reference code. In this paper, we develop StreamBit as a sketching methodology for the important class of bit-streaming programs (e.g., coding and cryptography). A sketch is a partial specification of the implementation, and as such, it affords several benefits to programmer in terms of productivity and code robustness. First, a sketch is easier to write compared to a complete implementation. Second, sketching allows the programmer to focus on exploiting algorithmic properties rather than on orchestrating low-level details. Third, a sketch-aware compiler rejects ""buggy"" sketches, thus improving reliability while allowing the programmer to quickly evaluate sophisticated implementation ideas. We evaluated the productivity and performance benefits of our programming methodology in a user-study, where a group of novice StreamBit programmers competed with a group of experienced C programmers on implementing a cipher. We learned that, given the same time budget, the ciphers developed in StreamBit ran 2.5× faster than ciphers coded in C. We also produced implementations of DES and Serpent that were competitive with hand optimized implementations available in the public domain. Copyright 2005 ACM.",Domain Specific Compiler | Domain Specific Language | Sketching | Stream Programming | Streamit | Synchronous Dataflow,142,0,,,,undefined,,PLDI Programming Languages
2-s2.0-33745176642,10.1109/CVPR.2005.293,,,Real-time non-rigid surface detection,cp,Conference Paper,Pilet J.,60028186,École Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,3,"Pilet, Julien;Lepetit, Vincent;Fua, Pascal",6602997634;6506612961;55159125200,60028186;60028186;60028186,2005-01-01,2005,"Proceedings - 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR 2005",,4700151909,,Conference Proceeding,I,,1467352,822-828,"We present a real-time method for detecting deformable surfaces, with no need whatsoever for a priori pose knowledge. Our method starts from a set of wide baseline point matches between an undeformed image of the object and the image in which it is to be detected. The matches are used not only to detect but also to compute a precise mapping from one to the other. The algorithm is robust to large deformations, lighting changes, motion blur, and occlusions. It runs at 10 frames per second on a 2.8 GHz PC and we are not aware of any other published technique that produces similar results. Combining deformable meshes with a well designed robust estimator is key to dealing with the large number of parameters involved in modeling deformable surfaces and rejecting erroneous matches for error rates of up to 95%, which is considerably more than what is required in practice. © 2005 IEEE.",,81,0,repositoryam,Green,,undefined,,CVPR Computer Vision
2-s2.0-84885578759,10.1145/1095810.1095833,,,Rx: Treating bugs as allergies - A safe method to survive software failures,cp,Conference Paper,Qin F.,60000745,University of Illinois Urbana-Champaign,Urbana,United States,4,"Qin, Feng;Tucek, Joseph;Sundaresan, Jagadeesan;Zhou, Yuanyuan",57203239221;15137346900;6507516203;7405365838,60000745;60000745;60000745;60000745,2005-12-01,2005,"Proceedings of the 20th ACM Symposium on Operating Systems Principles, SOSP 2005",,21100261951,,Conference Proceeding,,,,235-248,"Many applications demand availability. Unfortunately, software failures greatly reduce system availability. Prior work on surviving software failures suffers from one or more of the following limitations: Required application restructuring, inability to address deterministic software bugs, unsafe speculation on program execution, and long recovery time.This paper proposes an innovative safe technique, called Rx, which can quickly recover programs from many types of software bugs, both deterministic and non-deterministic. Our idea, inspired from allergy treatment in real life, is to rollback the program to a recent checkpoint upon a software failure, and then to re-execute the program in a modified environment. We base this idea on the observation that many bugs are correlated with the execution environment, and therefore can be avoided by removing the ""allergen"" from the environment. Rx requires few to no modifications to applications and provides programmers with additional feedback for bug diagnosis. We have implemented RX on Linux. Our experiments with four server applications that contain six bugs of various types show that RX can survive all the six software failures and provide transparent fast recovery within 0.017-0.16 seconds, 21-53 times faster than the whole program restart approach for all but one case (CVS). In contrast, the two tested alternatives, a whole program restart approach and a simple rollback and re-execution without environmental changes, cannot successfully recover the three servers (Squid, Apache, and CVS) that contain deterministic bugs, and have only a 40% recovery rate for the server (MySQL) that contains a non-deterministic concurrency bug. Additionally, RX's checkpointing system is lightweight, imposing small time and space overheads. © 2005 ACM.",availability | bug | reliability | software failure,164,0,,,NSF,CNS-0347854,National Science Foundation,SOSP Operating Systems
2-s2.0-84880710441,,,,Solving checkers,cp,Conference Paper,Schaeffer J.,60030835,University of Alberta,Edmonton,Canada,8,"Schaeffer, J.;Björnsson, Y.;Burch, N.;Kishimoto, A.;Müller, M.;Lake, R.;Lu, P.;Sutphen, S.",57203215676;15757008200;36080490300;15055905500;57208122193;56261372500;7402292851;6603319865,60030835;60030835;60030835;60030835;60030835;60030835;60030835;60030835,2005-12-01,2005,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,292-297,"AI has had notable success in building high-performance game-playing programs to compete against the best human players. However, the availability of fast and plentiful machines with large memories and disks creates the possibility of solving a game. This has been done before for simple or relatively small games. In this paper, we present new ideas and algorithms for solving the game of checkers. Checkers is a popular game of skill with a search space of 1020possible positions. This paper reports on our first result. One of the most challenging checkers openings has been solved - the White Doctor opening is a draw. Solving roughly 50 more openings will result in the game-theoretic value of checkers being determined.",,47,0,,,,undefined,,IJCAI Artificial Intelligence
2-s2.0-84885629677,10.1145/1095810.1095829,,,Speculative execution in a distributed file system,cp,Conference Paper,Nightingale E.B.,60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,3,"Nightingale, Edmund B.;Chen, Peter M.;Flinn, Jason",8704826300;7408356226;7007104232,60025778;60025778;60025778,2005-12-01,2005,"Proceedings of the 20th ACM Symposium on Operating Systems Principles, SOSP 2005",,21100261951,,Conference Proceeding,,,,191-205,"Speculator provides Linux kernel support for speculative execution. It allows multiple processes to share speculative state by tracking causal dependencies propagated through inter-process communication. It guarantees correct execution by preventing speculative processes from externalizing output, e.g., sending a network message or writing to the screen, until the speculations on which that output depends have proven to be correct. Speculator improves the performance of distributed file systems by masking I/O latency and increasing I/O throughput. Rather than block during a remote operation, a file system predicts the operation's result, then uses Speculator to checkpoint the state of the calling process and speculatively continue its execution based on the predicted result. If the prediction is correct, the checkpoint is discarded; if it is incorrect, the calling process is restored to the checkpoint, and the operation is retried. We have modified the client, server, and network protocol of two distributed file systems to use Speculator. For PostMark and Andrew-style benchmarks, speculative execution results in a factor of 2 performance improvement for NFS over local-area networks and an order of magnitude improvement over wide-area networks. For the same benchmarks, Speculator enables the Blue File System to provide the consistency of single-copy file semantics and the safety of synchronous I/O, yet still outperform current distributed file systems with weaker consistency and safety. © 2005 ACM.",causality | distributed file systems | speculative execution,45,0,repositoryvor,Green,NSF,CCR-0509093,National Science Foundation,SOSP Operating Systems
2-s2.0-29344432136,,,,The max K-armed bandit: A new model of exploration applied to search heuristic selection,cp,Conference Paper,Cicirello V.A.,60139958;60104841,College of Computing &amp; Informatics;The Robotics Institute,Philadelphia;Pittsburgh,United States;United States,2,"Cicirello, Vincent A.;Smith, Stephen F.",6602982257;7406648499,60139958;60104841,2005-12-01,2005,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,3,,,1355-1361,"The multiarmed bandit is often used as an analogy for the tradeoff between exploration and exploitation in search problems. The classic problem involves allocating trials to the arms of a multiarmed slot machine to maximize the expected sum of rewards. We pose a new variation of the multiarmed bandit - the Max K-Armed Bandit - in which trials must be allocated among the arms to maximize the expected best single sample reward of the series of trials. Motivation for the Max K-Armed Bandit is the allocation of restarts among a set of multistart stochastic search algorithms. We present an analysis of this Max K-Armed Bandit showing under certain assumptions that the optimal strategy allocates trials to the observed best arm at a rate increasing double exponentially relative to the other arms. This motivates an exploration strategy that follows a Boltzmann distribution with an exponentially decaying temperature parameter. We compare this exploration policy to policies that allocate trials to the observed best arm at rates faster (and slower) than double exponentially. The results confirm, for two scheduling domains, that the double exponential increase in the rate of allocations to the observed best heuristic outperforms the other approaches. Copyright © 2005, American Association for Artificial Intelligence (www.aaai.org). All rights reserved.",,45,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-84923924156,10.1145/2629614,,,"The unique games conjecture, integrality gap for cut problems and embeddability of negative-type metrics into ℓ<inf>1</inf>",ar,Article,Khot S.A.,60028186;60003261,École Polytechnique Fédérale de Lausanne;Courant Institute of Mathematical Sciences,Lausanne;New York,Switzerland;United States,2,"Khot, Subhash A.;Vishnoi, Nisheeth K.",6701814147;13607606100,60003261;60028186,2015-02-01,1 February 2015,Journal of the ACM,00045411,23127,1557735X,Journal,62,1,,8,"In this article, we disprove a conjecture of Goemans and Linial; namely, that every negative type metric embeds into ℓ1 with constant distortion. We show that for an arbitrarily small constant δ > 0, for all large enough n, there is an n-point negative type metric which requires distortion at least (log log n)1/6-δ to embed into ℓ1 . Surprisingly, our construction is inspired by the Unique Games Conjecture (UGC), establishing a previously unsuspected connection between probabilistically checkable proof systems (PCPs) and the theory of metric embeddings.We first prove that the UGC implies a super-constant hardness result for the (nonuniform) SPARSESTCUT problem. Though this hardness result relies on the UGC, we demonstrate, nevertheless, that the corresponding PCP reduction can be used to construct an ""integrality gap instance"" for SPARSESTCUT. Towards this, we first construct an integrality gap instance for a natural SDP relaxation of UNIQUEGAMES. Then we ""simulate"" the PCP reduction and ""translate"" the integrality gap instance ofUNIQUEGAMES to an integrality gap instance of SPARSESTCUT. This enables us to prove a (log log n)1/6-δ integrality gap for SPARSESTCUT, which is known to be equivalent to the metric embedding lower bound.",Hardness of approximation | Integrality gap | Metric embeddings | Negative-type metrics | Semidefinite programming | Sparsest cut | Unique games conjecture,49,0,repositoryam,Green,,undefined,,FOCS Theory
2-s2.0-84861294274,,,,The bubble cursor: Enhancing target acquisition by dynamic of the cursor's activation area,cp,Conference Paper,Grossman T.,60016849,University of Toronto,Toronto,Canada,2,"Grossman, Tovi;Balakrishnan, Ravin",7003520062;7006221860,60016849;60016849,2005-01-01,2005,Conference on Human Factors in Computing Systems - Proceedings,02749696,28664,,Conference Proceeding,,,,281-290,"We present the bubble cursor - a new target acquisition technique based on area cursors. The bubble cursor improves upon area cursors by dynamically resizing its activation area depending on the proximity of surrounding targets, such that only one target is selectable at any time. We also present two controlled experiments that evaluate bubble cursor performance in lD and 2D target acquisition tasks, in complex situations with multiple targets of varying layout densities. Results show that the bubble cursor significantly outperforms the point cursor and the object pointing technique [8], and that bubble cursor performance can be accurately modeled and predicted using Fitts' law. Copyright 2005 ACM.",Area cursor | Bubble cursor | Fitts' law | Target acquisition,367,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-33846307437,10.1007/s11280-006-0221-0,,,Three-level caching for efficient query processing in large Web search engines,cp,Conference Paper,Long X.,60108318,NYU Tandon School of Engineering,New York,United States,2,"Long, Xiaohui;Suel, Torsten",36877410800;55937037300,60108318;60108318,2006-12-01,December 2006,World Wide Web,1386145X,14965,,Journal,9,4,,369-395,"Large web search engines have to answer thousands of queries per second with interactive response times. Due to the sizes of the data sets involved, often in the range of multiple terabytes, a single query may require the processing of hundreds of megabytes or more of index data. To keep up with this immense workload, large search engines employ clusters of hundreds or thousands of machines, and a number of techniques such as caching, index compression, and index and query pruning are used to improve scalability. In particular, two-level caching techniques cache results of repeated identical queries at the frontend, while index data for frequently used query terms are cached in each node at a lower level. We propose and evaluate a three-level caching scheme that adds an intermediate level of caching for additional performance gains. This intermediate level attempts to exploit frequently occurring pairs of terms by caching intersections or projections of the corresponding inverted lists. We propose and study several offline and online algorithms for the resulting weighted caching problem, which turns out to be surprisingly rich in structure. Our experimental evaluation based on a large web crawl and real search engine query log shows significant performance gains for the best schemes, both in isolation and in combination with the other caching levels. We also observe that a careful selection of cache admission and eviction policies is crucial for best overall performance. © Springer Science + Business Media, LLC 2006.",Caching | Inverted index | Search engine architecture | Search engine query processing | Web search,37,0,repositoryam,Green,NSF,CCR-0093400,National Science Foundation,WWW World Wide Web
2-s2.0-33745795187,10.1145/1099554.1099676,,,Towards automatic association of relevant unstructured content with structured query results,cp,Conference Paper,Roy P.,60107856;60019647;60014313,IBM India Pvt Ltd;Georgia Institute of Technology;University of Massachusetts Amherst,Bengaluru;Atlanta;Amherst,India;United States;United States,4,"Roy, Prasan;Mohania, Mukesh;Bamba, Bhuvan;Raman, Shree",55272977700;57191242897;21741949500;7201483907,60107856;60107856;60107856-60019647;60107856-60014313,2005-12-01,2005,"International Conference on Information and Knowledge Management, Proceedings",,55826,,Conference Proceeding,,,,405-412,"Faced with growing knowledge management needs, enterprises are increasingly realizing the importance of seamlessly integrating critical business information distributed across both structured and unstructured data sources. In existing information integration solutions, the application needs to formulate the SQL logic to retrieve the needed structured data on one hand, and identify a set of keywords to retrieve the related unstructured data on the other. This paper proposes a novel approach wherein the application specifies its information needs using only a SQL query on the structured data, and this query is automatically ""translated"" into a set of keywords that can be used to retrieve relevant unstructured data. We describe the techniques used for obtaining these keywords from (i) the query result, and (ii) additional related information in the underlying database. We further show that these techniques achieve high accuracy with very reasonable overheads. Copyright 2005 ACM.",Context | Information Integration | Keyword Search | SQL,27,0,,,,undefined,,CIKM Knowledge Management
2-s2.0-34848865701,10.1145/1060590.1060647,,,Undirected ST-connectivity in log-space,cp,Conference Paper,Reingold O.,60017563,Weizmann Institute of Science Israel,Rehovot,Israel,1,"Reingold, Omer",6701589804,60017563,2005-12-01,2005,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,376-385,"We present a deterministic, log-space algorithm that solves st-connectivity in undirected graphs. The previous bound on the space complexity of undirected st-connectivity was log4/3 obtained by Armoni, Ta-Shma, Wigderson and Zhou [9]. As undirected st-connectivity is complete for the class of problems solvable by symmetric, non-deterministic, log-space computations (the class SL), this algorithm implies that SL = L (where L is the class of problems solvable by deterministic log-space computations). Independent of our work (and using different techniques), Trifonov [45] has presented an O(log n log log n)-space, deterministic algorithm for undirected st-connectivity. Our algorithm also implies a way to construct in log-space a fixed sequence of directions that guides a deterministic walk through all of the vertices of any connected graph. Specifically, we give universal-traversal sequences, constructible in logarithmic space, for graphs with restricted labelling and log-space constructible universal-exploration sequences for general graphs. Copyright 2005 ACM.",Algorithms | Theory,187,0,,,,undefined,,STOC Theory
2-s2.0-33244490514,10.1109/ICSE.2005.1553554,,,Using structural context to recommend source code examples,cp,Conference Paper,Holmes R.,60010365,The University of British Columbia,Vancouver,Canada,2,"Holmes, Reid;Murphy, Gail C.",56220448900;7402791460,60010365;60010365,2005-12-01,2005,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2005,,1553554,117-125,"When coding to a framework, developers often become stuck, unsure of which class to subclass, which objects to instantiate and which methods to call. Example code that demonstrates the use of the framework can help developers make progress on their task. In this paper, we describe an approach for locating relevant code in an example repository that is based on heuristically matching the structure of the code under development to the example code. Our tool improves on existing approaches in two ways. First, the structural context needed to query the repository is extracted automatically from the code, freeing the developer from learning a query language or from writing their code in a particular style. Second, the repository can be generated easily from existing applications. We demonstrate the utility of this approach by reporting on a case study involving two subjects completing four programming tasks within the Eclipse integrated development environment framework. Copyright 2005 ACM.",Development environment framework | Examples | Recommender | Software structure,273,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-84885679117,10.1145/1095810.1095824,,,Vigilante: End-to-end containment of internet worms,cp,Conference Paper,Costa M.,60098463;60031101;60021726,Microsoft Research Cambridge;University of Cambridge;Microsoft Research,Cambridge;Cambridge;Redmond,United Kingdom;United Kingdom;United States,7,"Costa, Manuel;Crowcroft, Jon;Castro, Miguel;Rowstron, Antony;Zhou, Lidong;Zhang, Lintao;Barham, Paul",55936420900;57203254211;57189717671;6701627471;8359438500;55335430600;7006307649,60031101-60098463;60031101;60098463;60098463;60021726;60021726;60098463,2005-12-01,2005,"Proceedings of the 20th ACM Symposium on Operating Systems Principles, SOSP 2005",,21100261951,,Conference Proceeding,,,,133-147,"Worm containment must be automatic because worms can spread too fast for humans to respond. Recent work has proposed network-level techniques to automate worm containment; these techniques have limitations because there is no information about the vulnerabilities exploited by worms at the network level. We propose Vigilante, a new end-to-end approach to contain worms automatically that addresses these limitations. Vigilante relies on collaborative worm detection at end hosts, but does not require hosts to trust each other. Hosts run instrumented software to detect worms and broadcast self-certifying alerts (SCAs) upon worm detection. SCAs are proofs of vulnerability that can be inexpensively verified by any vulnerable host. When hosts receive an SCA, they generate filters that block infection by analysing the SCA-guided execution of the vulnerable software. We show that Vigilante can automatically contain fast-spreading worms that exploit unknown vulnerabilities without blocking innocuous traffic. © 2005 ACM.",control flow analysis | data flow analysis | self-certifying alerts | worm containment,281,0,,,,undefined,,SOSP Operating Systems
2-s2.0-33244494874,10.1145/1065167.1065171,,,XML data exchange: Consistency and query answering,cp,Conference Paper,Arenas M.,60016849,University of Toronto,Toronto,Canada,2,"Arenas, Marcelo;Libkin, Leonid",7005937486;57203256125,60016849;60016849,2005-12-01,2005,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,13-24,"Data exchange is the problem of finding an instance of a target schema, given an instance of a source schema and a specification of the relationship between the source and the target. Theoretical foundations of data exchange have recently been investigated for relational data. In this paper, we start looking into the basic properties of XML data exchange, that is, restructuring of XML documents that conform to a source DTD under a target DTD, and answering queries written over the target schema. We define XML data exchange settings in which source-totarget dependencies refer to the hierarchical structure of the data. Combining DTDs and dependencies makes some XML data exchange settings inconsistent. We investigate the consistency problem and determine its exact complexity. We then move to query answering, and prove a dichotomy theorem that classifies data exchange settings into those over which query answering is tractable, and those over which it is coNP-complete, depending on classes of regular expressions used in DTDs. Furthermore, for all tractable cases we give polynomial-time algorithms that compute target XML documents over which queries can be answered. Copyright 2005 ACM.",,92,0,,,,undefined,,PODS Databases
2-s2.0-33745838287,,,,A role for haptics in mobile interaction: Initial design using a handheld tactile display prototype,cp,Conference Paper,Luk J.,60010365;60002494,The University of British Columbia;Université McGill,Vancouver;Montreal,Canada;Canada,6,"Luk, Joseph;Pasquero, Jérôme;Little, Shannon;MacLean, Karon;Lévesque, Vincent;Hayward, Vincent",14035936100;14036270000;14035685600;7006153893;14035803000;7004176182,60010365;60002494;60010365;60010365;60002494;60002494,2006-07-17,2006,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,1,,,171-180,"Mobile interaction can potentially be enhanced with well-designed haptic control and display. However, advances have been limited by a vicious cycle whereby inadequate haptic technology obstructs inception of vitalizing applications. We present the first stages of a systematic design effort to break that cycle, beginning with specific usage scenarios and a new handheld display platform based on lateral skin stretch. Results of a perceptual device characterization inform mappings between device capabilities and specific roles in mobile interaction, and the next step of hardware re-engineering. Copyright 2006 ACM.",Design process | Display | Handheld interaction | Haptic | Lateral skin stretch | Mobile | Multimodal | Tactile,165,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85093979636,,,,Availability of multi-object operations,cp,Conference Paper,Yu H.,60074754;60021726,Intel Research Laboratories;Microsoft Research,Santa Clara;Redmond,United States;United States,3,"Yu, Haifeng;Gibbons, Phillip B.;Nath, Suman",39763532500;7101919649;22835570000,60074754;60074754;60021726,2006-01-01,2006,"3rd Symposium on Networked Systems Design and Implementation, NSDI 2006",,21101023760,,Conference Proceeding,,,,,"Highly-available distributed storage systems are commonly designed to optimize the availability of individual data objects, despite the fact that user level tasks typically request multiple objects. In this paper, we show that the assignment of object replicas (or fragments, in the case of erasure coding) to machines plays a dramatic role in the availability of such multi-object operations, without affecting the availability of individual objects. For example, for the TPC-H benchmark under real-world failures, we observe differences of up to four nines between popular assignments used in existing systems. Experiments using our wide-area storage system prototype, MOAT, on the PlanetLab, as well as extensive simulations, show which assignments lead to the highest availability for a given setting.",,21,0,,,,undefined,,NSDI Networking
2-s2.0-85071319367,,,,BigTable: A distributed storage system for structured data,cp,Conference Paper,Chang F.,60006191,Google LLC,Mountain View,United States,9,"Chang, Fay;Dean, Jeffrey;Ghemawat, Sanjay;Hsieh, Wilson C.;Wallach, Deborah A.;Burrows, Mike;Chandra, Tushar;Fikes, Andrew;Gruber, Robert E.",57199948728;16427311000;6507434941;7203083164;7202034967;7103139604;7007125282;24174045000;7102883504,60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191,2006-01-01,2006,OSDI 2006 - 7th USENIX Symposium on Operating Systems Design and Implementation,,21100963386,,Conference Proceeding,,,,205-218,"Bigtable is a distributed storage system for managing structured data that is designed to scale to a very large size: petabytes of data across thousands of commodity servers. Many projects at Google store data in Bigtable, including web indexing, Google Earth, and Google Finance. These applications place very different demands on Bigtable, both in terms of data size (from URLs to web pages to satellite imagery) and latency requirements (from backend bulk processing to real-time data serving). Despite these varied demands, Bigtable has successfully provided a flexible, high-performance solution for all of these Google products. In this paper we describe the simple data model provided by Bigtable, which gives clients dynamic control over data layout and format, and we describe the design and implementation of Bigtable.",,1518,0,,,,undefined,,OSDI Operating Systems
2-s2.0-34547339975,10.1145/1181775.1181787,,,Controlling factors in evaluating path-sensitive error detection techniques,cp,Conference Paper,Dwyer M.B.,60026306,University of Nebraska–Lincoln,Lincoln,United States,3,"Dwyer, Matthew B.;Person, Suzette;Elbaum, Sebastian",7005193693;8579331000;6604075891,60026306;60026306;60026306,2006-12-01,2006,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,85109,,Conference Proceeding,,,1181787,92-104,"Recent advances in static program analysis have made it possible to detect errors in applications that have been thoroughly tested and are in wide-spread use. The ability to find errors that have eluded traditional validation methods is due to the development and combination of sophisticated algorithmic techniques that are embedded in the implementations of analysis tools. Evaluating new analysis techniques is typically performed by running an analysis tool on a collection of subject programs, perhaps enabling and disabling a given technique in different runs. While seemingly sensible, this approach runs the risk of attributing improvements in the cost-effectiveness of the analysis to the technique under consideration, when those improvements may actually be due to details of analysis tool implementations that are uncontrolled during evaluation.In this paper, we focus on the specific class of path-sensitive error detection techniques and identify several factors that can significantly influence the cost of analysis. We show, through careful empirical studies, that the influence of these factors is sufficiently large that, if left uncontrolled, they may lead researchers to improperly attribute improvements in analysis cost and effectiveness. We make several recommendations as to how the influence of these factors can be mitigated when evaluating techniques. Copyright ACM 2006.",Empirical study | Model checking | Path-sensitive analysis,41,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-39049148855,10.1109/INFOCOM.2006.144,,,Delay and capacity trade-offs in mobile ad hoc networks: A global perspective,cp,Conference Paper,Sharma G.,60014171;60009254,University of Waterloo;Purdue University,Waterloo;West Lafayette,Canada;United States,3,"Sharma, Gaurav;Mazumdar, Ravi;Shroff, Ness",7202756906;7003268509;7005989631,60009254;60014171;60009254,2006-12-01,2006,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,,,4146797,,"Since the original work of Grossglauser and Tse, which showed that mobility can increase the capacity of an ad hoc network, there has been a lot of interest in characterizing the delay-capacity relationship in ad hoc networks. Various mobility models have been studied in the literature, and the delay-capacity relationships under those models have been characterized. The results indicate that there are trade-offs between the delay and capacity, and that the nature of these trade-offs is strongly influenced by the choice of the mobility model. Some questions that arise are: (i) How representative are these mobility models studied in the literature? (ii) Can the delay-capacity relationship be significantly different under some other ""reasonable"" mobility model? (iii) What sort of delay-capacity trade-off are we likely to see in a real world scenario? In this paper, we take the first step toward answering these questions. In particular, we analyze, among others, the mobility models studied in recent related works, under a unified framework. We relate the nature of delay-capacity trade-off to the nature of node motion, thereby providing a better understanding of the delay-capacity relationship in ad hoc networks in comparison to earlier works. © 2006 IEEE.",,114,0,,,,undefined,,INFOCOM Networking
2-s2.0-34547637575,10.1145/1183614.1183643,,,Discovering and exploiting keyword and attribute-value co-occurrences to improve P2P routing indices,cp,Conference Paper,Michel S.,60031155;60000256,University of Patras;Max Planck Institute for Informatics,Rio;Saarbrucken,Greece;Germany,6,"Michel, Sebastian;Bender, Matthias;Ntarmos, Nikos;Triantafillou, Peter;Weikum, Gerhard;Zimmer, Christian",24832051100;9939673200;7801571801;7003940986;56270327600;9939578000,60000256;60000256;60031155;60031155;60000256;60000256,2006-12-01,2006,"International Conference on Information and Knowledge Management, Proceedings",,55826,,Conference Proceeding,,,,172-181,"Peer-to-Peer (P2P) search requires intelligent decisions for query routing: selecting the best peers to which a given query, initiated at some peer, should be forwarded for retrieving additional search results. These decisions are based on statistical summaries for each peer, which are usually organized on a per-keyword basis and managed in a distributed directory of routing indices. Such architectures disregard the possible correlations among keywords. Together with the coarse granularity of per-peer summaries, which are mandated for scalability, this limitation may lead to poor search result quality.This paper develops and evaluates two solutions to this problem, sk-STAT based on single-key statistics only, and mk-STAT based on additional multi-key statistics. For both cases, hash sketch synopses are used to compactly represent a peer's data items and are efficiently disseminated in the P2P network to form a decentralized directory. Experimental studies with Gnutella and Web data demonstrate the viability and the trade-offs of the approaches. Copyright 2006 ACM.",Distributed IR | Key co-occurrences | Peer-to-peer information systems | Query routing,29,0,,,,undefined,,CIKM Knowledge Management
2-s2.0-33745850825,,,,Embedded phenomena: Supporting science learning with classroom-sized distributed simulations,cp,Conference Paper,Moher T.,60137961,College of Engineering,Chicago,United States,1,"Moher, Tom",6701470300,60137961,2006-07-17,2006,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2,,,691-700,"'Embedded phenomena' is a learning technology framework in which simulated scientific phenomena are mapped onto the physical space of classrooms. Students monitor and control the local state of the simulation through distributed media positioned around the room, gathering and aggregating evidence to solve problems or answer questions related to those phenomena. Embedded phenomena are persistent, running continuously over weeks and months, creating information channels that are temporally and physically interleaved with, but asynchronous with respect to, the regular flow of instruction. In this paper, we describe the motivations for the framework, describe classroom experiences with three embedded phenomena in the domains of seismology, insect ecology, and astronomy, and situate embedded phenomena within the context of human-computer interaction research in co-located group interfaces and learning technologies. Copyright 2006 ACM.",Classroom learning | Embedded phenomena | Science inquiry,78,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-55149090014,,,,Experience with an object reputation system for peer-to-peer filesharing,cp,Conference Paper,Walsh K.,60007776,Cornell University,Ithaca,United States,2,"Walsh, Kevin;Sirer, Emin Gün",57214667057;8522094600,60007776;60007776,2006-01-01,2006,"3rd Symposium on Networked Systems Design and Implementation, NSDI 2006",,21101023760,,Conference Proceeding,,,,,"In this paper, we describe Credence, a decentralized object reputation and ranking system for large-scale peer-to-peer filesharing networks. Credence counteracts pollution in these networks by allowing honest peers to assess the authenticity of online content through secure tabulation and management of endorsements from other peers. Our system enables peers to learn relationships even in the absence of direct observations or interactions through a novel, flow-based trust computation to discover trustworthy peers. We have deployed Credence as an overlay on top of the Gnutella filesharing network, with more than 10,000 downloads of our client software to date. We describe the system design, our experience with its deployment, and results from a long-term study of the trust network built by users. Data from the live deployment shows that Credence's flow-based trust computation enables users to avoid undesirable content. Honest Credence clients can identify three quarters of the decoys encountered when querying the Gnutella network.",,157,0,,,NSF,0546568,National Science Foundation,NSDI Networking
2-s2.0-33750353938,10.1145/1140103.1140283,,,Maximizing throughput in wireless networks via gossiping,cp,Conference Paper,Modiano E.,60022195,Massachusetts Institute of Technology,Cambridge,United States,3,"Modiano, Eytan;Shah, Devavrat;Zussman, Gil",7006138684;7402371516;14421965000,60022195;60022195;60022195,2006-06-01,June 2006,Performance Evaluation Review,01635999,26742,01635999,Conference Proceeding,34,1,,27-38,"A major challenge in the design of wireless networks is the need for distributed scheduling algorithms that will efficiently share the common spectrum. Recently, a few distributed algorithms for networks in which a node can converse with at most a single neighbor at a time have been presented. These algorithms guarantee 50% of the maximum possible throughput. We present the first distributed scheduling framework that guarantees maximum throughput. It is based on a combination of a distributed matching algorithm and an algorithm that compares and merges successive matching solutions. The comparison can be done by a deterministic algorithm or by randomized gossip algorithms. In the latter case, the comparison may be inaccurate. Yet, we show that if the matching and gossip algorithms satisfy simple conditions related to their performance and to the inaccuracy of the comparison (respectively), the framework attains the desired throughput. It is shown that the complexities of our algorithms, that achieve nearly 100% throughput, are comparable to those of the algorithms that achieve 50% throughput. Finally, we discuss extensions to general interference models. Even for such models, the framework provides a simple distributed throughput optimal algorithm. Copyright 2006 ACM.",Distributed algorithms | Gossip algorithms | Matching | Scheduling | Stability | Wireless networks,167,0,,,,undefined,,SIGMETRICS Performance
2-s2.0-33750359727,10.1145/1148170.1148219,,,Minimal test collections for retrieval evaluation,cp,Conference Paper,Carterette B.,60152130,Manning College of Information &amp; Computer Sciences,Amherst,United States,3,"Carterette, Ben;Allan, James;Sitaraman, Ramesh",6507636450;35432787900;57205572860,60152130;60152130;60152130,2006-01-01,2006,Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,,5000156902,,Conference Proceeding,2006,,,268-275,"Accurate estimation of information retrieval evaluation metrics such as average precision require large sets of relevance judgments. Building sets large enough for evaluation of realworld implementations is at best inefficient, at worst infeasible. In this work we link evaluation with test collection construction to gain an understanding of the minimal judging effort that must be done to have high confidence in the outcome of an evaluation. A new way of looking at average precision leads to a natural algorithm for selecting documents to judge and allows us to estimate the degree of confidence by defining a distribution over possible document judgments. A study with annotators shows that this method can be used by a small group of researchers to rank a set of systems in under three hours with 95% confidence. Copyright 2006 ACM.",Algorithms | Evaluation | Information retrieval | Test collections | Theory,171,0,repositoryvor,Green,,undefined,,SIGIR Information Retrieval
2-s2.0-33750707563,,,,Model counting: A new strategy for obtaining good bounds,cp,Conference Paper,Gomes C.P.,60278093,Cornell Ann S. Bowers College of Computing and Information Science,Ithaca,United States,3,"Gomes, Carla P.;Sabharwal, Ashish;Selman, Bart",7101707114;14831740900;7005516690,60278093;60278093;60278093,2006-11-13,2006,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,1,,,54-61,"Model counting is the classical problem of computing the number of solutions of a given prepositional formula. It vastly generalizes the NP-complete problem of prepositional satisfiability, and hence is both highly useful and extremely expensive to solve in practice. We present a new approach to model counting that is based on adding a carefully chosen number of so-called streamlining constraints to the input formula in order to cut down the size of its solution space in a controlled manner. Each of the additional constraints is a randomly chosen XOR or parity constraint on the problem variables, represented either directly or in the standard CNF form. Inspired by a related yet quite different theoretical study of the properties of XOR constraints, we provide a formal proof that with high probability, the number of XOR constraints added in order to bring the formula to the boundary of being unsatisfiable determines with high precision its model count. Experimentally, we demonstrate that this approach can be used to obtain good bounds on the model counts for formulas that are far beyond the reach of exact counting methods. In fact, we obtain the first non-trivial solution counts for very hard, highly structured combinatorial problem instances. Note that unlike other counting techniques, such as Markov Chain Monte Carlo methods, we are able to provide high-confidence guarantees on the quality of the counts obtained. Copyright © 2006, American Association for Artificial Intelligence (www.aaai.org). All rights reserved.",,100,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-34247136847,10.1145/1134285.1134337,,,Model-based development of dynamically adaptive software,cp,Conference Paper,Zhang J.,60146411,College of Engineering,East Lansing,United States,2,"Zhang, Ji;Cheng, Betty H.C.",53874367300;7202388859,60146411;60146411,2006-01-01,2006,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2006,,,371-380,"Increasingly, software should dynamically adapt its behavior at run-time in response to changing conditions in the supporting computing and communication infrastructure, and in the surrounding physical environment. In order for an adaptive program to be trusted, it is important to have mechanisms to ensure that the program functions correctly during and after adaptations. Adaptive programs are generally more difficult to specify, verify, and validate due to their high complexity. Particularly, when involving multi-threaded adaptations, the program behavior is the result of the collaborative behavior of multiple threads and software components. This paper introduces an approach to create formal models for the behavior of adaptive programs. Our approach separates the adaptation behavior and nonadaptive behavior specifications of adaptive programs, making the models easier to specify and more amenable to automated analysis and visual inspection. We introduce a process to construct adaptation models, automatically generate adaptive programs from the models, and verify and validate the models. We illustrate our approach through the development of an adaptive GSM-oriented audio streaming protocol for a mobile computing application. Copyright 2006 ACM.",Autonomic computing | Dynamic adaptation | Formal specification | Global invariants | Reliability | Verification,316,0,,,,undefined,,ICSE Software Engineering
2-s2.0-33845563923,10.1109/CVPR.2006.232,,,Putting objects in perspective,cp,Conference Paper,Hoiem D.,60027950,Carnegie Mellon University,Pittsburgh,United States,3,"Hoiem, Derek;Efros, Alexei A.;Hebert, Martial",14039007200;7005029942;7102121573,60027950;60027950;60027950,2006-12-22,2006,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,2,,1641015,2137-2144,"Image understanding requires not only individually estimating elements of the visual world but also capturing the interplay among them. In this paper, we provide a framework for placing local object detection in the context of the overall 3D scene by modeling the interdependence of objects, surface orientations, and camera viewpoint. Most object detection methods consider all scales and locations in the image as equally likely. We show that with probabilistic estimates of 3D geometry, both in terms of surfaces and world coordinates, we can put objects into perspective and model the scale and location variance in the image. Our approach reflects the cyclical nature of the problem by allowing probabilistic object hypotheses to refine geometry and vice-versa. Our framework allows painless substitution of almost any object detector and is easily extended to include other aspects of image understanding. Our results confirm the benefits of our integrated approach. © 2006 IEEE.",,353,0,repositoryam,Green,,undefined,,CVPR Computer Vision
2-s2.0-34250665891,10.1145/1135777.1135833,,,Random sampling from a search engine's index,cp,Conference Paper,Bar-Yossef Z.,60022403,Technion - Israel Institute of Technology,Haifa,Israel,2,"Bar-Yossef, Ziv;Gurevich, Maxim",22833417600;36785132800,60022403;60022403,2006-12-01,2006,Proceedings of the 15th International Conference on World Wide Web,,6300153111,,Conference Proceeding,,,,367-376,"We revisit a problem introduced by Bharat and Broder almost a decade ago: how to sample random pages from a search engine's index using only the search engine's public interface? Such a primitive is particularly useful in creating objective benchmarks for search engines.The technique of Bharat and Broder suffers from two well recorded biases: it favors long documents and highly ranked documents. In this paper we introduce two novel sampling techniques: a lexicon-based technique and a random walk technique. Our methods produce biased sample documents, but each sample is accompanied by a corresponding ""weight"", which represents the probability of this document to be selected in the sample. The samples, in conjunction with the weights, are then used to simulate near-uniform samples. To this end, we resort to three well known Monte Carlo simulation methods: rejection sampling, importance sampling and the Metropolis-Hastings algorithm.We analyze our methods rigorously and prove that under plausible assumptions, our techniques are guaranteed to produce near-uniform samples from the search engine's index. Experiments on a corpus of 2.4 million documents substantiate our analytical findings and show that our algorithms do not have significant bias towards long or highly ranked documents. We use our algorithms to collect fresh data about the relative sizes of Google, MSN Search, and Yahoo!.",Benchmarks | Sampling | Search engines | Size estimation,85,0,repositoryam,Green,,undefined,,WWW World Wide Web
2-s2.0-34547335024,10.1145/1166253.1166300,,,"Reflective physical prototyping through integrated design, test, and analysis",cp,Conference Paper,Hartmann B.,60141508,Stanford Engineering,Stanford,United States,7,"Hartmann, Björn;Klemmer, Scott R.;Bernstein, Michael;Abdulla, Leith;Burr, Brandon;Robinson-Mosher, Avi;Gee, Jennifer",15059978800;6603250689;57193014048;17433642800;17433516300;24538122100;36838058900,60141508;60141508;60141508;60141508;60141508;60141508;60141508,2006-12-01,2006,UIST: Proceedings of the Annual ACM Symposium on User Interface Softaware and Technology,,145310,,Conference Proceeding,,,,299-308,"Prototyping is the pivotal activity that structures innovation, collaboration, and creativity in design. Prototypes embody design hypotheses and enable designers to test them. Framing design as a thinking-by-doing activity foregrounds iteration as a central concern. This paper presents d.tools, a toolkit that embodies an iterative-design-centered approach to prototyping information appliances. This work offers contributions in three areas. First, d.tools introduces a statechart-based visual design tool that provides a low threshold for early-stage prototyping, extensible through code for higher-fidelity prototypes. Second, our research introduces three important types of hardware extensibility - at the hardware-to-PC interface, the intra-hardware communication level, and the circuit level. Third, d.tools integrates design, test, and analysis of information appliances. We have evaluated d.tools through three studies: a laboratory study with thirteen participants; rebuilding prototypes of existing and emerging devices; and by observing seven student teams who built prototypes with d.tools. Copyright ACM.",Design thinking | Design tools | Information appliances | Integrating physical &amp; digital | Prototyping | Toolkits,193,0,,,,undefined,,UIST User Interface
2-s2.0-41149089633,,,,Rethink the Sync,cp,Conference Paper,Nightingale E.B.,60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,4,"Nightingale, Edmund B.;Veeraraghavan, Kaushik;Chen, Peter M.;Flinn, Jason",8704826300;25032163400;7408356226;7007104232,60025778;60025778;60025778;60025778,2006-01-01,2006,OSDI 2006 - 7th USENIX Symposium on Operating Systems Design and Implementation,,21100963386,,Conference Proceeding,,,,1-14,"We introduce external synchrony, a new model for local file I/O that provides the reliability and simplicity of synchronous I/O, yet also closely approximates the performance of asynchronous I/O. An external observer cannot distinguish the output of a computer with an externally synchronous file system from the output of a computer with a synchronous file system. No application modification is required to use an externally synchronous file system: in fact, application developers can program to the simpler synchronous I/O abstraction and still receive excellent performance. We have implemented an externally synchronous file system for Linux, called xsyncfs. Xsyncfs provides the same durability and ordering guarantees as those provided by a synchronously mounted ext3 file system. Yet, even for I/O-intensive benchmarks, xsyncfs performance is within 7% of ext3 mounted asynchronously. Compared to ext3 mounted synchronously, xsyncfs is up to two orders of magnitude faster.",,96,0,,,NSF,CNS-0346686,National Science Foundation,OSDI Operating Systems
2-s2.0-34547150779,10.1145/1181775.1181790,,,SYNERGY: A new algorithm for property checking,cp,Conference Paper,Gulavani B.S.,60028186;60021726;60014153,École Polytechnique Fédérale de Lausanne;Microsoft Research;Indian Institute of Technology Bombay,Lausanne;Redmond;Mumbai,Switzerland;United States;India,5,"Gulavani, Bhargav S.;Henzinger, Thomas A.;Kannan, Yamini;Nori, Aditya V.;Rajamani, Sriram K.",14034312400;7004449411;56396688600;15832336400;7004184325,60014153;60028186;60021726;60021726;60021726,2006-12-01,2006,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,85109,,Conference Proceeding,,,1181790,117-127,"We consider the problem if a given program satisfies a specified safety property. Interesting programs have infinite state spaces, with inputs ranging over infinite domains, and for these programs the property checking problem is undecidable. Two broad approaches to property checking are testing and verification. Testing tries to find inputs and executions which demonstrate violations of the property. Verification tries to construct a formal proof which shows that all executions of the program satisfy the property. Testing works best when errors are easy to find, but it is often difficult to achieve sufficient coverage for correct programs. On the other hand, verification methods are most successful when proofs are easy to find, but they are often inefficient at discovering errors. We propose a new algorithm, Synergy, which combines testing and verification. Synergy unifies several ideas from the literature, including counterexample-guided model checking, directed testing, and partition refinement.This paper presents a description of the Synergy algorithm, its theoretical properties, a comparison with related algorithms, and a prototype implementation called Yogi. Copyright ACM 2006.",Abstraction refinement | Directed testing | Software model checking | Testing,187,0,,,,undefined,,FSE Software Engineering
2-s2.0-51449115991,10.3115/1220175.1220276,,,Semantic taxonomy induction from heterogenous evidence,cp,Conference Paper,Snow R.,60141508;60012708,Stanford Engineering;Stanford University,Stanford;Stanford,United States;United States,3,"Snow, Rion;Jurafsky, Daniel;Ng, Andrew Y.",51864770800;6602872553;35410071600,60141508;60012708;60141508,2006-01-01,2006,"COLING/ACL 2006 - 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference",,21100201743,,Conference Proceeding,1,,,801-808,"We propose a novel algorithm for inducing semantic taxonomies. Previous algorithms for taxonomy induction have typically focused on independent classifiers for discovering new single relationships based on hand-constructed or automatically discovered textual patterns. By contrast, our algorithm flexibly incorporates evidence from multiple classifiers over heterogenous relationships to optimize the entire structure of the taxonomy, using knowledge of a word's coordinate terms to help in determining its hypernyms, and vice versa. We apply our algorithm on the problem of sense-disambiguated noun hyponym acquisition, where we combine the predictions of hypernym and coordinate term classifiers with the knowledge in a preexisting semantic taxonomy (WordNet 2.1). We add 10, 000 novel synsets to WordNet 2.1 at 84% precision, a relative error reduction of 70% over a non-joint algorithm using the same component classifiers. Finally, we show that a taxonomy built using our algorithm shows a 23% relative F-score improvement over WordNet 2.1 on an independent testset of hypernym pairs. © 2006 Association for Computational Linguistics.",,365,1,repositoryam,Green,,undefined,,ACL Natural Language Processing
2-s2.0-33748103149,10.1145/1132516.1132553,,,The PCP theorem by gap amplification,cp,Conference Paper,Dinur I.,60007903,Hebrew University of Jerusalem,Jerusalem,Israel,1,"Dinur, Irit",55884748700,60007903,2006-01-01,2006,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,2006,,,241-250,"We present a new proof of the PCP theorem that is based on a combinatorial amplification lemma. The unsat value of a set of constraints C = {c 1,..., cn}, denoted UNSAT(C), is the smallest fraction of unsatisfied constraints, ranging over all possible assignments for the underlying variables. We describe a new combinatorial amplification transformation that doubles the unsat-value of a constraint-system, with only a linear blowup in the size of the system. The amplification step causes an increase in alphabet-size that is corrected by a PCP composition step. Iterative application of these two steps yields a proof for the PCP theorem. The amplification lemma relies on a new notion of ""graph powering"" that can be applied to systems of constraints. This powering amplifies the unsat-value of a constraint system provided that the underlying graph structure is an expander. We also apply the amplification lemma to construct PCPs and locally-testable codes whose length is linear up to a polylog factor, and whose correctness can be probabilistically verified by making a constant number of queries. Namely, we prove SAT ∈ PCP1/2, 1 [log2(n · poly log n), O(1)]. Copyright 2006 ACM.",Gap amplification | PCP,45,0,,,,undefined,,STOC Theory
2-s2.0-34250654176,10.1145/1142473.1142504,,,To search or to crawl?: Towards a query optimizer for text-centric tasks,cp,Conference Paper,Ipeirotis P.G.,60030162;60021784;60021726,Columbia University;New York University;Microsoft Research,New York;New York;Redmond,United States;United States;United States,4,"Ipeirotis, Panagiotis G.;Agichtein, Eugene;Jain, Pranay;Gravano, Luis",6603236863;6603264513;16425688000;7003940794,60021784;60021726;60030162;60030162,2006-12-01,2006,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,265-276,"Text is ubiquitous and, not surprisingly, many important applications rely on textual data for a variety of tasks. As a notable example, information extraction applications derive structured relations from unstructured text; as another example, focused crawlers explore the web to locate pages about specific topics. Execution plans for text-centric tasks follow two general paradigms for processing a text database: either we can scan, or 'crawl,"" the text database or, alternatively, we can exploit search engine indexes and retrieve the documents of interest via carefully crafted queries constructed in task-specific ways. The choice between crawl- and query-based execution plans can have a substantial impact on both execution time and output ""completeness"" (e.g., in terms of recall). Nevertheless, this choice is typically ad-hoc and based on heuristics or plain intuition. In this paper, we present fundamental building blocks to make the choice of execution plans for text-centric tasks in an informed, cost-based way. Towards this goal, we show how to analyze query- and crawl-based plans in terms of both execution time and output completeness. We adapt results from random-graph theory and statistics to develop a rigorous cost model for the execution plans. Our cost model reflects the fact that the performance of the plans depends on fundamental task-specific properties of the underlying text databases. We identify these properties and present efficient techniques for estimating the associated cost-model parameters. Overall, our approach helps predict the most appropriate execution plans for a task, resulting in significant efficiency and output completeness benefits. We complement our results with a large-scale experimental evaluation for three important text-centric tasks and over multiple real-life data sets. Copyright 2006 ACM.",Focused crawling | Information extraction | Metasearching | Query optimization | Research | Text databases,55,0,,,,undefined,,SIGMOD Databases
2-s2.0-33750732954,,,,Towards an axiom system for default logic,cp,Conference Paper,Lakemeyer G.,60016849;60016653,University of Toronto;Rheinisch-Westfälische Technische Hochschule Aachen,Toronto;Aachen,Canada;Germany,2,"Lakemeyer, Gerhard;Levesque, Hector J.",6603571701;7103141050,60016653;60016849,2006-11-13,2006,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,1,,,263-268,"Recently, Lakemeyer and Levesque proposed a logic of only-knowing which precisely captures three forms of nonmonotonic reasoning: Moore's Autoepistemic Logic, Konolige's variant based on moderately grounded expansions, and Reiter's default logic. Defaults have a uniform representation under all three interpretations in the new logic. Moreover, the logic itself is monotonic, that is, nonmonotonic reasoning is cast in terms of validity in the classical sense. While Lakemeyer and Levesque gave a model-theoretic account of their logic, a proof-theoretic characterization remained open. This paper fills that gap for the propositional subset: a sound and complete axiom system in the new logic for all three varieties of default reasoning. We also present formal derivations for some examples of default reasoning. Finally we present evidence that it is unlikely that a complete axiom system exists in the first-order case, even when restricted to the simplest forms of default reasoning. Copyright © 2006, American Association for Artificial Intelligence (www.aaai.org). All rights reserved.",,9,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-33745847575,10.1145/1124772.1124845,,,Trackball text entry for people with motor impairments,cp,Conference Paper,Wobbrock J.O.,60136640,School of Computer Science,Pittsburgh,United States,2,"Wobbrock, Jacob O.;Myers, Brad A.",6603152369;7202684451,60136640;60136640,2006-01-01,2006,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,1,,,479-488,"We present a new gestural text entry method for trackballs. The method uses the mouse cursor and relies on crossing instead of pointing. A user writes in fluid Roman-like unistrokes by ""pulsing"" the trackball in desired letter patterns. We examine this method both theoretically using the Steering Law and empirically in two studies. Our studies show that able-bodied users who were unfamiliar with trackballs could write at about 10 wpm with <4% total errors after 45 minutes. In eight sessions, a motor-impaired trackball user peaked at 7.11 wpm with 0% unconnected errors, compared to 5.95 wpm with 0% unconnected errors with an on-screen keyboard. Over sessions, his speeds were significantly faster with our gestural method than with an on-screen keyboard. A former 15-year veteran of on-screen keyboards, he now uses our gestural method instead. Copyright 2006 ACM.",Crossing | EdgeWrite | Fitts' Law | Gestures | Pointing | Steering Law | Text entry | Text input | Trackballs | Unistrokes,58,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-33747105621,,,,Trading convexity for scalability,cp,Conference Paper,Collobert R.,60018008;60004898,"NEC Laboratories America, Inc.;Max Planck Institute for Biological Cybernetics",Princeton;Tubingen,United States;Germany,4,"Collobert, Ronan;Sinz, Fabian;Weston, Jason;Bottou, Léon",14064641400;14036645300;8865128200;6701721644,60018008;60018008-60004898;60018008;60018008,2006-10-06,2006,ICML 2006 - Proceedings of the 23rd International Conference on Machine Learning,,5000153102,,Conference Proceeding,2006,,,201-208,"Convex learning algorithms, such as Support Vector Machines (SVMs), are often seen as highly desirable because they offer strong practical properties and are amenable to theoretical analysis. However, in this work we show how non-convexity can provide scalability advantages over convexity. We show how concave-convex programming can be applied to produce (i) faster SVMs where training errors are no longer support vectors, and (ii) much faster Transductive SVMs.",,149,0,,,,undefined,,ICML Machine Learning
2-s2.0-33749563073,10.1145/1150402.1150429,,,Training linear SVMs in linear time,cp,Conference Paper,Joachims T.,60278093,Cornell Ann S. Bowers College of Computing and Information Science,Ithaca,United States,1,"Joachims, Thorsten",6602804136,60278093,2006-01-01,2006,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,101510,,Conference Proceeding,2006,,,217-226,"Linear Support Vector Machines (SVMs) have become one of the most prominent machine learning techniques for high-dimensional sparse data commonly encountered in applications like text classification, word-sense disambiguation, and drug design. These applications involve a large number of examples n as well as a large number of features N, while each example has only s <<N non-zero features. This paper presents a Cutting-Plane Algorithm for training linear SVMs that provably has training time O(sn) for classification problems and O(sn log(n)) for ordinal regression problems. The algorithm is based on an alternative, but equivalent formulation of the SVM optimization problem. Empirically, the Cutting-Plane Algorithm is several orders of magnitude faster than decomposition methods like SVM-Light for large datasets. Copyright 2006 ACM.",Large-Scale Problems | Ordinal Regression | ROC-Area | Support Vector Machines (SVM) | Training Algorithms,1507,0,,,,undefined,,KDD Data Mining
2-s2.0-85054431103,,,,Trustworthy Keyword Search for Regulatory-Compliant Records Retention,cp,Conference Paper,Mitra S.,60158506;60009253,The Grainger College of Engineering;IBM Research - Almaden,Urbana;San Jose,United States;United States,3,"Mitra, Soumyadeb;Hsu, Windsor W.;Winslett, Marianne",8232271200;7402002648;7003882945,60158506;60009253;60158506,2006-01-01,2006,VLDB 2006 - Proceedings of the 32nd International Conference on Very Large Data Bases,,21101096744,,Conference Proceeding,,,,1001-1012,"Recent litigation and intense regulatory focus on secure retention of electronic records have spurred a rush to introduce Write-Once-Read-Many (WORM) storage devices for retaining business records such as electronic mail. However, simply storing records in WORM storage is insufficient to ensure that the records are trustworthy, i.e., able to provide irrefutable proof and accurate details of past events. Specifically, some form of index is needed for timely access to the records, but unless the index is maintained securely, the records can in effect be hidden or altered, even if stored in WORM storage. In this paper, we systematically analyze the requirements for establishing a trustworthy inverted index to enable keyword-based search queries. We propose a novel scheme for efficient creation of such an index and demonstrate, through extensive simulations and experiments with an enterprise keyword search engine, that the scheme can achieve online update speeds while maintaining good query performance. In addition, we present a secure index structure for multi-keyword queries that supports insert, lookup and range queries in time logarithmic in the number of documents.",,19,0,,,NSF,0331707,National Science Foundation,VLDB Databases
2-s2.0-34250617163,10.1145/1142351.1142354,,,Two-variable logic on data trees and XML reasoning,cp,Conference Paper,Bojańczyk M.,60123660;60032991;60013756;60013373,Institut de Recherche en Informatique Fondamentale (IRIF);Technische Universität Dortmund;University of Warsaw;INRIA Institut National de Recherche en Informatique et en Automatique,Paris;Dortmund;Warsaw;Le Chesnay,France;Germany;Poland;France,5,"Bojańczyk, Mikolaj;David, Claire;Muscholl, Anca;Schwentick, Thomas;Segoufin, Luc",11540205100;36166475900;6701760467;56023744700;55965366000,60013756;60123660;60123660;60032991;60013373,2006-12-01,2006,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,10-19,"Motivated by reasoning tasks in the context of XML languages, the satisfiability problem of logics on data trees is investigated. The nodes of a data tree have a label from a finite set and a data value from a possibly infinite set. It is shown that satisfiability for two-variable first-order logic is decidable if the tree structure can be accessed only through the child and the next sibling predicates and the access to data values is restricted to equality tests. From this main result decidability of satisfiability and containment for a data-aware fragment of XPath and of the implication problem for unary key and inclusion constraints is concluded. Copyright 2006 ACM.",Data trees | Decidability | First-order logic,43,0,repositoryam,Green,,undefined,,PODS Databases
2-s2.0-34247101896,10.1145/1134285.1134336,,,Who should fix this bug?,cp,Conference Paper,Anvik J.,60010365,The University of British Columbia,Vancouver,Canada,3,"Anvik, John;Hiew, Lyndon;Murphy, Gail C.",6603127911;56002793800;7402791460,60010365;60010365;60010365,2006-01-01,2006,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2006,,,361-370,"Open source development projects typically support an open bug repository to which both developers and users can report bugs. The reports that appear in this repository must be triaged to determine if the report is one which requires attention and if it is, which developer will be assigned the responsibility of resolving the report. Large open source developments are burdened by the rate at which new bug reports appear in the bug repository. In this paper, we present a semi-automated approach intended to ease one part of this process, the assignment of reports to a developer. Our approach applies a machine learning algorithm to the open bug repository to learn the kinds of reports each developer resolves. When a new report arrives, the classifier produced by the machine learning technique suggests a small number of developers suitable to resolve the report. With this approach, we have reached precision levels of 57% and 64% on the Eclipse and Firefox development projects respectively. We have also applied our approach to the gcc open source development with less positive results. We describe the conditions under which the approach is applicable and also report on the lessons we learned about applying machine learning to repositories used in open source development. Copyright 2006 ACM.",Bug report assignment | Bug triage | Issue tracking | Machine learning | Problem tracking,805,0,,,,undefined,,ICSE Software Engineering
2-s2.0-35348860314,10.1145/1240624.1240646,,,Authoring sensor-based interactions by demonstration with direct manipulation and pattern recognition,cp,Conference Paper,Hartmann B.,60141508;60002243,Stanford Engineering;MIT Media Lab,Stanford;Cambridge,United States;United States,4,"Hartmann, Björn;Abdulla, Leith;Mittal, Manas;Klemmer, Scott R.",15059978800;17433642800;22835398400;6603250689,60141508;60141508;60002243;60141508,2007-01-01,2007,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,145-154,"Sensors are becoming increasingly important in interaction design. Authoring a sensor-based interaction comprises three steps: choosing and connecting the appropriate hardware, creating application logic, and specifying the relationship between sensor values and application logic. Recent research has successfully addressed the first two issues. However, linking sensor input data to application logic remains an exercise in patience and trial-and-error testing for most designers. This paper introduces techniques for authoring sensor-based interactions by demonstration. A combination of direct manipulation and pattern recognition techniques enables designers to control how demonstrated examples are generalized to interaction rules. This approach emphasizes design exploration by enabling very rapid iterative demonstrate-edit-review cycles. This paper describes the manifestation of these techniques in a design tool, Exemplar, and presents evaluations through a first-use lab study and a theoretical analysis using the Cognitive Dimensions of Notation framework. © Copyright 2007 ACM.",Design tools | PBD | Physical computing | Sensors,118,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-58849103803,,,,Automated heart wall motion abnormality detection from ultrasound images using Bayesian networks,cp,Conference Paper,Qazi M.,60084261;60032114,Siemens USA;Erasmus MC,New York;Rotterdam,United States;Netherlands,8,"Qazi, Maleeha;Fung, Glenn;Krishnan, Sriram;Rosales, Romer;Steck, Harald;Rao, R. Bharat;Poldermans, Don;Chandrasekaran, Dhanalakshmi",16023052500;55630041100;57197459399;7004530676;23394009100;55664953000;7005216045;56357197100,60084261;60084261;60084261;60084261;60084261;60084261;60032114;,2007-12-01,2007,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,519-525,"Coronary Heart Disease can be diagnosed by measuring and scoring regional motion of the heart wall in ultrasound images of the left ventricle (LV) of the heart. We describe a completely automated and robust technique that detects diseased hearts based on detection and automatic tracking of the endocardium and epicardium of the LV. The local wall regions and the entire heart are then classified as normal or abnormal based on the regional and global LV wall motion. In order to leverage structural information about the heart we applied Bayesian Networks to this problem, and learned the relations among the wall regions off of the data using a structure learning algorithm. We checked the validity of the obtained structure using anatomical knowledge of the heart and medical rules as described by doctors. The resultant Bayesian Network classifier depends only on a small subset of numerical features extracted from dual-contours tracked through time and selected using a filterbased approach. Our numerical results confirm that our system is robust and accurate on echocardiograms collected in routine clinical practice at one hospital; our system is built to be used in real-time.",,39,0,,,,undefined,,IJCAI Artificial Intelligence
2-s2.0-37849011253,10.1145/1287624.1287659,,,Automatic consistency assessment for query results in dynamic environments,cp,Conference Paper,Payton J.,60280568;60150401;60010261,College of Computing and Informatics;Cockrell School of Engineering;Washington University in St. Louis,Charlotte;Austin;St. Louis,United States;United States;United States,3,"Payton, Jamie;Julien, Christine;Roman, Gruia Catalin",22433803500;23397494900;35612338300,60280568;60150401;60010261,2007-12-01,2007,"6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE 2007",,21100979896,,Conference Proceeding,,,,245-254,"Queries are convenient abstractions for the discovery of information and services, as they offer content-based information access. In distributed settings, query semantics are well-defined, e.g., they often satisfy ACID transactional properties. In a dynamic network setting, however, achieving transactional semantics becomes complex due to the openness and unpredictability. In this paper, we propose a query processing model for mobile ad hoc and sensor networks suitable for expressing a wide range of query semantics; the semantics differ in the degree of consistency with which results reflect the state of the environment during execution. We introduce several distinct notions of consistency and formalize them. A practical contribution of this paper is a protocol for query processing that automatically assesses and adaptively provides an achievable degree of consistency given the state of the operational environment throughout its execution. The protocol attaches an assessment of the achieved guarantee to returned query results, allowing precise reasoning about a query with a range of possible semantics. Copyright 2007 ACM.",Mobile computing | Query semantics,10,0,,,,undefined,,FSE Software Engineering
2-s2.0-63449137155,10.1145/1321440.1321449,,,Autonomously semantifying wikipedia,cp,Conference Paper,Wu F.,60015481,University of Washington,Seattle,United States,2,"Wu, Fei;Weld, Daniel S.",56003295600;7003334103,60015481;60015481,2007-12-01,2007,"International Conference on Information and Knowledge Management, Proceedings",,55826,,Conference Proceeding,,,,41-50,"Berners-Lee's compelling vision of a Semantic Web is hindered by a chicken-and-egg problem, which can be best solved by a bootstrapping method - creating enough structured data to motivate the development of applications. This paper argues that autonomously ""Semantifying Wikipedia"" is the best way to solve the problem. We choose Wikipedia as an initial data source, because it is comprehensive, not too large, high-quality, and contains enough manually- derived structure to bootstrap an autonomous, self-supervised process. We identify several types of structures which can be automatically enhanced in Wikipedia (e.g., link structure, taxonomic data, infoboxes, etc.), and we describe a prototype implementation of a self-supervised, machine learning system which realizes our vision. Preliminary experiments demonstrate the high precision of our system's extracted data - in one case equaling that of humans. Copyright 2007 ACM.",Information extraction | Semantic web | Wikipedia,307,0,,,,undefined,,CIKM Knowledge Management
2-s2.0-84880913380,,,,Building structure into local search for SAT,cp,Conference Paper,Pham D.N.,60032987;60029470,Griffith University;Commonwealth Scientific and Industrial Research Organisation,Brisbane;Canberra,Australia;Australia,3,"Pham, Duc Nghia;Thornton, John;Sattar, Abdul",56221073300;36900323100;7006680929,60029470-60032987;60029470-60032987;60029470-60032987,2007-12-01,2007,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,2359-2364,"Local search procedures for solving satisfiability problems have attracted considerable attention since the development of GSAT in 1992. However, recentwork indicates that for many real-world problems, complete search methods have the advantage, because modern heuristics are able to effectively exploit problem structure. Indeed, to develop a local search technique that can effectively deal with variable dependencies has been an open challenge since 1997. In this paper we show that local search techniques can effectively exploit information about problem structure producing significant improvements in performance on structured problem instances. Building on the earlier work of Ostrowski et al. we describe how information about variable dependencies can be built into a local search, so that only independent variables are considered for flipping. The cost effect of a flip is then dynamically calculated using a dependency lattice that models dependent variables using gates (specifically and, or and equivalence gates). The experimental study on hard structured benchmark problems demonstrates that our new approach significantly outperforms the previously reported best local search techniques.",,42,0,,,,undefined,,IJCAI Artificial Intelligence
2-s2.0-35548940331,10.1145/1247480.1247532,,,Compiling mappings to bridge applications and databases,cp,Conference Paper,Melnik S.,60026532;60021726,Microsoft Corporation;Microsoft Research,Redmond;Redmond,United States;United States,3,"Melnik, Sergey;Adya, Atul;Bernstein, Philip A.",57207509651;6701802018;7102505937,60021726;60026532;60021726,2007-10-31,2007,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,461-472,"Translating data and data access operations between applications and databases is a longstanding data management problem. We present a novel approach to this problem, in which the relationship between the application data and the persistent storage is specified using a declarative mapping, which is compiled into bidirectional views that drive the data transformation engine. Expressing the application model as a view on the database is used to answer queries, while viewing the database in terms of the application model allows us to leverage view maintenance algorithms for update translation. This approach has been implemented in a commercial product. It enables developers to interact with a relational database via a conceptual schema and an object oriented programming surface. We outline the implemented system and focus on the challenges of mapping compilation, which include rewriting queries under constraints and supporting non-relational constructs. Copyright 2007 ACM.",Mapping | Query rewriting | Updateable views,43,0,,,,undefined,,SIGMOD Databases
2-s2.0-35348886670,10.1145/1240624.1240754,,,Consuming video on mobile devices,cp,Conference Paper,O'Hara K.,60110398;60010574,"Hewlett Packard Laboratories, Bristol;Hewlett Packard Laboratories",Bristol;Palo Alto,United Kingdom;United States,3,"O'Hara, Kenton;Mitchell, April Slayden;Vorbau, Alex",7101930949;22835786700;22836999400,60110398;60010574;60010574,2007-10-22,2007,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,857-866,"Mobile video is now an everyday possibility with a wide array of commercially available devices, services and content. These technologies promise to transform the way that people can consume video media in their lives beyond the familiar behaviours associated with fixed TV and video technologies. Building upon earlier studies of mobile video, this paper reports on a study using diary techniques and ethnographic interviews to better understand how people are using commercially available mobile video technologies in their everyday lives. Drawing on reported episodes of mobile video behaviour, the study identifies the social motivations and values underpinning these behaviours that help characterise mobile video consumption beyond the simplistic notion of viewing TV to kill time wherever you may be. Implications for adoption and design of mobile video technologies and services are discussed. Copyright 2007 ACM.",Diary study | Interviews | Mobile TV | Mobile video | Mobility,129,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-34548355254,10.1109/INFCOM.2007.19,,,Disruption free topology reconfiguration in OSPF networks,cp,Conference Paper,Francois P.,60030003;60000874,Cisco Systems;Université Catholique de Louvain,San Jose;Louvain-la-Neuve,United States;Belgium,3,"Francois, Pierre;Shand, Mike;Bonaventure, Olivier",35857346600;20436549600;6602705725,60000874;60030003;60000874,2007-09-04,2007,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,,,4215601,89-97,"A few modifications to software and/or hardware of routers have been proposed recently to avoid the transient micro loops that can occur during the convergence of link-state interior gateway protocols like IS-IS and OSPF. We1 propose in this paper a technique that does not require modifications to IS-IS and OSPF, and that can be applied now by ISPs. Roughly, in the case of a manual modification of the state of a link, we progressively change the metric associated with this link to reach the required modification by ensuring that each step of the progression will be loop-free. The number of changes that are applied to a link to reach the targeted state by ensuring the transient consistency of the forwarding inside the network is minimized. Analysis performed on real regional and tier-1 ISP topologies show that the number of required transient changes is small. The solution can be applied in the case of link metric updates, manual set up, and shut down of links. © 2007 IEEE.",,86,0,repositoryam,Green,,undefined,,INFOCOM Networking
2-s2.0-34948903294,10.1109/CVPR.2007.383146,,,Dynamic 3D scene analysis from a moving vehicle,cp,Conference Paper,Leibe B.,60025858;60025063,ETH Zürich;KU Leuven,Zurich;Leuven,Switzerland;Belgium,4,"Leibe, Bastian;Cornelis, Nico;Cornelis, Kurt;Van Gool, Luc",57203231469;14015118600;7003825692;22735702300,60025858;60025063;60025063;60025858-60025063,2007-10-11,2007,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,,,4270171,,"In this paper, we present a system that integrates fully automatic scene geometry estimation, 2D object detection, 3D localization, trajectory estimation, and tracking for dynamic scene interpretation from a moving vehicle. Our sole input are two video streams from a calibrated stereo rig on top of a car. From these streams, we estimate Structure-from-Motion (SfM) and scene geometry in real-time. In parallel, we perform multi-view/multi-category object recognition to detect cars and pedestrians in both camera images. Using the SfM self-localization, 2D object detections are converted to 3D observations, which are accumulated in a world coordinate frame. A subsequent tracking module analyzes the resulting 3D observations to find physically plausible spacetime trajectories. Finally, a global optimization criterion takes object-object interactions into account to arrive at accurate 3D localization and trajectory estimates for both cars and pedestrians. We demonstrate the performance of our integrated system on challenging real-world data showing car passages through crowded city areas. © 2007 IEEE.",,242,0,repositoryam,Green,,undefined,,CVPR Computer Vision
2-s2.0-35448968883,10.1145/1250790.1250800,,,Faster integer multiplication,cp,Conference Paper,Fürer M.,60147936,Penn State College of Engineering,University Park,United States,1,"Fürer, Martin",6603676105,60147936,2007-10-30,2007,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,57-66,"For more than 35 years, the fastest known method for integer multiplication has been the Schönhage-Strassen algorithm running in time O(n log n log log n). Under certain restrictive conditions there is a corresponding (n log n) lower bound. The prevailing conjecture has always been that the complexity of an optimal algorithm is (n log n). We present a major step towards closing the gap from above by presenting an algorithm running in time n log n, 2 O(log*n). The main result is for boolean circuits as well as for multitape Turing machines, but it has consequences to other models of computation as well. Copyright 2007 ACM.",Complexity | Computer arithmetic | Discrete Fourier transform | FFT | Integer multiplication,131,0,,,,undefined,,STOC Theory
2-s2.0-35448936015,10.1145/1250734.1250741,,,Fault-tolerant typed assembly language,cp,Conference Paper,Perry F.,60141284;60007740,"School of Engineering and Applied Science;University of South Florida, Tampa",Princeton;Tampa,United States;United States,6,"Perry, Frances;MacKey, Lester;Reis, George A.;Ligatti, Jay;August, David I.;Walker, David",36176097100;57214520890;8962925500;6507530928;57119268500;7404440742,60141284;60141284;60141284;60007740;60141284;60141284,2007-10-30,2007,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,42-53,"A transient hardware fault occurs when an energetic particle strikes a transistor, causing it to change state. Although transient faults do not permanently damage the hardware, they may corrupt computations by altering stored values and signal transfers. In this paper, we propose a new scheme for provably safe and reliable computing in the presence of transient hardware faults. In our scheme, software computations are replicated to provide redundancy while special instructions compare the independently computed results to detect errors before writing critical data. In stark contrast to any previous efforts in this area, we have analyzed our fault tolerance scheme from a formal, theoretical perspective. To be specific, first, we provide an operational semantics for our assembly language, which includes a precise formal definition of our fault model. Second, we develop an assembly-level type system designed to detect reliability problems in compiled code. Third, we provide a formal specification for program fault tolerance under the given fault model and prove that all well-typed programs are indeed fault tolerant. In addition to the formal analysis, we evaluate our detection scheme and show that it only takes 34% longer to execute than the unreliable version. Copyright © 2007 ACM.",Fault tolerance | Soft faults | Transient hardware faults | Typed assembly language,19,0,repositoryvor,Green,,undefined,,PLDI Programming Languages
2-s2.0-35448946460,10.1145/1265530.1265533,,,Generalized hypertree decompositions: NP-hardness and tractable variants,cp,Conference Paper,Gottlob G.,60032991;60026851,Technische Universität Dortmund;University of Oxford,Dortmund;Oxford,Germany;United Kingdom,3,"Gottlob, Georg;Miklós, Zoltan;Schwentick, Thomas",7005068491;22938553800;56023744700,60026851;60026851;60032991,2007-10-29,2007,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,13-22,"The generalized hypertree width GHW(H) of a hypergraph H is a measure of its cyclicity. Classes of conjunctive queries or constraint satisfaction problems whose associated hypergraphs have bounded GHW are known to be solvable in polynomial time. However,it has been an open problem for several years if for a fixed constant k and input hypergraph H it can be determined in polynomial time whether GHW(H)< k. Here, this problem is settled by proving that even for k=3 the problem is already NP-hard. On the way to this result, another long standing open problem, originally raised by Goodman and Shmueli in 1984 all in the context of join optimization is solved. It is proven that determining whether a hypergraph H admits a tree projection with respect to a hypergraph G is NP-complete. Our intractability results on generalized hypertree width motivate further research on more restrictive tractable hypergraph decomposition methods that approximate general hypertree decomposition (GHD). We show that each such method is dnominated by a tractable decomposition method definable through a function that associates a set of partial edges to a hypergraph. By using one particular such function, we define the new Component Hypertree Decomposition method, which is tractable and strictly more general than other approximations to GHD published so far. Copyright 2007 ACM.",Acyclic | Conjunctive query | Hypergraph | Hypertree decomposition | NP-complete | Tractable | Tree projection problem,21,0,,,,undefined,,PODS Databases
2-s2.0-37849030530,10.1145/1287624.1287643,,,Globally distributed software development project performance: An empirical analysis,cp,Conference Paper,Ramasubbu N.,60018933,Singapore Management University,Singapore City,Singapore,2,"Ramasubbu, Narayan;Balan, Rajesh Krishna",16317345600;35576393800,60018933;60018933,2007-12-01,2007,"6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE 2007",,9800153143,,Conference Proceeding,,,,125-134,"Software firms are increasingly distributing their software development effort across multiple locations. In this paper we present the results of a two year field study that investigated the effects of dispersion on the productivity and quality of distributed software development. We first develop a model of distributed software development. We then use the model, along with our empirically observed data, to understand the consequences of dispersion on software project performance. Our analysis reveals that, even in high process maturity environments, a) dispersion significantly reduces development productivity and has effects on conformance quality, and b) these negative effects of dispersion can be significantly mitigated through deployment of structured software engineering processes. Copyright 2007 ACM.",Empirical analysis | Globally distributed software development | Quality management | Software engineering economics,80,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-34547996209,10.1145/1273496.1273523,,,Information-theoretic metric learning,cp,Conference Paper,Davis J.V.,60150459,Department of Computer Science,Austin,United States,5,"Davis, Jason V.;Kulis, Brian;Jain, Prateek;Sra, Suvrit;Dhillon, Inderjit S.",56326854800;12141279600;57209869316;8865497700;6603876297,60150459;60150459;60150459;60150459;60150459,2007-08-23,2007,ACM International Conference Proceeding Series,,11600154611,,Conference Proceeding,227,,,209-216,"In this paper, we present an information-theoretic approach to learning a Mahalanobis distance function. We formulate the problem as that of minimizing the differential relative entropy between two multivariate Gaussians under constraints on the distance function. We express this problem as a particular Bregman optimization problem - -that of minimizing the LogDet divergence subject to linear constraints. Our resulting algorithm has several advantages over existing methods. First, our method can handle a wide variety of constraints and can optionally incorporate a prior on the distance function. Second, it is fast and scalable. Unlike most existing methods, no eigenvalue computations or semi-definite programming are required. We also present an online version and derive regret bounds for the resulting algorithm. Finally, we evaluate our method on a recent error reporting system for software called Clarify, in the context of metric learning for nearest neighbor classification, as well as on standard data sets.",,1555,0,repositoryam,Green,,undefined,,ICML Machine Learning
2-s2.0-56449083629,,,,Learning synchronous grammars for semantic parsing with lambda calculus,cp,Conference Paper,Wong Y.W.,60150459,Department of Computer Science,Austin,United States,2,"Wong, Yuk Wah;Mooney, Raymond J.",10243466100;7102791999,60150459;60150459,2007-12-01,2007,ACL 2007 - Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics,,21100201742,,Conference Proceeding,,,,960-967,"This paper presents the first empirical results to our knowledge on learning synchronous grammars that generate logical forms. Using statistical machine translation techniques, a semantic parser based on a synchronous context-free grammar augmented with λ-operators is learned given a set of training sentences and their correct logical forms. The resulting parser is shown to be the best-performing system so far in a database query domain. © 2007 Association for Computational Linguistics.",,226,0,,,,undefined,,ACL Natural Language Processing
2-s2.0-85028155431,,,,"Life, death, and the critical transition: Finding liveness bugs in systems code",cp,Conference Paper,Killian C.,60030612,"University of California, San Diego",La Jolla,United States,4,"Killian, Charles;Anderson, James W.;Jhala, Ranjit;Vahdat, Amin",35619501000;57199275875;6602180143;6701708010,60030612;60030612;60030612;60030612,2007-01-01,2007,"4th Symposium on Networked Systems Design and Implementation, NSDI 2007",,21101081127,,Conference Proceeding,,,,243-256,"Modern software model checkers find safety violations: breaches where the system enters some bad state. However, we argue that checking liveness properties offers both a richer and more natural way to search for errors, particularly in complex concurrent and distributed systems. Liveness properties specify desirable system behaviors which must be satisfied eventually, but are not always satisfied, perhaps as a result of failure or during system initialization. Existing software model checkers cannot verify liveness because doing so requires finding an infinite execution that does not satisfy a liveness property. We present heuristics to find a large class of liveness violations and the critical transition of the execution. The critical transition is the step in an execution that moves the system from a state that does not currently satisfy some liveness property-but where recovery is possible in the future-to a dead state that can never achieve the liveness property. Our software model checker, MACEMC, isolates complex liveness errors in our implementations of PASTRY, CHORD, a reliable transport protocol, and an overlay tree.",,142,0,,,,undefined,,NSDI Networking
2-s2.0-34548726133,10.1109/ICSE.2007.50,,,Matching and merging of statecharts specifications,cp,Conference Paper,Nejati S.,60016849;60008383,University of Toronto;AT&amp;T Laboratories Florham Park,Toronto;Florham Park,Canada;United States,5,"Nejati, Shiva;Sabetzadeh, Mehrdad;Chechik, Marsha;Easterbrook, Steve;Zave, Pamela",18038340600;9133712900;6603893035;6603689305;7004876349,60016849;60016849;60016849;60016849;60008383,2007-09-25,2007,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,4222568,54-63,"Model Management addresses the problem of managing an evolving collection of models, by capturing the relationships between models and providing well-defined operators to manipulate them. In this paper, we describe two such operators for manipulating hierarchical Statecharts: Match, for finding correspondences between models, and Merge, for combining models with respect to known correspondences between them. Our Match operator is heuristic, making use of both static and behavioural properties of the models to improve the accuracy of matching. Our Merge operator preserves the hierarchical structure of the input models, and handles differences in behaviour through parameterization. In this way, we automatically construct merges that preserve the semantics of Statecharts models. We illustrate and evaluate our work by applying our operators to AT&T telecommunication features. © 2007 IEEE.",,220,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-37849017546,10.1145/1287624.1287628,,,Mining specifications of malicious behavior,cp,Conference Paper,Christodorescu M.,60018163;116437658,Technische Universität Wien;University of Wisconsin,Vienna;ST. LOUIS,Austria;United States,3,"Christodorescu, Mihai;Jha, Somesh;Kruegel, Christopher",8969401600;7202728236;14017971800,116437658;116437658;60018163,2007-12-01,2007,"6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE 2007",,21100969308,,Conference Proceeding,,,,5-14,"Malware detectors require a specification of malicious behavior. Typically, these specifications are manually constructed by investigating known malware. We present an automatic technique to overcome this laborious manual process. Our technique derives such a specification by comparing the execution behavior of a known malware against the execution behaviors of a set of benign programs. In other words, we mine the malicious behavior present in a known malware that is not present in a set of benign programs. The output of our algorithm can be used by malware detectors to detect malware variants. Since our algorithm provides a succinct description of malicious behavior present in a malware, it can also be used by security analysts for understanding the malware. We have implemented a prototype based on our algorithm and tested it on several malware programs. Experimental results obtained from our prototype indicate that our algorithm is effective in extracting malicious behaviors that can be used to detect malware variants. Copyright 2007 ACM.",Behavior-based detection | Differential analysis | Malspec,224,0,repositoryvor,Green,,undefined,,FSE Software Engineering
2-s2.0-36348946355,10.1145/1269899.1254887,,,Modeling the relative fitness of storage,cp,Conference Paper,Mesnier M.P.,60027950,Carnegie Mellon University,Pittsburgh,United States,5,"Mesnier, Michael P.;Wachs, Matthew;Sambasivan, Raja R.;Zheng, Alice X.;Ganger, Gregory R.",6602556897;14010666700;13613075600;36836484700;35580432900,60027950;60027950;60027950;60027950;60027950,2007-11-29,2007,Performance Evaluation Review,01635999,26742,,Conference Proceeding,35,1,,37-48,"Relative fitness is a new black-box approach to modeling the performance of storage devices. In contrast with an absolute model that predicts the performance of a workload on a given storage device, a relative fitness model predicts performance differences between a pair of devices. There are two primary advantages to this approach. First, because are lative fitness model is constructed for a device pair, the application-device feedback of a closed workload can be captured (e.g., how the I/O arrival rate changes as the workload moves from device A to device B). Second, a relative fitness model allows performance and resource utilization to be used in place of workload characteristics. This is beneficial when workload characteristics are difficult to obtain or concisely express (e.g., rather than describe the spatio-temporal characteristics of a workload, one could use the observed cache behavior of device A to help predict the performance of B. This paper describes the steps necessary to build a relative fitness model, with an approach that is general enough to be used with any black-box modeling technique. We compare relative fitness models and absolute models across a variety of workloads and storage devices. On average, relative fitness models predict bandwidth and throughput within 10-20% and can reduce prediction error by as much as a factor of two when compared to absolute models. © Copyright 2007 ACM.",Black-box | CART | Modeling | Storage,45,0,,,,undefined,,SIGMETRICS Performance
2-s2.0-35348855112,10.1145/1240624.1240846,,,Multiview: Improving trust in group video conferencing through spatial faithfulness,cp,Conference Paper,Nguyen D.T.,60025038,"University of California, Berkeley",Berkeley,United States,2,"Nguyen, David T.;Canny, John",57217381030;7005125209,60025038;60025038,2007-01-01,2007,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1465-1474,"Video conferencing is still considered a poor alternative to face-to-face meetings. In the business setting, where these systems are most prevalent, the misuse of video conferencing systems can have detrimental results, especially in high-stakes communications. Prior work suggests that spatial distortions of nonverbal cues, particularly gaze and deixis, negatively impact many aspects of effective communication in dyadic communications. However, video conferencing systems are often used for group-to-group meetings where spatial distortions are exacerbated. Meanwhile, its effects on the group dynamic are not well understood. In this study, we examine the effects that spatial distortions of nonverbal cues have on inter-group trust formation. We conducted a large (169 participant) study of group conferencing under various conditions. We found that the use of systems that introduce spatial distortions negatively affect trust formation patterns. On the other hand, these effects are essentially eliminated by using a spatially faithful video conferencing system. Copyright 2007 ACM.",CMC | CSCW | Eye contact | Gaze awareness | Prisoner's dilemma | Social dilemmas | Spatial faithfulness | Trust | Video conferencing,107,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-37849021932,10.1145/1287624.1287637,,,Object and reference immutability using java generics,cp,Conference Paper,Zibin Y.,60006320;60002316,MIT Computer Science &amp; Artificial Intelligence Laboratory;Victoria University of Wellington,Cambridge;Wellington,United States;New Zealand,6,"Zibin, Yoav;Potanin, Alex;Ali, Mahmood;Artzi, Shay;Kieun, Adam;Ernst, Michael D.",6602775141;37062710900;57199279262;23134814500;8837002600;36916423000,60006320;60002316;60006320;60006320;60006320;60006320,2007-12-01,2007,"6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE 2007",,9800153143,,Conference Proceeding,,,,75-84,"A compiler-checked immutability guarantee provides useful documentation, facilitates reasoning, and enables optimizations. This paper presents Immutability Generic Java (IGJ), a novel language extension that expresses immutability without changing Java's syntax by building upon Java's generics and annotation mechanisms. In IGJ, each class has one additional type parameter that is Immutable, Mutable, or ReadOnly. IGJ guarantees both reference immutability (only mutable references can mutate an object) and object immutability (an immutable reference points to an immutable object). IGJ is the first proposal for enforcing object immutability within Java's syntax and type system, and its reference immutability is more expressive than previous work. IGJ also permits covariant changes of type parameters in a type-safe manner, e.g., a readonly list of integers is a subtype of a readonly list of numbers. IGJ extends Java's type system with a few simple rules. We formalize this type system and prove it sound. Our IGJ compiler works by type-erasure and generates byte-code that can be executed on any JVM without runtime penalty. Copyright 2007 ACM.",Const | Generic | IGJ | Immutability | Java | Readonly,66,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-36348976895,,,,PLOW: A collaborative task learning agent,cp,Conference Paper,Allen J.,60152526;60141508;60083181,Hajim School of Engineering and Applied Sciences;Stanford Engineering;Florida Institute for Human &amp; Machine Cognition,Rochester;Stanford;Pensacola,United States;United States;United States,7,"Allen, James;Chambers, Nathanael;Ferguson, George;Galescu, Lucian;Jung, Hyuckchul;Swift, Mary;Taysom, William",7406425278;8251547300;7202204825;8251547400;8635180200;14042706300;8251547800,60083181;60141508;60152526;60083181;60083181;60152526;60083181,2007-11-28,2007,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,2,,,1514-1519,"To be effective, an agent that collaborates with humans needs to be able to learn new tasks from humans they work with. This paper describes a system that learns executable task models from a single collaborative learning session consisting of demonstration, explanation and dialogue. To accomplish this, the system integrates a range of AI technologies: deep natural language understanding, knowledge representation and reasoning, dialogue systems, planning/agent-based systems and machine learning. A formal evaluation shows the approach has great promise. Copyright © 2007, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,106,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-84880899936,,,,Performance analysis of online anticipatory algorithms for large multistage stochastic integer programs,cp,Conference Paper,Mercier L.,60011460,Brown University,Providence,United States,2,"Mercier, Luc;Van Hentenryck, Pascal",23012552000;55667017700,60011460;60011460,2007-12-01,2007,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,1979-1984,"Despite significant algorithmic advances in recent years, finding optimal policies for large-scale, multistage stochastic combinatorial optimization problems remains far beyond the reach of existing methods. This paper studies a complementary approach, online anticipatory algorithms, that make decisions at each step by solving the anticipatory relaxation for a polynomial number of scenarios. Online anticipatory algorithms have exhibited surprisingly good results on a variety of applications and this paper aims at understanding their success. In particular, the paper derives sufficient conditions under which online anticipatory algorithms achieve good expected utility and studies the various types of errors arising in the algorithms including the anticipativity and sampling errors. The sampling error is shown to be negligible with a logarithmic number of scenarios. The anticipativity error is harder to bound and is shown to be low, both theoretically and experimentally, for the existing applications.",,30,0,,,NSF,DMI-0600384,National Science Foundation,IJCAI Artificial Intelligence
2-s2.0-50649113224,10.1109/ICCV.2007.4408977,,,Population shape regression from random design data,cp,Conference Paper,Davis B.C.,60114004;60025488;60025111,"Kitware, Inc.;The University of Utah;The University of North Carolina at Chapel Hill",Clifton Park;Salt Lake City;Chapel Hill,United States;United States;United States,4,"Davis, B. C.;Bullitt, E.;Fletcher, P. T.;Joshi, S.",8421821000;7007087127;22434364200;35426777000,60025111-60114004;60025111;60025488;60025488,2007-12-01,2007,Proceedings of the IEEE International Conference on Computer Vision,,110561,,Conference Proceeding,,,4408977,,"Regression analysis is a powerful tool for the study of changes in a dependent variable as a function of an independent regressor variable, and in particular it is applicable to the study of anatomical growth and shape change. When the underlying process can be modeled by parameters in a Euclidean space, classical regression techniques [13, 34] are applicable and have been studied extensively. However, recent work suggests that attempts to describe anatomical shapes using flat Euclidean spaces undermines our ability to represent natural biological variability [9, 11]. In this paper we develop a method for regression analysis of general, manifold-valued data. Specifically, we extend Nadaraya-Watson kernel regression by recasting the regression problem in terms of Fréchet expectation. Although this method is quite general, our driving problem is the study anatomical shape change as a function of age from random design image data. We demonstrate our method by analyzing shape change in the brain from a random design dataset of MR images of 89 healthy adults ranging in age from 22 to 79 years. To study the small scale changes in anatomy, we use the infinite dimensional manifold of diffeomorphic transformations, with an associated metric. We regress a representative anatomical shape, as a function of age, from this population. ©2007 IEEE.",,124,0,repositoryam,Green,,undefined,,ICCV Computer Vision
2-s2.0-34548793480,10.1109/ICSE.2007.66,,,Predicting faults from cached history,cp,Conference Paper,Kim S.,60033241;60024941;60022195,"Universität des Saarlandes;University of California, Santa Cruz;Massachusetts Institute of Technology",Saarbrucken;Santa Cruz;Cambridge,Germany;United States;United States,4,"Kim, Sunghun;Zimmermann, Thomas;Whitehead, E. James;Zeller, Andreas",12241083400;16308551800;7005742792;7007015864,60022195;60033241;60024941;60033241,2007-09-25,2007,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,4222610,489-498,"We analyze the version history of 7 software systems to predict the most fault prone entities and files. The basic assumption is that faults do not occur in isolation, but rather in bursts of several related faults. Therefore, we cache locations that are likely to have faults: starting from the location of a known (fixed) fault, we cache the location itself, any locations changed together with the fault, recently added locations, and recently changed locations. By consulting the cache at the moment a fault is fixed, a developer can detect likely fault-prone locations. This is useful for prioritizing verification and validation resources on the most fault prone files or entities. In our evaluation of seven open source projects with more than 200,000 revisions, the cache selects 10% of the source code files; these files account for 73%-95% of faults - a significant advance beyond the state of the art. © 2007 IEEE.",,402,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-36849023117,10.1145/1281192.1281199,,,Predictive discrete latent factor models for large scale dyadic data,cp,Conference Paper,Agarwal D.,60075274,Yahoo Research Labs,Sunnyvale,United States,2,"Agarwal, Deepak;Merugu, Srujana",35829799700;6602619637,60075274;60075274,2007-12-14,2007,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,101510,,Conference Proceeding,,,,26-35,"We propose a novel statistical method to predict large scale dyadic response variables in the presence of covariate information. Our approach simultaneously incorporates the effect of covariates and estimates local structure that is induced by interactions among the dyads through a discrete latent factor model. The discovered latent factors provide a redictive model that is both accurate and interpretable. We illustrate our method by working in a framework of generalized linear models, which include commonly used regression techniques like linear regression, logistic regression and Poisson regression as special cases. We also provide scalable generalized EM-based algorithms for model fitting using both ""hard"" and ""soft"" cluster assignments. We demonstrate the generality and efficacy of our approach through large scale simulation studies and analysis of datasets obtained from certain real-world movie recommendation and internet advertising applications. © 2007 ACM.",Co-clustering | Dyadic data | Generalized linear regression | Latent factor modeling,46,0,,,,undefined,,KDD Data Mining
2-s2.0-34548714139,10.1109/ICSE.2007.70,,,Refactoring for parameterizing java classes,cp,Conference Paper,Kiezun A.,60017366;101358965,IBM Thomas J. Watson Research Center;MIT CSandAI Lab,Yorktown Heights;,United States;,4,"Kiezun, Adam;Ernst, Michael D.;Tip, Frank;Fuhrer, Robert M.",8837002600;36916423000;57203108250;7005898672,101358965;101358965;60017366;60017366,2007-09-25,2007,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,4222605,437-446,"Type safety and expressiveness of many existing Java libraries and their client applications would improve, if the libraries were upgraded to define generic classes. Efficient and accurate tools exist to assist client applications to use generic libraries, but so far the libraries themselves must be parameterized manually, which is a tedious, time-consuming, and error-prone task. We present a typeconstraint-based algorithm for converting non-generic libraries to add type parameters. The algorithm handles the full Java language and preserves backward compatibility, thus making it safe for existing clients. Among other features, it is capable of inferring wildcard types and introducing type parameters for mutually-dependent classes. We have implemented the algorithm as a fully automatic refactoring in Eclipse. We evaluated our work in two ways. First, our tool parameterized code that was lacking type parameters. We contacted the developers of several of these applications, and in all cases they confirmed that the resulting parameterizations were correct and useful. Second, to better quantify its effectiveness, our tool parameterized classes from already-generic libraries, and we compared the results to those that were created by the libraries' authors. Our tool performed the refactoring accurately - in 87% of cases the results were as good as those created manually by a human expert, in 9% of cases the tool results were better, and in 4% of cases the tool results were worse. © 2007 IEEE.",,46,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-35449000607,10.1145/1247480.1247560,,,Scalable approximate query processing with the DBO engine,cp,Conference Paper,Jermaine C.,60013959,University of Florida,Gainesville,United States,4,"Jermaine, Christopher;Arumugam, Subramanian;Pol, Abhijit;Dobra, Alin",6602420113;57220500470;10739123900;10739776200,60013959;60013959;60013959;60013959,2007-10-30,2007,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,725-736,"This paper describes query processing in the DBO database system. Like other database systems designed for ad-hoc, analytic processing, DBO is able to compute the exact answer to queries over a large relational database in a scalable fashion. Unlike any other system designed for analytic processing, DBO can constantly maintain a guess as to the final answer to an aggregate query throughout execution, along with statistically meaningful bounds for the guess's accuracy. As DBO gathers more and more information, the guess gets more and more accurate, until it is 100% accurate as the query is completed. This allows users to stop the execution at any time that they are happy with the query accuracy, and encourages exploratory data analysis. Copyright 2007 ACM.",DBO | Online aggregation | Randomized algorithms | Sampling,57,0,repositoryam,Green,,undefined,,SIGMOD Databases
2-s2.0-85011081955,,,,Scalable semantic web data management using vertical partitioning,cp,Conference Paper,Abadi D.,60022195,Massachusetts Institute of Technology,Cambridge,United States,4,"Abadi, Daniel J.;Marcus, Adam;Madden, Samuel R.;Hollenbach, Kate",6603276361;55613231286;7007132780;23392467500,60022195;60022195;60022195;60022195,2007-01-01,2007,"33rd International Conference on Very Large Data Bases, VLDB 2007 - Conference Proceedings",,21100793692,,Conference Proceeding,,,,411-422,"Efficient management of RDF data is an important factor in realizing the Semantic Web vision. Performance and scalability issues are becoming increasingly pressing as Semantic Web technology is applied to real-world applications. In this paper, we examine the reasons why current data management solutions for RDF data scale poorly, and explore the fundamental scalability limitations of these approaches. We review the state of the art for improving performance for RDF databases and consider a recent suggestion, ""property tables."" We then discuss practically and empirically why this solution has undesirable features. As an improvement, we propose an alternative solution: vertically partitioning the RDF data. We compare the performance of vertical partitioning with prior art on queries generated by a Web-based RDF browser over a large-scale (more than 50 million triples) catalog of library data. Our results show that a vertical partitioned schema achieves similar performance to the property table technique while being much simpler to design. Further, if a column-oriented DBMS (a database architected specially for the vertically partitioned case) is used instead of a row-oriented DBMS, another order of magnitude performance improvement is observed, with query times dropping from minutes to several seconds.",,498,0,,,NSF,CNS-0520032,National Science Foundation,VLDB Databases
2-s2.0-70450092979,10.1145/1323293.1294265,,,Secure web applications via automatic partitioning,cp,Conference Paper,Chong S.,60007776,Cornell University,Ithaca,United States,7,"Chong, Stephen;Liu, Jed;Myers, Andrew C.;Qi, Xin;Vikram, K.;Zheng, Lantian;Zheng, Xin",7201660989;14018368500;7202743179;35235170200;57190117726;7403406427;56295581900,60007776;60007776;60007776;60007776;60007776;60007776;60007776,2007-01-01,2007,SOSP'07 - Proceedings of 21st ACM SIGOPS Symposium on Operating Systems Principles,,19400158507,,Conference Proceeding,,,1294265,31-44,"Swift is a new, principled approach to building web applications that are secure by construction. In modern web applications, some application functionality is usually implemented as client-side code written in JavaScript. Moving code and data to the client can create security vulnerabilities, but currently there are no good methods for deciding when it is secure to do so. Swift automatically partitions application code while providing assurance that the resulting placement is secure and efficient. Application code is written as Java-like code annotated with information flow policies that specify the confidentiality and integrity of web application information. The compiler uses these policies to automatically partition the program into JavaScript code running in the browser, and Java code running on the server. To improve interactive performance, code and data are placed on the client side. However, security-critical code and data are always placed on the server. Code and data can also be replicated across the client and server, to obtain both security and performance. A max-flow algorithm is used to place code and data in a way that minimizes client-server communication. Copyright 2007 ACM.",Compilers | Information flow | Security policies,90,0,repositoryam,Green,,undefined,,SOSP Operating Systems
2-s2.0-35348907454,10.1145/1240624.1240727,,,Shift: A technique for operating pen-based interfaces using touch,cp,Conference Paper,Vogel D.,60021726;60016849,Microsoft Research;University of Toronto,Redmond;Toronto,United States;Canada,2,"Vogel, Daniel;Baudisch, Patrick",8435582600;10039576700,60016849;60021726,2007-10-22,2007,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,657-666,"Retrieving the stylus of a pen-based device takes time and requires a second hand. Especially for short intermittent interactions many users therefore choose to use their bare fingers. Although convenient, this increases targeting times and error rates. We argue that the main reasons are the occlusion of the target by the user's finger and ambiguity about which part of the finger defines the selection point. We propose a pointing technique we call Shift that is designed to address these issues. When the user touches the screen, Shift creates a callout showing a copy of the occluded screen area and places it in a non-occluded location. The callout also shows a pointer representing the selection point of the finger. Using this visual feedback, users guide the pointer into the target by moving their finger on the screen surface and commit the target acquisition by lifting the finger. Unlike existing techniques, Shift is only invoked when necessary - over large targets no callout is created and users enjoy the full performance of an unaltered touch screen. We report the results of a user study showing that with Shift participants can select small targets with much lower error rates than an unaided touch screen and that Shift is faster than Offset Cursor for larger targets. Copyright 2007 ACM.",Interaction techniques | Mobile devices | Occlusion | Precise target acquisition | Touch-screens,364,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-55849133671,,,,Sinfonia: A new paradigm for building scalable distributed systems,cp,Conference Paper,Aguilera M.,60103987;60010574,"VMware, Inc;Hewlett Packard Laboratories",Palo Alto;Palo Alto,United States;United States,5,"Aguilera, Marcos K.;Merchant, Arif;Shah, Mehul;Veitch, Alistair;Karamanolis, Christos",7004433951;7102567857;7402047299;8341679300;6602786722,60010574;60010574;60010574;60010574;60103987,2007-12-01,2007,SOSP'07 - Proceedings of 21st ACM SIGOPS Symposium on Operating Systems Principles,,19400158507,,Conference Proceeding,,,1294278,159-174,"We propose a new paradigm for building scalable distributed systems. Our approach does not require dealing with message-passing protocols - a major complication in existing distributed systems. Instead, developers just design and manipulate data structures within our service called Sinfonia. Sinfonia keeps data for applications on a set of memory nodes, each exporting a linear address space. At the core of Sinfonia is a novel minitransaction primitive that enables efficient and consistent access to data, while hiding the complexities that arise from concurrency and failures. Using Sinfonia, we implemented two very different and complex applications in a few months: a cluster file system and a group communication service. Our implementations perform well and scale to hundreds of machines. Copyright 2007 ACM.",Distributed systems | Fault tolerance | Scalability | Shared memory | Transactions | Two-phase commit,117,0,,,,undefined,,SOSP Operating Systems
2-s2.0-35348818093,10.1145/1240624.1240635,,,Software or wetware? Discovering when and why people use digital prosthetic memory,cp,Conference Paper,Kalnikaité V.,60001881,The University of Sheffield,Sheffield,United Kingdom,2,"Kalnikaité, Vaiva;Whittaker, Steve",22834628700;7103333133,60001881;60001881,2007-01-01,2007,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,71-80,"Our lives are full of memorable and important moments, as well as important items of information. The last few years have seen the proliferation of digital devices intended to support prosthetic memory (PM), to help users recall experiences, conversations and retrieve personal information. We nevertheless have little systematic understanding of when and why people might use such devices, in preference to their own organic memory (OM). Although OM is fallible, it may be more efficient than accessing information from a complex PM device. We report a controlled lab study which investigates when and why people use PM and OM. We found that PM use depended on users' evaluation of the quality of their OM, as well as PM device properties. In particular, we found that users trade-off Accuracy and Efficiency, preferring rapid access to potentially inaccurate information over laborious access to accurate information. We discuss the implications of these results for future PM design and theory. Rather than replacing OM, future PM designs need to focus on allowing OM and PM to work in synergy. © Copyright 2007 ACM.",Digital memory | Memory | Notes | Prosthetic memory | Remembering | Speech browsing | Speech retrieval,39,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-43149116953,10.1109/FOCS.2007.4389533,,,Space-efficient identity based encryption without pairings,cp,Conference Paper,Boneh D.,60141508,Stanford Engineering,Stanford,United States,3,"Boneh, Dan;Gentry, Craig;Hamburg, Michael",7003748305;57203084724;24461679900,60141508;60141508;60141508,2007-12-01,2007,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,,,4389533,647-657,"Identity Based Encryption (IBE) systems are often constructed using bilinear maps (a.k.a. pairings) on elliptic curves. One exception is an elegant system due to Cocks which builds an IBE based on the quadratic residuosity problem modulo an RSA composite N. The Cocks system, however, produces long ciphertexts. Since the introduction of the Cocks system in 2001 it has been an open problem to construct a space efficient IBE system without pairings. In this paper we present an IBE system in which ciphertext size is short: an encryption of an ℓ-bit message consists of a single element in ℤ/Nℤ plus ℓ+1 additional bits. Security, as in the Cocks system, relies on the quadratic residuosity problem. The system is based on the theory of ternary quadratic forms and as a result, encryption and decryption are slower than in the Cocks system. © 2007 IEEE.",,183,0,repositoryam,Green,,undefined,,FOCS Theory
2-s2.0-36448946825,10.1145/1277741.1277771,,,Studying the use of popular destinations to enhance web search interaction,ar,Article,White R.W.,60021726,Microsoft Research,Redmond,United States,3,"White, Ryen W.;Bilenko, Mikhail;Cucerzan, Silviu",7501422012;7006143034;14033735300,60021726;60021726;60021726,2007-11-30,2007,"Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR'07",,8900153313,,Conference Proceeding,,,,159-166,"We present a novel Web search interaction feature which, for a given query, provides links to websites frequently visited by other users with similar information needs. These popular destinations complement traditional search results, allowing direct navigation to authoritative resources for the query topic. Destinations are identified using the history of search and browsing behavior of many users over an extended time period, whose collective behavior provides a basis for computing source authority. We describe a user study which compared the suggestion of destinations with the previously proposed suggestion of related queries, as well as with traditional, unaided Web search. Results show that search enhanced by destination suggestions outperforms other systems for exploratory tasks, with best performance obtained from mining past user behavior at query-level granularity. Copyright 2007 ACM.",Enhanced web search | Search destinations | User studies,160,0,,,,undefined,,SIGIR Information Retrieval
2-s2.0-35348875545,10.1145/1240624.1240705,,,"Sustainable interaction design: Invention &amp; disposal, renewal &amp; reuse",cp,Conference Paper,Blevis E.,60010875,"Luddy School of Informatics, Computing, and Engineering",Bloomington,United States,1,"Blevis, Eli",22833683800,60010875,2007-10-22,2007,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,503-512,"This paper presents the perspective that sustainability can and should be a central focus of interaction design-a perspective that is termed Sustainable Interaction Design (SID). As a starting point for a perspective of sustainability, design is defined as an act of choosing among or informing choices of future ways of being. This perspective of sustainability is presented in terms of design values, methods, and reasoning. The paper proposes (i) a rubric for understanding the material effects of particular interaction design cases in terms of forms of use, reuse, and disposal, and (ii) several principles to guide SID. The paper illustrates - with particular examples of design critique for interactive products and appeals to secondary research - how two of these principles may be applied to move the effects of designs from less preferred forms of use to more preferred ones. Finally, a vision for incorporating sustainability into the research and practice of interaction design is described. Copyright 2007 ACM.",Design | Design theory | Interaction design | Sustainability | Sustainable interaction design,456,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-35448946037,10.1145/1250734.1250767,,,The ant and the grasshopper: Fast and accurate pointer analysis for millions of lines of code,cp,Conference Paper,Hardekopf B.,60013372,The University of Texas at Austin,Austin,United States,2,"Hardekopf, Ben;Lin, Calvin",22937356000;15035154800,60013372;60013372,2007-10-30,2007,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,290-299,"Pointer information is a prerequisite for most program analyses, and the quality of this information can greatly affect their precision and performance. Inclusion-based (i.e. Andersen-style) pointer analysis is an important point in the space of pointer analyses, offering a potential sweet-spot in the trade-off between precision and performance. However, current techniques for inclusion-based pointer analysis can have difficulties delivering on this potential. We introduce and evaluate two novel techniques for inclusionbased pointer analysis-one lazy, one eager1-that significantly improve upon the current state-of-the-art without impacting precision. These techniques focus on the problem of online cycle detection, a critical optimization for scaling such analyses. Using a suite of six open-source C programs, which range in size from 169K to 2.17M LOC, we compare our techniques against the three best inclusion-based analyses-described by Heintze and Tardieu [11], by Pearce et al. [21], and by Berndl et al. [4]. The combination of our two techniques results in an algorithm which is on average 3.2× faster than Heintze and Tardieu's algorithm, 6.4× faster than Pearce et al.'s algorithm, and 20.6 faster than Berndl et al.'s algorithm. We also investigate the use of different data structures to represent points-to sets, examining the impact on both performance and memory consumption. We compare a sparse-bitmap implementation used in the GCC compiler with a BDD-based implementation, and we find that the BDD implementation is on average 2× slower than using sparse bitmaps but uses 5.5× less memory. Copyright © 2007 ACM.",Pointer analysis,141,0,,,,undefined,,PLDI Programming Languages
2-s2.0-47149106666,,,,ThinSight: Versatile multi-touch sensing for thin form-factor displays,cp,Conference Paper,Hodges S.,60098463,Microsoft Research Cambridge,Cambridge,United Kingdom,5,"Hodges, Steve;Izadi, Shahram;Butler, Alex;Rrustemi, Alban;Buxton, Bill",15044574300;16426108500;15043778600;23052270400;7101750777,60098463;60098463;60098463;60098463;60098463,2007-12-01,2007,UIST: Proceedings of the Annual ACM Symposium on User Interface Softaware and Technology,,21100525756,,Conference Proceeding,,,,259-268,"ThinSight is a novel optical sensing system, fully integrated into a thin form factor display, capable of detecting multiple fingers placed on or near the display surface. We describe this new hardware in detail, and demonstrate how it can be embedded behind a regular LCD, allowing sensing without degradation of display capability. With our approach, fingertips and hands are clearly identifiable through the display, allowing zero force multi-touch interaction. The approach of optical sensing also opens up the possibility for detecting other physical objects and visual markers through the display, and some initial experiments with these are described. A major advantage of ThinSight over existing camera and projector based optical systems is its compact, thin form-factor making it easier to deploy. We therefore envisage using this approach to capture rich sensor data through the display to enable both multi-touch and tangible interaction. We also discuss other novel capabilities of our system including interacting with the display from a distance and direct bidirectional communication between the display and mobile devices. Copyright 2007 ACM.",Infrared sensing | Multi-touch | Novel hardware | Physical objects | Thin form-factor displays,95,0,,,,undefined,,UIST User Interface
2-s2.0-36349019706,,,,"Thresholded rewards: Acting optimally in timed, zero-sum games",cp,Conference Paper,McMillen C.,60136640,School of Computer Science,Pittsburgh,United States,2,"McMillen, Colin;Veloso, Manuela",7004309767;7006520632,60136640;60136640,2007-11-28,2007,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,2,,,1250-1255,"In timed, zero-sum games, the goal is to maximize the probability of winning, which is not necessarily the same as maximizing our expected reward. We consider cumulative intermediate reward to be the difference between our score and our opponent's score; the ""true"" reward of a win, loss, or tie is determined at the end of a game by applying a threshold function to the cumulative intermediate reward. We introduce thresholded-rewards problems to capture this dependency of the final reward outcome on the cumulative intermediate reward. Thresholded-rewards problems reflect different real-world stochastic planning domains, especially zero-sum games, in which time and score need to be considered. We investigate the application of thresholded rewards to finite-horizon Markov Decision Processes (MDPs). In general, the optimal policy for a thresholded-rewards MDP will be non-stationary, depending on the number of time steps remaining and the cumulative intermediate reward. We introduce an efficient value iteration algorithm that solves thresholded-rewards MDPs exactly, but with running time quadratic on the number of states in the MDP and the length of the time horizon. We investigate a number of heuristic-based techniques that efficiently find approximate solutions for MDPs with large state spaces or long time horizons. Copyright © 2007, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,6,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-34648841198,10.1145/1250790.1250830,,,Towards 3-query locally decodable codes of subexponential length,cp,Conference Paper,Yekhanin S.,60022195,Massachusetts Institute of Technology,Cambridge,United States,1,"Yekhanin, Sergey",6506493185,60022195,2007-10-30,2007,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,266-274,"A q-query Locally Decodable Code (LDC) encodes an n-bitmessage x as an n-bit codeword C(x), such that one canprobabilistically recover any bit x i of the message by queryingonly q bits of the codeword C(x), even after some constantfraction of codeword bits has been corrupted.We give new constructions of three query LDCs of vastly shorterlength than that of previous constructions. Specifically, givenany Mersenne prime p = 2 t - 1, we design three query LDCs of length N=(n 1/t), for every n. Based on thelargest known Mersenne prime, this translates to a length of less than exp(n 10-7), compared to exp(n 1/2) in the previous constructions. It hasoften been conjectured that there are infinitely many Mersenneprimes. Under this conjecture, our constructions yield three querylocally decodable codes of length N=exp(n O(1/(log log n))) forinfinitely many n. We also obtain analogous improvements for Private InformationRetrieval (PIR) schemes. We give 3-server PIR schemes withcommunication complexity of O(n 10-7) to accessan n-bit database, compared to the previous best scheme withcomplexity O(n 1/5.25). Assuming again that there areinfinitely many Mersenne primes, we get 3-server PIR schemes ofcommunication complexity n O(1/(log log n))for infinitely many n. Previous families of LDCs and PIR schemes were based on theproperties of low-degree multivariate polynomials over finitefields. Our constructions are completely different and areobtained by constructing a large number of vectors in a smalldimensional vector space whose inner products are restricted tolie in an algebraically nice set. Copyright 2007 ACM.",Locally decodable codes | Mersenne primes | Private information retrieval,48,0,repositoryvor,Green,,undefined,,STOC Theory
2-s2.0-34548805888,10.1109/ICSE.2007.90,,,Tracking code clones in evolving software,cp,Conference Paper,Duala-Ekoko E.,60002494,Université McGill,Montreal,Canada,2,"Duala-Ekoko, Ekwa;Robillard, Martin P.",21742146000;7006311463,60002494;60002494,2007-09-25,2007,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,4222578,158-167,"Code clones are generally considered harmful in software development, and the predominant approach is to try to eliminate them through refactoring. However, recent research has provided evidence that it may not always be practical, feasible, or cost-effective to eliminate certain clone groups. We propose a technique for tracking clones in evolving software. Our technique relies on the concept of abstract clone region descriptors (CRD), which describe clone regions within methods in a robust way that is independent from the exact text of the clone region or its location in a file. We present our definition of CRDs, and describe a complete clone tracking system capable of producing CRDs from the output of a clone detection tool, notify developers of modifications to clone regions, and support the simultaneous editing of clone regions. We report on two experiments and a case study conducted to assess the performance and usefulness of our approach. © 2007 IEEE.",,159,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-35348848696,10.1145/1242572.1242598,,,"Wherefore art thou r3579x?: Anonymized social networks, hidden patterns, and structural steganography",cp,Conference Paper,Backstrom L.,60278093;60021726,Cornell Ann S. Bowers College of Computing and Information Science;Microsoft Research,Ithaca;Redmond,United States;United States,3,"Backstrom, Lars;Dwork, Cynthia;Kleinberg, Jon",14831068600;7003960086;7005755823,60278093;60021726;60278093,2007-10-23,2007,"16th International World Wide Web Conference, WWW2007",,8200153113,,Conference Proceeding,,,,181-190,"In a social network, nodes correspond topeople or other social entities, and edges correspond to social links between them. In an effort to preserve privacy, the practice of anonymization replaces names with meaningless unique identifiers. We describe a family of attacks such that even from a single anonymized copy of a social network, it is possible for an adversary to learn whether edges exist or not between specific targeted pairs of nodes.",Anonymization | Privacy in data mining | Social networks,631,0,,,,undefined,,WWW World Wide Web
2-s2.0-70450015331,,,,Zyzzyva: Speculative Byzantine fault tolerance,cp,Conference Paper,Kotla R.,60150459,Department of Computer Science,Austin,United States,5,"Kotla, Ramakrishna;Alvisi, Lorenzo;Dahlin, Mike;Clement, Allen;Wong, Edmund",9735588500;6603768937;7003483638;23033773000;23037634600,60150459;60150459;60150459;60150459;60150459,2007-12-01,2007,SOSP'07 - Proceedings of 21st ACM SIGOPS Symposium on Operating Systems Principles,,19400158507,,Conference Proceeding,,,1294267,351-366,"We present Zyzzyva, a protocol that uses speculation to reduce the cost and simplify the design of Byzantine fault tolerant state machine replication. In Zyzzyva, replicas respond to a client's request without first running an expensive three-phase commit protocol to reach agreement on the order in which the request must be processed. Instead, they optimistically adopt the order proposed by the primary and respond immediately to the client. Replicas can thus become temporarily inconsistent with one another, but clients detect inconsistencies, help correct replicas converge on a single total ordering of requests, and only rely on responses that are consistent with this total order. This approach allows Zyzzyva to reduce replication overheads to near their theoretical minima. Copyright 2007 ACM.",Byzantine fault tolerance | Output commit | Replication | Speculative execution,180,0,,,,undefined,,SOSP Operating Systems
2-s2.0-84859913396,,,,A new string-to-dependency machine translation algorithm with a target dependency language model,cp,Conference Paper,Shen L.,60011761,BBN Technologies,Cambridge,United States,3,"Shen, Libin;Xu, Jinxi;Weischedel, Ralph",8889278600;7407000537;6603005682,60011761;60011761;60011761,2008-12-01,2008,"ACL-08: HLT - 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference",,21100201001,,Conference Proceeding,,,,577-585,"In this paper, we propose a novel string-todependency algorithm for statistical machine translation. With this new framework, we employ a target dependency language model during decoding to exploit long distance word relations, which are unavailable with a traditional n-gram language model. Our experiments show that the string-to-dependency decoder achieves 1.48 point improvement in BLEU and 2.53 point improvement in TER compared to a standard hierarchical string-tostring system on the NIST 04 Chinese-English evaluation set. © 2008 Association for Computational Linguistics.",,203,0,,,,undefined,,ACL Natural Language Processing
2-s2.0-57549112405,10.1145/1386352.1386426,,,FXPAL collaborative exploratory video search system,cp,Conference Paper,Adcock J.,60027200,FX Palo Alto Laboratory,Palo Alto,United States,2,"Adcock, John;Pickens, Jeremy",35781682800;7005535299,60027200;60027200,2008-12-17,2008,CIVR 2008 - Proceedings of the International Conference on Content-based Image and Video Retrieval,,13800154713,,Conference Proceeding,,,,551-552,"This paper describes FXPAL's collaborative, exploratory interactive video search application. We introduce a new approach to information retrieval: algorithmic mediation in support of intentional, synchronous collaborative exploratory search. Using our system, two or more users with a common information need search together, simultaneously. The collaborative system provides tools, user interfaces and, most importantly, algorithmically-mediated retrieval to focus, enhance and augment the team's search and communication activities.",Collaborative | Interactive | TRECVID | Video search,4,0,,,,undefined,,SIGIR Information Retrieval
2-s2.0-57649235371,10.1145/1357054.1357306,,,An error model for pointing based on Fitts' law,cp,Conference Paper,Wobbrock J.O.,60033420;60028661;60021726;60015481,York University;UW College of Engineering;Microsoft Research;University of Washington,Toronto;Seattle;Redmond;Seattle,Canada;United States;United States;United States,4,"Wobbrock, Jacob O.;Cutrell, Edward;Harada, Susumu;MacKenzie, I. Scott",6603152369;57203053744;36336913700;7202956135,60015481;60021726;60028661;60033420,2008-12-22,2008,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1613-1622,"For decades, Fitts' law (1954) has been used to model pointing time in user interfaces. As with any rapid motor act, faster pointing movements result in increased errors. But although prior work has examined accuracy as the ""spread of hits,"" no work has formulated a predictive model for error rates (0-100%) based on Fitts' law parameters. We show that Fitts' law mathematically implies a predictive error rate model, which we derive. We then describe an experiment in which target size, target distance, and movement time are manipulated. Our results show a strong model fit: a regression analysis of observed vs. predicted error rates yields a correlation of R2 = .959 for N=90 points. Furthermore, we show that the effect on error rate of target size (W) is greater than that of target distance (A), indicating a departure from Fitts' law, which maintains that W and A contribute proportionally to index of difficulty (ID). Our error model can be used with Fitts' law to estimate and predict error rates along with speeds, providing a framework for unifying this dichotomy. Copyright 2008 ACM.",Clicking errors | Error model | Error rates | Fitts' law | Mousing errors | Movement time | Pointing errors | Pointing time | Schmidt's law | Speedaccuracy tradeoff,117,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-60149094530,10.1145/1409944.1409967,,,Assessment of urban-scale wireless networks with a small number of measurements,cp,Conference Paper,Robinson J.P.,60010574;60005286,Hewlett Packard Laboratories;Rice University,Palo Alto;Houston,United States;United States,3,"Robinson, Joshua Paul;Swaminathan, Ram;Knightly, Edward W.",14629394900;7102213722;7004150113,60005286;60010574;60005286,2008-12-01,2008,"Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM",,70461,,Conference Proceeding,,,,187-198,"In order to evaluate, improve, or expand a deployed, city-wide wireless mesh network, it is necessary to assess the network's spatial performance. In this paper, we present a general framework to accurately predict a network's well-served area, termed the metric region, via a small number of measurements. Assessment of deployed networks must address two key issues: non-uniform physical-layer propagation and high spatial variance in performance. Addressing non-uniformity, our framework estimates a mesh node's metric region via a data-driven sectorization of the region. We find each sector's boundary (radius) with a two-stage process of estimation and then measurement-driven ""push-pull"" refinement of the estimated boundary. To address high spatial variation, our coverage estimation couples signal strength measurements with terrain information from publicly available digital maps to estimate propagation characteristics between a wireless node and the client's location. To limit measurements and yield connected metric regions, we consider performance metrics (such as signal strength) to be monotonic with distance from the wireless node within each sector. We show that despite measured violations in coverage monotonicity, we obtain high accuracy with this assumption. We validate our estimation and refinement framework with measurements from 30,000 client locations obtained in each of two currently operational mesh networks, GoogleWiFi and TFA. We study three illustrative metrics: coverage, modulation rate, and redundancy, and find that to achieve a given accuracy, our framework requires two to five times fewer measurements than grid sampling strategies. Finally, we use the framework to evaluate the two deployments and study the average size and location of their coverage holes as well as the impact of client association policies on load-balancing. Copyright 2008 ACM.",Access network | Coverage | Deployment | Measurement assessment | Mesh networks | Signal strength | Wireless,62,0,,,,undefined,,MOBICOM Mobile
2-s2.0-51949099868,10.1109/CVPR.2008.4587586,,,Beyond sliding windows: Object localization by efficient subwindow search,cp,Conference Paper,Lampert C.H.,60074542;60004898,Google Switzerland GmbH;Max Planck Institute for Biological Cybernetics,Zurich;Tubingen,Switzerland;Germany,3,"Lampert, Christoph H.;Blaschko, Matthew B.;Hofmann, Thomas",8420891100;24829297300;56735589800,60004898;60004898;60074542,2008-09-23,2008,"26th IEEE Conference on Computer Vision and Pattern Recognition, CVPR",,12100157103,,Conference Proceeding,,,4587586,,"Most successful object recognition systems rely on binary classification, deciding only if an object is present or not, but not providing information on the actual object location. To perform localization, one can take a sliding window approach, but this strongly increases the computational cost, because the classifier function has to be evaluated over a large set of candidate subwindows. In this paper, we propose a simple yet powerful branchand-bound scheme that allows efficient maximization of a large class of classifier functions over all possible subimages. It converges to a globally optimal solution typically in sublinear time. We show how our method is applicable to different object detection and retrieval scenarios. The achieved speedup allows the use of classifiers for localization that formerly were considered too slow for this task, such as SVMs with a spatial pyramid kernel or nearest neighbor classifiers based on the χ2-distance. We demonstrate state-of-the-art performance of the resulting systems on the UIUC Cars dataset, the PASCAL VOC 2006 dataset and in the PASCAL VOC 2007 competition. ©2008 IEEE.",,586,0,,,,undefined,,CVPR Computer Vision
2-s2.0-63349087691,10.1145/1449715.1449728,,,Bringing physics to the surface,cp,Conference Paper,Wilson A.D.,60098463;60021726,Microsoft Research Cambridge;Microsoft Research,Cambridge;Redmond,United Kingdom;United States,5,"Wilson, Andrew D.;Izadi, Shahram;Hilliges, Otmar;Garcia-Mendoza, Armando;Kirk, David",57199229209;16426108500;14041644100;26424583900;27169862100,60021726;60098463;60098463;60098463;60098463,2008-12-01,2008,UIST 2008 - Proceedings of the 21st Annual ACM Symposium on User Interface Software and Technology,,17300154976,,Conference Proceeding,,,,67-76,"This paper explores the intersection of emerging surface technologies, capable of sensing multiple contacts and often shape information, and advanced games physics engines. We define a technique for modeling the data sensed from such surfaces as input within a physics simulation. This affords the user the ability to interact with digital objects in ways analogous to manipulation of real objects. Our technique is capable of modeling both multiple contact points and more sophisticated shape information, such as the entire hand or other physical objects, and of mapping this user input to contact forces due to friction and collisions within the physics simulation. This enables a variety of fine-grained and casual interactions, supporting finger-based, whole-hand, and tangible input. We demonstrate how our technique can be used to add real-world dynamics to interactive surfaces such as a vision-based tabletop, creating a fluid and natural experience. Our approach hides from application developers many of the complexities inherent in using physics engines, allowing the creation of applications without preprogrammed interaction behavior or gesture recognition.",game physics engines | Interactive surfaces,158,0,,,,undefined,,UIST User Interface
2-s2.0-83455210839,,,,Consensus routing: The internet as a distributed system,cp,Conference Paper,John J.P.,60015481;60014313,University of Washington;University of Massachusetts Amherst,Seattle;Amherst,United States;United States,5,"John, John P.;Katz-Bassett, Ethan;Krishnamurthy, Arvind;Anderson, Thomas;Venkataramani, Arun",14832503200;15127399400;7005516119;35560665700;6602082483,60015481;60015481;60015481;60015481;60014313,2008-01-01,2008,"5th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2008",,21101024043,,Conference Proceeding,,,,351-364,"Internet routing protocols (BGP, OSPF, RIP) have traditionally favored responsiveness over consistency. A router applies a received update immediately to its forwarding table before propagating the update to other routers, including those that potentially depend upon the outcome of the update. Responsiveness comes at the cost of routing loops and blackholes-a router A thinks its route to a destination is via B but B disagrees. By favoring responsiveness (a liveness property) over consistency (a safety property), Internet routing has lost both. Our position is that consistent state in a distributed system makes its behavior more predictable and securable. To this end, we present consensus routing, a consistency-first approach that cleanly separates safety and liveness using two logically distinct modes of packet delivery: a stable mode where a route is adopted only after all dependent routers have agreed upon it, and a transient mode that heuristically forwards the small fraction of packets that encounter failed links. Somewhat surprisingly, we find that consensus routing improves overall availability when used in conjunction with existing transient mode heuristics such as backup paths, deflections, or detouring. Experiments on the Internet's AS-level topology show that consensus routing eliminates nearly all transient disconnectivity in BGP.",,80,0,,,NSF,CNS-0435065,National Science Foundation,NSDI Networking
2-s2.0-79951611880,10.14778/1453856.1453863,,,Constrained physical design tuning,ar,Article,Bruno N.,60021726,Microsoft Research,Redmond,United States,2,"Bruno, Nicolas;Chaudhuri, Surajit",7005015682;7402978010,60021726;60021726,2008-01-01,2008,Proceedings of the VLDB Endowment,,21100199855,21508097,Conference Proceeding,1,1,,4-15,"Existing solutions to the automated physical design problem in database systems attempt tominimize execution costs of input workloads for a given a storage constraint. In this paper, we argue that this model is not flexible enough to address several real-world situations. To overcome this limitation, we introduce a constraint language that is simple yet powerful enough to express many important scenarios. We build upon an existing transformation-based framework to effectively incorporate constraints in the search space. We then show experimentally that we are able to handle a rich class of constraints and that our proposed technique scales gracefully. © 2008 VLDB Endowment.",,23,0,,,,undefined,,VLDB Databases
2-s2.0-57349116869,10.1145/1375457.1375472,,,Counter braids: A novel counter architecture for per-flow measurement,cp,Conference Paper,Lu Y.,60012708;106210643,"Stanford University;Nuova Systems, Inc.",Stanford;San Jose,United States;United States,5,"Lu, Yi;Montanari, Andrea;Prabhakar, Balaji;Dharmapurikar, Sarang;Kabbani, Abdul",36938986300;7101889523;7102955788;7801627132;20436121600,60012708;60012708;60012708;106210643;60012708,2008-12-12,2008,SIGMETRICS'08: Proceedings of the 2008 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems,,13600154738,,Conference Proceeding,36,1 SPECIAL ISSUE,,121-132,"Fine-grained network measurement requires routers and switches to update large arrays of counters at very high link speed (e.g. 40 Gbps). A naive algorithm needs an infeasible amount of SRAM to store both the counters and a flow-to-counter association rule, so that arriving packets can update corresponding counters at link speed. This has made accurate per-flow measurement complex and expensive, and motivated approximate methods that detect and measure only the large flows. This paper revisits the problem of accurate per-flow measurement. We present a counter architecture, called Counter Braids, inspired by sparse random graph codes. In a nutshell, Counter Braids ""compresses while counting"". It solves the central problems (counter space and flow-to-counter association) of per-flow measurement by ""braiding"" a hierarchy of counters with random graphs. Braiding results in drastic space reduction by sharing counters among flows: and using random graphs generated on-the-fly with hash functions avoids the storage of flow-to-counter association. The Counter Braids architecture is optimal (albeit with a complex decoder) as it achieves the maximum compression rate asymptotically. For implementation, we present a low-complexity message passing decoding algorithm, which can recover flow sizes with essentially zero error. Evaluation on Internet traces demonstrates that almost all flow sizes are recovered exactly with only a few bits of counter space per flow. Copyright 2008 ACM.",Message passing algorithms | Network measurement | Statistics counters,204,0,,,FP7,217068,Seventh Framework Programme,SIGMETRICS Performance
2-s2.0-57349156958,10.1145/1368088.1368130,,,Debugging reinvented: Asking and answering why and why not questions about program behavior,cp,Conference Paper,Ko A.J.,60136640,School of Computer Science,Pittsburgh,United States,2,"Ko, Andrew J.;Myers, Brad A.",7007018374;7202684451,60136640;60136640,2008-12-15,2008,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,301-310,"When software developers want to understand the reason for a program's behavior, they must translate their questions about the behavior into a series of questions about code, speculating about the causes in the process. The Whyline is a new kind of debugging tool that avoids such speculation by instead enabling developers to select a question about program output from a set of why did and why didn't questions derived from the program's code and execution. The tool then finds one or more possible explanations for the output in question, using a combination of static and dynamic slicing, precise call graphs, and new algorithms for determining potential sources of values and explanations for why a line of code was not reached. Evaluations of the tool on one task showed that novice programmers with the Whyline were twice as fast as expert programmers without it. The tool has the potential to simplify debugging in many software development contexts. Copyright 2008 ACM.",Algorithms | Design | Human factors | Performance | Reliability,216,0,,,,undefined,,ICSE Software Engineering
2-s2.0-51149099723,10.1145/1357054.1357155,,,Designs on dignity: Perceptions of technology among the homeless,cp,Conference Paper,Le Dantec C.A.,60097290,College of Computing,Atlanta,United States,2,"Le Dantec, Christopher A.;Edwards, W. Keith",24767766900;7401482762,60097290;60097290,2008-12-22,2008,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,627-636,"Technology, it is argued, has the potential to improve everyone's life: from the workplace, to entertainment, to easing chores around the home. But what of people who have neither job nor home? We undertook a qualitative study of the homeless population in a metropolitan U.S. city to better understand what it means to be homeless and how technology-from cell phones to bus passes-affects their daily lives. The themes we identify provide an array of opportunities for technological interventions that can empower the homeless population. Our investigation also reveals the need to reexamine some of the assumptions made in HCI about the relationship people have with technology. We suggest a broader awareness of the social context of technology use as a critical component when considering design innovation for the homeless. Copyright 2008 ACM.",At-risk populations | Diary study | Homeless | Social Computing | Urban Computing | Value sensitive design,147,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85076898936,,,,Difference engine: Harnessing memory redundancy in virtual machines,cp,Conference Paper,Gupta D.,60030612;60013372,"University of California, San Diego;The University of Texas at Austin",La Jolla;Austin,United States;United States,8,"Gupta, Diwaker;Lee, Sangmin;Vrable, Michael;Savage, Stefan;Snoeren, Alex C.;Varghese, George;Voelker, Geoffrey M.;Vahdat, Amin",8308524900;55716510400;12241423500;7103218472;10142863200;15038288800;7003306507;6701708010,60030612;60030612-60013372;60030612;60030612;60030612;60030612;;60030612,2019-01-01,2019,"Proceedings of the 8th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2008",,21100939709,,Conference Proceeding,,,,309-322,"Virtual machine monitors (VMMs) are a popular platform for Internet hosting centers and cloud-based compute services. By multiplexing hardware resources among virtual machines (VMs) running commodity operating systems, VMMs decrease both the capital outlay and management overhead of hosting centers. Appropriate placement and migration policies can take advantage of statistical multiplexing to effectively utilize available processors. However, main memory is not amenable to such multiplexing and is often the primary bottleneck in achieving higher degrees of consolidation. Previous efforts have shown that content-based page sharing provides modest decreases in the memory footprint of VMs running similar operating systems and applications. Our studies show that significant additional gains can be had by leveraging both sub-page level sharing (through page patching) and in-core memory compression. We build Difference Engine, an extension to the Xen virtual machine monitor, to support each of these-in addition to standard copy-on-write full page sharing-and demonstrate substantial savings not only between VMs running similar applications and operating systems (up to 90%), but even across VMs running disparate workloads (up to 65%). In head-to-head memory-savings comparisons, Difference Engine outperforms VMware ESX server by a factor of 1.5 for homogeneous workloads and by a factor of 1.6-2.5 for heterogeneous workloads. In all cases, the performance overhead of Difference Engine is less than 7%.",,123,0,,,,undefined,,OSDI Operating Systems
2-s2.0-85076882757,,,,Dryadlinq: A system for general-purpose distributed data-parallel computing using a high-level language,cp,Conference Paper,Yu Y.,60071140;60021726,Reykjavík University;Microsoft Research,Reykjavik;Redmond,Iceland;United States,7,"Yu, Yuan;Isard, Michael;Fetterly, Dennis;Budiu, Mihai;Erlingsson, Úlfar;Gunda, Pradeep Kumar;Currey, Jon",55731461200;6601968991;55884014600;6506040266;6603357907;22937300000;35224607300,60021726;60021726;60021726;60021726;60071140;60021726;60021726,2019-01-01,2019,"Proceedings of the 8th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2008",,21100963055,,Conference Proceeding,,,,1-14,"DryadLINQ is a system and a set of language extensions that enable a new programming model for large scale distributed computing. It generalizes previous execution environments such as SQL, MapReduce, and Dryad in two ways: by adopting an expressive data model of strongly typed .NET objects; and by supporting general-purpose imperative and declarative operations on datasets within a traditional high-level programming language. A DryadLINQ program is a sequential program composed of LINQ expressions performing arbitrary side-effect-free transformations on datasets, and can be written and debugged using standard .NET development tools. The DryadLINQ system automatically and transparently translates the data-parallel portions of the program into a distributed execution plan which is passed to the Dryad execution platform. Dryad, which has been in continuous operation for several years on production clusters made up of thousands of computers, ensures efficient, reliable execution of this plan. We describe the implementation of the DryadLINQ compiler and runtime. We evaluate DryadLINQ on a varied set of programs drawn from domains such as web-graph analysis, large-scale log mining, and machine learning. We show that excellent absolute performance can be attained-a general-purpose sort of 1012 Bytes of data executes in 319 seconds on a 240-computer, 960-disk cluster-as well as demonstrating near-linear scaling of execution time on representative applications as we vary the number of computers used for a job.",,326,0,,,,undefined,,OSDI Operating Systems
2-s2.0-77950515223,10.1145/1453101.1453125,,,Efficient online monitoring of web-service SLAs,cp,Conference Paper,Raimondi F.,60022148,University College London,London,United Kingdom,3,"Raimondi, Franco;Skene, James;Emmerich, Wolfgang",7005439840;8224171900;7006786370,60022148;60022148;60022148,2008-12-01,2008,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,85109,,Conference Proceeding,,,,170-180,"If an organization depends on the service quality provided by another organization it often enters into a bilateral service level agreement (SLA), which mitigates outsourcing risks by associating penalty payments with poor service quality. Once these agreements are entered into, it becomes necessary to monitor their conditions, which will commonly relate to timeliness, reliability and request throughput, at run-time. We show how these conditions can be translated into timed automata. Acceptance of a timed word by a timed automaton can be decided in quadratic time and because the timed automata can operate while messages are exchanged at run-time there is effectively only a linear run-time overhead. We present an implementation to derive on-line monitors for web services automatically from SLAs using an Eclipse plugin. We evaluate the efficiency and scalability of this approach using a large-scale case study in a service-oriented computational grid. © 2008 ACM.",On-line monitoring | Service Level Agreements | Services,121,0,repositoryam,Green,FP7,215605,Seventh Framework Programme,FSE Software Engineering
2-s2.0-57349088162,10.1145/1376916.1376928,,,Estimating Pagerank on graph streams,cp,Conference Paper,Sarma A.D.,60021726;123814863,Microsoft Research;Georgia Tech,Redmond;,United States;,3,"Sarma, Atish Das;Gollapudi, Sreetinvas;Panigrahy, Rina",6506890547;7005568854;6603855341,123814863;60021726;60021726,2008-12-15,2008,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,69-78,"This study focuses on computations on large graphs (e.g., the web-graph) where the edges of the graph are presented as a stream. The objective in the streaming model is to use small amount of memory (preferably sub-linear in the number of nodes n) and a few passes. In the streaming model, we show how to perform several graph computations including estimating the probability distribution after a random walk of length l,mixing time, and the conductance. We estimate the mixing time M of a andom walk inÕ(nα + Mα√n+√Mn/α)space and Õ(√Mn/α) passes. Furthermore, the relation between mixing time and conductance gives us an estimate for the conductance of the graph. By applying our algorithm for computing probability distribution on the web-graph, we can estimate the PageRank p of any node up to an additive error of √ep in Õ(√Mn/α) passes and Õ(min(nα + 1/ε √M/α + 1/ε M α,αn √Mα + 1/ε√M/α)) space, for any α ε (0, 1]. In particular, for ε = M/n, by setting α = M- 1/2 , we can compute the approximate PageRank values in Õ(nM-1/4) space and Õ(M3/4) passes. In comparison, a standard implementation of the PageRank algorithm will take O(n) space and O(M) passes. Copyright 2008 ACM.",Graph conductance | Mixing time | Pagerank | Random walk | Streaming algorithms,47,0,repositoryam,Green,,undefined,,PODS Databases
2-s2.0-65449155592,10.1145/1401890.1401988,,,FastANOVA: An efficient algorithm for genome-wide association study,cp,Conference Paper,Zhang X.,60025111,The University of North Carolina at Chapel Hill,Chapel Hill,United States,3,"Zhang, Xiang;Zou, Fei;Wang, Wei",55264772100;35294423500;55157954300,60025111;60025111;60025111,2008-12-01,2008,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,101510,,Conference Proceeding,,,,821-829,"Studying the association between quantitative phenotype (such as height or weight) and single nucleotide polymorphisms (SNPs) is an important problem in biology. To understand underlying mechanisms of complex phenotypes, it is often necessary to consider joint genetic effects across multiple SNPs. ANOVA (analysis of variance) test is routinely used in association study. Important findings from studying gene-gene (SNP-pair) interactions are appearing in the literature. However, the number of SNPs can be up to millions. Evaluating joint effects of SNPs is a challenging task even for SNP-pairs. Moreover, with large number of SNPs correlated, permutation procedure is preferred over simple Bonferroni correction for properly controlling family-wise error rate and retaining mapping power, which dramatically increases the computational cost of association study. In this paper, we study the problem of finding SNP-pairs that have significant associations with a given quantitative phenotype. We propose an efficient algorithm, FastANOVA, for performing ANOVA tests on SNP-pairs in a batch mode, which also supports large permutation test. We derive an upper bound of SNP-pair ANOVA test, which can be expressed as the sum of two terms. The first term is based on single-SNP ANOVA test. The second term is based on the SNPs and independent of any phenotype permutation. Furthermore, SNP-pairs can be organized into groups, each of which shares a common upper bound. This allows for maximum reuse of intermediate computation, efficient upper bound estimation, and effective SNP-pair pruning. Consequently, FastANOVA only needs to perform the ANOVA test on a small number of candidate SNP-pairs without the risk of missing any significant ones. Extensive experiments demonstrate that FastANOVA is orders of magnitude faster than the brute-force implementation of ANOVA tests on all SNP pairs. © 2008 ACM.",ANOVA test | Association study,37,0,,,,undefined,,KDD Data Mining
2-s2.0-84867128082,10.14778/1454159.1454225,,,Finding frequent items in data streams,ar,Article,Cormode G.,60008383,AT&amp;T Laboratories Florham Park,Florham Park,United States,2,"Cormode, Graham;Hadjieleftheriou, Marios",6602625379;6506875114,60008383;60008383,2008-01-01,August 2008,Proceedings of the VLDB Endowment,,21100199855,21508097,Conference Proceeding,1,2,,1530-1541,"The frequent items problem is to process a stream of items and find all items occurring more than a given fraction of the time. It is one of the most heavily studied problems in data stream mining, dating back to the 1980s. Many applications rely directly or indirectly on finding the frequent items, and implementations are in use in large scale industrial systems. However, there has not been much comparison of the different methods under uniform experimental conditions. It is common to find papers touching on this topic in which important related work is mischaracterized, overlooked, or reinvented. In this paper, we aim to present the most important algorithms for this problem in a common framework. We have created baseline implementations of the algorithms, and used these to perform a thorough experimental study of their properties. We give empirical evidence that there is considerable variation in the performance of frequent items algorithms. The best methods can be implemented to find frequent items with high accuracy using only tens of kilobytes of memory, at rates of millions of items per second on cheap modern hardware. © 2008 VLDB Endowment.",,225,0,,,USDOE,CCR-0205594,U.S. Department of Energy,VLDB Databases
2-s2.0-84859887879,,,,Forest reranking: Discriminative parsing with non-local features,cp,Conference Paper,Huang L.,60006297,University of Pennsylvania,Philadelphia,United States,1,"Huang, Liang",55746553600,60006297,2008-12-01,2008,"ACL-08: HLT - 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference",,21100201001,,Conference Proceeding,,,,586-594,"Conventional n-best reranking techniques often suffer from the limited scope of the nbest list, which rules out many potentially good alternatives. We instead propose forest reranking, a method that reranks a packed forest of exponentially many parses. Since exact inference is intractable with non-local features, we present an approximate algorithm inspired by forest rescoring that makes discriminative training practical over the whole Treebank. Our final result, an F-score of 91.7, outperforms both 50-best and 100-best reranking baselines, and is better than any previously reported systems trained on the Treebank. © 2008 Association for Computational Linguistics.",,194,0,,,,undefined,,ACL Natural Language Processing
2-s2.0-51949087578,10.1109/CVPR.2008.4587672,,,Global stereo reconstruction under second order smoothness priors,cp,Conference Paper,Woodford O.,60098463;60026851;60014564,Microsoft Research Cambridge;University of Oxford;Oxford Brookes University,Cambridge;Oxford;Oxford,United Kingdom;United Kingdom;United Kingdom,4,"Woodford, O. J.;Torr, P. H.S.;Reid, I. D.;Fitzgibbon, A. W.",22236036400;56821543600;55643335100;56355070900,60026851;60014564;60026851;60098463,2008-09-23,2008,"26th IEEE Conference on Computer Vision and Pattern Recognition, CVPR",,12100157103,,Conference Proceeding,,,4587672,,"Second-order priors on the smoothness of 3D surfaces are a better model of typical scenes than first-order priors. However, stereo reconstruction using global inference algorithms, such as graph-cuts, has not been able to incorporate second-order priors because the triple cliques needed to express them yield intractable (non-submodular) optimization problems. This paper shows that inference with triple cliques can be effectively optimized. Our optimization strategy is a development of recent extensions to α-expansion, based on the ""QPBO"" algorithm [5, 14, 26]. The strategy is to repeatedly merge proposal depth maps using a novel extension of QPBO. Proposal depth maps can come from any source, for example fronto-parallel planes as in α-expansion, or indeed any existing stereo algorithm, with arbitrary parameter settings. Experimental results demonstrate the usefulness of the second-order prior and the efficacy of our optimization framework. An implementation of our stereo framework is available online [34]. ©2008 IEEE.",,110,0,,,,undefined,,CVPR Computer Vision
2-s2.0-57749181962,,,,How good is almost perfect?,cp,Conference Paper,Helmert M.,60025641,Universität Freiburg,Freiburg im Breisgau,Germany,2,"Helmert, Malte;Roger, Gabriele",57203118510;23009803800,60025641;60025641,2008-12-24,2008,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,2,,,944-949,"Heuristic search using algorithms such as A* and IDA* is the prevalent method for obtaining optimal sequential solutions for classical planning tasks. Theoretical analyses of these classical search algorithms, such as the well-known results of Pohl, Gaschnig and Pearl, suggest that such heuristic search algorithms can obtain better than exponential scaling behaviour, provided that the heuristics are accurate enough. Here, we show that for a number of common planning benchmark domains, including ones that admit optimal solution in polynomial time, general search algorithms such as A* must necessarily explore an exponential number of search nodes even under the optimistic assumption of almost perfect heuristic estimators, whose heuristic error is bounded by a small additive constant. Our results shed some light on the comparatively bad performance of optimal heuristic search approaches in ""simple"" planning domains such as GRIPPER. They suggest that in many applications, further improvements in run-time require changes to other parts of the search algorithm than the heuristic estimator. Copyright © 2008, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,63,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-57349187122,10.1145/1367497.1367556,,,IRLbot: Scaling to 6 billion pages and beyond,cp,Conference Paper,Lee H.T.,60020547,Texas A&amp;M University,College Station,United States,4,"Lee, Hsin Tsang;Leonard, Derek;Wang, Xiaoming;Loguinov, Dmitri",25825193600;12645776500;52763808300;6602584542,60020547;60020547;60020547;60020547,2008-12-15,2008,"Proceeding of the 17th International Conference on World Wide Web 2008, WWW'08",,13600154712,,Conference Proceeding,,,,427-436,"This paper shares our experience in designing a web crawler that can download billions of pages using a single-server implementation and models its performance. We show that with the quadratically increasing complexity of verifying URL uniqueness, BFS crawl order, and fixed per-host rate-limiting, current crawling algorithms cannot effectively cope with the sheer volume of URLs generated in large crawls, highly-branching spam, legitimate multi-million-page blog sites, and infinite loops created by server-side scripts. We offer a set of techniques for dealing with these issues and test their performance in an implementation we call IRLbot. In our recent experiment that lasted 41 days. IRLbot running on a single server successfully crawled 6.3 billion valid HTML pages (7.6 billion connection requests) and sustained an average download rate of 319 mb/s (1, 789 pages/s). Unlike our prior experiments with algorithms proposed in related work, this version of IRLbot did not experience any bottlenecks and successfully handled content from over 117 million hosts, parsed out 394 billion links, and discovered a subset of the web graph with 41 billion unique nodes.",Crawling | IRLbot | Large-scale,53,0,,,,undefined,,WWW World Wide Web
2-s2.0-56749156668,10.1145/1357054.1357250,,,"Improving the performance of motor-impaired users with automatically- generated, ability-based interfaces",cp,Conference Paper,Gajos K.Z.,60015481,University of Washington,Seattle,United States,3,"Gajos, Krzysztof Z.;Wobbrock, Jacob O.;Weld, Daniel S.",8375653300;6603152369;7003334103,60015481;60015481;60015481,2008-12-22,2008,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1257-1266,"We evaluate two systems for automatically generating personalized interfaces adapted to the individual motor capabilities of users with motor impairments. The first system, Supple, adapts to users' capabilities indirectly by first using the Arnauld preference elicitation engine to model a user's preferences regarding how he or she likes the interfaces to be created. The second system, SUPPLE++, models a user's motor abilities directly from a set of one-time motor performance tests. In a study comparing these approaches to baseline interfaces, participants with motor impairments were 26.4% faster using ability-based user interfaces generated by SUPPLE++. They also made 73% fewer errors, strongly preferred those interfaces to the manufacturers' defaults, and found them more efficient, easier to use, and much less physically tiring. These findings indicate that rather than requiring some users with motor impairments to adapt themselves to software using separate assistive technologies, software can now adapt itself to the capabilities of its users. Copyright 2008 ACM.",Ability-based user interfaces | Arnauld | Motor impairments | Supple | Supple++,139,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-57649244111,10.1145/1357054.1357316,,,In-car GPS navigation: Engagement with and disengagement from the environment,cp,Conference Paper,Leshed G.,60028072;60007776,Cornell University Department of Information Science;Cornell University,Ithaca;Ithaca,United States;United States,5,"Leshed, Gilly;Velden, Theresa;Rieger, Oya;Kot, Blazej;Sengers, Phoebe",13006060400;25925527900;6506792769;12752971800;22836146000,60028072;60028072;60007776;60028072;60028072,2008-12-22,2008,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1675-1684,"Although in-car GPS navigation technology is proliferating, it is not well understood how its use alters the ways people interpret their environment and navigate through it. We argue that GPS-based car navigation might disengage people from their surrounding environment, but also has the potential to open up novel ways to engage with it. We present an ethnographically-informed study with GPS users, showing evidence for practices of disengagement as well as new opportunities for engagement, illustrating our findings using rich descriptions from the field. Grounded in our observations we propose design principles for GPS systems that support richer experiences of driving. We argue that for a fuller understanding of issues of disengagement and engagement with the environment we need to move beyond a focus on the (re)design of GPS devices, and point to future directions of work that embrace a broader perspective. Copyright 2008 ACM.",Environmental engagement | GPS | Qualitative field study,131,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85076893888,,,,Klee: Unassisted and automatic generation of high-coverage tests for complex systems programs,cp,Conference Paper,Cadar C.,60012708,Stanford University,Stanford,United States,3,"Cadar, Cristian;Dunbar, Daniel;Engler, Dawson",8977801700;20336663500;7006155582,60012708;60012708;60012708,2019-01-01,2019,"Proceedings of the 8th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2008",,21100939709,,Conference Proceeding,,,,209-224,"We present a new symbolic execution tool, KLEE, capable of automatically generating tests that achieve high coverage on a diverse set of complex and environmentally-intensive programs. We used KLEE to thoroughly check all 89 stand-alone programs in the GNU COREUTILS utility suite, which form the core user-level environment installed on millions of Unix systems, and arguably are the single most heavily tested set of open-source programs in existence. KLEE-generated tests achieve high line coverage - on average over 90% per tool (median: over 94%) - and significantly beat the coverage of the developers' own hand-written test suite. When we did the same for 75 equivalent tools in the BUSYBOX embedded system suite, results were even better, including 100% coverage on 31 of them. We also used KLEE as a bug finding tool, applying it to 452 applications (over 430K total lines of code), where it found 56 serious bugs, including three in COREUTILS that had been missed for over 15 years. Finally, we used KLEE to crosscheck purportedly identical BUSYBOX and COREUTILS utilities, finding functional correctness errors and a myriad of inconsistencies.",,2051,0,,,NSF,CCF-0424422,National Science Foundation,OSDI Operating Systems
2-s2.0-57649222589,10.1145/1357054.1357241,,,Large scale analysis of web revisitation patterns,cp,Conference Paper,Adar E.,60021726;60015481,Microsoft Research;University of Washington,Redmond;Seattle,United States;United States,3,"Adar, Eytan;Teevan, Jaime;Dumais, Susan T.",8395017700;57207527470;7003862762,60015481;60021726;60021726,2008-12-22,2008,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1197-1206,"Our work examines Web revisitation patterns. Everybody revisits Web pages, but their reasons for doing so can differ depending on the particular Web page, their topic of interest, and their intent. To characterize how people revisit Web content, we analyzed five weeks of Web interaction logs of over 612,000 users. We supplemented these findings by a survey intended to identify the intent behind the observed revisitation. Our analysis reveals four primary revisitation patterns, each with unique behavioral, content, and structural characteristics. Through our analysis we illustrate how understanding revisitation patterns can enable Web sites to provide improved navigation, Web browsers to predict users' destinations, and search engines to better support fast, fresh, and effective finding and re-finding. Copyright 2008 ACM.",Query log analysis | Re-finding | Revisitation | Web behavior,137,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-67650697165,10.1145/1458082.1458150,,,Learning to link with wikipedia,cp,Conference Paper,Milne D.,60004424,The University of Waikato,Hamilton,New Zealand,2,"Milne, David;Witten, Ian H.",57188810837;35589184400,60004424;60004424,2008-12-01,2008,"International Conference on Information and Knowledge Management, Proceedings",,55826,,Conference Proceeding,,,,509-518,"This paper describes how to automatically cross-reference documents with Wikipedia: the largest knowledge base ever known. It explains how machine learning can be used to identify significant terms within unstructured text, and enrich it with links to the appropriate Wikipedia articles. The resulting link detector and disambiguator performs very well, with recall and precision of almost 75%. This performance is constant whether the system is evaluated on Wikipedia articles or -real world- documents. This work has implications far beyond enriching documents with explanatory links. It can provide structured knowledge about any unstructured fragment of text. Any task that is currently addressed with bags of words-indexing, clustering, retrieval, and summarization to name a few-could use the techniques described here to draw on a vast network of concepts and semantics. © 2008 ACM.",Data mining | Semantic annotation | Wikipedia | Word sense disambiguation,941,0,repositoryam,Green,,undefined,,CIKM Knowledge Management
2-s2.0-57649178609,10.1145/1357054.1357119,,,Multimodal collaborative handwriting training for visually-impaired people,cp,Conference Paper,Plimmer B.,60005686;60001490,The University of Auckland;University of Glasgow,Auckland;Glasgow,New Zealand;United Kingdom,4,"Plimmer, Beryl;Crossan, Andrew;Brewster, Stephen A.;Blagojevic, Rachel",14629169800;14831042100;7006514160;25649262200,60005686;60001490;60001490;60005686,2008-12-22,2008,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,393-402,"""McSig"" is a multimodal teaching and learning environment for visually-impaired students to learn character shapes, handwriting and signatures collaboratively with their teachers. It combines haptic and audio output to realize the teacher's pen input in parallel non-visual modalities. McSig is intended for teaching visually-impaired children how to handwrite characters (and from that signatures), something that is very difficult without visual feedback. We conducted an evaluation with eight visually-impaired children with a pre-test to assess their current skills with a set of character shapes, a training phase using McSig and then a post-test of the same character shapes to see if there were any improvements. The children could all use McSig and we saw significant improvements in the character shapes drawn, particularly by the completely blind children (many of whom could draw almost none of the characters before the test). In particular, the blind participants all expressed enjoyment and excitement about the system and using a computer to learn to handwrite. Copyright 2008 ACM.",Haptic trajectory playback | Multimodal interface design | Signature training | Visually-impaired users,61,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-51349085586,10.1109/INFOCOM.2007.21,,,On the feasibility of the link abstraction in (rural) mesh networks,cp,Conference Paper,Gokhale D.,60153202;60014153;106220423,"School of Computer, Data &amp; Information Sciences;Indian Institute of Technology Bombay;Electrical Branch",Madison;Mumbai;Navy,United States;India;,4,"Gokhale, Dattatraya;Sen, Sayandeep;Chebrolu, Kameswari;Raman, Bhaskaran",16238768500;15064665400;16027776200;8655731000,106220423;60153202;60014153;60014153,2008-09-15,2008,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,,,4509616,484-492,"Outdoor community mesh networks based on 802.11 have seen tremendous growth in the recent past. The current understanding is that wireless link performance in these settings in inherently unpredictable, due to multipath delay spread. Consequently, researchers have focused on developing intelligent routing techniques to achieve the best possible performance. In this paper, we are specifically interested in mesh networks in rural locations. We first present detailed measurements to show that the PHY layer in these settings is indeed stable and predictable. There is a strong correlation between the error rate and the received signal strength. We show that interference, and not multipath fading, is the primary cause of unpredictable performance. This is in sharp contrast with current widespread knowledge from prior studies. Furthermore, we corroborate our view with a fresh analysis of data presented in these prior studies. Based on our results, we argue that outdoor rural mesh networks can indeed be built with the link abstraction being valid. This has several design implications, and opens up a fresh perspective on a wide range of technical issues in this domain. © 2008 IEEE.",,36,0,repositoryam,Green,,undefined,,INFOCOM Networking
2-s2.0-57849145767,,,,Optimal false-name-proof voting rules with costly voting,cp,Conference Paper,Wagman L.,60008724,Duke University,Durham,United States,2,"Wagman, Liad;Conitzer, Vincent",25927673500;6603436056,60008724;60008724,2008-12-29,2008,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,1,,,190-195,"One way for agents to reach a joint decision is to vote over the alternatives. In open, anonymous settings such as the Internet, an agent can vote more than once without being detected. A voting rule is false-name-proof if no agent ever benefits from casting additional votes. Previous work has shown that all false-name-proof voting rules are unresponsive to agents' preferences. However, that work implicitly assumes that casting additional votes is costless. In this paper, we consider what happens if there is a cost to casting additional votes. We characterize the optimal (most responsive) false-name-proof-with-costs voting rule for 2 alternatives. In sharp contrast to the costless setting, we prove that as the voting population grows larger, the probability that this rule selects the majority winner converges to 1. We also characterize the optimal group false-name-proof rule for 2 alternatives, which is robust to coalitions of agents sharing the costs of additional votes. Unfortunately, the probability that this rule chooses the majority winner as the voting population grows larger is relatively low. We derive an analogous rule in a setting with 3 alternatives, and provide bounding results and computational approaches for settings with 4 or more alternatives. Copyright © 2008, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,27,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-85027275395,10.4230/LIPIcs.ICALP.2017.78,,,A birthday repetition theorem and complexity of approximating dense CSPs,cp,Conference Paper,Manurangsi P.,60025038,"University of California, Berkeley",Berkeley,United States,2,"Manurangsi, Pasin;Raghavendra, Prasad",55858818000;23390082900,60025038;60025038,2017-07-01,1 July 2017,"Leibniz International Proceedings in Informatics, LIPIcs",18688969,21100244929,,Conference Proceeding,80,,78,,"A (κ ×l)-birthday repetition Gκ×l of a two-prover game G is a game in which the two provers are sent random sets of questions from G of sizes k and l respectively. These two sets are sampled independently uniformly among all sets of questions of those particular sizes. We prove the following birthday repetition theorem: when G satisfies some mild conditions, val(Gκ×l) decreases exponentially in Ω(κl/n) where n is the total number of questions. Our result positively resolves an open question posted by Aaronson, Impagliazzo and Moshkovitz [Aaronson et al., CCC, 2014]. As an application of our birthday repetition theorem, we obtain new fine-grained inapproximability results for dense CSPs. Specifically, we establish a tight trade-off between running time and approximation ratio by showing conditional lower bounds, integrality gaps and approximation algorithms; in particular, for any sufficiently large i and for every κ ≤ 2, we show the following: We exhibit an O(q1/i)-approximation algorithm for dense Max κ-CSPs with alphabet size q via Oκ(i)-level of Sherali-Adams relaxation. Through our birthday repetition theorem, we obtain an integrality gap of q1/i for Ωκ(i)-level Lasserre relaxation for fully-dense Max κ-CSP. Assuming that there is a constant ϵ < 0 such that Max 3SAT cannot be approximated to within (1-ϵ) of the optimal in sub-exponential time, our birthday repetition theorem implies that any algorithm that approximates fully-dense Max κ-CSP to within a q1/i factor takes (nq)Ωκ(i) time, almost tightly matching our algorithmic result. As a corollary of our algorithm for dense Max κ-CSP, we give a new approximation algorithm for Densest κ-Subhypergraph, a generalization of Densest κ-Subgraph to hypergraphs. When the input hypergraph is O(1)-uniform and the optimal k-subhypergraph has constant density, our algorithm finds a κ-subhypergraph of density Ω(n-1/i) in time nO(i) for any integer i > 0.",Birthday repetition | Constraint satisfaction problems | Linear program,43,0,,,NSF,CCF-1343104,National Science Foundation,STOC Theory
2-s2.0-57049141635,10.1145/1374376.1374415,,,Optimal hierarchical decompositions for congestion minimization in networks,cp,Conference Paper,Räcke H.,60022020,University of Warwick,Coventry,United Kingdom,1,"Räcke, Harald",6602081824,60022020,2008-01-01,2008,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,255-263,"Hierarchical graph decompositions play an important role in the design of approximation and online algorithms for graph problems. This is mainly due to the fact that the results concerning the approximation of metric spaces by tree metrics (e.g. [10, 11, 14, 16]) depend on hierarchical graph decompositions. In this line of work a probability distribution over tree graphs is constructed from a given input graph, in such a way that the tree distances closely resemble the distances in the original graph. This allows it, to solve many-problems with a distance-based cost function on trees, and then transfer the tree solution to general undirected graphs with only a logarithmic loss in the performance guarantee. The results about oblivious routing [30, 22] in general undirected graphs are based on hierarchical decompositions of a different type in the sense that they are aiming to approximate the bottlenecks in the network (instead of the point-to-point distances). We call such decompositions cut-based decompositions. It has been shown that they also can be used to design approximation and online algorithms for a wide variety of different problems, but at the current state of the art the performance guarantee goes down by an O(log2 n log log n)-factor when making the transition from tree networks to general graphs. In this paper we show how to construct cut-based decompositions that only result in a logarithmic loss in performance, wdiich is asymptotically optimal. Remarkably, one major ingredient of our proof is a distance-based decomposition scheme due to Fakcharoenphol, Rao and Talwar [16]. This shows an interesting relationship between these seemingly different decomposition techniques. The main applications of the new decomposition are an optimal O(log n)-competitive algorithm for oblivious routing in general undirected graphs, and an O(log n)-approximation for Minimum Bisection, which improves the O(log1-5 n) approximation by Feige and Krauthgamer [17]. Copyright 2008 ACM.",Approximating metrics by tree metrics | Hierarchical decompositions | Oblivious routing,208,0,,,,undefined,,STOC Theory
2-s2.0-50249098733,10.1109/SP.2008.31,,,Pacemakers and implantable cardiac defibrillators: Software radio attacks and zero-power defenses,cp,Conference Paper,Halperin D.,60152130;60028661;60015481;60014313;60002746,Manning College of Information &amp; Computer Sciences;UW College of Engineering;University of Washington;University of Massachusetts Amherst;Harvard Medical School,Amherst;Seattle;Seattle;Amherst;Boston,United States;United States;United States;United States;United States,9,"Halperin, Daniel;Clark, Shane S.;Fu, Kevin;Heydt-Benjamin, Thomas S.;Defend, Benessa;Kohno, Tadayoshi;Ransford, Benjamin;Morgan, Will;Maisel, William H.",35988896200;24723406400;18434230000;23469239900;18433295300;7201820043;24725598400;57214556650;7003836355,60015481;60014313;60014313-60152130;60014313;60014313;60015481-60028661;60014313;60014313;60002746,2008-09-01,2008,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,,,4531149,129-142,"Our study analyzes the security and privacy properties of an implantable cardioverter defibrillator (ICD). Introduced to the U.S. market in 2003, this model of ICD includes pacemaker technology and is designed to communicate wirelessly with a nearby external programmer in the 175 kHz frequency range. After partially reverse-engineering the ICD's communications protocol with an oscilloscope and a software radio, we implemented several software radio-based attacks that could compromise patient safety and patient privacy. Motivated by our desire to improve patient safety, and mindful of conventional trade-offs between security and power consumption for resource-constrained devices, we introduce three new zero-power defenses based on RF power harvesting. Two of these defenses are human-centric, bringing patients into the loop with respect to the security and privacy of their implantable medical devices (IMDs). Our contributions provide a scientific baseline for understanding the potential security and privacy risks of current and future IMDs, and introduce human-perceptible and zero-power mitigation techniques that address those risks. To the best of our knowledge, this paper is the first in our community to use general-purpose software radios to analyze and attack previously unknown radio communications protocols. © 2008 IEEE.",,581,0,repositoryam,Green,,undefined,,S&P Security and Privacy
2-s2.0-67650714764,10.1145/1368088.1368110,,,Precise memory leak detection for java software using container profiling,cp,Conference Paper,Xu G.,60149838,College of Engineering,Columbus,United States,2,"Xu, Guoqing;Rountev, Atanas",55726319300;6602227713,60149838;60149838,2008-12-01,2008,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,4814126,151-160,"A memory leak in a Java program occurs when object references that are no longer needed are unnecessarily maintained. Such leaks are difficult to understand because static analyses typically cannot precisely identify these redundant references, and existing dynamic analyses for leak detection track and report fine-grained information about individual objects, producing results that are usually hard to interpret and lack precision. We introduce a novel container-based heap-tracking technique, based on the observation that many memory leaks in Java programs occur due to containers that keep references to unused data entries. The novelty of the described work is two-fold: (1) instead of tracking arbitrary objects and finding leaks by analyzing references to unused objects, the technique tracks only containers and directly identifies the source of the leak, and (2) the approach computes a confidence value for each container based on a combination of its memory consumption and its elements' staleness (time since last retrieval), while previous approaches do not consider such combined metrics. Our experimental results show that the reports generated by the proposed technique can be very precise: for two bugs reported by Sun and for a known bug in SPECjbb, the top containers in the reports include the containers that leak memory. Copyright 2008 ACM.",Container profiling | Leaking confidence | Memory leaks,124,0,,,,undefined,,ICSE Software Engineering
2-s2.0-57349111758,10.1145/1368088.1368135,,,Predicting accurate and actionable static analysis warnings: An experimental approach,cp,Conference Paper,Ruthruff J.R.,60026306;60006191,University of Nebraska–Lincoln;Google LLC,Lincoln;Mountain View,United States;United States,5,"Ruthruff, Joseph R.;Penix, John;Morgenthaler, J. David;Elbaum, Sebastian;Rothermel, Gregg",6506174104;55906481800;23018966700;6604075891;7003915481,60026306;60006191;60006191;60026306;60026306,2008-12-15,2008,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,341-350,"Static analysis tools report software defects that may or may not be detected by other verification methods. Two challenges complicating the adoption of these tools are spurious false positive warnings and legitimate warnings that are not acted on. This paper reports automated support to help address these challenges using logistic regression models that predict the foregoing types of warnings from signals in the warnings and implicated code. Because examining many potential signaling factors in large software development settings can be expensive, we use a screening methodology to quickly discard factors with low predictive power and cost-effectively build predictive models. Our empirical evaluation indicates that these models can achieve high accuracy in predicting accurate and actionable static analysis warnings, and suggests that the models are competitive with alternative models built without screening. Copyright 2008 ACM.",Experimental program analysis | Logistic regression analysis | Screening | Software quality | Static analysis tools,97,0,,,,undefined,,ICSE Software Engineering
2-s2.0-57349185958,10.1145/1368088.1368154,,,Recommending adaptive changes for framework evolution,cp,Conference Paper,Dagenais B.,60002494,Université McGill,Montreal,Canada,2,"Dagenais, Barthélémy;Robillard, Martin P.",19638625000;7006311463,60002494;60002494,2008-12-15,2008,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,481-490,"In the course of a framework's evolution, changes ranging from a simple refactoring to a complete rearchitecture can break client programs. Finding suitable replacements for framework elements that were accessed by a client program and deleted as part of the framework's evolution can be a challenging task. We present a recommendation system, SemDiff, that suggests adaptations to client programs by analyzing how a framework adapts to its own changes. In a study of the evolution of the Eclipse JDT framework and three client programs, our approach recommended relevant adaptive changes with a high level of precision, and detected non-trivial changes typically undiscovered by current refactoring detection techniques. Copyright 2008 ACM.",Documentation | Experimentation,118,0,repositoryvor,Green,,undefined,,ICSE Software Engineering
2-s2.0-85065163256,,,,Remus: High availability via asynchronous virtual machine replication,cp,Conference Paper,Cully B.,60096478;60010365,"Citrix Systems, Inc.;The University of British Columbia",Fort Lauderdale;Vancouver,United States;Canada,6,"Cully, Brendan;Lefebvre, Geoffrey;Meyer, Dutch;Feeley, Mike;Hutchinson, Norm;Warfield, Andrew",24337289000;26025691300;26025682400;7006334894;7007086001;6601955007,60010365;60010365;60010365;60010365;60010365;60010365-60096478,2008-01-01,2008,"5th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2008",,21101024043,,Conference Proceeding,,,,161-174,"Allowing applications to survive hardware failure is an expensive undertaking, which generally involves re-engineering software to include complicated recovery logic as well as deploying special-purpose hardware; this represents a severe barrier to improving the dependability of large or legacy applications. We describe the construction of a general and transparent high availability service that allows existing, unmodified software to be protected from the failure of the physical machine on which it runs. Remus provides an extremely high degree of fault tolerance, to the point that a running system can transparently continue execution on an alternate physical host in the face of failure with only seconds of downtime, while completely preserving host state such as active network connections. Our approach encapsulates protected software in a virtual machine, asynchronously propagates changed state to a backup host at frequencies as high as forty times a second, and uses speculative execution to concurrently run the active VM slightly ahead of the replicated system state.",,515,0,,,NSERC,undefined,Natural Sciences and Engineering Research Council of Canada,NSDI Networking
2-s2.0-56449110590,,,,SVM optimization: Inverse dependence on training set size,cp,Conference Paper,Shalev-Shwartz S.,60074721,Toyota Technological Institute at Chicago,Chicago,United States,2,"Shalev-Shwartz, Shai;Srebro, Nathan",6507998544;18937325300,60074721;60074721,2008-11-26,2008,Proceedings of the 25th International Conference on Machine Learning,,12900154712,,Conference Proceeding,,,,928-935,"We discuss how the runtime of SVM optimization should decrease as the size of the training data increases. We present theoretical and empirical results demonstrating how a simple subgradient descent approach indeed displays such behavior, at least for linear kernels. Copyright 2008 by the author(s)/owner(s).",,179,0,,,,undefined,,ICML Machine Learning
2-s2.0-57149143446,10.1145/1376616.1376623,,,Scalable network distance browsing in spatial databases,cp,Conference Paper,Samet H.,60020304;60006191,"University of Maryland, College Park;Google LLC",College Park;Mountain View,United States;United States,3,"Samet, Hanan;Sankaranarayanan, Jagan;Alborzi, Houman",35556471300;12759504100;7801441371,60020304-60006191;60020304;60020304,2008-12-10,2008,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,1376623,43-54,"An algorithm is presented for finding the k nearest neighbors in a spatial network in a best-first manner using network distance. The algorithm is based on precomputing the shortest paths between all possible vertices in the network and then making use of an encoding that takes advantage of the fact that the shortest paths from vertex u to all of the remaining vertices can be decomposed into subsets based on the first edges on the shortest paths to them from u. Thus, in the worst case, the amount of work depends on the number of objects that are examined and the number of links on the shortest paths to them from q, rather than depending on the number of vertices in the network. The amount of storage required to keep track of the subsets is reduced by taking advantage of their spatial coherence which is captured by the aid of a shortest path quadtree. In particular, experiments on a number of large road networks as well as a theoretical analysis have shown that the storage has been reduced from O(N3) to 0(N1.5) (i.e., by an order of magnitude equal to the square root). The precomputation of the shortest paths along the network essentially decouples the process of computing shortest paths along the network from that of finding the neighbors, and thereby also decouples the domain S of the query objects and that of the objects from which the neighbors are drawn from the domain V of the vertices of the spatial network. This means that as long as the spatial network is unchanged, the algorithm and underlying representation of the shortest paths in the spatial network can be used with different sets of objects. Copyright 2008 ACM.",Decoupling | Nearest neighbor | Scalability | Shortest path quadtree | Spatial networks,250,0,repositoryam,Green,,undefined,,SIGMOD Databases
2-s2.0-57149143052,10.1145/1376616.1376690,,,Serializable Isolation for Snapshot Databases,cp,Conference Paper,Cahill M.J.,60099659;60027758,School of Computer Science;Oracle Corporation,Sydney;Austin,Australia;United States,3,"Cahill, Michael J.;Röhm, Uwe;Fekete, Alan D.",7102099162;21743878900;7005955245,60099659-60027758;60099659;60099659,2008-12-10,2008,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,1376690,729-738,"Many popular database management systems offer snapshot isolation rather than full serializability. There are well-known anomalies permitted by snapshot isolation that can lead to violations of data consistency by interleaving transactions that individually maintain consistency. Until now, the only way to prevent these anomalies was to modify the applications by introducing artificial locking or update conflicts, following careful analysis of conflicts between all pairs of transactions. This paper describes a modification to the concurrency control algorithm of a database management system that automatically detects and prevents snapshot isolation anomalies at runtime for arbitrary applications, thus providing serializable isolation. The new algorithm preserves the properties that make snapshot isolation attractive, including that readers do not block writers and vice versa. An implementation and performance study of the algorithm are described, showing that the throughput approaches that of snapshot isolation in most cases. Copyright 2008 ACM.",Multiversion concurrency control | Serializability theory | Snapshot isolation,83,0,repositoryvor,Green,,undefined,,SIGMOD Databases
2-s2.0-57349094806,10.1145/1368088.1368111,,,Distinguished paper: The effect of program and model structure on MC/DC test adequacy coverage,cp,Conference Paper,Rajan A.,60029445;60003635,University of Minnesota Twin Cities;Rockwell Collins,Minneapolis;Cedar Rapids,United States;United States,3,"Rajan, Ajitha;Whalen, Michael W.;Heimdahl, Mats P.E.",16239550300;57210717052;6701804858,60029445;60003635;60029445,2008-12-15,2008,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,161-170,"In avionics and other critical systems domains, adequacy of test suites is currently measured using the MC/DC metric on source code (or on a model in model-based development). We believe that the rigor of the MC/DC metric is highly sensitive to the structure of the implementation and can therefore be misleading as a test adequacy criterion. We investigate this hypothesis by empirically studying the effect of program structure on MC/DC coverage. To perform this investigation, we use six realistic systems from the civil avionics domain and two toy examples. For each of these systems, we use two versions of their implementation-with and without expression folding (i.e., miming). To assess the sensitivity of MC/DC to program structure, we first generate test suites that satisfy MC/DC over a non-inlined implementation. We then run the generated test suites over the inlined implementation and measure MC/DC achieved. For our realistic examples, the test suites yield an average reduction of 29.5% in MC/DC achieved over the inlined implementations at 5% statistical significance level. Copyright 2008 ACM.",Experimentation | Verification,61,0,repositoryvor,Green,,undefined,,ICSE Software Engineering
2-s2.0-57649225687,10.1145/1357054.1357304,,,The network in the garden: An empirical analysis of social media in rural life,cp,Conference Paper,Gilbert E.,60000745,University of Illinois Urbana-Champaign,Urbana,United States,3,"Gilbert, Eric;Karahalios, Karrie;Sandvig, Christian",15519161300;23397392600;7801370310,60000745;60000745;60000745,2008-12-22,2008,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1603-1612,"History repeatedly demonstrates that rural communities have unique technological needs. Yet, we know little about how rural communities use modern technologies, so we lack knowledge on how to design for them. To address this gap, our empirical paper investigates behavioral differences between more than 3,000 rural and urban social media users. Using a dataset collected from a broadly popular social network site, we analyze users' profiles, 340,000 online friendships and 200,000 interpersonal messages. Using social capital theory, we predict differences between rural and urban users and find strong evidence supporting our hypotheses. Namely, rural people articulate far fewer friends online, and those friends live much closer to home. Our results also indicate that the groups have substantially different gender distributions and use privacy features differently. We conclude by discussing design implications drawn from our findings; most importantly, designers should reconsider the binary friend-or-not model to allow for incremental trust-building. Copyright 2008 ACM.",Digital divide | Rural | Social media | Social network sites,92,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-51349146647,10.1109/INFOCOM.2007.9,,,Theoretical results on base station movement problem for sensor network,cp,Conference Paper,Shi Y.,60157272,Virginia Tech College of Engineering,Blacksburg,United States,2,"Shi, Yi;Hou, Y. Thomas",58138109800;7402198673,60157272;60157272,2008-09-15,2008,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,,,4509604,376-384,"The benefits of using mobile base station to prolong sensor network lifetime have been well recognized. However, due to the complexity of the problem (time-dependent network topology and traffic routing), theoretical performance limit and provably optimal algorithms remain difficult to develop. This paper fills this important gap by contributing theoretical results regarding the optimal movement of a mobile base station. Our main result hinges upon a novel transformation of the joint base station movement and flow routing problem from time domain to space domain. Based on this transformation, we first show that if the base station is allowed to be present only on a set of pre-defined points, then we can find the optimal time span for the base station on each of these points so that the overall network lifetime is maximized. Based on this finding, we show that when the location of the base station is un-constrained (i.e., can move to any point in the two-dimensional plane), we can develop an approximation algorithm for the joint mobile base station location and flow routing problem such that the network lifetime is guaranteed to be at least (1 - ∈) of the maximum network lifetime, where s can be made arbitrarily small depending on required precision. © 2008 IEEE.",,137,0,repositoryam,Green,,undefined,,INFOCOM Networking
2-s2.0-57949102715,10.1109/FOCS.2008.60,,,Two query PCP with sub-constant error,cp,Conference Paper,Moshkovitz D.,60017563,Weizmann Institute of Science Israel,Rehovot,Israel,2,"Moshkovitz, Dana;Raz, Ran",14121841400;7102829173,60017563;60017563,2008-12-30,2008,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,,,4690965,314-323,"We show that the NP-Complete language 3SAT has a PCP verifier that makes two queries to a proof of almostlinear size and achieves sub-constant probability of error o(1). The verifier performs only projection tests, meaning that the answer to the first query determines at most one accepting answer to the second query. Previously, by the parallel repetition theorem, there were PCP Theorems with two-query projection tests, but only (arbitrarily small) constant error and polynomial size [26]. There were also PCP Theorems with sub-constant error and almost-linear size, but a constant number of queries that is larger than 2 [22]. As a corollary, we obtain a host of new results. In particular, our theorem improves many of the hardness of approximation results that are proved using the parallel repetition theorem. A partial list includes the following: 1. 3SAT cannot be efficiently approximated to within a factor of 7/8 + o(1), unless V = NP. This holds even under almost-linear reductions. Previously, the best known NP-hardness factor was 7/8 + ε for any constant ε > 0, under polynomial reductions (Håstad, [17]). 2. 3LIN cannot be efficiently approximated to within a factor of 1/2 + o(1), unless P = NP. This holds even under almost-linear reductions. Previously, the best known NP-hardness factor was 1/2 + ε for any constant ε > 0, under polynomial reductions (Håstad, [17]). 3. A PCP Theorem with amortized query complexity 1 + o(1) and amortized free bit complexity o(1). Previously, the best known amortized query complexity and free bit complexity were 1 + ε and ε, respectively, for any constant ε > 0 (Samorodnitsky and Trevisan, [29]). One of the new ideas that we use is a new technique for doing the composition step in the (classical) proof of the PCP Theorem, without increasing the number of queries to the proof. We formalize this as a composition of new objects that we call Locally Decode/Reject Codes (LDRC). The notion of LDRC was implicit in several previous works, and we make it explicit in this work. We believe that the formulation of LDRCs and their construction are of independent interest. © 2008 IEEE.",,21,0,repositoryam,Green,,undefined,,FOCS Theory
2-s2.0-51349140934,10.1109/INFOCOM.2007.165,,,Understanding the capacity region of the greedy maximal scheduling algorithm in multi-hop wireless networks,cp,Conference Paper,Joo C.,60009254;60003500,Purdue University;The Ohio State University,West Lafayette;Columbus,United States;United States,3,"Joo, Changhee;Lin, Xiaojun;Shroff, Ness B.",56243474000;24776268100;7005989631,60003500;60009254;60003500,2008-09-15,2008,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,,,4509760,1777-1785,"In this paper, we characterize the performance of an important class of scheduling schemes, called Greedy Maximal Scheduling (GMS), for multi-hop wireless networks. While a lower bound on the throughput performance of GMS is relatively well-known in the simple node-exclusive interference model, it has not been thoroughly explored in the more general K-hop interference model. Moreover, empirical observations suggest that the known bounds are quite loose, and that the performance of GMS is often close to optimal. In this paper, we provide a number of new analytic results characterizing the performance limits of GMS. We first provide an equivalent characterization of the efficiency ratio of GMS through a topological property called the local-pooling factor of the network graph. We then develop an iterative procedure to estimate the local-pooling factor under a large class of network topologies and interference models. We use these results to study the worst-case efficiency ratio of GMS on two classes of network topologies. First, we show how these results can be applied to tree networks to prove that GMS achieves the full capacity region in tree networks under the K-hop interference model. Second, we show that the worst-case efficiency ratio of GMS in geometric network graphs is between 1/6 and 1/3. © 2008 IEEE.",,128,0,repositoryam,Green,,undefined,,INFOCOM Networking
2-s2.0-77949403731,10.1145/1453101.1453146,,,What makes a good bug report?,cp,Conference Paper,Bettenburg N.,60033241;60012614;60003122;60002306,Universität des Saarlandes;Universität Zürich;University of Victoria;University of Calgary,Saarbrucken;Zurich;Victoria;Calgary,Germany;Switzerland;Canada;Canada,6,"Bettenburg, Nicolas;Just, Sascha;Schröter, Adrian;Weiss, Cathrin;Premraj, Rahul;Zimmermann, Thomas",25723011100;25822684100;25929529300;21743983000;23052128500;16308551800,60033241;60033241;60003122;60012614;60033241;60002306,2008-12-01,2008,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,85109,,Conference Proceeding,,,,308-318,"In software development, bug reports provide crucial information to developers. However, these reports widely differ in their quality. We conducted a survey among developers and users of APACHE, ECLIPSE, and MOZILLA to find out what makes a good bug report. The analysis of the 466 responses revealed an information mismatch between what developers need and what users supply. Most developers consider steps to reproduce, stack traces, and test cases as helpful, which are at the same time most difficult to provide for users. Such insight is helpful to design new bug tracking tools that guide users at collecting and providing more helpful information. Our CUEZILLA prototype is such a tool and measures the quality of new bug reports; it also recommends which elements should be added to improve the quality. We trained CUEZILLA on a sample of 289 bug reports, rated by developers as part of the survey. In our experiments, CUEZILLA was able to predict the quality of 31 - 48% of bug reports accurately. © 2008 ACM.",,412,0,,,,undefined,,FSE Software Engineering
2-s2.0-66549100735,10.1145/1402946.1402977,,,Zigzag decoding: Combating hidden terminals in wireless networks,cp,Conference Paper,Gollakota S.,60006320,MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge,United States,2,"Gollakota, Shyamnath;Katabi, Dina",24449959700;6507046077,60006320;60006320,2008-12-01,2008,Computer Communication Review,01464833,13683,01464833,Conference Proceeding,38,4,,159-170,"This paper presents ZigZag, an 802.11 receiver design that combats hidden terminals. ZigZag's core contribution is a new form of interference cancellation that exploits asynchrony across successive collisions. Specifically, 802.11 retransmissions, in the case of hidden terminals, cause successive collisions. These collisions have different interference-free stretches at their start, which ZigZag exploits to bootstrap its decoding. ZigZag makes no changes to the 802.11 MAC and introduces no overhead when there are no collisions. But, when senders collide, ZigZag attains the same throughput as if the colliding packets were a priori scheduled in separate time slots. We build a prototype of ZigZag in GNU Radio. In a testbed of 14 USRP nodes, ZigZag reduces the average packet loss rate at hidden terminals from 72.6% to about 0.7%. Copyright 2008 ACM.",Hidden terminals | Interference cancellation | Wireless,310,0,,,,undefined,,SIGCOMM Networking
2-s2.0-77952252122,10.14778/1687627.1687685,,,A unified approach to ranking in probabilistic databases,ar,Article,Li J.,60020304,"University of Maryland, College Park",College Park,United States,3,"Li, Jian;Saha, Barna;Deshpande, Amol",56199160700;35119400000;9734842400,60020304;60020304;60020304,2009-01-01,2009,Proceedings of the VLDB Endowment,,21100199855,21508097,Conference Proceeding,2,1,,502-513,"The dramatic growth in the number of application domains that naturally generate probabilistic, uncertain data has resulted in a need for efficiently supporting complex querying and decision-making over such data. In this paper, we present a unified approach to ranking and top-k query processing in probabilistic databases by viewing it as a multi-criteria optimization problem, and by deriving a set of features that capture the key properties of a probabilistic dataset that dictate the ranked result. We contend that a single, specific ranking function may not suffice for probabilistic databases, and we instead propose two parameterized ranking functions, called PRFw and PRFe, that generalize or can approximate many of the previously proposed ranking functions. We present novel generating functions-based algorithms for efficiently ranking large datasets according to these ranking functions, even if the datasets exhibit complex correlations modeled using probabilistic and/xor trees or Markov networks. We further propose that the parameters of the ranking function be learned from user preferences, and we develop an approach to learn those parameters. Finally, we present a comprehensive experimental study that illustrates the effectiveness of our parameterized ranking functions, especially PRFe, at approximating other ranking functions and the scalability of our proposed algorithms for exact or approximate ranking. © 2009 VLDB Endowment.",,104,0,repositoryam,Green,,undefined,,VLDB Databases
2-s2.0-70350668813,10.1145/1536414.1536462,,,A constructive proof of the lovász local lemma,cp,Conference Paper,Moser R.A.,60025858,ETH Zürich,Zurich,Switzerland,1,"Moser, Robin A.",35105499800,60025858,2009-11-09,2009,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,343-350,"The Lovász Local Lemma [2] is a powerful tool to prove the existence of combinatorial objects meeting a prescribed collection of criteria. The technique can directly be applied to the satisfiability problem, yielding that a k-CNF formula in which each clause has common variables with at most 2 k-2 other clauses is always satisfiable. All hitherto known proofs of the Local Lemma are non-constructive and do thus not provide a recipe as to how a satisfying assignment to such a formula can be efficiently found. In his breakthrough paper [3], Beck demonstrated that if the neighbourhood of each clause be restricted to O(2k/48), a polynomial time algorithm for the search problem exists. Alon simplified and randomized his procedure and improved the bound to O(2k/8) [4]. Srinivasan presented in [9] a variant that achieves a bound of essentially O(2k/4). In [11], we improved this to O(2k/2). In the present paper, we give a randomized algorithm that finds a satisfying assignment to every k-CNF formula in which each clause has a neighbourhood of at most the asymptotic optimum of 2 k-5-1 other clauses and that runs in expected time polynomial in the size of the formula, irrespective of k. If k is considered a constant, we can also give a deterministic variant. In contrast to all previous approaches, our analysis does not anymore invoke the standard non-constructive versions of the Local Lemma and can therefore be considered an alternative, constructive proof of it. Copyright 2009 ACM.",Bounded occurrence SAT instances | Derandomization | Hypergraph colouring | Lovász local lemma,106,0,repositoryam,Green,,undefined,,STOC Theory
2-s2.0-77949411652,10.1145/1595696.1595700,,,Asserting and checking determinism for multithreaded programs,cp,Conference Paper,Burnim J.,60025038,"University of California, Berkeley",Berkeley,United States,2,"Burnim, Jacob;Sen, Koushik",16202175100;8226489200,60025038;60025038,2009-12-01,2009,ESEC-FSE'09 - Proceedings of the Joint 12th European Software Engineering Conference and 17th ACM SIGSOFT Symposium on the Foundations of Software Engineering,,19700167008,,Conference Proceeding,,,,3-12,"The trend towards processors with more and more parallel cores is increasing the need for software that can take advantage of parallelism. The most widespread method for writing parallel software is to use explicit threads. Writing correct multithreaded programs, however, has proven to be quite challenging in practice. The key difficulty is non-determinism. The threads of a parallel application may be interleaved non-deterministically during execution. In a buggy program, non-deterministic scheduling will lead to non-deterministic results - some interleavings will produce the correct result while others will not. We propose an assertion framework for specifying that regions of a parallel program behave deterministically despite non-deterministic thread interleaving. Our framework allows programmers to write assertions involving pairs of program states arising from different parallel schedules. We describe an implementation of our deterministic assertions as a library for Java, and evaluate the utility of our specifications on a number of parallel Java benchmarks. We found specifying deterministic behavior to be quite simple using our assertions. Further, in experiments with our assertions, we were able to identify two races as true parallelism errors that lead to incorrect non-deterministic behavior. These races were distinguished from a number of benign races in the benchmarks. Copyright 2009 ACM.",Assertions | Determinism | Parallel programs,47,0,,,,undefined,,FSE Software Engineering
2-s2.0-70549112781,10.1109/ICSE.2009.5070536,,,Automatically finding patches using genetic programming,cp,Conference Paper,Weimer W.,60033021;60021918,The University of New Mexico;University of Virginia,Albuquerque;Charlottesville,United States;United States,4,"Weimer, Westley;Nguyen, Thanh Vu;Le Goues, Claire;Forrest, Stephanie",7003629741;57212283994;35113323900;57203256556,60021918;60033021;60021918;60033021,2009-12-01,2009,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,5070536,364-374,"Automatic program repair has been a longstanding goal in software engineering, yet debugging remains a largely manual process. We introduce a fully automated method for locating and repairing bugs in software. The approach works on off-the-shelf legacy applications and does not require formal specifications, program annotations or special coding practices. Once a program fault is discovered, an extended form of genetic programming is used to evolve program variants until one is found that both retains required functionality and also avoids the defect in question. Standard test cases are used to exercise the fault and to encode program requirements. After a successful repair has been discovered, it is minimized using structural differencing algorithms and delta debugging. We describe the proposed method and report experimental results demonstrating that it can successfully repair ten different C programs totaling 63,000 lines in under 200 seconds, on average. © 2009 IEEE.",,561,0,,,,undefined,,ICSE Software Engineering
2-s2.0-67650837951,10.1145/1543135.1542526,,,Binary analysis for measurement and attribution of program performance,cp,Conference Paper,Tallent N.R.,60005286,Rice University,Houston,United States,3,"Tallent, Nathan R.;Mellor-Crummey, John M.;Fagan, Michael W.",24482359600;57074967900;8243359900,60005286;60005286;60005286,2009-01-01,June 2009,ACM SIGPLAN Notices,15232867,19700185000,,Journal,44,6,,441-452,"Modern programs frequently employ sophisticated modular designs. As a result, performance problems cannot be identified from costs attributed to routines in isolation; understanding code performance requires information about a routine's calling context. Existing performance tools fall short in this respect. Prior strategies for attributing context-sensitive performance at the source level either compromise measurement accuracy, remain too close to the binary, or require custom compilers. To understand the performance of fully optimized modular code, we developed two novel binary analysis techniques: 1) on-the-fly analysis of optimized machine code to enable minimally intrusive and accurate attribution of costs to dynamic calling contexts; and 2) post-mortem analysis of optimized machine code and its debugging sections to recover its program structure and reconstruct a mapping back to its source code. By combining the recovered static program structure with dynamic calling context information, we can accurately attribute performance metrics to calling contexts, procedures, loops, and inlined instances of procedures. We demonstrate that the fusion of this information provides unique insight into the performance of complex modular codes. This work is implemented in the HPC-TOOLKIT1 performance tools. Copyright © 2009 ACM.",Binary analysis | Call path profiling | HPCTOOLKIT | Performance tools | Static analysis,33,0,,,,undefined,,PLDI Programming Languages
2-s2.0-70450285184,10.1145/1614320.1614353,,,CENTAUR: Realizing the full potential of centralized WLANs through a hybrid data path,cp,Conference Paper,Shrivastava V.,60033010;60014171;60006191;122904374,Intel Corporation;University of Waterloo;Google LLC;University of Wisconsin,Santa Clara;Waterloo;Mountain View;Falls,United States;Canada;United States;United States,7,"Shrivastava, Vivek;Ahmed, Nabeel;Rayanchu, Shravan;Banerjee, Suman;Keshav, Srinivasan;Papagiannaki, Konstantina;Mishra, Arunesh",57198387576;55362712000;24451185500;55323693100;10141917500;6603470572;7201441610,122904374;60014171;122904374;122904374;60014171;60033010;60006191,2009-11-30,2009,"Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM",,21100969570,,Conference Proceeding,,,,297-308,"Enterprise WLANs have made a dramatic shift towards centralized architectures in the recent past. The reasons for such a change have been ease of management and better design of various control and security functions. The data path of WLANs, however, continues to use the distributed, random-access model, as defined by the popular DCF mechanism of the 802.11 standard. While theoretical results indicate that a centrally scheduled data path can achieve higher efficiency than its distributed counterpart, the likely complexity of such a solution has inhibited practical consideration. In this paper, we take a fresh, implementation and deployment oriented, view in understanding data path choices in enterprise WLANs. We perform extensive measurements to characterize the impact of various design choices, like scheduling granularity on the performance of a centralized scheduler, and identify regions where such a centralized scheduler can provide the best gains. Our detailed evaluation with scheduling prototypes deployed on two different wireless testbeds indicates that DCF is quite robust in many scenarios, but centralization can play a unique role in 1) mitigating hidden terminals-scenarios which may occur infrequently, but become pain points when they do and 2) exploiting exposed terminals - scenarios which occur more frequently, and limit the potential of successful concurrent transmissions. Motivated by these results, we design and implement CENTAUR - a hybrid data path for enterprise WLANs, that combines the simplicity and ease of DCF with a limited amount of centralized scheduling from a unique vantage point. Our mechanisms do not require client cooperation and can support legacy 802.11 clients. Copyright 2009 ACM.",Centralized scheduling | Centralized WLAN | Epoch scheduling | Exposed terminals | Hidden terminals,123,0,,,,undefined,,MOBICOM Mobile
2-s2.0-70350647708,10.1145/1557019.1557072,,,Collaborative filtering with temporal dynamics,cp,Conference Paper,Koren Y.,60075274,Yahoo Research Labs,Sunnyvale,United States,1,"Koren, Yehuda",7004934292,60075274,2009-11-09,2009,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,101510,,Conference Proceeding,,,,447-455,"Customer preferences for products are drifting over time. Product perception and popularity are constantly changing as new selection emerges. Similarly, customer inclinations are evolving, leading them to ever redefine their taste. Thus, modeling temporal dynamics should be a key when designing recommender systems or general customer preference models. However, this raises unique challenges. Within the eco-system intersecting multiple products and customers, many different characteristics are shifting simultaneously, while many of them influence each other and often those shifts are delicate and associated with a few data instances. This distinguishes the problem from concept drift explorations, where mostly a single concept is tracked. Classical time-window or instancedecay approaches cannot work, as they lose too much signal when discarding data instances. A more sensitive approach is required, which can make better distinctions between transient effects and long term patterns. The paradigm we offer is creating a model tracking the time changing behavior throughout the life span of the data. This allows us to exploit the relevant components of all data instances, while discarding only what is modeled as being irrelevant. Accordingly, we revamp two leading collaborative filtering recommendation approaches. Evaluation is made on a large movie rating dataset by Netflix. Results are encouraging and better than those previously reported on this dataset. Copyright 2009 ACM.",Collaborative filtering | Concept drift | Recommender systems,931,0,repositoryam,Green,,undefined,,KDD Data Mining
2-s2.0-84859887629,10.3115/1687878.1687928,,,Concise integer linear programming formulations for dependency parsing,cp,Conference Paper,Martins A.F.T.,60136640;60004956,School of Computer Science;Instituto Superior Técnico,Pittsburgh;Lisbon,United States;Portugal,3,"Martins, André F.T.;Smith, Noah A.;Xing, Eric P.",55937372200;37044239600;57685890100,60136640-60004956;60136640;60136640,2009-01-01,2009,"ACL-IJCNLP 2009 - Joint Conf. of the 47th Annual Meeting of the Association for Computational Linguistics and 4th Int. Joint Conf. on Natural Language Processing of the AFNLP, Proceedings of the Conf.",,21100201002,,Conference Proceeding,,,,342-350,"We formulate the problem of nonprojective dependency parsing as a polynomial-sized integer linear program. Our formulation is able to handle non-local output features in an efficient manner; not only is it compatible with prior knowledge encoded as hard constraints, it can also learn soft constraints from data. In particular, our model is able to learn correlations among neighboring arcs (siblings and grandparents), word valency, and tendencies toward nearlyprojective parses. The model parameters are learned in a max-margin framework by employing a linear programming relaxation. We evaluate the performance of our parser on data in several natural languages, achieving improvements over existing state-of-the-art methods. © 2009 ACL and AFNLP.",,124,1,repositoryam,Green,,undefined,,ACL Natural Language Processing
2-s2.0-77953798872,,,,Consequence-driven reasoning for horn SHIQ ontologies,cp,Conference Paper,Kazakov Y.,60026851,University of Oxford,Oxford,United Kingdom,1,"Kazakov, Yevgeny",57205865503,60026851,2009-01-01,2009,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,2040-2045,"We present a novel reasoning procedure for Horn script Sℋℐscript Q ontologies - script Sℋℐscript Q ontologies that can be translated to the Horn fragment of first-order logic. In contrast to traditional reasoning procedures for ontologies, our procedure does not build models or model representations, but works by deriving new consequent axioms. The procedure is closely related to the so-called completion-based procedure for ℰℒ++ ontologies, and can be regarded as an extension thereof. In fact, our procedure is theoretically optimal for Horn script Sℋℐscript Q ontologies as well as for the common fragment of ℰℒ++ and script Sℋℐscript Q. A preliminary empirical evaluation of our procedure on large medical ontologies demonstrates a dramatic improvement over existing ontology reasoners. Specifically, our implementation allows the classification of the largest available OWL version of Galen. To the best of our knowledge no other reasoner is able to classify this ontology.",,171,0,,,,undefined,,IJCAI Artificial Intelligence
2-s2.0-77949398788,10.1145/1595696.1595704,,,DARWIN: An approach for debugging evolving programs,cp,Conference Paper,Qi D.,60021726;60017161,Microsoft Research;National University of Singapore,Redmond;Singapore City,United States;Singapore,4,"Qi, Dawei;Roychoudhury, Abhik;Liang, Zhenkai;Vaswani, Kapil",55556344900;7005260419;14034338200;15833285700,60017161;60017161;60017161;60021726,2009-12-01,2009,ESEC-FSE'09 - Proceedings of the Joint 12th European Software Engineering Conference and 17th ACM SIGSOFT Symposium on the Foundations of Software Engineering,,19700167008,,Conference Proceeding,,,,33-42,"Debugging refers to the laborious process of finding causes of program failures. Often, such failures are introduced when a program undergoes changes and evolves from a stable version to a new, modified version. In this paper, we propose an automated approach for debugging evolving programs. Given two programs (a reference, stable program and a new, modified program) and an input that fails on the modified program, our approach uses concrete as well as symbolic execution to synthesize new inputs that differ marginally from the failing input in their control flow behavior. A comparison of the execution traces of the failing input and the new inputs provides critical clues to the root-cause of the failure. A notable feature of our approach is that it handles hard-to-explain bugs like code missing errors by pointing to the relevant code in the reference program. We have implemented our approach in a tool called DARWIN. We have conducted experiments with several real-life case studies, including real-world web servers and the libPNG library for manipulating PNG images. Our experience from these experiments points to the efficacy of DARWIN in pinpointing bugs. Moreover, while localizing a given observable error, the new inputs synthesized by DARWIN can reveal other undiscovered errors. Copyright 2009 ACM.",Debugging | Software evolution | Symbolic execution,50,0,,,,undefined,,FSE Software Engineering
2-s2.0-77953180995,10.1109/ICCV.2009.5459256,,,Discriminative models for multi-class object layout,cp,Conference Paper,Desai C.,60007278,"University of California, Irvine",Irvine,United States,3,"Desai, Chaitanya;Ramanan, Deva;Fowlkes, Charless",36052212900;6506835622;6701549596,60007278;60007278;60007278,2009-12-01,2009,Proceedings of the IEEE International Conference on Computer Vision,,110561,,Conference Proceeding,,,5459256,229-236,"Many state-of-the-art approaches for object recognition reduce the problem to a 0-1 classification task. Such reductions allow one to leverage sophisticated classifiers for learning. These models are typically trained independently for each class using positive and negative examples cropped from images. At test-time, various post-processing heuristics such as non-maxima suppression (NMS) are required to reconcile multiple detections within and between different classes for each image. Though crucial to good performance on benchmarks, this post-processing is usually defined heuristically. We introduce a unified model for multi-class object recognition that casts the problem as a structured prediction task. Rather than predicting a binary label for each image window independently, our model simultaneously predicts a structured labeling of the entire image. Our model learns statistics that capture the spatial arrangements of various object classes in real images, both in terms of which arrangements to suppress through NMS and which arrangements to favor through spatial co-occurrence statistics. We formulate parameter estimation in our model as a max-margin learning problem. Given training images with ground-truth object locations, we show how to formulate learning as a convex optimization problem. We employ a cutting plane algorithm similar to [14] to efficiently learn a model from thousands of training images. We show state-of-the-art results on the PASCAL VOC benchmark that indicate the benefits of learning a global model encapsulating the spatial layout of multiple object classes. ©2009 IEEE.",,229,0,,,,undefined,,ICCV Computer Vision
2-s2.0-77949887177,10.1109/ICSE.2009.5070550,,,Does distributed development affect software quality? An empirical case study of windows vista,cp,Conference Paper,Bird C.,60021726;60014439;60012614,"Microsoft Research;University of California, Davis;Universität Zürich",Redmond;Davis;Zurich,United States;United States;Switzerland,5,"Bird, Christian;Nagappan, Nachiappan;Devanbu, Premkumar;Gall, Harald;Murphy, Brendan",17433640400;8261920700;35583833100;56223438700;7402698081,60014439;60021726;60014439;60012614;60021726,2009-12-01,2009,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,5070550,518-528,"It is widely believed that distributed software development is riskier and more challenging than collocated development. Prior literature on distributed development in software engineering and other fields discuss various challenges, including cultural barriers, expertise transfer dif-ficulties, and communication and coordination overhead. We evaluate this conventional belief by examining the overall development of Windows Vista and comparing the postrelease failures of components that were developed in a distributed fashion with those that were developed by collocated teams. We found a negligible difference in failures. This difference becomes even less significant when controlling for the number of developers working on a binary. We also examine component characteristics such as code churn, complexity, dependency information, and test code coverage and find very little difference between distributed and collocated components to investigate if less complex components are more distributed. Further, we examine the software process and phenomena that occurred during the Vista development cycle and present ways in which the development process utilized may be insensitive to geography by mitigating the difficulties introduced in prior work in this area. © 2009 IEEE.",,120,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-70350599876,10.1109/ICSE.2009.5070538,,,Effective static deadlock detection,cp,Conference Paper,Naik M.,60033010;60025038,"Intel Corporation;University of California, Berkeley",Santa Clara;Berkeley,United States;United States,4,"Naik, Mayur;Park, Chang Seo;Sen, Koushik;Gay, David",12140829000;55762888700;8226489200;7006989755,60033010;60025038;60025038;60033010,2009-12-01,2009,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,5070538,386-396,"We present an effective static deadlock detection algorithm for Java. Our algorithm uses a novel combination of static analyses each of which approximates a different necessary condition for a deadlock. We have implemented the algorithm and report upon our experience applying it to a suite of multi-threaded Java programs. While neither sound nor complete, our approach is effective in practice, finding all known deadlocks as well as discovering previously unknown ones in our benchmarks with few false alarms. © 2009 IEEE.",,155,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84892455203,10.1145/1518701.1518956,,,Ephemeral adaptation: The use of gradual onset to improve menu selection performance,cp,Conference Paper,Findlater L.,60010365,The University of British Columbia,Vancouver,Canada,4,"Findlater, Leah;Moffatt, Karyn;McGrenere, Joanna;Dawson, Jessica",10040303000;8358913100;6505966811;7403192032,60010365;60010365;60010365;60010365,2009-12-01,2009,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1655-1664,"We introduce ephemeral adaptation, a new adaptive GUI technique that improves performance by reducing visual search time while maintaining spatial consistency. Ephemeral adaptive interfaces employ gradual onset to draw the user's attention to predicted items: adaptively predicted items appear abruptly when the menu is opened, but non-predicted items fade in gradually. To demonstrate the benefit of ephemeral adaptation we conducted two experiments with a total of 48 users to show: (1) that ephemeral adaptive menus are faster than static menus when accuracy is high, and are not significantly slower when it is low and (2) that ephemeral adaptive menus are also faster than adaptive highlighting. While we focused on user-adaptive GUIs, ephemeral adaptation should be applicable to a broad range of visually complex tasks. Copyright 2009 ACM.",Abrupt visual onset | Adaptive interfaces | Interaction techniques | Menu design | Personalization | User study,85,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-72249085354,10.1145/1629575.1629577,,,FAWN: A fast array of wimpy nodes,cp,Conference Paper,Andersen D.G.,60033010;60027950,Intel Corporation;Carnegie Mellon University,Santa Clara;Pittsburgh,United States;United States,6,"Andersen, David G.;Franklin, Jason;Kaminsky, Michael;Phanishayee, Amar;Tan, Lawrence;Vasudevan, Vijay",57210522272;17434257600;35233511800;22035979400;35270581200;7005599027,60027950;60027950;60033010;60027950;60027950;60027950,2009-12-24,2009,SOSP'09 - Proceedings of the 22nd ACM SIGOPS Symposium on Operating Systems Principles,,19500157080,,Conference Proceeding,,,,1-14,"This paper presents a new cluster architecture for low-power data-intensive computing. FAWN couples low-power embedded CPUs to small amounts of local flash storage, and balances computation and I/O capabilities to enable efficient, massively parallel access to data. The key contributions of this paper are the principles of the FAWN architecture and the design and implementation of FAWN-KV - a consistent, replicated, highly available, and high-performance key-value storage system built on a FAWN prototype. Our design centers around purely log-structured datastores that provide the basis for high performance on flash storage, as well as for replication and consistency obtained using chain replication on a consistent hashing ring. Our evaluation demonstrates that FAWN clusters can handle roughly 350 key-value queries per Joule of energy - two orders of magnitude more than a disk-based system. Copyright 2009 ACM.",Cluster computing | Design | Energy efficiency | Flash | Measurement | Performance,406,0,,,,undefined,,SOSP Operating Systems
2-s2.0-84892468747,10.1145/1518701.1518812,,,From interaction to trajectories: Designing coherent journeys through user experiences,cp,Conference Paper,Benford S.,60026479;60015138,University of Exeter;University of Nottingham,Exeter;Nottingham,United Kingdom;United Kingdom,4,"Benford, Steve;Giannachi, Gabriella;Koleva, Boriana;Rodden, Tom",7006887786;23396898600;6602266660;7003488009,60015138;60026479;60015138;60015138,2009-12-01,2009,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,709-718,"The idea of interactional trajectories through interfaces has emerged as a sensitizing concept from recent studies of tangible interfaces and interaction in museums and galleries. We put this concept to work as a lens to reflect on published studies of complex user experiences that extend over space and time and involve multiple roles and interfaces. We develop a conceptual framework in which trajectories explain these user experiences as journeys through hybrid structures, punctuated by transitions, and in which interactivity and collaboration are orchestrated. Our framework is intended to sensitize future studies, help distill craft knowledge into design guidelines and patterns, identify technology requirements, and provide a boundary object to connect HCI with Performance Studies. Copyright 2009 ACM.",Collaboration | Cultural applications | Games | Museums | Performance | Role | Space | Time | Trajectory | User experience,206,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-70849135404,10.1145/1559845.1559873,,,Generating example data for dataflow programs,cp,Conference Paper,Olston C.,60075274,Yahoo Research Labs,Sunnyvale,United States,3,"Olston, Christopher;Chopra, Shubham;Srivastava, Utkarsh",6602571027;57614985800;7006148115,60075274;60075274;60075274,2009-12-04,2009,SIGMOD-PODS'09 - Proceedings of the International Conference on Management of Data and 28th Symposium on Principles of Database Systems,,19400158818,,Conference Proceeding,,,,245-256,"While developing data-centric programs, users often run (portions of) their programs over real data, to see how they behave and what the output looks like. Doing so makes it easier to formulate, understand and compose programs cor- rectly, compared with examination of program logic alone. For large input data sets, these experimental runs can be time-consuming and inefficient. Unfortunately, sampling the input data does not always work well, because selective op- erations such as ffilter and join can lead to empty results over sampled inputs, and unless certain indexes are present there is no way to generate biased samples efficiently. Con- sequently new methods are needed for generating example input data for data-centric programs. We focus on an important category of data-centric pro- grams, dataow programs, which are best illustrated by displaying the series of intermediate data tables that oc- cur between each pair of operations. We introduce andstudy the problem of generating example intermediate data for dataow programs, in a manner that illustrates the se- mantics of the operators while keeping the example data small. We identify two major obstacles that impede naïve approaches, namely (1) highly selective operators and (2) noninvertible operators, and offier techniques for dealing with these obstacles. Our techniques perform well on real dataow programs used at Yahoo! for web analytics. © 2009 ACM.",,49,0,,,,undefined,,SIGMOD Databases
2-s2.0-77949373144,10.1145/1595696.1595767,,,Graph-based mining of multiple object usage patterns,cp,Conference Paper,Nguyen T.T.,60145770,College of Engineering,Ames,United States,5,"Nguyen, Tung Thanh;Nguyen, Hoan Anh;Pham, Nam H.;Al-Kofahi, Jafar M.;Nguyen, Tien N.",57212284041;55459278800;58336591500;25647258800;55386311200,60145770;60145770;60145770;60145770;60145770,2009-12-01,2009,ESEC-FSE'09 - Proceedings of the Joint 12th European Software Engineering Conference and 17th ACM SIGSOFT Symposium on the Foundations of Software Engineering,,19700167008,,Conference Proceeding,,,,383-392,"The interplay of multiple objects in object-oriented programming often follows specific protocols, for example certain orders of method calls and/or control structure constraints among them that are parts of the intended object usages. Unfortunately, the information is not always documented. That creates long learning curve, and importantly, leads to subtle problems due to the misuse of objects. In this paper, we propose GrouMiner, a novel graph-based approach for mining the usage patterns of one or multiple objects. GrouMiner approach includes a graph-based representation for multiple object usages, a pattern mining algorithm, and an anomaly detection technique that are efficient, accurate, and resilient to software changes. Our experiments on several real-world programs show that our prototype is able to find useful usage patterns with multiple objects and control structures, and to translate them into user-friendly code skeletons to assist developers in programming. It could also detect the usage anomalies that caused yet undiscovered defects and code smells in those programs. Copyright 2009 ACM.",Anomaly | API usage | Clone | Graph mining | Groum | Object usage | Pattern,232,0,,,,undefined,,FSE Software Engineering
2-s2.0-77949904635,10.1109/ICSE.2009.5070529,,,"How we refactor, and how we know it",cp,Conference Paper,Murphy-Hill E.,60023908;60019647,Portland State University;Georgia Institute of Technology,Portland;Atlanta,United States;United States,3,"Murphy-Hill, Emerson;Parnin, Chris;Black, Andrew P.",16307910100;15136883200;7201755270,60023908;60019647;60023908,2009-12-01,2009,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,5070529,287-297,"Much of what we know about how programmers refactor in the wild is based on studies that examine just a few software projects. Researchers have rarely taken the time to replicate these studies in other contexts or to examine the assumptions on which they are based. To help put refactoring research on a sound scientific basis, we draw conclusions using four data sets spanning more than 13 000 developers, 240 000 tool-assisted refactorings, 2500 developer hours, and 3400 version control commits. Using these data, we cast doubt on several previously stated assumptions about how programmers refactor, while validating others. For example, we find that programmers frequently do not indicate refactoring activity in commit logs, which contradicts assumptions made by several previous researchers. In contrast, we were able to confirm the assumption that programmers do frequently intersperse refactoring with other program changes. By confirming assumptions and replicating studies made by other researchers, we can have greater confidence that those researchers' conclusions are generalizable. © 2009 IEEE.",,172,0,,,,undefined,,ICSE Software Engineering
2-s2.0-76649117661,10.1145/1526709.1526740,,,Hybrid keyword search auctions,cp,Conference Paper,Goel A.,60141508;60140145,Stanford Engineering;Department of Computer Science,Stanford;Durham,United States;United States,2,"Goel, Ashish;Munagala, Kamesh",7201830133;9736468700,60141508;60140145,2009-12-01,2009,WWW'09 - Proceedings of the 18th International World Wide Web Conference,,21100212110,,Conference Proceeding,,,,221-230,"Search auctions have become a dominant source of revenue generation on the Internet. Such auctions have typically used per-click bidding and pricing. We propose the use of hybrid auctions where an advertiser can make a per-impression as well as a per-click bid, and the auctioneer then chooses one of the two as the pricing mechanism. We assume that the advertiser and the auctioneer both have separate beliefs (called priors) on the click-probability of an advertisement. We first prove that the hybrid auction is truthful, assuming that the advertisers are risk-neutral. We then show that this auction is superior to the existing per-click auction in multiple ways: 1. We show that risk-seeking advertisers will choose only a per-impression bid whereas risk-averse advertisers will choose only a per-click bid, and argue that both kind of advertisers arise naturally. Hence, the ability to bid in a hybrid fashion is important to account for the risk characteristics of the advertisers. 2. For obscure keywords, the auctioneer is unlikely to have a very sharp prior on the click-probabilities. In such situations, we show that having the extra information from the advertisers in the form of a per-impression bid can result in significantly higher revenue. 3. An advertiser who believes that its click-probability is much higher than the auctioneer's estimate can use per-impression bids to correct the auctioneer's prior without incurring any extra cost. 4. The hybrid auction can allow the advertiser and auctioneer to implement complex dynamic programming strategies to deal with the uncertainty in the click-probability using the same basic auction. The per-click and per-impression bidding schemes can only be used to implement two extreme cases of these strategies. As Internet commerce matures, we need more sophisticated pricing models to exploit all the information held by each of the participants. We believe that hybrid auctions could be an important step in this direction. The hybrid auction easily extends to multiple slots, and is also applicable to scenarios where the hybrid bidding is per-impression and per-action (i.e. CPM and CPA), or per-click and per-action (i.e. CPC and CPA). Copyright is held by the International World Wide Web Conference Committee (IW3C2).",Internet | Keyword auctions | Mechanism design,31,0,repository,Green,CISE,0428868,Directorate for Computer and Information Science and Engineering,WWW World Wide Web
2-s2.0-77249160785,10.1109/ICSE.2009.5070522,,,Invariant-based automatic testing of Ajax user interfaces,cp,Conference Paper,Mesbah A.,60006288,Delft University of Technology,Delft,Netherlands,2,"Mesbah, Ali;Van Deursen, Arie",17345931800;7003969355,60006288;60006288,2009-12-01,2009,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,5070522,210-220,"AJAX-based Web 2.0 applications rely on stateful asynchronous client/server communication, and client-side runtime manipulation of the DOM tree. This not only makes them fundamentally different from traditional web applications, but also more error-prone and harder to test. We propose a method for testing AJAX applications automatically, based on a crawler to infer a flow graph for all (client-side) user interface states. We identify AJAX-specific faults that can occur in such states (related to DOM validity, error messages, discoverability, back-button compatibility, etc.) as well as DOM-tree invariants that can serve as oracle to detect such faults. We implemented our approach in ATUSA, a tool offering generic invariant checking components, a plugin-mechanism to add application-specific state validators, and generation of a test suite covering the paths obtained during crawling. We describe two case studies evaluating the fault revealing capabilities, scalability, required manual effort and level of automation of our approach. © 2009 IEEE.",,154,0,,,,undefined,,ICSE Software Engineering
2-s2.0-79959858882,,,,K-Best A<sup>∗</sup> Parsing,cp,Conference Paper,Pauls A.,60025038,"University of California, Berkeley",Berkeley,United States,2,"Pauls, Adam;Klein, Dan",6603665294;23009040500,60025038;60025038,2009-01-01,2009,"ACL-IJCNLP 2009 - Joint Conf. of the 47th Annual Meeting of the Association for Computational Linguistics and 4th Int. Joint Conf. on Natural Language Processing of the AFNLP, Proceedings of the Conf.",,21101201974,,Conference Proceeding,,,,958-966,"A∗ parsing makes 1-best search efficient by suppressing unlikely 1-best items. Existing kbest extraction methods can efficiently search for top derivations, but only after an exhaustive 1-best pass. We present a unified algorithm for k-best A∗ parsing which preserves the efficiency of k-best extraction while giving the speed-ups of A∗ methods. Our algorithm produces optimal k-best parses under the same conditions required for optimality in a 1-best A∗ parser. Empirically, optimal k-best lists can be extracted significantly faster than with other approaches, over a range of grammar types.",,27,0,,,,undefined,,ACL Natural Language Processing
2-s2.0-77249105045,,,,Learning conditional preference networks with queries,cp,Conference Paper,Koriche F.,60032215;60007853,"Université de Caen Normandie;Laboratoire d'Informatique, de Robotique et de Microélectronique de Montpellie",Caen;Montpellier,France;France,2,"Koriche, Frédéric;Zanuttini, Bruno",6602634765;6508199736,60007853;60032215,2009-01-01,2009,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,1930-1935,"We investigate the problem of eliciting CP-nets in the well-known model of exact learning with equivalence and membership queries. The goal is to identify a preference ordering with a binary-valued CP-net by guiding the user through a sequence of queries. Each example is a dominance test on some pair of outcomes. In this setting, we show that acyclic CP-nets are not learnable with equivalence queries alone, while they are learnable with the help of membership queries if the supplied examples are restricted to swaps. A similar property holds for tree CP-nets with arbitrary examples. In fact, membership queries allow us to provide attribute-efficient algorithms for which the query complexity is only logarithmic in the number of attributes. Such results highlight the utility of this model for eliciting CP-nets in large multi-attribute domains.",,23,0,,,,undefined,,IJCAI Artificial Intelligence
2-s2.0-70450191342,10.1145/1622176.1622184,,,Mouse 2.0: Multi-touch meets the mouse,cp,Conference Paper,Villar N.,60098463;60026532;60021726,Microsoft Research Cambridge;Microsoft Corporation;Microsoft Research,Cambridge;Redmond;Redmond,United Kingdom;United States;United States,11,"Villar, Nicolas;Izadi, Shahram;Rosenfeld, Dan;Benko, Hrvoje;Helmes, John;Westhues, Jonathan;Hodges, Steve;Ofek, Eyal;Butler, Alex;Cao, Xiang;Chen, Billy",8419646300;16426108500;36343975900;9737287100;34879971800;18435544200;15044574300;10139546600;15043778600;35110847500;10139988100,60098463;60098463;60026532;60021726;60098463;60026532;60098463;60026532;60098463;60098463;60026532,2009-11-27,2009,UIST 2009 - Proceedings of the 22nd Annual ACM Symposium on User Interface Software and Technology,,19400158615,,Conference Proceeding,,,,33-42,"In this paper we present novel input devices that combine the standard capabilities of a computer mouse with multitouch sensing. Our goal is to enrich traditional pointerbased desktop interactions with touch and gestures. To chart the design space, we present five different multitouch mouse implementations. Each explores a different touch sensing strategy, which leads to differing formfactors and hence interactive possibilities. In addition to the detailed description of hardware and software implementations of our prototypes, we discuss the relative strengths, limitations and affordances of these novel input devices as informed by the results of a preliminary user study. Copyright 2009 ACM.",Desktop computing | Input device | Mouse | Multi-touch | Novel hardware | Surface computing,67,0,,,,undefined,,UIST User Interface
2-s2.0-84892452942,10.1145/1518701.1518827,,,Musink: Composing music through augmented drawing,cp,Conference Paper,Tsandilas T.,60105988,INRIA Saclay,Palaiseau,France,3,"Tsandilas, Theophanis;Letondal, Catherine;Mackay, Wendy E.",6507282888;9132416200;7102699682,60105988;60105988;60105988,2009-12-01,2009,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,819-828,"We focus on the creative use of paper in the music composition process, particularly the interaction between paper and end-user programming. When expressing musical ideas, composers draw in a precise way, not just sketch. Working in close collaboration with composers, we designed Musink to provide them with a smooth transition between paper drawings and OpenMusic, a flexible music composition tool. MuswA's built-in recognizers handle common needs, such as scoping and annotation. Users can also define new gestures and associate them with their own or pre-defined software functions. Mus ink supports semi* structured, delayed interpretation and serves as a customizable gesture browser, giving composers significant freedom to create their own, individualized composition languages and to experiment with music, on-paper and on-line. Copyright 2009 ACM.",Creativity | End-user programming | Gesture interfaces | Interactive paper | Musical interfaces | Participatory design,51,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-69149106605,10.1109/SP.2009.25,,,"Native client: A sandbox for portable, untrusted x86 native code",cp,Conference Paper,Yee B.,60006191,Google LLC,Mountain View,United States,9,"Yee, Bennet;Sehr, David;Dardyk, Gregory;Chen, J. Bradley;Muth, Robert;Ormandy, Tavis;Okasaka, Shiki;Narula, Neha;Fullagar, Nicholas",35197467600;56153843800;6504323533;57196107236;7007134356;35174865000;8693951500;57210703953;35174746100,60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191,2009-11-23,2009,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,,,5207638,79-93,"This paper describes the design, implementation and evaluation of Native Client, a sandbox for untrusted x86 native code. Native Client aims to give browser-based applications the computational performance of native applications without compromising safety. Native Client uses software fault isolation and a secure runtime to direct system interaction and side effects through interfaces managed by Native Client. Native Client provides operating system portability for binary code while supporting performance-oriented features generally absent from web application programming environments, such as thread support, instruction set extensions such as SSE, and use of compiler intrinsics and hand-coded assembler. We combine these properties in an open architecture that encourages community review and 3rd-party tools. © 2009 IEEE.",,396,0,repositoryam,Green,,undefined,,S&P Security and Privacy
2-s2.0-70349141346,10.1137/1.9781611973068.47,,,Natural algorithms,cp,Conference Paper,Chazelle B.,60141284,School of Engineering and Applied Science,Princeton,United States,1,"Chazelle, Bernard",7005144537,60141284,2009-01-01,2009,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,,,,422-431,"We provide further evidence that the study of complex self-organizing systems can benefit from an algorithmic perspective. The subject has been traditionally viewed through the lens of physics and control theory. Using tools typically associated with theoretical computer science, we settle an old question in theoretical ecology: bounding the convergence of bird flocks. We bound the time to reach steady state by a tower-of-twos of height linear in the number of birds. We prove that, surprisingly, the tower-of-twos growth is intrinsic to the model. This unexpected result demonstrates the merits of approaching biological dynamical systems as ""natural algorithms"" and applying algorithmic techniques to them. Copyright © by SIAM.",,52,0,,,,undefined,,SODA Theory
2-s2.0-74549206193,10.1145/1645953.1646009,,,On the feasibility of multi-site web search engines,cp,Conference Paper,Baeza-Yates R.,60085104,Yahoo Research Barcelona,Barcelona,Spain,5,"Baeza-Yates, Ricardo;Gionis, Aristides;Junqueira, Flavio;Plachouras, Vassilis;Telloli, Luca",7004433908;6602531754;6506934684;55909109200;35318839900,60085104;60085104;60085104;60085104;60085104,2009-12-01,2009,"International Conference on Information and Knowledge Management, Proceedings",,55826,,Conference Proceeding,,,,425-434,"Web search engines are often implemented as centralized systems. Designing and implementing a Web search engine in a distributed environment is a challenging engineering task that encompasses many interesting research questions. However, distributing a search engine across multiple sites has several advantages, such as utilizing less compute resources and exploiting data locality. In this paper we investigate the cost-effectiveness of building a distributed Web search engine. We propose a model for assessing the total cost of a distributed Web search engine that includes the computational costs and the communication cost among all distributed sites. We then present a query-processing algorithm that maximizes the amount of queries answered locally, without sacrificing the quality of the results compared to a centralized search engine. We simulate the algorithm on real document collections and query workloads to measure the actual parameters needed for our cost model, and we show that a distributed search engine can be competitive compared to a centralized architecture with respect to real cost. Copyright 2009 ACM.",Cost model | Distributed systems | Query processing | Web search,29,0,,,,undefined,,CIKM Knowledge Management
2-s2.0-84892455410,10.1145/1518701.1518736,,,Predicting tie strength with social media,cp,Conference Paper,Gilbert E.,60000745,University of Illinois Urbana-Champaign,Urbana,United States,2,"Gilbert, Eric;Karahalios, Karrie",15519161300;23397392600,60000745;60000745,2009-12-01,2009,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,211-220,"Social media treats all users the same: trusted friend or total stranger, with little or nothing in between. In reality, relationships fall everywhere along this spectrum, a topic social science has investigated for decades under the theme of tie strength. Our work bridges this gap between theory and practice. In this paper, we present a predictive model that maps social media data to tie strength. The model builds on a dataset of over 2,000 social media ties and performs quite well, distinguishing between strong and weak ties with over 85% accuracy. We complement these quantitative findings with interviews that unpack the relationships we could not predict. The paper concludes by illustrating how modeling tie strength can improve social media design elements, including privacy controls, message routing, friend introductions and information prioritization. Copyright 2009 ACM.",Relationship modeling | Sns | Social media | Social networks | Tie strength | Ties,1002,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-70350642078,10.1145/1536414.1536461,,,Public-key cryptosystems from the worst-case shortest vector problem,cp,Conference Paper,Peikert C.,60000461,SRI International,Menlo Park,United States,1,"Peikert, Chris",6507397868,60000461,2009-11-09,2009,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,333-342,"We construct public-key cryptosystems that are secure assuming the worst-case hardness of approximating the minimum distance on n-dimensional lattices to within small poly(n) factors. Prior cryptosystems with worst-case connections were based either on the shortest vector problem for a special class of lattices (Ajtai and Dwork, STOC 1997; Regev, J. ACM 2004), or on the conjectured hardness of lattice problems for quantum algorithms (Regev, STOC 2005). Our main technical innovation is a reduction from variants of the shortest vector problem to corresponding versions of the ""learning with errors"" (LWE) problem; previously, only a quantum reduction of this kind was known. As an additional contribution, we construct a natural chosen ciphertext-secure cryptosystem having a much simpler description and tighter underlying worst-case approximation factor than prior schemes. Copyright 2009 ACM.",Cryptography | Lattices,617,0,repositoryam,Green,,undefined,,STOC Theory
2-s2.0-70349678652,10.1109/INFCOM.2009.5061908,,,Queuing network models for multi-channel P2P live streaming systems,cp,Conference Paper,Wu D.,60108318,NYU Tandon School of Engineering,New York,United States,3,"Wu, Di;Liu, Yong;Ross, Keith W.",57215064114;55387885100;7202122991,60108318;60108318;60108318,2009-10-12,2009,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,,,5061908,73-81,"In recent years there have been several large-scale deployments of P2P live video systems. Existing and future P2P live video systems will offer a large number of channels, with users switching frequently among the channels. In this paper, we develop infinite-server queueing network models to analytically study the performance of multi-channel P2P streaming systems. Our models capture essential aspects of multi-channel video systems, including peer channel switching, peer churn, peer bandwidth heterogeneity, and Zipf-like channel popularity. We apply the queueing network models to two P2P streaming designs: the isolated channel design (ISO) and the View-Upload Decoupling (VUD) design. For both of these designs, we develop efficient algorithms to calculate critical performance measures, develop an asymptotic theory to provide closed-form results when the number of peers approaches infinity, and derive near-optimal provisioning rules for assigning peers to groups in VUD. We use the analytical results to compare VUD with ISO. We show that VUD design generally performs significantly better, particularly for systems with heterogeneous channel popularities and streaming rates.© 2009 IEEE.",,116,0,repositoryam,Green,,undefined,,INFOCOM Networking
2-s2.0-80051494649,10.3115/1687878.1687892,,,Reinforcement learning for mapping instructions to actions,cp,Conference Paper,Branavan S.R.K.,60006320,MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge,United States,4,"Branavan, S. R.K.;Chen, Harr;Zettlemoyer, Luke S.;Barzilay, Regina",35279066800;15044115200;57204370628;23007765100,60006320;60006320;60006320;60006320,2009-01-01,2009,"ACL-IJCNLP 2009 - Joint Conf. of the 47th Annual Meeting of the Association for Computational Linguistics and 4th Int. Joint Conf. on Natural Language Processing of the AFNLP, Proceedings of the Conf.",,21100201002,,Conference Proceeding,,,,82-90,"In this paper, we present a reinforcement learning approach for mapping natural language instructions to sequences of executable actions. We assume access to a reward function that defines the quality of the executed actions. During training, the learner repeatedly constructs action sequences for a set of documents, executes those actions, and observes the resulting reward. We use a policy gradient algorithm to estimate the parameters of a log-linear model for action selection. We apply our method to interpret instructions in two domains-Windows troubleshooting guides and game tutorials. Our results demonstrate that this method can rival supervised learning techniques while requiring few or no annotated training examples. © 2009 ACL and AFNLP.",,191,1,repositoryam,Green,,undefined,,ACL Natural Language Processing
2-s2.0-72249104877,10.1145/1629575.1629578,,,RouteBricks: Exploiting parallelism to scale software routers,cp,Conference Paper,Dobrescu M.,60074754;60028186;60023643,Intel Research Laboratories;École Polytechnique Fédérale de Lausanne;Lancaster University,Santa Clara;Lausanne;Lancaster,United States;Switzerland;United Kingdom,9,"Dobrescu, Mihai;Egi, Norbert;Argyraki, Katerina;Chun, Byung Gon;Fall, Kevin;Iannaccone, Gianluca;Knies, Allan;Manesh, Maziar;Ratnasamy, Sylvia",35268288600;14037286000;6507197229;7102410988;6602092222;7006384375;57190414468;35269325800;6602335905,60028186;60023643;60028186;60074754;60074754;60074754;60074754;60074754;60074754,2009-12-24,2009,SOSP'09 - Proceedings of the 22nd ACM SIGOPS Symposium on Operating Systems Principles,,19500157080,,Conference Proceeding,,,,15-28,"We revisit the problem of scaling software routers, motivated by recent advances in server technology that enable high-speed parallel processing - a feature router workloads appear ideally suited to exploit. We propose a software router architecture that parallelizes router functionality both across multiple servers and across multiple cores within a single server. By carefully exploiting parallelism at every opportunity, we demonstrate a 35Gbps parallel router prototype; this router capacity can be linearly scaled through the use of additional servers. Our prototype router is fully programmable using the familiar Click/Linux environment and is built entirely from off-the-shelf, general-purpose server hardware. Copyright 2009 ACM.",Multicore | Parallelism | Programmability | Software router,367,0,repositoryam,Green,,undefined,,SOSP Operating Systems
2-s2.0-70450191456,10.1109/CVPRW.2009.5206515,,,Single image haze removal using dark channel prior,cp,Conference Paper,He K.,60102083;60098464;60002798,Shenzhen Institute of Advanced Technology;Microsoft Research Asia;Chinese University of Hong Kong,Shenzhen;Beijing;Hong Kong,China;China;Hong Kong,3,"He, Kaiming;Sun, Jian;TTang, Xiaoou",57209052101;56333360900;36715601000,60002798;60098464;60002798-60102083,2009-01-01,2009,"2009 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2009",,21101062311,,Conference Proceeding,,,5206515,1956-1963,"In this paper, we propose a simple but effective image prior - dark channel prior to remove haze from a single input image. The dark channel prior is a kind of statistics of the haze-free outdoor images. It is based on a key observation - most local patches in haze-free outdoor images contain some pixels which have very low intensities in at least one color channel. Using this prior with the haze imaging model, we can directly estimate the thickness of the haze and recover a high quality haze-free image. Results on a variety of outdoor haze images demonstrate the power of the proposed prior. Moreover, a high quality depth map can also be obtained as a by-product of haze removal. © 2009 IEEE.",,1436,0,,,,undefined,,CVPR Computer Vision
2-s2.0-70350681059,10.1145/1559795.1559804,,,Size and treewidth bounds for conjunctive queries,cp,Conference Paper,Gottlob G.,60112639;60026851;60025038,"Oxford-Man Institute of Quantitative Finance;University of Oxford;University of California, Berkeley",Oxford;Oxford;Berkeley,United Kingdom;United Kingdom;United States,3,"Gottlob, Georg;Lee, Stephanie Tien;Valianty, Gregory J.",7005068491;26650561900;15052632800,60112639;60026851;60025038,2009-01-01,2009,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,45-54,"This paper provides new worst-case bounds for the size and treewith of the result Q(D) of a conjunctive query Q to a database D. We derive bounds for the result size jQ(D)j in terms of structural properties of Q, both in the absence and in the presence of keys and functional dependencies. These bounds are based on a novel ""coloring"" of the query variables that associates a coloring number C(Q) to each query Q. Using this coloring number, we derive tight bounds for the size of Q(D) in case (i) no functional dependencies or keys are specified, and (ii) simple (one-attribute) keys are given. These results generalize recent size-bounds for join queries obtained by Atserias, Grohe, and Marx (FOCS 2008). An extension of our coloring technique also gives a lower bound for jQ(D)j in the general setting of a query with arbitrary functional dependencies. Our new coloring scheme also al-lows us to precisely characterize (both in the absence of keys and with simple keys) the treewidth-preserving queries the queries for which the output treewidth is bounded by a function of the input treewidth. Finally we characterize the queries that preserve the sparsity of the input in the general setting with arbitrary functional dependencies. Copyright 2009 ACM.",Conjunctive queries | Database theory | Size bounds | Treewidth,10,0,,,,undefined,,PODS Databases
2-s2.0-84892463502,10.1145/1518701.1518897,,,Sizing the horizon: The effects of chart size and layering on the graphical perception of time series visualizations,cp,Conference Paper,Heer J.,60141508;60025038,"Stanford Engineering;University of California, Berkeley",Stanford;Berkeley,United States;United States,3,"Heer, Jeffrey;Kong, Nicholas;Agrawala, Maneesh",6603794736;35179559500;57204250599,60141508;60025038;60025038,2009-12-01,2009,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1303-1312,"We investigate techniques for visualizing time series data and evaluate their effect in value comparison tasks. We compare line charts with horizon graphs-a space-efficient time series visualization technique-across a range of chart sizes, measuring the speed and accuracy of subjects' estimates of value differences between charts. We identify transition points at which reducing the chart height results in significantly differing drops in estimation accuracy across the compared chart types, and we find optimal positions in the speed-accuracy tradeoff curve at which viewers performed quickly without attendant drops in accuracy. Based on these results, we propose approaches for increasing data density that optimize graphical perception. Copyright 2009 ACM.",Graphical perception | Horizon graphs | Line charts | Time series | Visualization,224,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84872278868,10.1145/1518701.1518920,,,Social immersive media: Pursuing best practices for multi-user interactive camera/projector exhibits,cp,Conference Paper,Snibbe S.S.,60023290;60002243;114143271,Nokia USA;MIT Media Lab;Sona Research,Murray;Cambridge;San Francisco,United States;United States;United States,2,"Snibbe, Scott S.;Raffle, Hayes S.",6506002278;6505841163,114143271;60023290-60002243,2009-12-01,2009,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1447-1456,"Based on ten years' experience developing interactive camera/projector systems for public science and culture exhibits, we define a distinct form of augmented reality focused on social interaction: social immersive media. Our work abandons GUI metaphors and builds on the language of cinema, casting users as actors within simulated narrative models. We articulate philosophical goals, design principles, and interaction techniques that create strong emotional responses and social engagement through visceral interaction. We describe approaches to clearly communicate cultural and scientific ideas through the medium. And we demonstrate how practitioners can design interactions that promote specific social behaviors in users. Copyright 2009 ACM.",Animation | Augmented reality | Camera-based interaction | Cinema | Computer vision | Embodied interaction | Learning | Social computing,97,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85076891121,,,,SORA: High performance software radio using general purpose multi-core processors,cp,Conference Paper,Tan K.,60098464;60030612;60025278;60022381,"Microsoft Research Asia;University of California, San Diego;Tsinghua University;Beijing Jiaotong University",Beijing;La Jolla;Beijing;Beijing,China;United States;China;China,10,"Tan, Kun;Zhang, Jiansong;Fang, Ji;Liu, He;Ye, Yusheng;Wang, Shen;Zhang, Yongguang;Wu, Haitao;Wang, Wei;Voelker, Geoffrey M.",35249847600;24777623100;35182967700;49961721400;57215305534;57852758000;7601319429;7405581009;57215334436;7003306507,60098464;60098464;60022381;60025278;60025278;60025278;60098464;60098464;60098464;60030612,2009-01-01,2009,"Proceedings of the 6th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2009",,21101017665,,Conference Proceeding,,,,75-90,"This paper presents Sora, a fully programmable software radio platform on commodity PC architectures. Sora combines the performance and fidelity of hardware SDR platforms with the programmability and flexibility of general-purpose processor (GPP) SDR platforms. Sora uses both hardware and software techniques to address the challenges of using PC architectures for high-speed SDR. The Sora hardware components consist of a radio front-end for reception and transmission, and a radio control board for high-throughput, low-latency data transfer between radio and host memories. Sora makes extensive use of features of contemporary processor architectures to accelerate wireless protocol processing and satisfy protocol timing requirements, including using dedicated CPU cores, large low-latency caches to store lookup tables, and SIMD processor extensions for highly efficient physical layer processing on GPPs. Using the Sora platform, we have developed a demonstration radio system called SoftWiFi. SoftWiFi seamlessly interoperates with commercial 802.11a/b/g NICs, and achieves equivalent performance as commercial NICs at each modulation.",,164,0,,,MSRA,undefined,Multiple Sclerosis Research Australia,NSDI Networking
2-s2.0-72449139601,10.1145/1571941.1571997,,,Sources of evidence for vertical selection,cp,Conference Paper,Arguello J.,60136640;108131936,School of Computer Science;Yahoo Labs. Montreal,Pittsburgh;Montreal,United States;Canada,4,"Arguello, Jaime;Diaz, Fernando;Callan, Jamie;Crespo, Jean Francois",12345191500;55605195900;35588436200;35229161900,60136640;108131936;60136640;108131936,2009-12-28,2009,"Proceedings - 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2009",,19500157217,,Conference Proceeding,,,,315-322,"Web search providers often include search services for domain-specific subcollections, called verticals, such as news, images, videos, job postings, company summaries, and artist profiles. We address the problem of vertical selection, predicting relevant verticals (if any) for queries issued to the search engine's main web search page. In contrast to prior query classification and resource selection tasks, vertical selection is associated with unique resources that can inform the classification decision. We focus on three sources of evidence: (1) the query string, from which features are derived independent of external resources, (2) logs of queries previously issued directly to the vertical, and (3) corpora representative of vertical content. We focus on 18 different verticals, which differ in terms of semantics, media type, size, and level of query traffic. We compare our method to prior work in federated search and retrieval effectiveness prediction. An in-depth error analysis reveals unique challenges across different verticals and provides insight into vertical selection for future work. Copyright 2009 ACM.",Aggregated search | Distributed information retrieval | Query classification | Resource selection | Vertical selection,134,0,repositoryam,Green,,undefined,,SIGIR Information Retrieval
2-s2.0-71149117790,,,,Structure preserving embedding,cp,Conference Paper,Shaw B.,60031321,The Fu Foundation School of Engineering and Applied Science,New York,United States,2,"Shaw, Blake;Jebara, Tony",34875827900;6602498082,60031321;60031321,2009-12-09,2009,"Proceedings of the 26th International Conference On Machine Learning, ICML 2009",,19400158902,,Conference Proceeding,,,,937-944,"Structure Preserving Embedding (SPE) is an algorithm for embedding graphs in Euclidean space such that the embedding is low-dimensional and preserves the global topological properties of the input graph. Topology is preserved if a connectivity algorithm, such as k-nearest neighbors, can easily recover the edges of the input graph from only the coordinates of the nodes after embedding. SPE is formulated as a semidefinite program that learns a low-rank kernel matrix constrained by a set of linear inequalities which captures the connectivity structure of the input graph. Traditional graph embedding algorithms do not preserve structure according to our definition, and thus the resulting visualizations can be misleading or less informative. SPE provides significant improvements in terms of visualization and lossless compression of graphs, outperforming popular methods such as spectral embedding and Laplacian eigen-maps. We find that many classical graphs and networks can be properly embedded using only a few dimensions. Furthermore, introducing structure preserving constraints into dimensionality reduction algorithms produces more accurate representations of high-dimensional data.",,126,0,,,,undefined,,ICML Machine Learning
2-s2.0-70449627940,10.1145/1555349.1555363,,,The age of gossip: Spatial mean field regime,cp,Conference Paper,Chaintreau A.,60028186;60007716,"École Polytechnique Fédérale de Lausanne;Thomson, SA",Lausanne;Boulogne-Billancourt,Switzerland;France,3,"Chaintreau, Augustin;Le Boudec, Jean Yves;Ristanovic, Nikodin",23007401300;7005325654;35113886100,60007716;60028186;60028186,2009-11-23,2009,SIGMETRICS/Performance'09 - Proceedings of the 11th International Joint Conference on Measurement and Modeling of Computer Systems,,19400158474,,Conference Proceeding,37,1,1555363,109-120,"Disseminating a piece of information, or updates for a piece of information, has been shown to benefit greatly from simple randomized procedures, sometimes referred to as gossiping, or epidemic algorithms. Similarly, in a network where mobile nodes occasionally receive updated content from a base station, gossiping using opportunistic contacts allows for recent updates to be efficiently maintained, for a large number of nodes. In this case, however, gossiping depends on node mobility. For this reason, we introduce a new gossip model, with mobile nodes moving between different classes that can represent locations or states, which determine gossiping behavior of the nodes. Here we prove that, when the number of mobile nodes becomes large, the age of the latest updates received by mobile nodes approaches a deterministic mean-field regime. More precisely, we show that the occupancy measure of the process constructed, with the ages defined above, converges to a deterministic limit that can be entirely characterized by differential equations. This major simplification allows us to characterize how mobility, source inputs and gossiping influence the age distribution for low and high ages. It also leads to a scalable numerical evaluation of the performance of mobile update systems, which we validate (using a trace of 500 taxicabs) and use to propose infrastructure deployment. Copyright 2009 ACM.",Dynamic content | Epidemic | Gossip | Infrastructure deployment | Mean field | Updates,107,0,repositoryvor,Green,,undefined,,SIGMETRICS Performance
2-s2.0-85076877909,,,,TRINC: Small trusted hardware for large distributed systems,cp,Conference Paper,Levin D.,60021726;60020304,"Microsoft Research;University of Maryland, College Park",Redmond;College Park,United States;United States,4,"Levin, Dave;Douceur, John R.;Lorch, Jacob R.;Moscibroda, Thomas",57213243673;6602278425;7003372473;8208672900,60020304;60021726;60021726;60021726,2009-01-01,2009,"Proceedings of the 6th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2009",,21101017665,,Conference Proceeding,,,,1-14,"A simple yet remarkably powerful tool of selfish and malicious participants in a distributed system is “equivocation”: making conflicting statements to others. We present TrInc, a small, trusted component that combats equivocation in large, distributed systems. Consisting fundamentally of only a non-decreasing counter and a key, TrInc provides a new primitive: unique, once-in-a-lifetime attestations. We show that TrInc is practical, versatile, and easily applicable to a wide range of distributed systems. Its deployment is viable because it is simple and because its fundamental components-a trusted counter and a key-are already deployed in many new personal computers today. We demonstrate TrInc's versatility with three detailed case studies: attested append-only memory (A2M), PeerReview, and BitTorrent. We have implemented TrInc and our three case studies using real, currently available trusted hardware. Our evaluation shows that TrInc eliminates most of the trusted storage needed to implement A2M, significantly reduces communication overhead in PeerReview, and solves an open incentives issue in BitTorrent. Microbenchmarks of our TrInc implementation indicate directions for the design of future trusted hardware.",,127,0,,,,undefined,Microsoft,NSDI Networking
2-s2.0-80755144127,10.1145/1518701.1518804,,,Undo and erase events as indicators of usability problems,cp,Conference Paper,Akers D.,60141508;60006191,Stanford Engineering;Google LLC,Stanford;Mountain View,United States;United States,4,"Akers, David;Simpson, Matthew;Jeffries, Robin;Winograd, Terry",7006746140;57203048040;35862725700;7003633896,60141508-60006191;60006191;60006191;60141508,2009-12-01,2009,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,659-668,"One approach to reducing the costs of usability testing is to facilitate the automatic detection of critical incidents: serious breakdowns in interaction that stand out during software use. This research evaluates the use of undo and erase events as indicators of critical incidents in Google SketchUp (a 3D-modeling application), measuring an indicator's usefulness by the numbers and types of usability problems discovered. We compared problems identified using undo and erase events to problems identified using the user-reported critical incident technique [Hartson and Castillo 1998]. In a within-subjects experiment with 35 participants, undo and erase episodes together revealed over 90% of the problems rated as severe, several of which would not have been discovered by self-report alone. Moreover, problems found by all three methods were rated as significantly more severe than those identified by only a subset of methods. These results suggest that undo and erase events will serve as useful complements to user- reported critical incidents for low cost usability evaluation of creation-oriented applications like SketchUp. Copyright 2009 ACM.",Critical incidents | Erase | Google sketchup | Undo | Usability testing | User- reported critical incident technique,31,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-70450260682,10.1145/1594977.1592573,,,White space networking with Wi-Fi like connectivity,cp,Conference Paper,Bahl P.,60021726;60009982,Microsoft Research;Harvard University,Redmond;Cambridge,United States;United States,5,"Bahl, Paramvir;Chandra, Ranveer;Moscibroda, Thomas;Murty, Rohan;Welsh, Matt",7003632006;22936982500;8208672900;7003334537;7202401743,60021726;60021726;60021726;60009982;60009982,2009-11-30,2009,Computer Communication Review,01464833,13683,01464833,Conference Proceeding,39,4,,27-38,"Networking over UHF white spaces is fundamentally different from conventional Wi-Fi along three axes: spatial variation, temporal variation, and fragmentation of the UHF spectrum. Each of these differences gives rise to new challenges for implementing a wireless network in this band. We present the design and implementation of WhiteFi, the first Wi-Fi like system constructed on top of UHF white spaces. WhiteFi incorporates a new adaptive spectrum assignment algorithm to handle spectrum variation and fragmentation, and proposes a low overhead protocol to handle temporal variation. WhiteFi builds on a simple technique, called SIFT, that reduces the time to detect transmissions in variable channel width systems by analyzing raw signals in the time domain. We provide an extensive system evaluation in terms of a prototype implementation and detailed experimental and simulation results. Copyright 2009 ACM.",Channel width | Cognitive radios | Dynamic spectrum access | White spaces | Wi-Fi,207,0,,,,undefined,,SIGCOMM Networking
2-s2.0-72249120603,10.1145/1629575.1629596,,,SeL4: Formal verification of an OS kernel,cp,Conference Paper,Klein G.,60103987;60071082;60029470;60008950;106567446,"VMware, Inc;University of Peradeniya;Commonwealth Scientific and Industrial Research Organisation;The Australian National University;Open Kernel Labs",Palo Alto;Peradeniya;Canberra;Canberra;Sydney,United States;Sri Lanka;Australia;Australia;Australia,13,"Klein, Gerwin;Elphinstone, Kevin;Heiser, Gernot;Andronick, June;Cock, David;Derrin, Philip;Elkaduwe, Dhammika;Engelhardt, Kai;Kolanski, Rafal;Norrish, Michael;Sewell, Thomas;Tuch, Harvey;Winwood, Simon",15831824600;6505805480;35547668800;8977358800;15062267800;15062372900;26423662000;13404933400;24467846400;15832391000;36730162300;15833485900;14030680200,60029470;60029470;60029470-106567446;60029470;60029470;60029470-106567446;60029470-60071082;60029470;60029470;60029470-60008950;60029470;60029470-60103987;60029470,2009-12-24,2009,SOSP'09 - Proceedings of the 22nd ACM SIGOPS Symposium on Operating Systems Principles,,19500157080,,Conference Proceeding,,,,207-220,"Complete formal verification is the only known way to guarantee that a system is free of programming errors. We present our experience in performing the formal, machine-checked verification of the seL4 microkernel from an abstract specification down to its C implementation. We assume correctness of compiler, assembly code, and hardware, and we used a unique design approach that fuses formal and operating systems techniques. To our knowledge, this is the first formal proof of functional correctness of a complete, general-purpose operating-system kernel. Functional correctness means here that the implementation always strictly follows our high-level abstract specification of kernel behaviour. This encompasses traditional design and implementation safety properties such as the kernel will never crash, and it will never perform an unsafe operation. It also proves much more: we can predict precisely how the kernel will behave in every possible situation. seL4, a third-generation microkernel of L4 provenance, comprises 8,700 lines of C code and 600 lines of assembler. Its performance is comparable to other high-performance L4 kernels. Copyright 2009 ACM.",Isabelle/HOL | L4 | Microkernel | seL4,1171,0,,,,undefined,,SOSP Operating Systems
2-s2.0-77954706969,10.1145/1806799.1806851,,,A cut-off approach for bounded verification of parameterized systems,cp,Conference Paper,Yang Q.,60025256,Institute of Software Chinese Academy of Sciences,Beijing,China,2,"Yang, Qiusong;Li, Mingshu",14017014300;14037679100,60025256;60025256,2010-07-23,2010,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,1,,,345-354,"The features in multi-threaded programs, such as recursion, dynamic creation and communication, pose a great challenge to formal verification. A widely adopted strategy is to verify tentatively a system with a smaller size, by limiting the depth of recursion or the number of replicated processes, to find errors without ensuring the full correctness. The model checking of parameterized systems, a parametric infinite family of systems, is to decide if a property holds in every size instance. There has been a quest for finding cut-offs for the verification of parameterized systems. The basic idea is to find a cut-off on the number of replicated processes or on the maximum length of paths needed to prove a property, standing a chance of improving verification efficiency substantially if one can come up with small or modest cut-offs. In this paper, a novel approach, called Forward Bounded Reachability Analysis (FBRA), based upon the cut-off on the maximum lengths of paths is proposed for the verification of parameterized systems. Experimental results show that verification efficiency has been significantly improved as a result of the introduction of our new cut-offs. © 2010 ACM.",bounded model checking | cut-off | parameterized system,16,0,,,,undefined,,ICSE Software Engineering
2-s2.0-77954752925,10.1145/1806799.1806856,,,A degree-of-knowledge model to capture source code familiarity,cp,Conference Paper,Fritz T.,60010365,The University of British Columbia,Vancouver,Canada,4,"Fritz, Thomas;Ou, Jingwen;Murphy, Gail C.;Murphy-Hill, Emerson",13408078500;36176343400;7402791460;16307910100,60010365;60010365;60010365;60010365,2010-07-23,2010,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,1,,,385-394,"The size and high rate of change of source code comprising a software system make it difficult for software developers to keep up with who on the team knows about particular parts of the code. Existing approaches to this problem are based solely on authorship of code. In this paper, we present data from two professional software development teams to show that both authorship and interaction information about how a developer interacts with the code are important in characterizing a developer's knowledge of code. We introduce the degree-of-knowledge model that computes automatically a real value for each source code element based on both authorship and interaction information. We show that the degree-of-knowledge model can provide better results than an existing expertise finding approach and also report on case studies of the use of the model to support knowledge transfer and to identify changes of interest. © 2010 ACM.",authorship | degree-of-interest | degree-of-knowledge | expertise | interaction | onboarding | recommendation,96,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-77954755668,10.1145/1806799.1806825,,,A machine learning approach for tracing regulatory codes to product specific requirements,cp,Conference Paper,Cleland-Huang J.,60026860,DePaul University,Chicago,United States,4,"Cleland-Huang, Jane;Czauderna, Adam;Gibiec, Marek;Emenecker, John",6506741859;36175591700;36175855900;36175600300,60026860;60026860;60026860;60026860,2010-07-23,2010,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,1,,,155-164,"Regulatory standards, designed to protect the safety, security, and privacy of the public, govern numerous areas of software intensive systems. Project personnel must therefore demonstrate that an as-built system meets all relevant regulatory codes. Current methods for demonstrating compliance rely either on after-the-fact audits, which can lead to significant refactoring when regulations are not met, or else require analysts to construct and use traceability matrices to demonstrate compliance. Manual tracing can be prohibitively time-consuming; however automated trace retrieval methods are not very effective due to the vocabulary mismatches that often occur between regulatory codes and product level requirements. This paper introduces and evaluates two machine-learning methods, designed to improve the quality of traces generated between regulatory codes and product level requirements. The first approach uses manually created traceability matrices to train a trace classifier, while the second approach uses web-mining techniques to reconstruct the original trace query. The techniques were evaluated against security regulations from the USA government's Health Insurance Privacy and Portability Act (HIPAA) traced against ten healthcare related requirements specifications. Results demonstrated improvements for the subset of HIPAA regulations that exhibited high fan-out behavior across the requirements datasets. © 2010 ACM.",regulatory compliance | requirements classification | traceability,148,0,,,,undefined,,ICSE Software Engineering
2-s2.0-77958569760,,,,A novel transition based encoding scheme for planning as satisfiability,cp,Conference Paper,Huang R.,60105336,McKelvey School of Engineering,St. Louis,United States,3,"Huang, Ruoyun;Chen, Yixin;Zhang, Weixiong",25825128800;57196271259;7409429245,60105336;60105336;60105336,2010-01-01,2010,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,1,,,89-94,"Planning as satisfiability is a principal approach to planning with many eminent advantages. The existing planning as satisfiability techniques usually use encodings compiled from the STRIPS formalism. We introduce a novel SAT encoding scheme based on the SAS+ formalism. It exploits the structural information in the SAS+ formalism, resulting in more compact SAT instances and reducing the number of clauses by up to 50 fold. Our results show that this encoding scheme improves upon the STRlPS-based encoding, in terms of both time and memory efficiency. Copyright © 2010, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,40,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-77954742764,10.1145/1807085.1807094,,,An optimal algorithm for the distinct elements problem,cp,Conference Paper,Kane D.,60009982;60009253;60006320,Harvard University;IBM Research - Almaden;MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge;San Jose;Cambridge,United States;United States;United States,3,"Kane, Daniel M.;Nelson, Jelani;Woodruff, David P.",12802053000;22734928100;35407448600,60009982;60006320;60009253,2010-07-23,2010,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,41-52,"We give the first optimal algorithm for estimating the number of distinct elements in a data stream, closing a long line of theoretical research on this problem begun by Flajolet and Martin in their seminal paper in FOCS 1983. This problem has applications to query optimization, Internet routing, network topology, and data mining. For a stream of indices in {1,...,n}, our algorithm computes a (1 ± ε)-approximation using an optimal O(ε-2 + log(n)) bits of space with 2/3 success probability, where 0<ε<1 is given. This probability can be amplified by independent repetition. Furthermore, our algorithm processes each stream update in O(1) worst-case time, and can report an estimate at any point midstream in O(1) worst-case time, thus settling both the space and time complexities simultaneously. We also give an algorithm to estimate the Hamming norm of a stream, a generalization of the number of distinct elements, which is useful in data cleaning, packet tracing, and database auditing. Our algorithm uses nearly optimal space, and has (1) update and reporting times. © 2010 ACM.",data mining | distinct elements | query optimization | streaming,228,0,repositoryam,Green,,undefined,,PODS Databases
2-s2.0-77954711587,10.1145/1806689.1806769,,,An improved LP-based approximation for steiner tree,cp,Conference Paper,Byrka J.,60028186;60027509,"École Polytechnique Fédérale de Lausanne;Università degli Studi di Roma ""Tor Vergata""",Lausanne;Rome,Switzerland;Italy,4,"Byrka, Jaroslaw;Grandoni, Fabrizio;Rothvoß, Thomas;Sanità, Laura",8987678100;56430748900;23991787100;35111780200,60028186;60027509;60028186;60028186,2010-07-23,2010,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,583-592,"The Steiner tree problem is one of the most fundamental NP-hard problems: given a weighted undirected graph and a subset of terminal nodes, find a minimum-cost tree spanning the terminals. In a sequence of papers, the approximation ratio for this problem was improved from 2 to the current best 1.55 [Robins,Zelikovsky-SIDMA'05]. All these algorithms are purely combinatorial. A long-standing open problem is whether there is an LP-relaxation for Steiner tree with integrality gap smaller than 2 [Vazirani,Rajagopalan- SODA'99]. In this paper we improve the approximation factor for Steiner tree, developing an LP-based approximation algorithm. Our algorithm is based on a, seemingly novel, iterative randomized rounding technique. We consider a directed-component cut relaxation for the k-restricted Steiner tree problem. We sample one of these components with probability proportional to the value of the associated variable in the optimal fractional solution and contract it. We iterate this process for a proper number of times and finally output the sampled components together with a minimum-cost terminal spanning tree in the remaining graph. Our algorithm delivers a solution of cost at most ln(4) times the cost of an optimal k-restricted Steiner tree. This directly implies a ln(4)+ε<1.39 approximation for Steiner tree. As a byproduct of our analysis, we show that the integrality gap of our LP is at most 1.55, hence answering to the mentioned open question. This might have consequences for a number of related problems. Copyright 2010 ACM.",approximation algorithms | linear programming relaxations | network design | randomized algorithms,197,0,repositoryvor,Green,,undefined,,STOC Theory
2-s2.0-77956025820,10.1145/1835449.1835548,,,Assessing the scenic route: Measuring the value of search trails in web logs,cp,Conference Paper,White R.,60021726;60015481,Microsoft Research;University of Washington,Redmond;Seattle,United States;United States,2,"White, Ryen W.;Huang, Jeff",7501422012;55742390500,60021726;60015481,2010-09-01,2010,SIGIR 2010 Proceedings - 33rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,,19700177323,,Conference Proceeding,,,,587-594,"Search trails mined from browser or toolbar logs comprise queries and the post-query pages that users visit. Implicit endorsements from many trails can be useful for search result ranking, where the presence of a page on a trail increases its query relevance. Following a search trail requires user effort, yet little is known about the benefit that users obtain from this activity versus, say, sticking with the clicked search result or jumping directly to the destination page at the end of the trail. In this paper, we present a log-based study estimating the user value of trail following. We compare the relevance, topic coverage, topic diversity, novelty, and utility of full trails over that provided by sub-trails, trail origins (landing pages), and trail destinations (pages where trails end). Our findings demonstrate significant value to users in following trails, especially for certain query types. The findings have implications for the design of search systems, including trail recommendation systems that display trails on search result pages. © 2010 ACM.",Log analysis | Search trails | Trail following,108,0,,,,undefined,,SIGIR Information Retrieval
2-s2.0-77953970245,10.1145/1753326.1753434,,,Avaaj Otalo - A field study of an interactive voice forum for small farmers in rural India,cp,Conference Paper,Patel N.,60141508;60107856;60104850;107138695,Stanford Engineering;IBM India Pvt Ltd;UC Berkeley School of Information;Development Support Center,Stanford;Bengaluru;Berkeley;Ahmedabad,United States;India;United States;India,5,"Patel, Neil;Chittamuru, Deepti;Jain, Anupam;Dave, Paresh;Parikh, Tapan S.",57198804092;36141539700;55470986000;26664476500;8512994700,60141508;60104850;60107856;107138695;60104850,2010-07-01,2010,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2,,,733-742,"In this paper we present the results of a field study of Avaaj Otalo (literally, ""voice stoop""), an interactive voice application for small-scale farmers in Gujarat, India. Through usage data and interviews, we describe how 51 farmers used the system over a seven month pilot deployment. The most popular feature of Avaaj Otalo was a forum for asking questions and browsing others' questions and responses on a range of agricultural topics. The forum developed into a lively social space with the emergence of norms, persistent moderation, and a desire for both structured interaction with institutionally sanctioned authorities and open discussion with peers. For all 51 users this was the first experience participating in an online community of any sort. In terms of usability, simple menu-based navigation was readily learned, with users preferring numeric input over speech. We conclude by discussing implications of our findings for designing voice-based social media serving rural communities in India and elsewhere. © 2010 ACM.",ictd | india | ivr | voice forum | voice user interface,277,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-80053176795,,,,Beyond NomBank: A study of implicit arguments for nominal predicates,cp,Conference Paper,Gerber M.,60146411,College of Engineering,East Lansing,United States,2,"Gerber, Matthew;Chai, Joyce Y.",55100223100;8842227500,60146411;60146411,2010-12-01,2010,"ACL 2010 - 48th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference",,21100201023,,Conference Proceeding,,,,1583-1592,"Despite its substantial coverage, Nom-Bank does not account for all with in sentence arguments and ignores extra sentential arguments altogether. These arguments, which we call implicit, are important to semantic processing, and their recovery could potentially benefit many NLP applications. We present a study of implicit arguments for a select group of frequent nominal predicates. We show that implicit arguments are pervasive for these predicates, adding 65% to the coverage of NomBank. We demonstrate the feasibility of recovering implicit arguments with a supervised classification model. Our results and analyses provide a baseline for future work on this emerging task. © 2010 Association for Computational Linguistics.",,66,0,,,,undefined,,ACL Natural Language Processing
2-s2.0-77954712967,10.1145/1806799.1806809,,,Collaborative reliability prediction of service-oriented systems,cp,Conference Paper,Zheng Z.,60002798,Chinese University of Hong Kong,Hong Kong,Hong Kong,2,"Zheng, Zibin;Lyu, Michael R.",25224189400;7006811415,60002798;60002798,2010-07-23,2010,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,1,,,35-44,"Service-oriented architecture (SOA) is becoming a major software framework for building complex distributed systems. Reliability of the service-oriented systems heavily depends on the remote Web services as well as the unpredictable Internet. Designing effective and accurate reliability prediction approaches for the service-oriented systems has become an important research issue. In this paper, we propose a collaborative reliability prediction approach, which employs the past failure data of other similar users to predict the Web service reliability for the current user, without requiring real-world Web service invocations. We also present a user-collaborative failure data sharing mechanism and a reliability composition model for the service-oriented systems. Large-scale real-world experiments are conducted and the experimental results show that our collaborative reliability prediction approach obtains better reliability prediction accuracy than other approaches. © 2010 ACM.",reliability composition | reliability prediction | user-collaboration | web service,254,0,,,,undefined,,ICSE Software Engineering
2-s2.0-78751492707,10.1109/FOCS.2010.34,,,Computational transition at the uniqueness threshold,cp,Conference Paper,Sly A.,60021726,Microsoft Research,Redmond,United States,1,"Sly, Allan",19338177000,60021726,2010-01-01,2010,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,,,5671190,287-296,"The hardcore model is a model of lattice gas systems which has received much attention in statistical physics, probability theory and theoretical computer science. It is the probability distribution over independent sets I of a graph weighted proportionally to λ|I| with fugacity parameter λ. We prove that at the uniqueness threshold of the hardcore model on the d-regular tree, approximating the partition function becomes computationally hard on graphs of maximum degree d. Specifically, we show that unless NP=RP there is no polynomial time approximation scheme for the partition function (the sum of such weighted independent sets) on graphs of maximum degree d for fugacity λc(d) < λ < λ c(d) + ε(d) where λc = (d - 1) d-1/(d - 2)d is the uniqueness threshold on the d-regular tree and ε(d) > 0 is a positive constant. Weitz [36] produced an FPTAS for approximating the partition function when 0 < λ < λc(d) so this result demonstrates that the computational threshold exactly coincides with the statistical physics phase transition thus confirming the main conjecture of [30]. We further analyze the special case of λ = 1; d = 6 and show there is no polynomial time approximation scheme for approximately counting independent sets on graphs of maximum degree d = 6, which is optimal, improving the previous bound of d = 24. Our proof is based on specially constructed random bipartite graphs which act as gadgets in a reduction to MAX-CUT. Building on the involved second moment method analysis of [30] and combined with an analysis of the reconstruction problem on the tree our proof establishes a strong version of ""replica"" method heuristics developed by theoretical physicists. The result establishes the first rigorous correspondence between the hardness of approximate counting and sampling with statistical physics phase transitions. © 2010 IEEE.",,175,0,repositoryam,Green,MPS,0548249,Directorate for Mathematical and Physical Sciences,FOCS Theory
2-s2.0-77956221585,10.1145/1835804.1835884,,,Connecting the dots between news articles,cp,Conference Paper,Shahaf D.,60027950,Carnegie Mellon University,Pittsburgh,United States,2,"Shahaf, Dafna;Guestrin, Carlos",57204201222;57195906692,60027950;60027950,2010-09-07,2010,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,101510,,Conference Proceeding,,,,623-632,"The process of extracting useful knowledge from large datasets has become one of the most pressing problems in today's society. The problem spans entire sectors, from scientists to intelligence analysts and web users, all of whom are constantly struggling to keep up with the larger and larger amounts of content published every day. With this much data, it is often easy to miss the big picture. In this paper, we investigate methods for automatically connecting the dots - providing a structured, easy way to navigate within a new topic and discover hidden connections. We focus on the news domain: given two news articles, our system automatically finds a coherent chain linking them together. For example, it can recover the chain of events starting with the decline of home prices (January 2007), and ending with the ongoing health-care debate. We formalize the characteristics of a good chain and provide an efficient algorithm (with theoretical guarantees) to connect two fixed endpoints. We incorporate user feedback into our framework, allowing the stories to be refined and personalized. Finally, we evaluate our algorithm over real news data. Our user studies demonstrate the algorithm's effectiveness in helping users understanding the news. © 2010 ACM.",Algorithms | Experimentation,137,0,,,,undefined,,KDD Data Mining
2-s2.0-78751500321,10.1145/1882291.1882312,,,Creating and evolving developer documentation: Understanding the decisions of open source contributors,cp,Conference Paper,Dagenais B.,60002494,Université McGill,Montreal,Canada,2,"Dagenais, Barthélémy;Robillard, Martin P.",19638625000;7006311463,60002494;60002494,2010-12-01,2010,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,85109,,Conference Proceeding,,,,127-136,"Developer documentation helps developers learn frameworks and libraries. To better understand how documentation in open source projects is created and maintained, we performed a qualitative study in which we interviewed core contributors who wrote developer documentation and developers who read documentation. In addition, we studied the evolution of 19 documents by analyzing more than 1500 document revisions. We identified the decisions that contributors make, the factors influencing these decisions and the consequences for the project. Among many findings, we observed how working on the documentation could improve the code quality and how constant interaction with the projects' community positively impacted the documentation. © 2010 ACM.",developer documentation | framework | grounded theory | open source projects | qualitative studies | software documentation,98,0,,,,undefined,,FSE Software Engineering
2-s2.0-78751496215,10.1145/1882291.1882313,,,Developer fluency: Achieving true mastery in software projects,cp,Conference Paper,Zhou M.,60124573;60010012,"Key Lab of High Confidence Software Technologies, Ministry of Education;Avaya LLC",Beijing;Morristown,China;United States,2,"Zhou, Minghui;Mockus, Audris",13305920400;57211066860,60124573;60010012,2010-12-01,2010,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,85109,,Conference Proceeding,,,,137-146,"Outsourcing and offshoring lead to a rapid influx of new developers in software projects. That, in turn, manifests in lower productivity and project delays. To address this common problem we study how the developers become fluent in software projects. We found that developer productivity in terms of number of tasks per month increases with project tenure and plateaus within a few months in three small and medium projects and it takes up to 12 months in a large project. When adjusted for the task difficulty, developer productivity did not plateau but continued to increase over the entire three year measurement interval. We also discovered that tasks vary according to their importance(centrality) to a project. The increase in task centrality along four dimensions: customer, system-wide, team, and future impact was approximately linear over the entire period. By studying developer fluency we contribute by determining dimensions along which developer expertise is acquired, finding ways to measure them, and quantifying the trajectories of developer learning. © 2010 ACM.",developer fluency | developer learning | productivity | task centrality | task difficulty,75,0,,,,undefined,,FSE Software Engineering
2-s2.0-77955994778,10.1109/CVPR.2010.5540139,,,Efficient computation of robust low-rank matrix approximations in the presence of missing data using the L<inf>1</inf> norm,cp,Conference Paper,Eriksson A.,60009512,The University of Adelaide,Adelaide,Australia,2,"Eriksson, Anders;Van Den Hengel, Anton",7202802431;35587677100,60009512;60009512,2010-08-31,2010,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,,,5540139,771-778,"The calculation of a low-rank approximation of a matrix is a fundamental operation in many computer vision applications. The workhorse of this class of problems has long been the Singular Value Decomposition. However, in the presence of missing data and outliers this method is not applicable, and unfortunately, this is often the case in practice. In this paper we present a method for calculating the low-rank factorization of a matrix which minimizes the L1 norm in the presence of missing data. Our approach represents a generalization the Wiberg algorithm of one of the more convincing methods for factorization under the L2 norm. By utilizing the differentiability of linear programs, we can extend the underlying ideas behind this approach to include this class of L1 problems as well. We show that the proposed algorithm can be efficiently implemented using existing optimization software. We also provide preliminary experiments on synthetic as well as real world data with very convincing results. ©2010 IEEE.",,180,0,repositoryam,Green,,undefined,,CVPR Computer Vision
2-s2.0-78149289945,10.1145/1851182.1851186,,,Efficient error estimating coding: Feasibility and applications,cp,Conference Paper,Chen B.,60017161,National University of Singapore,Singapore City,Singapore,4,"Chen, Binbin;Zhou, Ziling;Zhao, Yuda;Yu, Haifeng",56367849500;26322200300;39763320800;39763532500,60017161;60017161;60017161;60017161,2010-11-15,2010,SIGCOMM'10 - Proceedings of the SIGCOMM 2010 Conference,,19700182240,,Conference Proceeding,,,,3-14,"Motivated by recent emerging systems that can leverage partially correct packets in wireless networks, this paper investigates the novel concept of error estimating codes (EEC). Without correcting the errors in the packet, EEC enables the receiver of the packet to estimate the packet's bit error rate, which is perhaps the most important meta-information of a partially correct packet. Our EEC algorithm provides provable estimation quality, with rather low redundancy and computational overhead. To demonstrate the utility of EEC, we exploit and implement EEC in two wireless network applications, Wi-Fi rate adaptation and real-time video streaming. Our real-world experiments show that these applications can significantly benefit from EEC. © 2010 ACM.",bit error rate | error correcting coding | error estimating coding | partial packet | partially correct packet,39,1,publisherfree2read,Bronze,,undefined,,SIGCOMM Networking
2-s2.0-78650158728,10.1145/1866835.1866854,,,Determinating timing channels in compute clouds,cp,Conference Paper,Aviram A.,60014313;60005455,University of Massachusetts Amherst;Yale University,Amherst;New Haven,United States;United States,4,"Aviram, Amittai;Hu, Sen;Ford, Bryan;Gummadi, Ramakrishna",36704344200;55475604800;36791913700;8957454400,60005455;60005455;60005455;60014313,2010-12-20,2010,Proceedings of the ACM Conference on Computer and Communications Security,15437221,110362,,Conference Proceeding,,,,103-108,"Timing side-channels represent an insidious security challenge for cloud computing, because: (a) massive parallelism in the cloud makes timing channels pervasive and hard to control; (b) timing channels enable one customer to steal information from another without leaving a trail or raising alarms; (c) only the cloud provider can feasibly detect and report such attacks, but the provider's incentives are not to; and (d) resource partitioning schemes for timing channel control undermine statistical sharing efficiency, and, with it, the cloud computing business model. We propose a new approach to timing channel control, using provider-enforced deterministic execution instead of resource partitioning to eliminate timing channels within a shared cloud domain. Provider-enforced determinism prevents execution timing from affecting the results of a compute task, however large or parallel, ensuring that a task's outputs leak no timing information apart from explicit timing inputs and total compute duration. Experiments with a prototype OS for deterministic cloud computing suggest that such an approach may be practical and efficient. The OS supports deterministic versions of familiar APIs such as processes, threads, shared memory, and file systems, and runs coarse-grained parallel tasks as efficiently and scalably as current timing channel-ridden systems. © 2010 ACM.",Cloud computing | Deterministic parallelism | Timing channels,105,0,repositoryam,Green,,undefined,,OSDI Operating Systems
2-s2.0-78651268983,10.1145/1871437.1871530,,,FACeTOR: Cost-driven exploration of faceted query results,cp,Conference Paper,Kashyap A.,60153573;60015206,School of Engineering and Applied Sciences;Florida International University,Buffalo;Miami,United States;United States,3,"Kashyap, Abhijith;Hristidis, Vagelis;Petropoulos, Michalis",26666009300;6507537461;6507213803,60153573;60015206;60153573,2010-10-26,26 October 2010,"International Conference on Information and Knowledge Management, Proceedings",,55826,,Conference Proceeding,,,,719-728,"Faceted navigation is being increasingly employed as an effective technique for exploring large query results on structured databases. This technique of mitigating information-overload leverages metadata of the query results to provide users with facet conditions that can be used to progressively refine the user's query and filter the query results. However, the number of facet conditions can be quite large, thereby increasing the burden on the user. We present the FACeTOR system that proposes a cost-based approach to faceted navigation. At each step of the navigation, the user is presented with a subset of all possible facet conditions that are selected such that the overall expected navigation cost is minimized and every result is guaranteed to be reachable by a facet condition. We prove that the problem of selecting the optimal facet conditions at each navigation step is NP-Hard, and subsequently present two intuitive heuristics employed by FACeTOR. Our user study at Amazon Mechanical Turk shows that FACeTOR reduces the user navigation time compared to the cutting edge commercial and academic faceted search algorithms. The user study also confirms the validity of our cost model. We also present the results of an extensive experimental evaluation on the performance of the proposed approach using two real datasets. FACeTOR is available at http://db.cse.buffalo. edu/facetor/. © 2010 ACM.",Faceted navigation | Information overload | Query interfaces,59,0,,,,undefined,,CIKM Knowledge Management
2-s2.0-77954701719,10.1145/1807167.1807206,,,FAST: Fast architecture sensitive tree search on modern CPUs and GPUs,cp,Conference Paper,Kim C.,60033010;60027758;60024941,"Intel Corporation;Oracle Corporation;University of California, Santa Cruz",Santa Clara;Austin;Santa Cruz,United States;United States;United States,9,"Kim, Changkyu;Chhugani, Jatin;Satish, Nadathur;Sedlar, Eric;Nguyen, Anthony D.;Kaldewey, Tim;Lee, Victor W.;Brandt, Scott A.;Dubey, Pradeep",55697736800;6506913869;9039607100;10738900100;14029161300;23489065500;35302949800;7202305910;7102976269,60033010;60033010;60033010;60027758;60033010;60027758;60033010;60024941;60033010,2010-07-23,2010,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,339-350,"In-memory tree structured index search is a fundamental database operation. Modern processors provide tremendous computing power by integrating multiple cores, each with wide vector units. There has been much work to exploit modern processor architectures for database primitives like scan, sort, join and aggregation. However, unlike other primitives, tree search presents significant challenges due to irregular and unpredictable data accesses in tree traversal. In this paper, we present FAST, an extremely fast architecture sensitive layout of the index tree. FAST is a binary tree logically organized to optimize for architecture features like page size, cache line size, and SIMD width of the underlying hardware. FAST eliminates impact of memory latency, and exploits thread-level and datalevel parallelism on both CPUs and GPUs to achieve 50 million (CPU) and 85 million (GPU) queries per second, 5X (CPU) and 1.7X (GPU) faster than the best previously reported performance on the same architectures. FAST supports efficient bulk updates by rebuilding index trees in less than 0.1 seconds for datasets as large as 64Mkeys and naturally integrates compression techniques, overcoming the memory bandwidth bottleneck and achieving a 6X performance improvement over uncompressed index search for large keys on CPUs. © 2010 ACM.",compression | cpu | data-level parallelism | gpu | thread-level parallelism | tree search,242,0,,,,undefined,,SIGMOD Databases
2-s2.0-77954599758,10.1145/1772690.1772773,,,Factorizing personalized Markov chains for next-basket recommendation,cp,Conference Paper,Rendle S.,60024322;60002941,Osaka University;Universität Hildesheim,Suita;Hildesheim,Japan;Germany,3,"Rendle, Steffen;Freudenthaler, Christoph;Schmidt-Thieme, Lars",14042211300;36170270300;55890913900,60024322-60002941;60002941;60002941,2010-07-20,2010,"Proceedings of the 19th International Conference on World Wide Web, WWW '10",,19700175801,,Conference Proceeding,,,,811-820,"Recommender systems are an important component of many websites. Two of the most popular approaches are based on matrix factorization (MF) and Markov chains (MC). MF methods learn the general taste of a user by factorizing the matrix over observed user-item preferences. On the other hand, MC methods model sequential behavior by learning a transition graph over items that is used to predict the next action based on the recent actions of a user. In this paper, we present a method bringing both approaches together. Our method is based on personalized transition graphs over underlying Markov chains. That means for each user an own transition matrix is learned - thus in total the method uses a transition cube. As the observations for estimating the transitions are usually very limited, our method factorizes the transition cube with a pairwise interaction model which is a special case of the Tucker Decomposition. We show that our factorized personalized MC (FPMC) model subsumes both a common Markov chain and the normal matrix factorization model. For learning the model parameters, we introduce an adaption of the Bayesian Personalized Ranking (BPR) framework for sequential basket data. Empirically, we show that our FPMC model outperforms both the common matrix factorization and the unpersonalized MC model both learned with and without factorization. © 2010 International World Wide Web Conference Committee (IW3C2).",basket recommendation | markov chain | matrix factorization,1703,0,,,FP7,215006,Seventh Framework Programme,WWW World Wide Web
2-s2.0-77954027165,10.1145/1753326.1753521,,,Feminist HCI: Taking stock and outlining an agenda for design,cp,Conference Paper,Bardzell S.,60010875,"Luddy School of Informatics, Computing, and Engineering",Bloomington,United States,1,"Bardzell, Shaowen",17345284300,60010875,2010-07-01,2010,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2,,,1301-1310,"Feminism is a natural ally to interaction design, due to its central commitments to issues such as agency, fulfillment, identity, equity, empowerment, and social justice. In this paper, I summarize the state of the art of feminism in HCI and propose ways to build on existing successes to more robustly integrate feminism into interaction design research and practice. I explore the productive role of feminism in analogous fields, such as industrial design, architecture, and game design. I introduce examples of feminist interaction design already in the field. Finally, I propose a set of femi-nist interaction design qualities intended to support design and evaluation processes directly as they unfold. © 2010 ACM.",design | feminism | feminist design qualities | feminist HCI | feminist standpoint theory | gender | HCI | interaction design,606,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-77956540831,,,,Hilbert space embeddings of Hidden Markov Models,cp,Conference Paper,Song L.,60136640;60075274;60006191,School of Computer Science;Yahoo Research Labs;Google LLC,Pittsburgh;Sunnyvale;Mountain View,United States;United States;United States,5,"Song, Le;Boots, Byron;Siddiqi, Sajid M.;Gordon, Geoffrey;Smola, Alex",55587150100;10239214300;12140906400;57203070987;6701849799,60136640;60136640;60006191;60136640;60075274,2010-09-17,2010,"ICML 2010 - Proceedings, 27th International Conference on Machine Learning",,19700180515,,Conference Proceeding,,,,991-998,"Hidden Markov Models (HMMs) are important tools for modeling sequence data. However, they are restricted to discrete latent states, and are largely restricted to Gaussian and discrete observations. And, learning algorithms for HMMs have predominantly relied on local search heuristics, with the exception of spectral methods such as those described below. We propose a nonparametric HMM that extends traditional HMMs to structured and non-Gaussian continuous distributions. Furthermore, we derive a local-minimum-free kernel spectral algorithm for learning these HMMs. We apply our method to robot vision data, slot car inertial sensor data and audio event classification data, and show that in these applications, embedded HMMs exceed the previous state-of-the-art performance. Copyright 2010 by the author(s)/owner(s).",,124,0,,,,undefined,,ICML Machine Learning
2-s2.0-77958552719,,,,How incomplete is your Semantic Web reasoner?: Systematic analysis of the completeness of query answering systems,cp,Conference Paper,Stoilos G.,60026851,University of Oxford,Oxford,United Kingdom,3,"Stoilos, Giorgos;Grau, Bernardo Cuenca;Horrocks, Ian",13405487600;22834310900;20734105100,60026851;60026851;60026851,2010-01-01,2010,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,3,,,1431-1436,"Conjunctive query answering is a key reasoning service for many ontology-based applications. In order to improve scalability, many Semantic Web query answering systems give up completeness (i.e., they do not guarantee to return all query answers). It may be useful or even critical to the designers and users of such systems to understand how much and what kind of information is (potentially) being lost. We present a method for generating test data that can be used to provide at least partial answers to these questions, a purpose for which existing benchmarks are not well suited. In addition to developing a general framework that formalises the problem, we describe practical data generation algorithms for some popular ontology languages, and present some very encouraging results from our preliminary evaluation. Copyright © 2010, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,9,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-77954011910,10.1145/1753326.1753333,,,How does search behavior change as search becomes more difficult?,cp,Conference Paper,Aula A.,60006191,Google LLC,Mountain View,United States,3,"Aula, Anne;Khan, Rehan M.;Guan, Zhiwei",55934789400;36142058400;58457975800,60006191;60006191;60006191,2010-07-01,2010,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,1,,,35-44,"Search engines make it easy to check facts online, but finding some specific kinds of information sometimes proves to be difficult. We studied the behavioral signals that suggest that a user is having trouble in a search task. First, we ran a lab study with 23 users to gain a preliminary understanding on how users' behavior changes when they struggle finding the information they're looking for. The observations were then tested with 179 participants who all completed an average of 22.3 tasks from a pool of 100 tasks. The large-scale study provided quantitative support for our qualitative observations from the lab study. When having difficulty in finding information, users start to formulate more diverse queries, they use advanced operators more, and they spend a longer time on the search result page as compared to the successful tasks. The results complement the existing body of research focusing on successful search strategies. © 2010 ACM.",behavioral signals | difficult search tasks | search engines | search strategies | web search,178,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-77956195198,10.1145/1835804.1835910,,,Large linear classification when data cannot fit in memory,cp,Conference Paper,Yu H.F.,60005429,National Taiwan University,Taipei,Taiwan,4,"Yu, Hsiang Fu;Hsieh, Cho Jui;Chang, Kai Wei;Lin, Chih Jen",57141060300;24502954900;24502911300;57154890600,60005429;60005429;60005429;60005429,2010-09-07,2010,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,101510,,Conference Proceeding,,,,833-842,"Recent advances in linear classification have shown that for applications such as document classification, the training can be extremely efficient. However, most of the existing training methods are designed by assuming that data can be stored in the computer memory. These methods cannot be easily applied to data larger than the memory capacity due to the random access to the disk. We propose and analyze a block minimization framework for data larger than the memory size. At each step a block of data is loaded from the disk and handled by certain learning methods. We investigate two implementations of the proposed framework for primal and dual SVMs, respectively. As data cannot fit in memory, many design considerations are very different from those for traditional algorithms. Experiments using data sets 20 times larger than the memory demonstrate the effectiveness of the proposed method. © 2010 ACM.",Algorithms | Experimentation | Performance,51,0,repositoryam,Green,,undefined,,KDD Data Mining
2-s2.0-77954919612,10.1145/1811099.1811072,,,Load balancing via random local search in closed and open systems,cp,Conference Paper,Ganesh A.,60098463;60032401;60031101;60020650;60014153,Microsoft Research Cambridge;INRIA Rocquencourt;University of Cambridge;University of Bristol;Indian Institute of Technology Bombay,Cambridge;Le Chesnay;Cambridge;Bristol;Mumbai,United Kingdom;France;United Kingdom;United Kingdom;India,5,"Ganesh, Ayalvadi;Lilienthal, Sarah;Manjunath, D.;Proutiere, Alexandre;Simatos, Florian",7005856945;36185685900;56234452100;6603905943;25825575400,60020650;60031101;60014153;60098463;60032401,2010-07-30,2010,Performance Evaluation Review,01635999,26742,,Conference Proceeding,38,1 SPEC. ISSUE,,287-297,"In this paper, we analyze the performance of random load resampling and migration strategies in parallel server systems. Clients initially attach to an arbitrary server, but may switch servers independently at random instants of time in an attempt to improve their service rate. This approach to load balancing contrasts with traditional approaches where clients make smart server selections upon arrival (e.g., Join-the-Shortest-Queue policy and variants thereof). Load resampling is particularly relevant in scenarios where clients cannot predict the load of a server before being actually attached to it. An important example is in wireless spectrum sharing where clients try to share a set of frequency bandsin a distributed manner. We first analyze the natural Random Local Search (RLS) strategy. Under this strategy, after sampling a new server randomly, clients only switch to it if their service rate is improved. In closed systems, where the client population is fixed, we derive tight estimates of the time it takes under RLS strategy to balance the load across servers. We then study open systems where clients arrive according to a random process and leave the system upon service completion. In this scenario, we analyze how client migrations within the system interact with the system dynamics induced by client arrivals and departures. We compare the load-aware RLS strategy to a load-oblivious strategy in which clients just randomly switch server without accounting for the server loads. Surprisingly, we show that both load-oblivious and load-aware strategies stabilize the system whenever this is at all possible. We further demonstrate, using large-system asymptotics, that the average client sojourn time under the load-oblivious strategy is not considerably reduced when clients apply smarter load-aware strategies.",Mean field asymptotics | Queueing theory | Stability analysis,16,0,repositoryam,Green,,undefined,,SIGMETRICS Performance
2-s2.0-77953974481,10.1145/1753326.1753500,,,Lumino: Tangible blocks for tabletop computers based on glass fiber bundles,cp,Conference Paper,Baudisch P.,60106550,Hasso-Plattner-Institut für Softwaresystemtechnik GmbH,Potsdam,Germany,3,"Baudisch, Patrick;Becker, Torsten;Rudeck, Frederik",10039576700;36141878600;36142208900,60106550;60106550;60106550,2010-07-01,2010,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2,,,1165-1174,"Tabletop computers based on diffuse illumination can track fiducial markers placed on the table's surface. In this paper, we demonstrate how to do the same with objects arranged in a three-dimensional structure without modifying the table. We present lumino, a system of building blocks. In addition to a marker, each block contains a glass fiber bundle. The bundle optically guides the light reflected off markers in the higher levels down to the table surface, where the table's built-in camera reads it. While guiding marker images down, the bundle optically scales and rearranges them. It thereby fits the images of an entire vertical arrangement of markers into the horizontal space usually occupied by a single 2D marker. We present six classes of blocks and matching marker designs, each of which is optimized for different requirements. We show three demo applications. One of them is a construction kit that logs and critiques constructions. The presented blocks are unpowered and maintenance-free, keeping larger numbers of blocks manageable. © 2010 ACM.",building blocks | construction kit | fiducial markers | glass fiber bundles | stacking | tabletop | tangible,83,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-78651269398,10.1145/1871437.1871577,,,MENTA: Inducing multilingual taxonomies from Wikipedia,cp,Conference Paper,De Melo G.,60000256,Max Planck Institute for Informatics,Saarbrucken,Germany,2,"De Melo, Gerard;Weikum, Gerhard",23088528100;56270327600,60000256;60000256,2010-12-01,2010,"International Conference on Information and Knowledge Management, Proceedings",,55826,,Conference Proceeding,,,,1099-1108,"In recent years, a number of projects have turned to Wikipedia to establish large-scale taxonomies that describe orders of magnitude more entities than traditional manually built knowledge bases. So far, however, the multilingual nature of Wikipedia has largely been neglected. This paper investigates how entities from all editions of Wikipedia as well as WordNet can be integrated into a single coherent taxonomic class hierarchy. We rely on linking heuristics to discover potential taxonomic relationships, graph partitioning to form consistent equivalence classes of entities, and a Markov chain-based ranking approach to construct the final taxonomy. This results in MENTA (Multilingual Entity Taxonomy), a resource that describes 5.4 million entities and is presumably the largest multilingual lexical knowledge base currently available. © 2010 ACM.",Algorithms,77,0,,,,undefined,,CIKM Knowledge Management
2-s2.0-77954026810,10.1145/1753326.1753625,,,Mapping the landscape of sustainable HCI,cp,Conference Paper,DiSalvo C.,60028072;60019647,Cornell University Department of Information Science;Georgia Institute of Technology,Ithaca;Atlanta,United States;United States,3,"DiSalvo, Carl;Sengers, Phoebe;Brynjarsdóttir, Hrönn",12239466000;22836146000;24330786600,60019647;60028072;60028072,2010-07-01,2010,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,3,,,1975-1984,"With the recent growth in sustainable HCI, now is a good time to map out the approaches being taken and the intellectual commitments that underlie the area, to allow for community discussion about where the field should go. Here, we provide an empirical analysis of how sustainable HCI is defining itself as a research field. Based on a corpus of published works, we identify (1) established genres in the area, (2) key unrecognized intellectual differences, and (3) emerging issues, including urgent avenues for further exploration, opportunities for interdisciplinary engagement, and key topics for debate. © 2010 ACM.",reflective hci | sustainability | sustainable hci,515,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-77953986434,10.1145/1753326.1753610,,,Mobile-izing health workers in rural India,cp,Conference Paper,Ramachandran D.,60025038;60021726;109080490,"University of California, Berkeley;Microsoft Research;Dhirubhai Ambani Institute of ICT",Berkeley;Redmond;,United States;United States;India,4,"Ramachandran, Divya;Canny, John;Das, Prabhu Dutta;Cutrell, Edward",57203082412;7005125209;35617829800;57203053744,60025038;60025038;109080490;60021726,2010-07-01,2010,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,3,,,1889-1898,"Researchers have long been interested in the potential of ICTs to enable positive change in developing regions communities. In these environments, ICT interventions often fail because political, social and cultural forces work against the changes ICTs entail. We argue that familiar uses of ICTs for information services in these contexts are less potent than their use for persuasion and motivation in order to facilitate change. We focus on India's rural maternal health system where health workers are employed in villages to persuade pregnant women to utilize health services. Health workers face challenges due to resistance to change in the village, and because of their limited education, training and status. These factors appear to reduce the motivation of health workers and impair their performance. For two months, we deployed short videos on mobile phones designed to persuade village women and motivate health workers. We also asked health workers to record their own videos. While our results are preliminary, they show evidence that the creation and use of videos did help (1) engage village women in dialogue, (2) show positive effects toward health worker motivation and learning, and (3) motivate key community influencers to participate in promoting the health workers. © 2010 ACM.",developing regions | health care | ictd | mobile phones | motivation | persuasion | qualitative research,147,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-77954006376,10.1145/1753326.1753365,,,Occlusion-aware interfaces,cp,Conference Paper,Vogel D.,60016849;60005081,University of Toronto;Mount Allison University,Toronto;Sackville,Canada;Canada,2,"Vogel, Daniel;Balakrishnan, Ravin",8435582600;7006221860,60016849-60005081;60016849,2010-07-01,2010,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,1,,,263-272,"We define occlusion-aware interfaces as interaction techniques which know what area of the display is currently occluded, and use this knowledge to counteract potential problems and/or utilize the hidden area. As a case study, we describe the Occlusion-Aware Viewer, which identifies important regions hidden beneath the hand and displays them in a non-occluded area using a bubble-like callout. To determine what is important, we use an application agnostic image processing layer. For the occluded area, we use a user configurable, real-time version of Vogel et al.'s [21] geometric model. In an evaluation with a simultaneous monitoring task, we find the technique can successfully mitigate the effects of occlusion, although issues with ambiguity and stability suggest further refinements. Finally, we present designs for three other occlusion-aware techniques for pop-ups, dragging, and a hidden widget. © 2010 ACM.",hand | image processing | Occlusion | pen,60,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-77953310884,10.1109/INFCOM.2010.5461923,,,On the feasibility and efficacy of protection routing in IP networks,cp,Conference Paper,Kwong K.W.,60029445;60013894;60006297,University of Minnesota Twin Cities;University of Massachusetts System;University of Pennsylvania,Minneapolis;Boston;Philadelphia,United States;United States;United States,4,"Kwong, Kin Wah;Gao, Lixin;Guêrin, Roch;Zhang, Zhi Li",9044456200;7401801245;7102723542;35197549700,60006297;60013894;60006297;60029445,2010-06-15,2010,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,,,5461923,,"With network components increasingly reliable, routing is playing an ever greater role in determining network reliability. This has spurred much activity in improving routing stability and reaction to failures, and rekindled interest in centralized routing solutions, at least within a single routing domain. Centralizing decisions eliminates uncertainty and many inconsistencies, and offers added flexibility in computing routes that meet different criteria. However, it also introduces new challenges; especially in reacting to failures where centralization can increase latency. This paper leverages the flexibility afforded by centralized routing to address these challenges. Specifically, we explore when and how standby backup forwarding options can be activated, while waiting for an update from the centralized server after the failure of an individual component (link or node). We provide analytical insight into the feasibility of such backups as a function of network structure, and quantify their computational complexity. We also develop an efficient heuristic reconciling protectability and performance, and demonstrate its effectiveness in a broad range of scenarios. The results should facilitate deployments of centralized routing solutions. ©2010 IEEE.",,31,0,repositoryam,Green,,undefined,,INFOCOM Networking
2-s2.0-77954024190,10.1145/1753326.1753554,,,Prefab: Implementing advanced behaviors using pixel-based reverse engineering of interface structure,cp,Conference Paper,Dixon M.,60015481,University of Washington,Seattle,United States,2,"Dixon, Morgan;Fogarty, James",22834249400;7004668263,60015481;60015481,2010-07-01,2010,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,3,,,1525-1534,"Current chasms between applications implemented with different user interface toolkits make it difficult to implement and explore potentially important interaction techniques in new and existing applications, limiting the progress and impact of human-computer interaction research. We examine an approach based in the single most common characteristic of all graphical user interface toolkits, that they ultimately paint pixels to a display. We present Prefab, a system for implementing advanced behaviors through the reverse engineering of the pixels in graphical interfaces. Informed by how user interface toolkits paint interfaces, Prefab features a separation of the modeling of widget layout from the recognition of widget appearance. We validate Prefab in implementations of three applications: target-aware pointing techniques, Phosphor transitions, and Side Views parameter spectrums. Working only from pixels, we demonstrate a single implementation of these enhancements in complex existing applications created in different user interface toolkits running on different windowing systems. © 2010 ACM.",pixel-based reverse engineering | prefab | user interface toolkits,112,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-77954754160,10.1145/1806689.1806768,,,QIP = PSPACE,cp,Conference Paper,Jain R.,60095887;60031486;60025256;60014171,Centre for Quantum Technologies;Perimeter Institute for Theoretical Physics;Institute of Software Chinese Academy of Sciences;University of Waterloo,Singapore City;Waterloo;Beijing;Waterloo,Singapore;Canada;China;Canada,4,"Jain, Rahul;Ji, Zhengfeng;Upadhyay, Sarvagya;Watrous, John",22034907700;8220183800;57616992000;7004448523,60095887;60031486-60025256;60014171;60014171,2010-07-23,2010,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,573-581,"We prove that the complexity class QIP, which consists of all problems having quantum interactive proof systems, is contained in PSPACE. This containment is proved by applying a parallelized form of the matrix multiplicative weights update method to a class of semidefinite programs that captures the computational power of quantum interactive proofs. As the containment of PSPACE in QIP follows immediately from the well-known equality IP = PSPACE, the equality QIP = PSPACE follows. © 2010 ACM.",matrix multiplicative weights update method | quantum computation | quantum interactive proof systems | semidefinite programming,12,0,,,,undefined,,STOC Theory
2-s2.0-85076729939,,,,Reverse traceroute,cp,Conference Paper,Katz-Bassett E.,60030612;60029445;60015481,"University of California, San Diego;University of Minnesota Twin Cities;University of Washington",La Jolla;Minneapolis;Seattle,United States;United States;United States,8,"Katz-Bassett, Ethan;Madhyastha, Harsha V.;Adhikari, Vijay Kumar;Scott, Colin;Sherry, Justine;Van Wesep, Peter;Anderson, Thomas;Krishnamurthy, Arvind",15127399400;6507095569;36719943000;54685162600;36816367200;57215342509;35560665700;7005516119,60015481;60030612;60029445;60015481;60015481;60015481;60015481;60015481,2010-01-01,2010,Proceedings of NSDI 2010: 7th USENIX Symposium on Networked Systems Design and Implementation,,21101017666,,Conference Proceeding,,,,219-234,"Traceroute is the most widely used Internet diagnostic tool today. Network operators use it to help identify routing failures, poor performance, and router misconfigurations. Researchers use it to map the Internet, predict performance, geolocate routers, and classify the performance of ISPs. However, traceroute has a fundamental limitation that affects all these applications: it does not provide reverse path information. Although various public traceroute servers across the Internet provide some visibility, no general method exists for determining a reverse path from an arbitrary destination. In this paper, we address this longstanding limitation by building a reverse traceroute system. Our system provides the same information as traceroute, but for the reverse path, and it works in the same case as traceroute, when the user may lack control of the destination. We use a variety of measurement techniques to incrementally piece together the path from the destination back to the source. We deploy our system on PlanetLab and compare reverse traceroute paths with traceroutes issued from the destinations. In the median case our tool finds 87% of the hops seen in a directly measured traceroute along the same path, versus only 38% if one simply assumes the path is symmetric, a common fallback given the lack of available tools. We then illustrate how we can use our reverse traceroute system to study previously unmeasurable aspects of the Internet: we present a case study of how a content provider could use our tool to troubleshoot poor path performance, we uncover more than a thousand peer-to-peer AS links invisible to current topology mapping efforts, and we measure the latency of individual backbone links with average error under a millisecond.",,114,0,,,NSF,CNS-0905568,National Science Foundation,NSDI Networking
2-s2.0-77955178939,10.1109/SP.2010.39,,,SCiFI - A system for secure face identification,cp,Conference Paper,Osadchy M.,60002999,University of Haifa,Haifa,Israel,4,"Osadchy, Margarita;Pinkas, Benny;Jarrous, Ayman;Moskovich, Boaz",6603646259;57203587982;32867802000;36198617000,60002999;60002999;60002999;60002999,2010-08-09,2010,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,,,5504789,239-254,"We introduce SCiFI, a system for Secure Computation of Face Identification. The system performs face identification which compares faces of subjects with a database of registered faces. The identification is done in a secure way which protects both the privacy of the subjects and the confidentiality of the database. A specific application of SCiFI is reducing the privacy impact of camera based surveillance. In that scenario, SCiFI would be used in a setting which contains a server which has a set of faces of suspects, and client machines which might be cameras acquiring images in public places. The system runs a secure computation of a face recognition algorithm, which identifies if an image acquired by a client matches one of the suspects, but otherwise reveals no information to neither of the parties. Our work includes multiple contributions in different areas: • A new face identification algorithm which is unique in having been specifically designed for usage in secure computation. Nonetheless, the algorithm has face recognition performance comparable to that of state of the art algorithms. We ran experiments which show the algorithm to be robust to different viewing conditions, such as illumination, occlusions, and changes in appearance (like wearing glasses). . A secure protocol for computing the new face recognition algorithm. In addition, since our goal is to run an actual system, considerable effort was made to optimize the protocol and minimize its online latency. . A system - SCiFI, which implements a secure computation of the face identification protocol. . Experiments which show that the entire system can run in near real-time: The secure computation protocol performs a preprocessing of all public-key cryptographic operations. Its online performance therefore mainly depends on the speed of data communication, and our experiments show it to be extremely efficient. ©2010 IEEE.",Face recognition | Privacy | Secure computation,191,0,,,FP7,208173,Seventh Framework Programme,S&P Security and Privacy
2-s2.0-77954740490,10.1145/1806596.1806610,,,Safe to the last instruction: Automated verification of a type-safe operating system,cp,Conference Paper,Yang J.,60021726;60006320,Microsoft Research;MIT Computer Science &amp; Artificial Intelligence Laboratory,Redmond;Cambridge,United States;United States,2,"Yang, Jean;Hawblitzel, Chris",36237182200;18041996700,60006320;60021726,2010-07-23,2010,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,99-110,"Typed assembly language (TAL) and Hoare logic can verify the absence of many kinds of errors in low-level code. We use TAL and Hoare logic to achieve highly automated, static verification of the safety of a new operating system called Verve. Our techniques and tools mechanically verify the safety of every assembly language instruction in the operating system, run-time system, drivers, and applications (in fact, every part of the system software except the boot loader). Verve consists of a ""Nucleus"" that provides primitive access to hardware and memory, a kernel that builds services on top of the Nucleus, and applications that run on top of the kernel. The Nucleus, written in verified assembly language, implements allocation, garbage collection, multiple stacks, interrupt handling, and device access. The kernel, written in C# and compiled to TAL, builds higher-level services, such as preemptive threads, on top of the Nucleus. A TAL checker verifies the safety of the kernel and applications. A Hoare-style verifier with an automated theorem prover verifies both the safety and correctness of the Nucleus. Verve is, to the best of our knowledge, the first operating system mechanically verified to guarantee both type and memory safety. More generally, Verve's approach demonstrates a practical way to mix high-level typed code with low-level untyped code in a verifiably safe manner. © 2010 ACM.",operating system | run-time system | type safety | verification,73,0,,,,undefined,,PLDI Programming Languages
2-s2.0-77954008818,10.1145/1753326.1753394,,,Skinput: Appropriating the body as an input surface,cp,Conference Paper,Harrison C.,60136640;60021726,School of Computer Science;Microsoft Research,Pittsburgh;Redmond,United States;United States,3,"Harrison, Chris;Tan, Desney;Morris, Dan",35792227900;7202902029;55547128588,60136640-60021726;60021726;60021726,2010-07-01,2010,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,1,,,453-462,"We present Skinput, a technology that appropriates the human body for acoustic transmission, allowing the skin to be used as an input surface. In particular, we resolve the location of finger taps on the arm and hand by analyzing mechanical vibrations that propagate through the body. We collect these signals using a novel array of sensors worn as an armband. This approach provides an always available, naturally portable, and on-body finger input system. We assess the capabilities, accuracy and limitations of our technique through a two-part, twenty-participant user study. To further illustrate the utility of our approach, we conclude with several proof-of-concept applications we developed. © 2010 ACM.",audio interfaces | bio-acoustics | buttons | finger input | gestures | on-body interaction | projected displays,453,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-78751529723,10.1145/1882291.1882301,,,Staged concurrent program analysis,cp,Conference Paper,Sinha N.,60018008,"NEC Laboratories America, Inc.",Princeton,United States,2,"Sinha, Nishant;Wang, Chao",55154332600;55647141100,60018008;60018008,2010-12-01,2010,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,85109,,Conference Proceeding,,,,47-56,"Concurrent program verification is challenging because it involves exploring a large number of possible thread interleavings together with complex sequential reasoning. As a result, concurrent program verifiers resort to bi-modal reasoning, which alternates between reasoning over intra-thread (sequential) semantics and inter-thread (concurrent) semantics. Such reasoning often involves repeated intra-thread reasoning for exploring each interleaving (inter-thread reasoning) and leads to inefficiency. In this paper, we present a new two-stage analysis which completely separates intra- and inter-thread reasoning. The first stage uses sequential program semantics to obtain a precise summary of each thread in terms of the global accesses made by the thread. The second stage performs inter-thread reasoning by composing these thread-modular summaries using the notion of sequential consistency. Assertion violations and other concurrency errors are then checked in this composition with the help of an off-the-shelf SMT solver. We have implemented our approach in the FUSION framework for checking concurrent C programs shows that avoiding redundant bi-modal reasoning makes the analysis more scalable. © 2010 ACM.",axiomatic composition | interference abstraction | interference skeleton | sequential consistency | smt solvers | staged analysis | thread-modular summarization,46,0,,,,undefined,,FSE Software Engineering
2-s2.0-78751539332,10.1109/FOCS.2010.59,,,Subexponential algorithms for unique games and related problems,cp,Conference Paper,Arora S.,60141284;60098463;60003269,School of Engineering and Applied Science;Microsoft Research Cambridge;Princeton University,Princeton;Cambridge;Princeton,United States;United Kingdom;United States,3,"Arora, Sanjeev;Barak, Boaz;Steurer, David",7202419160;55909951700;24512792300,60141284;60003269-60141284;60098463-60141284,2010-01-01,2010,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,,,5671307,563-572,"We give a subexponential time approximation algorithm for the Unique Games problem. The algorithms run in time that is exponential in an arbitrarily small polynomial of the input size, nε. The approximation guarantee depends on ε, but not on the alphabet size or the number of variables. We also obtain a subexponential algorithms with improved approximations for SMALL-SET EXPANSION and MULTICUT. For MAX CUT, SPARSEST CUT, and VERTEX COVER, we give subexponential algorithms with improved approximations on some interesting subclasses of instances. Khot's Unique Games Conjecture (UGC) states that it is NP-hard to achieve approximation guarantees such as ours for the Unique Games. While our results stop short of refuting the UGC, they do suggest that Unique Games is significantly easier than NP-hard problems such as MAX 3SAT, MAX 3LIN, LABEL COVER and more, that are believed not to have a subexponential algorithm achieving a non-trivial approximation ratio. The main component in our algorithms is a new result on graph decomposition that may have other applications. Namely we show that for every ε > 0 and every regular n-vertex graph G, by changing at most ε fraction of G's edges, one can break G into disjoint parts so that the stochastic adjacency matrix of the induced graph on each part has at most nε eigenvalues larger than 1 - η, where η depends polynomially on ε. © 2010 IEEE.",Approximation algorithms | Constraint satisfaction problems | Eigenvalues | Graph decompositions | Spectral methods | Subexponential algorithms | Unique games,111,0,,,,undefined,,FOCS Theory
2-s2.0-77954725197,10.1145/1806799.1806835,,,Test generation through programming in UDITA,cp,Conference Paper,Gligoric M.,60028186;60013372;60000745,École Polytechnique Fédérale de Lausanne;The University of Texas at Austin;University of Illinois Urbana-Champaign,Lausanne;Austin;Urbana,Switzerland;United States;United States,6,"Gligoric, Milos;Gvero, Tihomir;Jagannath, Vilas;Khurshid, Sarfraz;Kuncak, Viktor;Marinov, Darko",26221765900;26221649500;26967821000;56231912700;6602919120;8730036800,60000745;60028186;60000745;60013372;60028186;60000745,2010-07-23,2010,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,1,,,225-234,"We present an approach for describing tests using non-deterministic test generation programs. To write such programs, we introduce UDITA, a Java-based language with non-deterministic choice operators and an interface for generating linked structures. We also describe new algorithms that generate concrete tests by efficiently exploring the space of all executions of non-deterministic UDITA programs. We implemented our approach and incorporated it into the official, publicly available repository of Java PathFinder (JPF), a popular tool for verifying Java programs. We evaluate our technique by generating tests for data structures, refactoring engines, and JPF itself. Our experiments show that test generation using UDITA is faster and leads to test descriptions that are easier to write than in previous frameworks. Moreover, the novel execution mechanism of UDITA is essential for making test generation feasible. Using UDITA, we have discovered a number of bugs in Eclipse, NetBeans, Sun javac, and JPF. © 2010 ACM.",automated testing | Java PathFinder | Pex | test filtering | test generation | test predicates | test programs | UDITA,119,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-77953979542,10.1145/1753326.1753629,,,The design of eco-feedback technology,cp,Conference Paper,Froehlich J.,60015481,University of Washington,Seattle,United States,3,"Froehlich, Jon;Findlater, Leah;Landay, James",7101665384;10040303000;7004487828,60015481;60015481;60015481,2010-07-01,2010,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,3,,,1999-2008,"Eco-feedback technology provides feedback on individual or group behaviors with a goal of reducing environmental impact. The history of eco-feedback extends back more than 40 years to the origins of environmental psychology. Despite its stated purpose, few HCI eco-feedback studies have attempted to measure behavior change. This leads to two overarching questions: (1) what can HCI learn from environmental psychology and (2) what role should HCI have in designing and evaluating eco-feedback technology? To help answer these questions, this paper conducts a comparative survey of eco-feedback technology, including 89 papers from environmental psychology and 44 papers from the HCI and UbiComp literature. We also provide an overview of predominant models of proenvironmental behaviors and a summary of key motivation techniques to promote this behavior. © 2010 ACM.",eco-feedback | environmental hci | reflective hci | survey,558,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-77953973981,10.1145/1753326.1753370,,,The tower of Babel meets web 2.0: User-generated content and its applications in a multilingual context,cp,Conference Paper,Hecht B.,60147353;60007363,Robert R. McCormick School of Engineering and Applied Science;Northwestern University,Evanston;Evanston,United States;United States,2,"Hecht, Brent;Gergle, Darren",24824723600;6505994142,60147353;60147353-60007363,2010-07-01,2010,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,1,,,291-300,"This study explores language's fragmenting effect on user-generated content by examining the diversity of knowledge representations across 25 different Wikipedia language editions. This diversity is measured at two levels: the concepts that are included in each edition and the ways in which these concepts are described. We demonstrate that the diversity present is greater than has been presumed in the literature and has a significant influence on applications that use Wikipedia as a source of world knowledge. We close by explicating how knowledge diversity can be beneficially leveraged to create ""culturally- aware applications"" and ""hyperlingual applications"". © 2010 ACM.",explicit semantic analysis | hyperlingual | knowledge diversity | language | multilingual | semantic relatedness | wikipedia,130,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85076921347,,,,The turtles project: Design and implementation of nested virtualization,cp,Conference Paper,Ben-Yehuda M.,60026303;60021293,IBM Research - Haifa;International Business Machines,Haifa;Armonk,Israel;United States,9,"Ben-Yehuda, Muli;Day, Michael D.;Dubitzky, Zvi;Factor, Michael;Har'El, Nadav;Gordon, Abel;Liguori, Anthony;Wasserman, Orit;Yassour, Ben Ami",24079691000;36191911000;42561268300;7004363241;6506894681;55000614200;57212512525;36189153300;10738963500,60026303;60021293;60026303;60026303;60026303;60026303;60021293;60026303;60026303,2019-01-01,2019,"Proceedings of the 9th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2010",,21100939707,,Conference Proceeding,,,,423-436,"In classical machine virtualization, a hypervisor runs multiple operating systems simultaneously, each on its own virtual machine. In nested virtualization, a hypervisor can run multiple other hypervisors with their associated virtual machines. As operating systems gain hypervisor functionality-Microsoft Windows 7 already runs Windows XP in a virtual machine-nested virtualization will become necessary in hypervisors that wish to host them. We present the design, implementation, analysis, and evaluation of high-performance nested virtualization on Intel x86-based systems. The Turtles project, which is part of the Linux/KVM hypervisor, runs multiple unmodified hypervisors (e.g., KVM and VMware) and operating systems (e.g., Linux and Windows). Despite the lack of architectural support for nested virtualization in the x86 architecture, it can achieve performance that is within 6-8% of single-level (non-nested) virtualization for common workloads, through multi-dimensional paging for MMU virtualization and multi-level device assignment for I/O virtualization.",,159,0,,,KVA,undefined,Royal Swedish Academy of Sciences,OSDI Operating Systems
2-s2.0-84858615261,10.14778/1920841.1920867,,,Towards certain fixes with editing rules and master data,ar,Article,Fan W.,60027272;60019616,The University of Edinburgh;Harbin Institute of Technology,Edinburgh;Harbin,United Kingdom;China,5,"Fan, Wenfei;Li, Jianzhong;Ma, Shuai;Tang, Nan;Yu, Wenyuan",7401635408;55861641100;56611103800;55570310100;42263090700,60027272-60019616;60019616;60027272;60027272;60027272,2010-01-01,September 2010,Proceedings of the VLDB Endowment,,21100199855,21508097,Conference Proceeding,3,1,,173-184,"A variety of integrity constraints have been studied for data cleaning. While these constraints can detect the presence of errors, they fall short of guiding us to correct the errors. Indeed, data repairing based on these constraints may not find certain fixes that are absolutely correct, and worse, may introduce new errors when repairing the data. We propose a method for finding certain fixes, based on master data, a notion of certain regions, and a class of editing rules. A certain region is a set of attributes that are assured correct by the users. Given a certain region and master data, editing rules tell us what attributes to fix and how to update them. We show how the method can be used in data monitoring and enrichment. We develop techniques for reasoning about editing rules, to decide whether they lead to a unique fix and whether they are able to fix all the attributes in a tuple, relative to master data and a certain region. We also provide an algorithm to identify minimal certain regions, such that a certain fix is warranted by editing rules and master data as long as one of the regions is correct. We experimentally verify the effectiveness and scalability of the algorithm. © 2010 VLDB Endowment.",,96,0,,,,undefined,,VLDB Databases
2-s2.0-77953994698,10.1145/1753326.1753716,,,Useful junk? The effects of visual embellishment on comprehension and memorability of charts,cp,Conference Paper,Bateman S.,60015186,University of Saskatchewan,Saskatoon,Canada,6,"Bateman, Scott;Mandryk, Regan L.;Gutwin, Carl;Genest, Aaron;McDine, David;Brooks, Christopher",14047994300;6506898492;35587413900;35175886400;34977338500;14047887300,60015186;60015186;60015186;60015186;60015186;60015186,2010-07-01,2010,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,4,,,2573-2582,"Guidelines for designing information charts (such as bar charts) often state that the presentation should reduce or remove 'chart junk' - visual embellishments that are not essential to understanding the data. In contrast, some popular chart designers wrap the presented data in detailed and elaborate imagery, raising the questions of whether this imagery is really as detrimental to understanding as has been proposed, and whether the visual embellishment may have other benefits. To investigate these issues, we conducted an experiment that compared embellished charts with plain ones, and measured both interpretation accuracy and long-term recall. We found that people's accuracy in describing the embellished charts was no worse than for plain charts, and that their recall after a two-to-three-week gap was significantly better. Although we are cautious about recommending that all charts be produced in this style, our results question some of the premises of the minimalist approach to chart design. © 2010 ACM.",charts | imagery | information visualization | memorability,274,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-78649587763,10.1145/1866029.1866080,,,VizWiz: Nearly real-time answers to visual questions,cp,Conference Paper,Bigham J.P.,60027165;60022144;60020304;60015481;60006320,"University of Rochester;University of Central Florida;University of Maryland, College Park;University of Washington;MIT Computer Science &amp; Artificial Intelligence Laboratory",Rochester;Orlando;College Park;Seattle;Cambridge,United States;United States;United States;United States;United States,11,"Bigham, Jeffrey P.;Jayant, Chandrika;Ji, Hanjie;Little, Greg;Miller, Andrew;Miller, Robert C.;Miller, Robin;Tatarowicz, Aubrey;White, Brandyn;White, Samuel;Yeh, Tom",16238221500;24071201300;26422246100;16643068200;56026126700;57216196948;57199446653;36167498900;23394355900;55452528100;57194267314,60027165;60015481;60027165;60006320;60022144;60006320;60027165;60006320;60020304;60027165;60020304,2010-12-06,2010,UIST 2010 - 23rd ACM Symposium on User Interface Software and Technology,,19700182663,,Conference Proceeding,,,,333-342,"The lack of access to visual information like text labels, icons, and colors can cause frustration and decrease independence for blind people. Current access technology uses automatic approaches to address some problems in this space, but the technology is error-prone, limited in scope, and quite expensive. In this paper, we introduce VizWiz, a talking application for mobile phones that offers a new alternative to answering visual questions in nearly real-time-asking multiple people on the web. To support answering questions quickly, we introduce a general approach for intelligently recruiting human workers in advance called quikTurkit so that workers are available when new questions arrive. A field deployment with 11 blind participants illustrates that blind people can effectively use VizWiz to cheaply answer questions in their everyday lives, highlighting issues that automatic approaches will need to address to be useful. Finally, we illus-trate the potential of using VizWiz as part of the participatory design of advanced tools by using it to build and evaluate VizWiz::LocateIt, an interactive mobile tool that helps blind people solve general visual search problems.",Blind users | Non-visual interfaces | Real-time human computation,580,0,,,,undefined,,UIST User Interface
2-s2.0-82655165305,10.1145/2043556.2043564,,,A file is not a file: Understanding the I/O behavior of Apple desktop applications,cp,Conference Paper,Harter T.,60153202,"School of Computer, Data &amp; Information Sciences",Madison,United States,5,"Harter, Tyler;Dragga, Chris;Vaughn, Michael;Arpaci-Dusseau, Andrea C.;Arpaci-Dusseau, Remzi H.",54415799500;54415613000;54416358100;6602169729;6602342083,60153202;60153202;60153202;60153202;60153202,2011-12-07,2011,SOSP'11 - Proceedings of the 23rd ACM Symposium on Operating Systems Principles,,20600195604,,Conference Proceeding,,,,71-83,"We analyze the I/O behavior of iBench, a new collection of productivity and multimedia application workloads. Our analysis reveals a number of differences between iBench and typical file-system workload studies, including the complex organization of modern files, the lack of pure sequential access, the influence of underlying frameworks on I/O patterns, the widespread use of file synchronization and atomic operations, and the prevalence of threads. Our results have strong ramifications for the design of next generation local and cloud-based storage systems. © 2011 ACM.",,77,0,,,,undefined,,SOSP Operating Systems
2-s2.0-84862635899,10.1109/FOCS.2011.63,,,A polylogarithmic-competitive algorithm for the k-server problem,cp,Conference Paper,Bansal N.,60098463;60022591;60022403;60017366,Microsoft Research Cambridge;Open University of Israel;Technion - Israel Institute of Technology;IBM Thomas J. Watson Research Center,Cambridge;Tel Aviv-Yafo;Haifa;Yorktown Heights,United Kingdom;Israel;Israel;United States,4,"Bansal, Nikhil;Buchbinder, Niv;Ma̧dry, Aleksander;Naor, Joseph",7102714084;6602627006;24171757000;7006895259,60017366;60022591;60098463;60022403,2011-12-01,2011,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,,,6108181,267-276,"We give the first polylogarithmic-competitive randomized algorithm for the k-server problem on an arbitrary finite metric space. In particular, our algorithm achieves a competitive ratio of Õ(log 3 n log 2 k) for any metric space on n points. This improves upon the (2k-1)-competitive algorithm of Koutsoupias and Papadimitriou [22] whenever n is sub-exponential in k. © 2011 IEEE.",competitive analysis | k-server problem | randomized algorithms,49,0,repositoryam,Green,CISE,0829878,Directorate for Computer and Information Science and Engineering,FOCS Theory
2-s2.0-84862631341,10.1109/FOCS.2011.80,,,A randomized rounding approach to the traveling salesman problem,cp,Conference Paper,Gharan S.O.,60141508;60002494,Stanford Engineering;Université McGill,Stanford;Montreal,United States;Canada,3,"Gharan, Shayan Oveis;Saberi, Amin;Singh, Mohit",55401546700;57222707276;55469458300,60141508;60141508;60002494,2011-12-01,2011,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,,,6108216,550-559,"For some positive constant ε 0, we give a (3/2-ε 0)-approximation algorithm for the following problem: given a graph G 0=(V,E 0), find the shortest tour that visits every vertex at least once. This is a special case of the metric traveling salesman problem when the underlying metric is defined by shortest path distances in G 0. The result improves on the 3/2-approximation algorithm due to Christofides [C76] for this special case. Similar to Christofides, our algorithm finds a spanning tree whose cost is upper bounded by the optimum, then it finds the minimum cost Eulerian augmentation (or T-join) of that tree. The main difference is in the selection of the spanning tree. Except in certain cases where the solution of LP is nearly integral, we select the spanning tree randomly by sampling from a maximum entropy distribution defined by the linear programming relaxation. Despite the simplicity of the algorithm, the analysis builds on a variety of ideas such as properties of strongly Rayleigh measures from probability theory, graph theoretical results on the structure of near minimum cuts, and the integrality of the T-join polytope from polyhedral theory. Also, as a byproduct of our result, we show new properties of the near minimum cuts of any graph, which may be of independent interest. © 2011 IEEE.",Approximation Algorithms | Random Spanning Trees | Randomized Rounding | Traveling Salesman Problem,111,0,repositoryam,Green,,undefined,,FOCS Theory
2-s2.0-79955732724,10.1137/1.9781611973082.17,,,An almost optimal unrestricted fast Johnson-Lindenstrauss transform,cp,Conference Paper,Ailon N.,60075274;60022403,Yahoo Research Labs;Technion - Israel Institute of Technology,Sunnyvale;Haifa,United States;Israel,2,"Ailon, Nir;Liberty, Edo",9271489900;23393332700,60022403;60075274,2011-01-01,2011,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,,,,185-191,"The problems of random projections and sparse reconstruction have much in common and individually received much attention. Surprisingly, until now they progressed in parallel and remained mostly separate. Here, we employ new tools from probability in Banach spaces that were successfully used in the context of sparse reconstruction to advance on an open problem in random pojection. In particular, we generalize and use an intricate result by Rudelson and Vershynin for sparse reconstruction which uses Dudley's theorem for bounding Gaussian processes. Our main result states that any set of N = exp(Õ(n)) real vectors in n dimensional space can be Unearly mapped to a space of dimension k = O(log Arpolylog(n)), while (1) preserving the pair-wise distances among the vectors to within any constant distortion and (2) being able to apply the transformation in time 0(n log n) on each vector. This improves on the best known N = exp(Õ;(n1/2)) achieved by Ailon and Liberty and N = exp(Õ(n1/3)) by Ailon and Chazelle. The dependence in the distortion constant however is believed to be suboptimal and subject to further investigation. For constant distortion, this settles the open question posed by these authors up to a polylog(n) factor while considerably simplifying their constructions.",,32,0,repositoryam,Green,,undefined,,SODA Theory
2-s2.0-84862632630,10.1109/FOCS.2011.56,,,Approximating graphic TSP by matchings,cp,Conference Paper,Mömke T.,60028186;60002014,École Polytechnique Fédérale de Lausanne;The Royal Institute of Technology (KTH),Lausanne;Stockholm,Switzerland;Sweden,2,"Mömke, Tobias;Svensson, Ola",23390101400;23393910000,60002014;60028186,2011-12-01,2011,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,,,6108217,560-569,"We present a framework for approximating the metric TSP based on a novel use of matchings. Traditionally, matchings have been used to add edges in order to make a given graph Eulerian, whereas our approach also allows for the removal of certain edges leading to a decreased cost. For the TSP on graphic metrics (graph-TSP), the approach yields a 1.461-approximation algorithm with respect to the Held-Karp lower bound. For graph-TSP restricted to a class of graphs that contains degree three bounded and claw-free graphs, we show that the integrality gap of the Held-Karp relaxation matches the conjectured ratio 4/3. The framework allows for generalizations in a natural way and also leads to a 1.586-approximation algorithm for the traveling salesman path problem on graphic metrics where the start and end vertices are prespecified. © 2011 IEEE.",approximation | linear programming | TSP,70,0,repositoryam,Green,FP7,226203,Seventh Framework Programme,FOCS Theory
2-s2.0-79958168364,10.1145/1978942.1979199,,,Automics: Souvenir generating photoware for theme parks,cp,Conference Paper,Durrant A.,60026830;60015138,University of Lincoln;University of Nottingham,Lincoln;Nottingham,United Kingdom;United Kingdom,6,"Durrant, Abigail;Rowland, Duncan;Kirk, David S.;Benford, Steve;Fischer, Joel;McAuley, Derek",23024725800;7102182425;27169862100;7006887786;36095705300;56273430900,60015138;60026830;60015138;60015138;60015138;60015138,2011-01-01,2011,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1767-1776,"Automics is a photo-souvenir service which utilises mobile devices to support the capture, sharing and annotation of digital images amongst groups of visitors to theme parks. The prototype service mixes individual and group photocapture with existing in-park, on-ride photo services, to allow users to create printed photo-stories. Herein we discuss initial fieldwork in theme parks that grounded the design of Automics, our development of the service prototype, and its real-world evaluation with theme park visitors. We relate our findings on user experience of the service to a literature on mobile photoware, finding implications for the design of souvenir services. Copyright 2011 ACM.",Photoware | Souvenir | Theme park | Tourism,53,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-79958117361,10.1145/1978942.1979262,,,Bricolage: Example-based retargeting for web design,cp,Conference Paper,Kumar R.,60141508,Stanford Engineering,Stanford,United States,4,"Kumar, Ranjitha;Talton, Jerry O.;Ahmad, Salman;Klemmer, Scott R.",55480578200;22036874300;39361112200;6603250689,60141508;60141508;60141508;60141508,2011-01-01,2011,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,2197-2206,"The Web provides a corpus of design examples unparalleled in human history. However, leveraging existing designs to produce new pages is often difficult. This paper introduces the Bricolage algorithm for transferring design and content between Web pages. Bricolage employs a novel, structured-prediction technique that learns to create coherent mappings between pages by training on human-generated exemplars. The produced mappings are then used to automatically transfer the content from one page into the style and layout of another. We show that Bricolage can learn to accurately reproduce human page mappings, and that it provides a general, efficient, and automatic technique for retargeting content between a variety of real Web pages. Copyright 2011 ACM.",Examples | Retargeting | Structured prediction | Web design,112,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-82655162792,10.1145/2043556.2043574,,,Cells: A virtual mobile smartphone architecture,cp,Conference Paper,Andrus J.,60031321,The Fu Foundation School of Engineering and Applied Science,New York,United States,5,"Andrus, Jeremy;Dall, Christoffer;Hof, Alexander Van t.;Laadan, Oren;Nieh, Jason",54415397700;54415539000;57196881893;21743128900;7003645135,60031321;60031321;60031321;60031321;60031321,2011-12-07,2011,SOSP'11 - Proceedings of the 23rd ACM Symposium on Operating Systems Principles,,20600195604,,Conference Proceeding,,,,173-187,"Smartphones are increasingly ubiquitous, and many users carry multiple phones to accommodate work, personal, and geographic mobility needs. We present Cells, a virtualization architecture for enabling multiple virtual smartphones to run simultaneously on the same physical cellphone in an isolated, secure manner. Cells introduces a usage model of having one foreground virtual phone and multiple background virtual phones. This model enables a new device namespace mechanism and novel device proxies that integrate with lightweight operating system virtualization to multiplex phone hardware across multiple virtual phones while providing native hardware device performance. Cells virtual phone features include fully accelerated 3D graphics, complete power, management features, and full telephony functionality with separately assignable telephone numbers and caller ID support. We have implemented a prototype of Cells that supports multiple Android virtual phones on the same phone. Our performance results demonstrate that Cells imposes only modest runtime and memory overhead, works seamlessly across multiple hardware devices including Google Nexus 1 and Nexus S phones, and transparently runs Android applications at native speed without any modifications. © 2011 ACM.",Android | smartphones | virtualization,162,0,,,,undefined,,SOSP Operating Systems
2-s2.0-80055061484,,,,Complexity of and algorithms for Borda manipulation,cp,Conference Paper,Davies J.,60106017;60028333;60016849,Université Paris-Saclay;UNSW Sydney;University of Toronto,Gif-sur-Yvette;Sydney;Toronto,France;Australia;Canada,4,"Davies, Jessica;Katsirelos, George;Narodytska, Nina;Walsh, Toby",57191058886;10242084300;16029040600;55806690200,60016849;60106017;60028333;60028333,2011-01-01,2011,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,1,,,657-662,"We prove that it is NP-hard for a coalition of two manipulators to compute how to manipulate the Borda voting rule. This resolves one of the last open problems in the computational complexity of manipulating common voting rules. Because of this NP-hardness, we treat computing a manipulation as an approximation problem where we try to minimize the number of manipulators. Based on ideas from bin packing and multiprocessor scheduling, we propose two new approximation methods to compute manipulations of the Borda rule. Experiments show that these methods significantly outperform the previous best known approximation method. We are able to find optimal manipulations in almost all the randomly generated elections tested. Our results suggest that, whilst computing a manipulation of the Borda rule by a coalition is NP-hard, computational complexity may provide only a weak barrier against manipulation in practice. Copyright © 2011, Association for the Advancement of Artificial Intelligence. All rights reserved.",,56,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-80053454559,,,,Computational rationalization: The inverse equilibrium problem,cp,Conference Paper,Waugh K.,60027950,Carnegie Mellon University,Pittsburgh,United States,3,"Waugh, Kevin;Ziebart, Brian D.;Bagnell, J. Andrew",36914057200;13608719300;6506127486,60027950;60027950;60027950,2011-10-07,2011,"Proceedings of the 28th International Conference on Machine Learning, ICML 2011",,19900195088,,Conference Proceeding,,,,1169-1176,"Modeling the purposeful behavior of imperfect agents from a small number of observations is a challenging task. When restricted to the single-agent decision-theoretic setting, inverse optimal control techniques assume that observed behavior is an approximately optimal solution to an unknown decision problem. These techniques learn a utility function that explains the example behavior and can then be used to accurately predict or imitate future behavior in similar observed or unobserved situations. In this work, we consider similar tasks in competitive and cooperative multi-agent domains. Here, unlike single-agent settings, a player cannot myopically maximize its reward - it must speculate on how the other agents may act to influence the game's outcome. Employing the game-theoretic notion of regret and the principle of maximum entropy, we introduce a technique for predicting and generalizing behavior, as well as recovering a reward function in these domains. Copyright 2011 by the author(s)/owner(s).",,35,0,,,,undefined,,ICML Machine Learning
2-s2.0-79959893269,10.1145/1985793.1985830,,,"Configuring global software teams: A multi-company analysis of project productivity, quality, and profits",cp,Conference Paper,Ramasubbu N.,60027950;60018933,Carnegie Mellon University;Singapore Management University,Pittsburgh;Singapore City,United States;Singapore,4,"Ramasubbu, Narayan;Cataldo, Marcelo;Balan, Rajesh Krishna;Herbsleb, James D.",16317345600;17344957800;35576393800;6603734663,60018933;60027950;60018933;60027950,2011-07-07,2011,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,261-270,"In this paper, we examined the impact of project-level configurational choices of globally distributed software teams on project productivity, quality, and profits. Our analysis used data from 362 projects of four different firms. These projects spanned a wide range of programming languages, application domain, process choices, and development sites spread over 15 countries and 5 continents. Our analysis revealed fundamental tradeoffs in choosing configurational choices that are optimized for productivity, quality, and/or profits. In particular, achieving higher levels of productivity and quality require diametrically opposed configurational choices. In addition, creating imbalances in the expertise and personnel distribution of project teams significantly helps increase profit margins. However, a profit-oriented imbalance could also significantly affect productivity and/or quality outcomes. Analyzing these complex tradeoffs, we provide actionable managerial insights that can help software firms and their clients choose configurations that achieve desired project outcomes in globally distributed software development. © 2011 ACM.",empirical analysis | globally distributed software development | quality management | software engineering economics,66,0,repositoryvor,Green,,undefined,,ICSE Software Engineering
2-s2.0-79960180738,10.1145/1989284.1989293,,,Data exchange beyond complete data,cp,Conference Paper,Arenas M.,60027272;60012464,The University of Edinburgh;Universidad de Chile,Edinburgh;Santiago,United Kingdom;Chile,3,"Arenas, Marcelo;Pérez, Jorge;Reutter, Juan",7005937486;57195967788;34880850800,;60012464;60027272,2011-07-15,2011,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,83-94,"In the traditional data exchange setting, source instances are restricted to be complete in the sense that every fact is either true or false in these instances. Although natural for a typical database translation scenario, this restriction is gradually becoming an impediment to the development of a wide range of applications that need to exchange objects that admit several interpretations. In particular, we are motivated by two specific applications that go beyond the usual data exchange scenario: exchanging incomplete information and exchanging knowledge bases. In this paper, we propose a general framework for data exchange that can deal with these two applications. More specifically, we address the problem of exchanging information given by representation systems, which are essentially finite descriptions of (possibly infinite) sets of complete instances. We make use of the classical semantics of mappings specified by sets of logical sentences to give a meaningful semantics to the notion of exchanging representatives, from which the standard notions of solution, space of solutions, and universal solution naturally arise. We also introduce the notion of strong representation system for a class of mappings, that resembles the concept of strong representation system for a query language. We show the robustness of our proposal by applying it to the two applications mentioned above: exchanging incomplete information and exchanging knowledge bases, which are both instantiations of the exchanging problem for representation systems. We study these two applications in detail, presenting results regarding expressiveness, query answering and complexity of computing solutions, and also algorithms to materialize solutions. Copyright © 2011 ACM.",Data exchange | Data integration | Knowledge exchange | Metadata management | Representation system | Schema mapping,22,0,,,,undefined,,PODS Databases
2-s2.0-79959876215,10.1145/1993498.1993504,,,Data representation synthesis,cp,Conference Paper,Hawkins P.,60141508;60023143;60006320;60005681,Stanford Engineering;Tufts University;MIT Computer Science &amp; Artificial Intelligence Laboratory;Tel Aviv University,Stanford;Medford;Cambridge;Tel Aviv-Yafo,United States;United States;United States;Israel,5,"Hawkins, Peter;Aiken, Alex;Fisher, Kathleen;Rinard, Martin;Sagiv, Mooly",8543566500;57203049517;57214548612;7003321126;7004822914,60141508;60141508;60023143;60006320;60005681,2011-01-01,2011,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,38-49,"We consider the problem of specifying combinations of data structures with complex sharing in a manner that is both declarative and results in provably correct code. In our approach, abstract data types are specified using relational algebra and functional dependencies. We describe a language of decompositions that permit the user to specify different concrete representations for relations, and show that operations on concrete representations soundly implement their relational specification. It is easy to incorporate data representations synthesized by our compiler into existing systems, leading to code that is simpler, correct by construction, and comparable in performance to the code it replaces. © 2011 ACM.",composite data structures | synthesis,58,0,repositoryam,Green,,undefined,,PLDI Programming Languages
2-s2.0-85034112136,,,,"Design, implementation and evaluation of congestion control for multipath TCP",cp,Conference Paper,Wischik D.,60022148,University College London,London,United Kingdom,4,"Wischik, Damon;Raiciu, Costin;Greenhalgh, Adam;Handley, Mark",12807835200;16307632000;16177183500;7006454610,60022148;60022148;60022148;60022148,2011-01-01,2011,Proceedings of NSDI 2011: 8th USENIX Symposium on Networked Systems Design and Implementation,,21100939102,,Conference Proceeding,,,,99-112,"Multipath TCP, as proposed by the IETF working group mptcp, allows a single data stream to be split across multiple paths. This has obvious benefits for reliability, and it can also lead to more efficient use of networked resources. We describe the design of a multipath congestion control algorithm, we implement it in Linux, and we evaluate it for multihomed servers, data centers and mobile clients. We show that some 'obvious' solutions for multipath congestion control can be harmful, but that our algorithm improves throughput and fairness compared to single-path TCP. Our algorithm is a drop-in replacement for TCP, and we believe it is safe to deploy.",,492,0,,,,undefined,,NSDI Networking
2-s2.0-80053610622,10.1145/2030613.2030625,,,Detecting driver phone use leveraging car speakers,cp,Conference Paper,Yang J.,60119141;60027392,Rutgers University–New Brunswick;Stevens Institute of Technology,New Brunswick;Hoboken,United States;United States,9,"Yang, Jie;Sidhom, Simon;Chandrasekaran, Gayathri;Vu, Tam;Liu, Hongbo;Cecan, Nicolae;Chen, Yingying;Gruteser, Marco;Martin, Richard P.",57192451800;52564457200;23388109800;56410461600;35234118800;52563175300;57199756928;10143086500;7501382621,60027392;60027392;60119141;60119141;60027392;60119141;60027392;60119141;60119141,2011-10-12,2011,"Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM",,70461,,Conference Proceeding,,,,97-108,"This work addresses the fundamental problem of distinguishing between a driver and passenger using a mobile phone, which is the critical input to enable numerous safety and interface enhancements. Our detection system leverages the existing car stereo infrastructure, in particular the speakers and Bluetooth network. Our acoustic approach has the phone send a series of customized high frequency beeps via the car stereo. The beeps are spaced in time across the left, right, and if available, front and rear speakers. After sampling the beeps, we use a sequential change-point detection scheme to time their arrival, and then use a differential approach to estimate the phone's distance from the car's center. From these differences a passenger or driver classification can be made. To validate our approach, we experimented with two kinds of phones and in two different cars. We found that our customized beeps were imperceptible to most users, yet still playable and recordable in both cars. Our customized beeps were also robust to background sounds such as music and wind, and we found the signal processing did not require excessive computational resources. In spite of the cars' heavy multi-path environment, our approach had a classification accuracy of over 90%, and around 95% with some calibrations. We also found we have a low false positive rate, on the order of a few percent. © 2011 ACM.",acoustic ranging | bluetooth | car speakers | driving safety | location classification | smartphone,174,0,repositoryam,Green,,undefined,,MOBICOM Mobile
2-s2.0-80055034198,,,,Dynamic resource allocation in conservation planning,cp,Conference Paper,Golovin D.,60143898;60025858;60017542;60004923;60004404,California Institute of Technology Division of Engineering and Applied Science;ETH Zürich;Oregon Fish &amp; Wildlife Office;NC State University;Patuxent Wildlife Research Center,Pasadena;Zurich;Portland;Raleigh;Laurel,United States;Switzerland;United States;United States;United States,5,"Golovin, Daniel;Krause, Andreas;Gardner, Beth;Converse, Sarah J.;Morey, Steve",23008179200;26659842300;7103317719;6603683140;7006221563,60143898;60025858;60004923;60004404;60017542,2011-11-02,2011,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,2,,,1331-1336,"Consider the problem of protecting endangered species by selecting patches of land to be used for conservation purposes. Typically, the availability of patches changes over time, and recommendations must be made dynamically. This is a challenging prototypical example of a sequential optimization problem under uncertainty in computational sustainability. Existing techniques do not scale to problems of realistic size. In this paper, we develop an efficient algorithm for adaptively making recommendations for dynamic conservation planning, and prove that it obtains near-optimal performance. We further evaluate our approach on a detailed reserve design case study of conservation planning for three rare species in the Pacific Northwest of the United States. Copyright © 2011, Association for the Advancement of Artificial Intelligence. All rights reserved.",,20,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-79955577602,10.1109/INFCOM.2011.5934885,,,Dynamic right-sizing for power-proportional data centers,cp,Conference Paper,Lin M.,60031581;60030804;60021726,California Institute of Technology;Swinburne University of Technology;Microsoft Research,Pasadena;Hawthorn;Redmond,United States;Australia;United States,4,"Lin, Minghong;Wierman, Adam;Andrew, Lachlan L.H.;Thereska, Eno",19640586400;8148116600;7005545530;6504212554,60031581;60031581;60030804;60021726,2011-01-01,2011,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,,,5934885,1098-1106,"Power consumption imposes a significant cost for data centers implementing cloud services, yet much of that power is used to maintain excess service capacity during periods of predictably low load. This paper investigates how much can be saved by dynamically right-sizing the data center by turning off servers during such periods, and how to achieve that saving via an online algorithm. We prove that the optimal offline algorithm for dynamic right-sizing has a simple structure when viewed in reverse time, and this structure is exploited to develop a new lazy online algorithm, which is proven to be 3-competitive. We validate the algorithm using traces from two real data center workloads and show that significant cost-savings are possible. © 2011 IEEE.",,339,0,,,,undefined,,INFOCOM Networking
2-s2.0-80053585939,10.1145/2030613.2030637,,,E-MiLi: Energy-minimizing idle listening in wireless networks,cp,Conference Paper,Zhang X.,60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,2,"Zhang, Xinyu;Shin, Kang G.",57774583900;36079966700,60025778;60025778,2011-10-12,2011,"Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM",,70461,,Conference Proceeding,,,,205-216,"WiFi interface is known to be a primary energy consumer in mobile devices, and idle listening (IL) is the dominant source of energy consumption in WiFi. Most existing protocols, such as the 802.11 power-saving mode (PSM), attempt to reduce the time spent in IL by sleep scheduling. However, through an extensive analysis of real-world traffic, we found more than 60% of energy is consumed in IL, even with PSM enabled. To remedy this problem, we propose E-MiLi (Energy-Minimizing idle Listening) that reduces the power consumption in IL, given that the time spent in IL has already been optimized by sleep scheduling. Observing that radio power consumption decreases proportionally to its clock-rate, E-MiLi adaptively downclocks the radio during IL, and reverts to full clock-rate when an incoming packet is detected or a packet has to be transmitted. E-MiLi incorporates sampling rate invariant detection, ensuring accurate packet detection and address filtering even when the receiver's sampling clock-rate is much lower than the signal bandwidth. Further, it employs an opportunistic downclocking mechanism to optimize the efficiency of switching clock-rate, based on a simple interface to existing MAC-layer scheduling protocols. We have implemented E-MiLi on the USRP software radio platform. Our experimental evaluation shows that E-MiLi can detect packets with close to 100% accuracy even with downclocking by a factor of 16. When integrated with 802.11, E-MiLi can reduce energy consumption by around 44% for 92% of users in real-world wireless networks. © 2011 ACM.",adapting clock-rate | CSMA wireless networks | dynamic frequency scaling | energy efficiency | idle listening | packet detection,75,0,,,,undefined,,MOBICOM Mobile
2-s2.0-79958113800,10.1145/1978942.1979402,,,Ease of juggling: Studying the effects of manual multitasking,cp,Conference Paper,Oulasvirta A.,60002952;60000944,Helsingin Yliopisto;Helsinki Institute for Information Technology,Helsinki;Helsinki,Finland;Finland,2,"Oulasvirta, Antti;Bergstrom-Lehtovirta, Joanna",13006124600;35221233900,60000944-60002952;60000944-60002952,2011-01-01,2011,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,3103-3112,"Everyday activities often involve using an interactive device while one is handling various other physical objects (wallets, bags, doors, pens, mugs, etc.). This paper presents the Manual Multitasking Test, a test with 12 conditions emulating manual demands of everyday multitasking situations. It allows experimenters to expose the effects of design on ""manual flexibility"": users' ability to reconfigure the sensorimotor control of arms, hands, and fingers in order to regain the high performance levels they experience when using the device on its own. The test was deployed for pointing devices on laptops and Qwerty keyboards of mobile devices. In these studies, we identified facilitative design features whose absence explains, for example, why the mouse and stylus function poorly in multi-object performance. The issue deserves more attention, because interfaces that are nominally similar (e.g., ""one-handed input"") can vary dramatically in terms of ""ease of juggling"". Copyright 2011 ACM.",Evaluation | Human-computer interaction | Interface design | Multi-object manual performance | Multitasking | Usability,27,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-79958079535,10.1145/1978942.1979364,,,Effects of community size and contact rate in synchronous social Q&amp;A,cp,Conference Paper,White R.W.,60027950;60021726,Carnegie Mellon University;Microsoft Research,Pittsburgh;Redmond,United States;United States,3,"White, Ryen W.;Richardson, Matthew;Liu, Yandong",7501422012;36139751700;25825193700,60021726;60021726;60027950,2011-01-01,2011,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,2837-2846,"Social question-and-answer (Q&A) involves the location of answers to questions through communication with people. Social Q&A systems, such as mailing lists and Web forums are popular, but their asynchronous nature can lead to high answer latency. Synchronous Q&A systems facilitate realtime dialog, usually via instant messaging, but face challenges with interruption costs and the availability of knowledgeable answerers at question time. We ran a longitudinal study of a synchronous social Q&A system to investigate the effects of the rate with which potential answerers were contacted (trading off time-to-answer against interruption cost) and community size (varying total number of members). We found important differences in subjective and objective measures of system performance with these variations. Our findings help us understand the costs and benefits of varying contact rate and community size in synchronous social Q&A, and inform system design for social Q&A. Copyright 2011 ACM.",Community size | Contact rate | Synchronous social Q&amp;A,32,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-79959727901,10.1145/1993636.1993674,,,"Electrical flows, Laplacian systems, and faster approximation of maximum flow in undirected graphs",cp,Conference Paper,Christiano P.,60157832;60022195;122498146,Yale School of Engineering &amp; Applied Science;Massachusetts Institute of Technology;USC,New Haven;Cambridge;Los Angeles,United States;United States;United States,5,"Christiano, Paul;Kelner, Jonathan A.;Madry, Aleksander;Spielman, Daniel A.;Teng, Shang Hua",58707861600;6603724487;24171757000;7006769771;7102993292,60022195;60022195;60022195;60157832;122498146,2011-01-01,2011,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,273-281,"We introduce a new approach to computing an approximately maximum s-t flow in a capacitated, undirected graph. This flow is computed by solving a sequence of electrical flow problems. Each electrical flow is given by the solution of a system of linear equations in a Laplacian matrix, and thus may be approximately computed in nearly-linear time. Using this approach, we develop the fastest known algorithm for computing approximately maximum s-t flows. For a graph having n vertices and m edges, our algorithm computes a (1-∈)-approximately maximum s-t flow in time ∼O(mn1/3∈-11/3). A dual version of our approach gives the fastest known algorithm for computing a (1+∈)-approximately minimum s-t cut. It takes ∼O(m+n 4/3∈-16/3) time. Previously, the best dependence on m and n was achieved by the algorithm of Goldberg and Rao (J. ACM 1998), which can be used to compute approximately maximum s-t flows in time ∼O({m√n∈-1), and approximately minimum s-t cuts in time ∼O(m+n3/2∈-3). © 2011 ACM.",electrical flows | laplacian linear systems | maximum flows | minimum cuts | multiplicative weights update method,190,1,repositoryam,Green,CISE,0634904,Directorate for Computer and Information Science and Engineering,STOC Theory
2-s2.0-79958125839,10.1145/1978942.1979306,,,Enhancing physicality in touch interaction with programmable friction,cp,Conference Paper,Lévesque V.,60020585;60010365;60007363,University of Canterbury;The University of British Columbia;Northwestern University,Christchurch;Vancouver;Evanston,New Zealand;Canada;United States,8,"Lévesque, Vincent;Oram, Louise;MacLean, Karon;Cockburn, Andy;Marchuk, Nicholas D.;Johnson, Dan;Colgate, J. Edward;Peshkin, Michael A.",14035803000;37075507700;7006153893;7004557137;36080790900;57236142600;7005034076;7006115678,60010365;60010365;60010365;60020585;60007363;60007363;60007363;60007363,2011-01-01,2011,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,2481-2490,"Touch interactions have refreshed some of the 'glowing enthusiasm' of thirty years ago for direct manipulation interfaces. However, today's touch technologies, whose interactions are supported by graphics, sounds or crude clicks, have a tactile sameness and gaps in usability. We use a Large Area Tactile Pattern Display (LATPaD) to examine design possibilities and outcomes when touch interactions are enhanced with variable surface friction. In a series of four studies, we first confirm that variable friction gives significant performance advantages in low-level targeting activities. We then explore the design space of variable friction interface controls and assess user reactions. Most importantly, we demonstrate that variable friction can have a positive impact on the enjoyment, engagement and sense of realism experienced by users of touch interfaces. Copyright 2011 ACM.",Haptics | Tactile feedback | Touch screen,120,0,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-79959993857,10.1145/1989323.1989394,,,Entangled queries: Enabling declarative data-driven coordination,cp,Conference Paper,Gupta N.,60028186;60007776,École Polytechnique Fédérale de Lausanne;Cornell University,Lausanne;Ithaca,Switzerland;United States,6,"Gupta, Nitin;Kot, Lucja;Roy, Sudip;Bender, Gabriel;Gehrke, Johannes;Koch, Christoph",35310625700;9434110700;56818257600;42260952700;7006822445;56353512400,60007776;60007776;60007776;60007776;60007776;60028186,2011-01-01,2011,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,673-684,"Many data-driven social and Web applications involve collaboration and coordination. The vision of declarative data-driven coordination (D3C), proposed in [9], is to support coordination in the spirit of data management: to make it data-centric and to specify it using convenient declarative languages. This paper introduces entangled queries, a language that extends SQL by constraints that allow for the coordinated choice of result tuples across queries originating from different users or applications. It is nontrivial to define a declarative coordination formalism without arriving at the general (NP-complete) Constraint Satisfaction Problem from AI. In this paper, we propose an efficiently enforcible syntactic safety condition that we argue is at the sweet spot where interesting declarative power meets applicability in large scale data management systems and applications. The key computational problem of D3C is to match entangled queries to achieve coordination. We present an efficient matching algorithm which statically analyzes query workloads and merges coordinating entangled queries into compound SQL queries. These can be sent to a standard database system and return only coordinated results. We present the overall architecture of an implemented system that contains our evaluation algorithm; we also evaluate the performance of the matching algorithm experimentally on realistic coordination workloads. © 2011 ACM.",coordination | D3C | entangled queries,13,0,,,CISE,0534404,Directorate for Computer and Information Science and Engineering,SIGMOD Databases
2-s2.0-80052112523,10.1145/2009916.2009965,,,Find it if you can: A game for modeling different types of web search success using interaction data,cp,Conference Paper,Ageev M.,60007457;60000928,Lomonosov Moscow State University;Emory University,Moscow;Atlanta,Russian Federation;United States,4,"Ageev, Mikhail;Guo, Qi;Lagun, Dmitry;Agichtein, Eugene",36874321200;55459993800;36727735000;6603264513,60007457;60000928;60000928;60000928,2011-01-01,2011,SIGIR'11 - Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval,,19900193706,,Conference Proceeding,,,,345-354,"A better understanding of strategies and behavior of successful searchers is crucial for improving the experience of all searchers. However, research of search behavior has been struggling with the tension between the relatively small-scale, but controlled lab studies, and the large-scale log-based studies where the searcher intent and many other important factors have to be inferred. We present our solution for performing controlled, yet realistic, scalable, and reproducible studies of searcher behavior. We focus on difficult informational tasks, which tend to frustrate many users of the current web search technology. First, we propose a principled formalization of different types of ""success"" for informational search, which encapsulate and sharpen previously proposed models. Second, we present a scalable game-like infrastructure for crowdsourcing search behavior studies, specifically targeted towards capturing and evaluating successful search strategies on informational tasks with known intent. Third, we report our analysis of search success using these data, which confirm and extends previous findings. Finally, we demonstrate that our model can predict search success more effectively than the existing state-of-the-art methods, on both our data and on a different set of log data collected from regular search engine sessions. Together, our search success models, the data collection infrastructure, and the associated behavior analysis techniques, significantly advance the study of success in web search.",Query log analysis | User studies | Web search success,107,0,,,,undefined,,SIGIR Information Retrieval
2-s2.0-80053200028,10.1145/2025113.2025121,,,How do fixes become bugs? A comprehensive characteristic study on incorrect fixes in commercial and open source operating systems,cp,Conference Paper,Yin Z.,60158506;60121653;60082946,"The Grainger College of Engineering;Department of Computer Science and Engineering;NetApp, USA",Urbana;La Jolla;Sunnyvale,United States;United States;United States,5,"Yin, Zuoning;Yuan, Ding;Zhou, Yuanyuan;Pasupathy, Shankar;Bairavasundaram, Lakshmi",36663103900;23986872900;7405365838;23009792300;6508364647,60158506;60158506;60121653;60082946;60082946,2011-09-30,2011,SIGSOFT/FSE 2011 - Proceedings of the 19th ACM SIGSOFT Symposium on Foundations of Software Engineering,,21100262319,,Conference Proceeding,,,,26-36,"Software bugs affect system reliability. When a bug is exposed in the field, developers need to fix them. Unfortunately, the bug-fixing process can also introduce errors, which leads to buggy patches that further aggravate the damage to end users and erode software vendors'reputation. This paper presents a comprehensive characteristic study on incorrect bug-fixes from large operating system code bases including Linux, OpenSolaris, FreeBSD and also a mature commercial OS developed and evolved over the last 12 years, investigating not only themistake patterns during bug-fixing but also the possible human reasons in the development process when these incorrect bug-fixes were introduced. Our major findings include: (1) at least 14.8%∼24.4% of sampled fixes for post-release bugs in these large OSes are incorrect and have made impacts to end users. (2) Among several common bug types, concurrency bugs are the most difficult to fix correctly: 39% of concurrency bug fixes are incorrect. (3) Developers and reviewers for incorrect fixes usually do not have enough knowledge about the involved code. For example, 27% of the incorrect fixes are made by developers who have never touched the source code files associated with the fix. Our results provide useful guidelines to design new tools and also to improve the development process. Based on our findings, the commercial software vendor whose OS code we evaluated is building a tool to improve the bug fixing and code reviewing process. © 2011 ACM.",Bug fixing | Human factor | Incorrect fixes | Software bugs | Testing,163,0,,,,undefined,,FSE Software Engineering
2-s2.0-79958121660,10.1145/1978942.1979044,,,In the shadow of misperception: Assistive technology use and social interactions,cp,Conference Paper,Shinohara K.,60015481,University of Washington,Seattle,United States,2,"Shinohara, Kristen;Wobbrock, Jacob O.",16239695600;6603152369,60015481;60015481,2011-01-01,2011,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,705-714,"Few research studies focus on how the use of assistive technologies is affected by social interaction among people. We present an interview study of 20 individuals to determine how assistive technology use is affected by social and professional contexts and interactions. We found that specific assistive devices sometimes marked their users as having disabilities; that functional access took priority over feeling self-conscious when using assistive technologies; and that two misperceptions pervaded assistive technology use: (1) that assistive devices could functionally eliminate a disability, and (2) that people with disabilities would be helpless without their devices. Our findings provide further evidence that accessibility should be built into mainstream technologies. When this is not feasible, assistive devices should incorporate cutting edge technologies and strive to be designed for social acceptability, a new design approach we propose here. Copyright 2011 ACM.",Accessibility | Assistive devices | Interface design | Product design | Social interactions | Stigma,336,0,,,NSF,0952786,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-83055181838,10.1145/2063576.2063619,,,Intent-aware query similarity,cp,Conference Paper,Guo J.,60098464;60030904,Microsoft Research Asia;Institute of Computing Technology Chinese Academy of Sciences,Beijing;Beijing,China;China,4,"Guo, Jiafeng;Cheng, Xueqi;Xu, Gu;Zhu, Xiaofei",24174196100;55855927900;55983126200;57309131600,60030904;60030904;60098464;60030904,2011-12-13,2011,"International Conference on Information and Knowledge Management, Proceedings",,55826,,Conference Proceeding,,,,259-268,"Query similarity calculation is an important problem and has a wide range of applications in IR, including query recommendation, query expansion, and even advertisement matching. Existing work on query similarity aims to provide a single similarity measure without considering the fact that queries are ambiguous and usually have multiple search intents. In this paper, we argue that query similarity should be defined upon search intents, so-called intent-aware query similarity. By introducing search intents into the calculation of query similarity, we can obtain more accurate and also informative similarity measures on queries and thus help a variety of applications, especially those related to diversification. Specifically, we first identify the potential search intents of queries, and then measure query similarity under different intents using intent-aware representations. A regularized topic model is employed to automatically learn the potential intents of queries by using both the words from search result snippets and the regularization from query co-clicks. Experimental results confirm the effectiveness of intent-aware query similarity on ambiguous queries which can provide significantly better similarity scores over the traditional approaches. We also experimentally verified the utility of intent-aware similarity in the application of query recommendation, which can suggest diverse queries in a structured way to search users. © 2011 ACM.",graph-based measure | pair-wise measure | query similarity | regularized topic model | search intent,48,0,,,,undefined,,CIKM Knowledge Management
2-s2.0-80052651220,10.1145/2020408.2020496,,,"Leakage in data mining: Formulation, detection, and avoidance",cp,Conference Paper,Kaufman S.,60005681;113983409,Tel Aviv University;Media6Degrees,Tel Aviv-Yafo;New York,Israel;United States,3,"Kaufman, Shachar;Rosset, Saharon;Perlich, Claudia",50161687400;7004738103;14831800300,60005681;60005681;113983409,2011-01-01,2011,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,101510,,Conference Proceeding,,,,556-563,"Deemed ""one of the top ten data mining mistakes"", leakage is essentially the introduction of information about the data mining target, which should not be legitimately available to mine from. In addition to our own industry experience with real-life projects, controversies around several major public data mining competi-tions held recently such as the INFORMS 2010 Data Mining Challenge and the IJCNN 2011 Social Network Challenge are evidence that this issue is as relevant today as it has ever been. While acknowledging the importance and prevalence of leakage in both synthetic competitions and real-life data mining projects, existing literature has largely left this idea unexplored. What little has been said turns out not to be broad enough to cover more complex cases of leakage, such as those where the classical i.i.d. assumption is violated, that have been recently documented. In our new approach, these cases and others are explained by expli-citly defining modeling goals and analyzing the broader frame-work of the data mining problem. The resulting definition enables us to derive general methodology for dealing with the issue. We show that it is possible to avoid leakage with a simple specific approach to data management followed by what we call a learn-predict separation, and present several ways of detecting leakage when the modeler has no control over how the data have been collected. Copyright 2011 ACM.",Data mining | Leakage | Predictive modeling | Statistical inference,90,0,,,,undefined,,KDD Data Mining
2-s2.0-79958092458,10.1145/1978942.1978969,,,Mid-air pan-and-zoom on wall-sized displays,cp,Conference Paper,Nancel M.,60276635;60013373,Laboratoire Interdisciplinaire des Sciences du Numérique;INRIA Institut National de Recherche en Informatique et en Automatique,Orsay;Le Chesnay,France;France,5,"Nancel, Mathieu;Wagner, Julie;Pietriga, Emmanuel;Chapuis, Olivier;Mackay, Wendy",35264652600;55456622100;55918895300;55919438800;7102699682,60276635-60013373;60276635-60013373;60276635-60013373;60276635-60013373;60276635-60013373,2011-01-01,2011,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,177-186,"Very-high-resolution wall-sized displays offer new opportunities for interacting with large data sets. While pointing on this type of display has been studied extensively, higherlevel, more complex tasks such as pan-zoom navigation have received little attention. It thus remains unclear which techniques are best suited to perform multiscale navigation in these environments. Building upon empirical data gathered from studies of pan-and-zoom on desktop computers and studies of remote pointing, we identified three key factors for the design of mid-air pan-and-zoom techniques: univs. bimanual interaction, linear vs. circular movements, and level of guidance to accomplish the gestures in mid-air. After an extensive phase of iterative design and pilot testing, we ran a controlled experiment aimed at better understanding the influence of these factors on task performance. Significant effects were obtained for all three factors: bimanual interaction, linear gestures and a high level of guidance resulted in significantly improved performance. Moreover, the interaction effects among some of the dimensions suggest possible combinations for more complex, real-world tasks. Copyright 2011 ACM.",Mid-air interaction techniques | Multi-scale interfaces | Navigation | Pan &amp; zoom | Wall-sized displays,155,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84881043243,10.5591/978-1-57735-516-8/IJCAI11-115,,,Nested rollout policy adaptation for Monte Carlo tree search,cp,Conference Paper,Rosin C.D.,60104454,Parity Computing,San Diego,United States,1,"Rosin, Christopher D.",6701904588,60104454,2011-12-01,2011,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,649-654,"Monte Carlo tree search (MCTS) methods have had recent success in games, planning, and optimization. MCTS uses results from rollouts to guide search; a rollout is a path that descends the tree with a randomized decision at each ply until reaching a leaf. MCTS results can be strongly influenced by the choice of appropriate policy to bias the rollouts. Most previous work on MCTS uses static uniform random or domain-specific policies. We describe a new MCTS method that dynamically adapts the rollout policy during search, in deterministic optimization problems. Our starting point is Cazenave's original Nested Monte Carlo Search (NMCS), but rather than navigating the tree directly we instead use gradient ascent on the rollout policy at each level of the nested search. We benchmark this new Nested Rollout Policy Adaptation (NRPA) algorithm and examine its behavior. Our test problems are instances of Crossword Puzzle Construction and Morpion Solitaire. Over moderate time scales NRPA can substantially improve search efficiency compared to NMCS, and over longer time scales NRPA improves upon all previous published solutions for the test problems. Results include a new Morpion Solitaire solution that improves upon the previous human-generated record that had stood for over 30 years.",,87,0,,,DARPA,undefined,Defense Advanced Research Projects Agency,IJCAI Artificial Intelligence
2-s2.0-84878799762,10.5591/978-1-57735-516-8/IJCAI11-165,,,On the decidability of connectedness constraints in 2D and 3D euclidean spaces,cp,Conference Paper,Kontchakov R.,60009016;60003771,"Birkbeck, University of London;The University of Manchester",London;Manchester,United Kingdom;United Kingdom,4,"Kontchakov, Roman;Nenov, Yavor;Pratt-Hartmann, Ian;Zakharyaschev, Michael",23008721700;36473927400;7801463305;6602982360,60009016;60003771;60003771;60009016,2011-12-01,2011,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,957-962,"We investigate (quantifier-free) spatial constraint languages with equality, contact and connectedness predicates, as well as Boolean operations on regions, interpreted over low-dimensional Euclidean spaces. We show that the complexity of reasoning varies dramatically depending on the dimension of the space and on the type of regions considered. For example, the logic with the interior-connectedness predicate (and without contact) is undecidable over polygons or regular closed sets in ℝ2, EXPTIME-complete over polyhedra in ℝ3, and NP-complete over regular closed sets in ℝ3.",,10,0,,,EPSRC,EP/E034942/1,Engineering and Physical Sciences Research Council,IJCAI Artificial Intelligence
2-s2.0-79959861140,10.1145/1985793.1985819,,,On-demand feature recommendations derived from mining public product descriptions,cp,Conference Paper,Dumitru H.,60026860,DePaul University,Chicago,United States,7,"Dumitru, Horatiu;Gibiec, Marek;Hariri, Negar;Cleland-Huang, Jane;Mobasher, Bamshad;Castro-Herrera, Carlos;Mirakhorli, Mehdi",35078382100;36175855900;35092426700;6506741859;7006824941;25929040000;23390242500,60026860;60026860;60026860;60026860;60026860;60026860;60026860,2011-07-07,2011,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,181-190,"We present a recommender system that models and recommends product features for a given domain. Our approach mines product descriptions from publicly available online specifications, utilizes text mining and a novel incremental diffusive clustering algorithm to discover domain-specific features, generates a probabilistic feature model that represents commonalities, variants, and cross-category features, and then uses association rule mining and the k-Nearest-Neighbor machine learning strategy to generate product specific feature recommendations. Our recommender system supports the relatively labor-intensive task of domain analysis, potentially increasing opportunities for re-use, reducing time-to-market, and delivering more competitive software products. The approach is empirically validated against 20 different product categories using thousands of product descriptions mined from a repository of free software applications. © 2011 ACM.",clustering | domain analysis | recommender systems,132,0,,,,undefined,,ICSE Software Engineering
2-s2.0-80051967189,10.1109/SP.2011.34,,,Phonotactic reconstruction of encrypted VoIP conversations: Hookt on fon-iks,cp,Conference Paper,White A.M.,60142067;60025111,Department of Computer Science;The University of North Carolina at Chapel Hill,Chapel Hill;Chapel Hill,United States;United States,4,"White, Andrew M.;Matthews, Austin R.;Snow, Kevin Z.;Monrose, Fabian",55473147700;48361539700;35175203100;8943339800,60142067;60142067-60025111;60142067;60142067,2011-01-01,2011,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,,,5958018,3-18,"In this work, we unveil new privacy threats against Voice-over-IP (VoIP) communications. Although prior work has shown that the interaction of variable bit-rate codecs and length-preserving stream ciphers leaks information, we show that the threat is more serious than previously thought. In particular, we derive approximate transcripts of encrypted VoIP conversations by segmenting an observed packet stream into subsequences representing individual phonemes and classifying those subsequences by the phonemes they encode. Drawing on insights from the computational linguistics and speech recognition communities, we apply novel techniques for unmasking parts of the conversation. We believe our ability to do so underscores the importance of designing secure (yet efficient) ways to protect the confidentiality of VoIP conversations. © 2011 IEEE.",,87,0,,,,undefined,,S&P Security and Privacy
2-s2.0-80053218147,10.1145/2025113.2025139,,,Proactive detection of collaboration conflicts,cp,Conference Paper,Brun Y.,60015481;60014171,University of Washington;University of Waterloo,Seattle;Waterloo,United States;Canada,4,"Brun, Yuriy;Holmes, Reid;Ernst, Michael D.;Notkin, David",23003307600;56220448900;36916423000;7004090547,60015481;60014171;60015481;60015481,2011-01-01,2011,SIGSOFT/FSE 2011 - Proceedings of the 19th ACM SIGSOFT Symposium on Foundations of Software Engineering,,21100262319,,Conference Proceeding,,,,168-178,"Collaborative development can be hampered when conflicts arise because developers have inconsistent copies of a shared project. We present an approach to help developers identify and resolve conflicts early, before those conflicts become severe and before relevant changes fade away in the developers'memories. This paper presents three results. First, a study of open-source systems establishes that conflicts are frequent, persistent, and appear not only as overlapping textual edits but also as subsequent build and test failures. The study spans nine open-source systems totaling 3.4 million lines of code; our conflict data is derived from 550,000 development versions of the systems. Second, using previously-unexploited information, we precisely diagnose important classes of conflicts using the novel technique of speculative analysis over version control operations. Third, we describe the design of Crystal, a publicly-available tool that uses speculative analysis to make concrete advice unobtrusively available to developers, helping them identify, manage, and prevent conflicts. © 2011 ACM.",Collaboration conflicts | Collaborative development | Crystal | Developer awareness | Speculative analysis | Version control,157,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-79959901246,10.1145/1985793.1985847,,,"Programs, tests, and oracles: The foundations of testing revisited",cp,Conference Paper,Staats M.,60029445,University of Minnesota Twin Cities,Minneapolis,United States,3,"Staats, Matt;Whalen, Michael W.;Heimdahl, Mats P.E.",25648207100;57210717052;6701804858,60029445;60029445;60029445,2011-07-07,2011,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,391-400,"In previous decades, researchers have explored the formal foundations of program testing. By exploring the foundations of testing largely separate from any specific method of testing, these researchers provided a general discussion of the testing process, including the goals, the underlying problems, and the limitations of testing. Unfortunately, a common, rigorous foundation has not been widely adopted in empirical software testing research, making it difficult to generalize and compare empirical research. We continue this foundational work, providing a framework intended to serve as a guide for future discussions and empirical studies concerning software testing. Specifically, we extend Gourlay's functional description of testing with the notion of a test oracle, an aspect of testing largely overlooked in previous foundational work and only lightly explored in general. We argue additional work exploring the interrelationship between programs, tests, and oracles should be performed, and use our extension to clarify concepts presented in previous work, present new concepts related to test oracles, and demonstrate that oracle selection must be considered when discussing the efficacy of a testing process. © 2011 ACM.",testing formalism | theory of testing,78,0,,,CISE,0916583,Directorate for Computer and Information Science and Engineering,ICSE Software Engineering
2-s2.0-80053201999,10.1145/2025113.2025131,,,Proving programs robust,cp,Conference Paper,Chaudhuri S.,60021726;60005286;60001439,Microsoft Research;Rice University;Pennsylvania State University,Redmond;Houston;University Park,United States;United States;United States,4,"Chaudhuri, Swarat;Gulwani, Sumit;Lublinerman, Roberto;Navidpour, Sara",8727948900;55901318200;15623422700;24829672200,60005286;60021726;60001439;60001439,2011-09-30,2011,SIGSOFT/FSE 2011 - Proceedings of the 19th ACM SIGSOFT Symposium on Foundations of Software Engineering,,21100262319,,Conference Proceeding,,,,102-112,"We present a program analysis for verifying quantitative robustness properties of programs, stated generally as: ""If the inputs of a program are perturbed by an arbitrary amount ε, then its outputs change at most by K ε, where K can depend on the size of the input but not its value. Robustness properties generalize the analytic notion of continuity-e.g., while the function ex is continuous, it is not robust. Our problem is to verify the robustness of a function P that is coded as an imperative program, and can use diverse data types and features such as branches and loops. Our approach to the problem soundly decomposes it into two subproblems: (a) verifying that the smallest possible perturbations to the inputs of P do not change the corresponding outputs significantly, even if control now flows along a different control path; and (b) verifying the robustness of the computation along each control-flow path of P. To solve the former subproblem, we build on an existing method for verifying that a program encodes a continuous function [5]. The latter is solved using a static analysis that bounds the magnitude of the slope of any function computed by a control flow path of P. The outcome is a sound program analysis for robustness that uses proof obligations which do not refer to ε-changes and can often be fully automated using off-the-shelf SMT-solvers. We identify three application domains for our analysis. First, our analysis can be used to guarantee the predictable execution of embedded control software, whose inputs come from physical sources and can suffer from error and uncertainty. A guarantee of robustness ensures that the system does not react disproportionately to such uncertainty. Second, our analysis is directly applicable to approximate computation, and can be used to provide foundations for a recently-proposed program approximation scheme called {loop perforation}. A third application is in database privacy: proofs of robustness of queries are essential to differential privacy, the most popular notion of privacy for statistical databases. © 2011 ACM.",Continuity | Lipschitz | Perturbations | Program approximation | Quantitative program analysis | Robustness | Sensitivity | Uncertainty,89,0,,,,undefined,,FSE Software Engineering
2-s2.0-80052878786,10.1109/CVPR.2011.5995316,,,Real-time human pose recognition in parts from single depth images,cp,Conference Paper,Shotton J.,60098463,Microsoft Research Cambridge,Cambridge,United Kingdom,8,"Shotton, Jamie;Fitzgibbon, Andrew;Cook, Mat;Sharp, Toby;Finocchio, Mark;Moore, Richard;Kipman, Alex;Blake, Andrew",23019722900;56355070900;52263605400;24829727400;50561312900;57199008628;52263660000;7201402207,60098463;60098463;60098463;60098463;60098463;60098463;60098463;60098463,2011-01-01,2011,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,,,5995316,1297-1304,"We propose a new method to quickly and accurately predict 3D positions of body joints from a single depth image, using no temporal information. We take an object recognition approach, designing an intermediate body parts representation that maps the difficult pose estimation problem into a simpler per-pixel classification problem. Our large and highly varied training dataset allows the classifier to estimate body parts invariant to pose, body shape, clothing, etc. Finally we generate confidence-scored 3D proposals of several body joints by reprojecting the classification result and finding local modes. The system runs at 200 frames per second on consumer hardware. Our evaluation shows high accuracy on both synthetic and real test sets, and investigates the effect of several training parameters. We achieve state of the art accuracy in our comparison with related work and demonstrate improved generalization over exact whole-skeleton nearest neighbor matching. © 2011 IEEE.",,2778,0,repositoryam,Green,,undefined,,CVPR Computer Vision
2-s2.0-84856670612,10.1109/ICCV.2011.6126281,,,Relative attributes,cp,Conference Paper,Parikh D.,60074721;60013372,Toyota Technological Institute at Chicago;The University of Texas at Austin,Chicago;Austin,United States;United States,2,"Parikh, Devi;Grauman, Kristen",22234699400;6506707692,60074721;60013372,2011-12-01,2011,Proceedings of the IEEE International Conference on Computer Vision,,110561,,Conference Proceeding,,,6126281,503-510,"Human-nameable visual ""attributes"" can benefit various recognition tasks. However, existing techniques restrict these properties to categorical labels (for example, a person is smiling or not, a scene is dry or not), and thus fail to capture more general semantic relationships. We propose to model relative attributes. Given training data stating how object/scene categories relate according to different attributes, we learn a ranking function per attribute. The learned ranking functions predict the relative strength of each property in novel images. We then build a generative model over the joint space of attribute ranking outputs, and propose a novel form of zero-shot learning in which the supervisor relates the unseen object category to previously seen objects via attributes (for example, bears are furrier than giraffes). We further show how the proposed relative attributes enable richer textual descriptions for new images, which in practice are more precise for human interpretation. We demonstrate the approach on datasets of faces and natural scenes, and show its clear advantages over traditional binary attribute prediction for these new tasks. © 2011 IEEE.",,752,0,,,,undefined,,ICCV Computer Vision
2-s2.0-84858761980,10.14778/3402707.3402714,,,RemusDB: Transparent high availability for database systems,cp,Conference Paper,Minhas U.F.,60014171;60010365,University of Waterloo;The University of British Columbia,Waterloo;Vancouver,Canada;Canada,6,"Minhas, Umar Farooq;Rajagopalan, Shriram;Cully, Brendan;Aboulnaga, Ashraf;Salem, Kenneth;Warfield, Andrew",24725343600;7103018793;24337289000;21742040900;7003632842;6601955007,60014171;60010365;60010365;60014171;60014171;60010365,2011-01-01,August 2011,Proceedings of the VLDB Endowment,,21100199855,21508097,Journal,4,11,,737-748,"In this paper we present a technique for building a high-availability (HA) database management system (DBMS). The proposed technique can be applied to any DBMS with little or no customization, and with reasonable performance overhead. Our approach is based on Remus, a commodity HA solution implemented in the virtualization layer, that uses asynchronous virtual machine (VM) state replication to provide transparent HA and failover capabilities. We show that while Remus and similar systems can protect a DBMS, database workloads incur a performance overhead of up to 32% as compared to an unprotected DBMS. We identify the sources of this overhead and develop optimizations that mitigate the problems. We present an experimental evaluation using two popular database systems and industry standard benchmarks showing that for certain workloads, our optimized approach provides very fast failover (≤ 3 seconds of downtime) with low performance overhead when compared to an unprotected DBMS. Our approach provides a practical means for existing, deployed database systems to be made more reliable with a minimum of risk, cost, and effort. Furthermore, this paper invites new discussion about whether the complexity of HA is best implemented within the DBMS, or as a service by the infrastructure below it. © 2011 VLDB Endowment.",,29,1,publisherfree2read,Bronze,,undefined,,VLDB Databases
2-s2.0-79958165352,10.1145/1978942.1979167,,,Review Spotlight: A user interface for summarizing user-generated reviews using adjective-noun word pairs,cp,Conference Paper,Yatani K.,60016849,University of Toronto,Toronto,Canada,4,"Yatani, Koji;Novati, Michael;Trusty, Andrew;Truong, Khai N.",55926070600;39361898300;39362693500;7005764228,60016849;60016849;60016849;60016849,2011-01-01,2011,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1541-1550,"Many people read online reviews written by other users to learn more about a product or venue. However, the overwhelming amount of user-generated reviews and variance in length, detail and quality across the reviews make it difficult to glean useful information. In this paper, we present the iterative design of our system, called Review Spotlight. It provides a brief overview of reviews using adjective-noun word pairs, and allows the user to quickly explore the reviews in greater detail. Through a laboratory user study which required participants to perform decision making tasks, we showed that participants could form detailed impressions about restaurants and decide between two options significantly faster with Review Spotlight than with traditional review webpages. Copyright 2011 ACM.",Natural language processing | Summarization | User interface | User-generated reviews | Word pairs,60,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-79959900961,10.1145/1985793.1985840,,,Run-time efficient probabilistic model checking,cp,Conference Paper,Filieri A.,60023256,Politecnico di Milano,Milan,Italy,3,"Filieri, Antonio;Ghezzi, Carlo;Tamburrelli, Giordano",36170481900;16512874900;30567801500,60023256;60023256;60023256,2011-07-07,2011,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,341-350,"Unpredictable changes continuously affect software systems and may have a severe impact on their quality of service, potentially jeopardizing the system's ability to meet the desired requirements. Changes may occur in critical components of the system, clients' operational profiles, requirements, or deployment environments. The adoption of software models and model checking techniques at run time may support automatic reasoning about such changes, detect harmful configurations, and potentially enable appropriate (self-)reactions. However, traditional model checking techniques and tools may not be simply applied as they are at run time, since they hardly meet the constraints imposed by on-the-fly analysis, in terms of execution time and memory occupation. This paper precisely addresses this issue and focuses on reliability models, given in terms of Discrete Time Markov Chains, and probabilistic model checking. It develops a mathematical framework for run-time probabilistic model checking that, given a reliability model and a set of requirements, statically generates a set of expressions, which can be efficiently used at run-time to verify system requirements. An experimental comparison of our approach with existing probabilistic model checkers shows its practical applicability in run-time verification. © 2011 ACM.",discrete time markov chains | run-time model checking,159,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-85029391728,,,,ServerSwitch: A programmable and high performance platform for data center networks,cp,Conference Paper,Lu G.,60098464;60025278,Microsoft Research Asia;Tsinghua University,Beijing;Beijing,China;China,9,"Lu, Guohan;Guo, Chuanxiong;Li, Yulong;Zhou, Zhiqiang;Yuan, Tong;Wu, Haitao;Xiong, Yongqiang;Gao, Rui;Zhang, Yongguang",35183541300;7402497048;57212410047;57212407994;57212409115;7405581009;35207647800;57203297508;7601319429,60098464;60098464;60098464;60025278;60098464;60098464;60098464;60098464;60098464,2011-01-01,2011,Proceedings of NSDI 2011: 8th USENIX Symposium on Networked Systems Design and Implementation,,21100939102,,Conference Proceeding,,,,15-28,"As one of the fundamental infrastructures for cloud computing, data center networks (DCN) have recently been studied extensively. We currently use pure software-based systems, FPGA based platforms, e.g., NetFPGA, or OpenFlow switches, to implement and evaluate various DCN designs including topology design, control plane and routing, and congestion control. However, software-based approaches suffer from high CPU overhead and processing latency; FPGA based platforms are difficult to program and incur high cost; and OpenFlow focuses on control plane functions at present. In this paper, we design a ServerSwitch to address the above problems. ServerSwitch is motivated by the observation that commodity Ethernet switching chips are becoming programmable and that the PCI-E interface provides high throughput and low latency between the server CPU and I/O subsystem. ServerSwitch uses a commodity switching chip for various customized packet forwarding, and leverages the server CPU for control and data plane packet processing, due to the low latency and high throughput between the switching chip and server CPU. We have built our ServerSwitch at low cost. Our experiments demonstrate that ServerSwitch is fully programmable and achieves high performance. Specifically, we have implemented various forwarding schemes including source routing in hardware. Our in-network caching experiment showed high throughput and flexible data processing. Our QCN (Quantized Congestion Notification) implementation further demonstrated that ServerSwitch can react to network congestions in 23us.",,114,0,,,MSRA,undefined,Microsoft Research Asia,NSDI Networking
2-s2.0-80755144016,10.1145/2047196.2047254,,,SideBySide: Ad-hoc multi-user interaction with handheld projectors,cp,Conference Paper,Willis K.D.D.,60136640;60032776;60027950,School of Computer Science;The Walt Disney Company;Carnegie Mellon University,Pittsburgh;Burbank;Pittsburgh,United States;United States;United States,4,"Willis, Karl D.D.;Poupyrev, Ivan;Hudson, Scott E.;Mahler, Moshe",57221152340;6603553340;7201375469;54383719700,60032776-60027950;60032776;60032776-60136640;60032776,2011-11-14,2011,UIST'11 - Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology,,20500195019,,Conference Proceeding,,,,431-440,"We introduce SideBySide, a system designed for ad-hoc multi-user interaction with handheld projectors. SideBySide uses device-mounted cameras and hybrid visible/infrared light projectors to track multiple independent projected images in relation to one another. This is accomplished by projecting invisible fiducial markers in the near-infrared spectrum. Our system is completely self-contained and can be deployed as a handheld device without instrumentation of the environment. We present the design and implementation of our system including a hybrid handheld projector to project visible and infrared light, and techniques for tracking projected fiducial markers that move and overlap. We introduce a range of example applications that demonstrate the applicability of our system to real-world scenarios such as mobile content exchange, gaming, and education. © 2011 ACM.",Ad hoc interaction | Games | Handheld projector | Interaction techniques | Multi-user | Pico projector,73,0,,,,undefined,,UIST User Interface
2-s2.0-79959705417,10.1145/1993636.1993675,,,Subexponential lower bounds for randomized pivoting rules for the simplex algorithm,cp,Conference Paper,Friedmann O.,60029616;60028717;60005681,Aarhus Universitet;Ludwig-Maximilians-Universität München;Tel Aviv University,Aarhus;Munich;Tel Aviv-Yafo,Denmark;Germany;Israel,3,"Friedmann, Oliver;Hansen, Thomas Dueholm;Zwick, Uri",35111091400;25926376800;7003415356,60028717;60029616;60005681,2011-01-01,2011,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,283-292,"The simplex algorithm is among the most widely used algorithms for solving linear programs in practice. With essentially all deterministic pivoting rules it is known, however, to require an exponential number of steps to solve some linear programs. No non-polynomial lower bounds were known, prior to this work, for randomized pivoting rules. We provide the first subexponential (i.e., of the form 2ω(nα), for some α>0) lower bounds for the two most natural, and most studied, randomized pivoting rules suggested to date. The first randomized pivoting rule considered is Random-Edge, which among all improving pivoting steps (or edges) from the current basic feasible solution (or vertex) chooses one uniformly at random. The second randomized pivoting rule considered is Random-Facet, a more complicated randomized pivoting rule suggested by Kalai and by Matousek, Sharir and Welzl. Our lower bound for the Random-Facet pivoting rule essentially matches the subexponential upper bounds given by Kalai and by Matousek et al Lower bounds for Random-Edge and Random-Facet were known before only in abstract settings, and not for concrete linear programs. Our lower bounds are obtained by utilizing connections between pivoting steps performed by simplex-based algorithms and improving switches performed by policy iteration algorithms for solving Markov Decision Processes (MDPs). © 2011 ACM.",linear programming | Markov decision processes | randomized pivoting rules | simplex algorithm,44,0,,,,undefined,,STOC Theory
2-s2.0-79958125605,10.1145/1978942.1979013,,,Synchronous interaction among hundreds: An evaluation of a conference in an avatar-based virtual environment,cp,Conference Paper,Erickson T.,60017366,IBM Thomas J. Watson Research Center,Yorktown Heights,United States,4,"Erickson, Thomas;Sadat Shami, N.;Kellogg, Wendy A.;Levine, David W.",7005246729;12545297400;57200009282;57197611554,60017366;60017366;60017366;60017366,2011-01-01,2011,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,503-512,"This paper presents the first in-depth evaluation of a large multi-format virtual conference. The conference took place in an avatar-based 3D virtual world with spatialized audio, and had keynote, poster and social sessions. We studied it by drawing on logs, a survey and interviews with 30 participants. We develop a model - Coalescence, Focused Interaction, Remixing (CoFIRe) - of large synchronous interactions, and use it to discuss how the technology supported, or failed to support, the interactions that are the raison d'etre of conferences. We conclude by discussing the prospects for such large virtual gatherings. Copyright 2011 ACM.",Collaboration | CSCW | CVE | Second life | Spatialized audio | Synchronous interaction | Virtual environment | Virtual world,42,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-79958159108,10.1145/1978942.1979161,,,Teenagers and their virtual possessions: Design opportunities and issues,cp,Conference Paper,Odom W.,60136640,School of Computer Science,Pittsburgh,United States,3,"Odom, William;Zimmerman, John;Forlizzi, Jodi",6701770018;7401859828;6602845027,60136640;60136640;60136640,2011-01-01,2011,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1491-1500,"Over the past several years, people have increasingly acquired virtual possessions. We consider these things to include artifacts that are increasingly becoming immaterial (e.g. books, photos, music, movies) and things that have never traditionally had a lasting material form (e.g. SMS archives, social networking profiles, personal behavior logs). To date, little research exists about how people value and form attachments to virtual possessions. To investigate, we conducted a study with 21 teenagers exploring the perceived value of their virtual possessions, and the comparative similarities and differences with their material things. Findings are interpreted to detail design and research opportunities and issues in this emerging space. Copyright 2011 ACM.",Interactive systems design | Teenagers | Virtual possessions,130,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-80053135174,10.1145/2018436.2018438,,,They can hear your heartbeats: Non-invasive security for implantable medical devices,cp,Conference Paper,Gollakota S.,60022195;60014313,Massachusetts Institute of Technology;University of Massachusetts Amherst,Cambridge;Amherst,United States;United States,5,"Gollakota, Shyamnath;Hassanieh, Haitham;Ransford, Benjamin;Katabi, Dina;Fu, Kevin",24449959700;36617337500;24725598400;6507046077;18434230000,60022195;60022195;60014313;60022195;60014313,2011-09-29,2011,"Proceedings of the ACM SIGCOMM 2011 Conference, SIGCOMM'11",,19900194915,,Conference Proceeding,,,,2-13,"Wireless communication has become an intrinsic part of modern implantable medical devices (IMDs). Recent work, however, has demonstrated that wireless connectivity can be exploited to compromise the confidentiality of IMDs' transmitted data or to send unauthorized commands to IMDs-even commands that cause the device to deliver an electric shock to the patient. The key challenge in addressing these attacks stems from the difficulty of modifying or replacing already-implanted IMDs. Thus, in this paper, we explore the feasibility of protecting an implantable device from such attacks without modifying the device itself. We present a physicallayer solution that delegates the security of an IMD to a personal base station called the shield. The shield uses a novel radio design that can act as a jammer-cum-receiver. This design allows it to jam the IMD's messages, preventing others from decoding them while being able to decode them itself. It also allows the shield to jam unauthorized commands-even those that try to alter the shield's own transmissions. We implement our design in a software radio and evaluate it with commercial IMDs. We find that it effectively provides confidentiality for private data and protects the IMD from unauthorized commands. Copyright 2011 ACM.",Full-duplex | Implanted medical devices | Wireless,261,1,repositoryvor,Green,CISE,0831244,Directorate for Computer and Information Science and Engineering,SIGCOMM Networking
2-s2.0-79960182620,10.1145/1993744.1993774,,,Topology discovery of sparse random graphs with few participants,cp,Conference Paper,Anandkumar A.,60111166;60007278;60006320,"Google LLC, Africa &amp; Middle East;University of California, Irvine;MIT Computer Science &amp; Artificial Intelligence Laboratory",Dubai;Irvine;Cambridge,United Arab Emirates;United States;United States,3,"Anandkumar, Animashree;Hassidim, Avinatan;Kelner, Jonathan",16068201100;11440573000;6603724487,60007278;60111166;60006320,2011-01-01,2011,Performance Evaluation Review,01635999,26742,,Journal,39,1 SPEC. ISSUE,,293-304,"We consider the task of topology discovery of sparse random graphs using end-to-end random measurements (e.g., delay) between a subset of nodes, referred to as the participants. The rest of the nodes are hidden, and do not provide any information for topology discovery. We consider topology discovery under two routing models: (a) the participants exchange messages along the shortest paths and obtain end-to-end measurements, and (b) additionally, the participants exchange messages along the second shortest path. For scenario (a), our proposed algorithm results in a sub-linear edit-distance guarantee using a sub-linear number of uniformly selected participants. For scenario (b), we obtain a much stronger result, and show that we can achieve consistent reconstruction when a sub-linear number of uniformly selected nodes participate. This implies that accurate discovery of sparse random graphs is tractable using an extremely small number of participants. We finally obtain a lower bound on the number of participants required by any algorithm to reconstruct the original random graph up to a given edit distance. We also demonstrate that while consistent discovery is tractable for sparse random graphs using a small number of participants, in general, there are graphs which cannot be discovered by any algorithm even with a significant number of participants, and with the availability of end-to-end information along all the paths between the participants. © Copyright 2011 ACM.",End-to-end measurements | Hidden nodes | Quartet tests | Sparse random graphs | Topology discovery,3,0,repositoryam,Green,,undefined,,SIGMETRICS Performance
2-s2.0-80055041725,10.1145/1963405.1963453,,,Towards a theory model for product search,cp,Conference Paper,Li B.,60108316,Leonard N. Stern School of Business,New York,United States,3,"Li, Beibei;Ghose, Anindya;Ipeirotis, Panagiotis G.",55904168700;9845067800;6603236863,60108316;60108316;60108316,2011-12-01,2011,"Proceedings of the 20th International Conference on World Wide Web, WWW 2011",,21100228515,,Conference Proceeding,,,,327-336,"With the growing pervasiveness of the Internet, online search for products and services is constantly increasing. Most product search engines are based on adaptations of theoretical models devised for information retrieval. However, the decision mechanism that underlies the process of buying a product is different than the process of locating relevant documents or objects. We propose a theory model for product search based on expected utility theory from economics. Specifically, we propose a ranking technique in which we rank highest the products that generate the highest surplus, after the purchase. In a sense, the top ranked products are the ""best value for money"" for a specific user. Our approach builds on research on ""demand estimation"" from economics and presents a solid theoretical foundation on which further research can build on. We build algorithms that take into account consumer demographics, heterogeneity of consumer preferences, and also account for the varying price of the products. We show how to achieve this without knowing the demographics or purchasing histories of individual consumers but by using aggregate demand data. We evaluate our work, by applying the techniques on hotel search. Our extensive user studies, using more than 15,000 user-provided ranking comparisons, demonstrate an overwhelming preference for the rankings generated by our techniques, compared to a large number of existing strong state-of-the-art baselines. Copyright © 2011 by the Association for Computing Machinery, Inc. (ACM).",Consumer surplus | Economics | Product search | Ranking | Text mining | User-generated content | Utility theory,47,0,,,,undefined,,WWW World Wide Web
2-s2.0-84859090981,,,,Unsupervised part-of-speech tagging with bilingual graph-based projections,cp,Conference Paper,Das D.,60027950;60006191,Carnegie Mellon University;Google LLC,Pittsburgh;Mountain View,United States;United States,2,"Das, Dipanjan;Petrov, Slav",16238076400;51665451200,60027950;60006191,2011-12-01,2011,ACL-HLT 2011 - Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,,21100199763,,Conference Proceeding,1,,,600-609,"We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language. Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages. We use graph-based label propagation for cross-lingual knowledge transfer and use the projected labels as features in an unsupervised model (Berg-Kirkpatrick et al., 2010). Across eight European languages, our approach results in an average absolute improvement of 10.4% over a state-of-the-art baseline, and 16.7% over vanilla hidden Markov models induced with the Expectation Maximization algorithm. © 2011 Association for Computational Linguistics.",,211,0,,,,undefined,,ACL Natural Language Processing
2-s2.0-84855604361,10.5591/978-1-57735-516-8/IJCAI11-021,,,Unweighted coalitional manipulation under the borda rule is NP-hard,cp,Conference Paper,Betzler N.,60032882;60011604,Technische Universiteit Eindhoven;Technische Universität Berlin,Eindhoven;Berlin,Netherlands;Germany,3,"Betzler, Nadja;Niedermeier, Rolf;Woeginger, Gerhard J.",23088469600;7004137881;7006428435,60011604;60011604;60032882,2011-12-01,2011,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,55-60,"The Borda voting rule is a positional scoring rule where, for m candidates, for every vote the first candidate receives m - 1 points, the second m - 2 points and so on. A Borda winner is a candidate with highest total score. It has been a prominent open problem to determine the computational complexity of UNWEIGHTED COALITIONAL MANIPULATION UNDER BORDA: Can one add a certain number of additional votes (called manipulators) to an election such that a distinguished candidate becomes a winner? We settle this open problem by showing NP-hardness even for two manipulators and three input votes. Moreover, we discuss extensions and limitations of this hardness result.",,69,0,,,DFG,undefined,Deutsche Forschungsgemeinschaft,IJCAI Artificial Intelligence
2-s2.0-79958117118,10.1145/1978942.1979001,,,Usable gestures for blind people: Understanding preference and performance,cp,Conference Paper,Kane S.K.,60015481,University of Washington,Seattle,United States,3,"Kane, Shaun K.;Wobbrock, Jacob O.;Ladner, Richard E.",16241496400;6603152369;7005099015,60015481;60015481;60015481,2011-01-01,2011,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,413-422,"Despite growing awareness of the accessibility issues surrounding touch screen use by blind people, designers still face challenges when creating accessible touch screen interfaces. One major stumbling block is a lack of understanding about how blind people actually use touch screens. We conducted two user studies that compared how blind people and sighted people use touch screen gestures. First, we conducted a gesture elicitation study in which 10 blind and 10 sighted people invented gestures to perform common computing tasks on a tablet PC. We found that blind people have different gesture preferences than sighted people, including preferences for edge-based gestures and gestures that involve tapping virtual keys on a keyboard. Second, we conducted a performance study in which the same participants performed a set of reference gestures. We found significant differences in the speed, size, and shape of gestures performed by blind people versus those performed by sighted people. Our results suggest new design guidelines for accessible touch screen interfaces. Copyright 2011 ACM.",Accessibility | Blind | Gesture recognition | Gestures | Touch screens,234,0,,,NSF,0811063,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-79959878971,10.1145/1985793.1985839,,,Verifying multi-threaded software using SMT-based context-bounded model checking,cp,Conference Paper,Cordeiro L.,60025225,University of Southampton,Southampton,United Kingdom,2,"Cordeiro, Lucas;Fischer, Bernd",24328704500;55574221165,60025225;60025225,2011-07-07,2011,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,331-340,"We describe and evaluate three approaches to model check multi-threaded software with shared variables and locks using bounded model checking based on Satisfiability Modulo Theories (SMT) and our modelling of the synchronization primitives of the Pthread library. In the lazy approach, we generate all possible interleavings and call the SMT solver on each of them individually, until we either find a bug, or have systematically explored all interleavings. In the schedule recording approach, we encode all possible interleavings into one single formula and then exploit the high speed of the SMT solvers. In the underapproximation and widening approach, we reduce the state space by abstracting the number of interleavings from the proofs of unsatisfiability generated by the SMT solvers. In all three approaches, we bound the number of context switches allowed among threads in order to reduce the number of interleavings explored. We implemented these approaches in ESBMC, our SMT-based bounded model checker for ANSI-C programs. Our experiments show that ESBMC can analyze larger problems and substantially reduce the verification time compared to state-of-the-art techniques that use iterative context-bounding algorithms or counter-example guided abstraction refinement. © 2011 ACM.",formal software verification | multi-threaded systems | sat modulo theories | symbolic and explicit model checking,107,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-79958096343,10.1145/1978942.1979217,,,Why is my internet slow?: Making network speeds visible,cp,Conference Paper,Chetty M.,60076757;60019647;128937671,"Amazon.com, Inc.;Georgia Institute of Technology;Orange Sparkle Ball",Seattle;Atlanta;Orange,United States;United States;United States,6,"Chetty, Marshini;Haslem, David;Baird, Andrew;Ofoha, Ugochi;Sumner, Bethany;Grinter, Rebecca E.",57204342511;36650851800;56277322900;39361897300;39362240400;6604035559,60019647;128937671;60076757;60019647;60019647;60019647,2011-01-01,2011,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1889-1898,"With widespread broadband adoption, more households report experiencing sub-optimal speeds. Not only are slow speeds frustrating, they may indicate consumers are not receiving the services they are paying for from their internet service providers. Yet, determining the speed and source of slow-downs is difficult because few tools exist for broadband management. We report on results of a field trial with 10 households using a visual network probe designed to address these problems. We describe the results of the study and provide design implications for future tools. More importantly, we argue that tools like this can educate and empower consumers by making broadband speeds and sources of slow-downs more visible. Copyright 2011 ACM.",Broadband speed | Broadband tools | Home networks,45,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-79958164807,10.1145/1978942.1979058,,,Your noise is my command: Sensing gestures using the body as an antenna,cp,Conference Paper,Cohn G.,60021726;105607132,Microsoft Research;DUB Group,Redmond;Seattle,United States;United States,4,"Cohn, Gabe;Morris, Dan;Patel, Shwetak N.;Tan, Desney S.",36117476900;55547128588;8450420300;7202902029,60021726-105607132;60021726;60021726-105607132;60021726,2011-01-01,2011,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,791-800,"Touch sensing and computer vision have made humancomputer interaction possible in environments where keyboards, mice, or other handheld implements are not available or desirable. However, the high cost of instrumenting environments limits the ubiquity of these technologies, particularly in home scenarios where cost constraints dominate installation decisions. Fortunately, home environments frequently offer a signal that is unique to locations and objects within the home: electromagnetic noise. In this work, we use the body as a receiving antenna and leverage this noise for gestural interaction. We demonstrate that it is possible to robustly recognize touched locations on an uninstru-mented home wall using no specialized sensors. We conduct a series of experiments to explore the capabilities that this new sensing modality may offer. Specifically, we show robust classification of gestures such as the position of discrete touches around light switches, the particular light switch being touched, which appliances are touched, differentiation between hands, as well as continuous proximity of hand to the switch, among others. We close by discussing opportunities, limitations, and future work. Copyright 2011 ACM.",Electrical noise | Input | Surface interaction | Touch interaction,74,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84871970528,10.1109/FOCS.2012.54,,,A polylogarithmic approximation algorithm for edge-disjoint paths with congestion 2,cp,Conference Paper,Chuzhoy J.,60141284;60074721,School of Engineering and Applied Science;Toyota Technological Institute at Chicago,Princeton;Chicago,United States;United States,2,"Chuzhoy, Julia;Li, Shi",15924915900;36809973200,60074721;60141284,2012-12-01,2012,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,,,6375301,233-242,"In the Edge-Disjoint Paths with Congestion problem (EDPwC), we are given an undirected n-vertex graph G, a collection M = {(s1, t 1),...,(sk, tk)} of demand pairs and an integer c. The goal is to connect the maximum possible number of the demand pairs by paths, so that the maximum edge congestion - the number of paths sharing any edge - is bounded by c. When the maximum allowed congestion is c=1, this is the classical Edge-Disjoint Paths problem (EDP). The best current approximation algorithm for EDP achieves an O(√n)-approximation, by rounding the standard multi-commodity flow relaxation of the problem. This matches the Ω(√n) lower bound on the integrality gap of this relaxation. We show an O(poly log k)-approximation algorithm for EDPwC with congestion c = 2, by rounding the same multi-commodity flow relaxation. This gives the best possible congestion for a sub-polynomial approximation of EDPwC via this relaxation. Our results are also close to optimal in terms of the number of pairs routed, since EDPwC is known to be hard to approximate to within a factor of Ω((log n)1/(c+1)) for any constant congestion c. Prior to our work, the best approximation factor for EDPwC with congestion 2 was tilde Õ(n 3/7), and the best algorithm achieving a polylogarithmic approximation required congestion 14. © 2012 IEEE.",approximation algorithms | edge-disjoint paths | network routing,34,0,,,,undefined,,FOCS Theory
2-s2.0-84866698990,10.1109/CVPR.2012.6247905,,,A simple prior-free method for non-rigid structure-from-motion factorization,cp,Conference Paper,Dai Y.,60008950;60003977,The Australian National University;Northwestern Polytechnical University,Canberra;Xi'an,Australia;China,3,"Dai, Yuchao;Li, Hongdong;He, Mingyi",24829251300;55707613900;7402609138,60003977;60008950;60003977,2012-10-01,2012,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,,,6247905,2018-2025,"This paper proposes a simple prior-free method for solving non-rigid structure-from-motion factorization problems. Other than using the basic low-rank condition, our method does not assume any extra prior knowledge about the nonrigid scene or about the camera motions. Yet, it runs reliably, produces optimal result, and does not suffer from the inherent basis-ambiguity issue which plagued many conventional nonrigid factorization techniques. Our method is easy to implement, which involves solving no more than an SDP (semi-definite programming) of small and fixed size, a linear Least-Squares or trace-norm minimization. Extensive experiments have demonstrated that it outperforms most of the existing linear methods of nonrigid factorization. This paper offers not only new theoretical insight, but also a practical, everyday solution, to non-rigid structure-from-motion. © 2012 IEEE.",,132,1,publisherfree2read,Bronze,,undefined,,CVPR Computer Vision
2-s2.0-84864210634,10.1109/ICSE.2012.6227153,,,A tactic-centric approach for automating traceability of quality concerns,cp,Conference Paper,Mirakhorli M.,60026860,DePaul University,Chicago,United States,4,"Mirakhorli, Mehdi;Shin, Yonghee;Cleland-Huang, Jane;Cinar, Murat",23390242500;24492397200;6506741859;57197558564,60026860;60026860;60026860;60026860,2012-07-30,2012,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,6227153,639-649,"The software architectures of business, mission, or safety critical systems must be carefully designed to balance an exacting set of quality concerns describing characteristics such as security, reliability, and performance. Unfortunately, software architectures tend to degrade over time as maintainers modify the system without understanding the underlying architectural decisions. Although this problem can be mitigated by manually tracing architectural decisions into the code, the cost and effort required to do this can be prohibitively expensive. In this paper we therefore present a novel approach for automating the construction of traceability links for architectural tactics. Our approach utilizes machine learning methods and lightweight structural analysis to detect tactic-related classes. The detected tactic-related classes are then mapped to a Tactic Traceability Information Model. We train our trace algorithm using code extracted from fifteen performance-centric and safety-critical open source software systems and then evaluate it against the Apache Hadoop framework. Our results show that automatically generated traceability links can support software maintenance activities while helping to preserve architectural qualities. © 2012 IEEE.",Architecture | tactics | traceability | traceability information models,72,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84871982670,10.1109/FOCS.2012.11,,,A multi-prover interactive proof for NEXP sound against entangled provers,cp,Conference Paper,Ito T.,60018008;60006320,"NEC Laboratories America, Inc.;MIT Computer Science &amp; Artificial Intelligence Laboratory",Princeton;Cambridge,United States;United States,2,"Ito, Tsuyoshi;Vidick, Thomas",55471022900;24802325000,60018008;60006320,2012-12-01,2012,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,,,6375302,243-252,"We prove a strong limitation on the ability of entangled provers to collude in a multiplayer game. Our main result is the first nontrivial lower bound on the class MIP* of languages having multi-prover interactive proofs with entangled provers, namely MIP* contains NEXP, the class of languages decidable in non-deterministic exponential time. While Babai, Fort now, and Lund (Computational Complexity 1991) proved the celebrated equality MIP = NEXP in the absence of entanglement, ever since the introduction of the class MIP* it was open whether shared entanglement between the provers could weaken or strengthen the computational power of multi-prover interactive proofs. Our result shows that it does not weaken their computational power: MIP* contains MIP. At the heart of our result is a proof that Babai, Fort now, and Lund's multilinearity test is sound even in the presence of entanglement between the provers, and our analysis of this test could be of independent interest. As a byproduct we show that the correlations produced by any entangled strategy which succeeds in the multilinearity test with high probability can always be closely approximated using shared randomness alone. © 2012 IEEE.",entanglement | multiple provers | quantum interactive proofs,46,0,repositoryam,Green,,undefined,,FOCS Theory
2-s2.0-84862094303,10.1145/2207676.2208541,,,Affordances in HCI: Toward a mediated action perspective,cp,Conference Paper,Kaptelinin V.,60031040;60029622;60007278,"Umeå Universitet;Universitetet i Bergen;University of California, Irvine",Umea;Bergen;Irvine,Sweden;Norway;United States,2,"Kaptelinin, Victor;Nardi, Bonnie",6603297258;7004159679,60029622-60031040;60007278,2012-05-24,2012,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,967-976,"Interpretations of the concept of ""affordances"" in HCI are becoming increasingly diverse, extending well beyond the original Gibsonian meaning. We discuss some of the key analyses of affordances in HCI research and make three related claims. First, we argue that many current interpretations of the concept are essentially incompatible with Gibson. Second, we hold that the Gibsonian concept of affordances, conceptualized as interaction between animals and their environments, provides some important insights, but is, in the end, of limited relevance to HCI research. Third, we call for adopting a mediated action perspective on affordances as an alternative to Gibson's ecological psychology. We outline a view of technology affordances as possibilities for human action mediated by cultural means conceived as a relational property of a three-way interaction between the person, mediational means, and environment. We conclude with a discussion of prospects for future conceptual and empirical explorations of the meditational perspective in HCI research. Copyright 2012 ACM.",Affordances | Ecological psychology | Mediated action | Technology affordances,204,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84864186387,10.1109/ICSE.2012.6227157,,,Amplifying tests to validate exception handling code,cp,Conference Paper,Zhang P.,60026306,University of Nebraska–Lincoln,Lincoln,United States,2,"Zhang, Pingyu;Elbaum, Sebastian",55491627600;6604075891,60026306;60026306,2012-07-30,2012,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,6227157,595-605,"Validating code handling exceptional behavior is difficult, particularly when dealing with external resources that may be noisy and unreliable, as it requires: 1) the systematic exploration of the space of exceptions that may be thrown by the external resources, and 2) the setup of the context to trigger specific patterns of exceptions. In this work we present an approach that addresses those difficulties by performing an exhaustive amplification of the space of exceptional behavior associated with an external resource that is exercised by a test suite. Each amplification attempts to expose a program exception handling construct to new behavior by mocking an external resource so that it returns normally or throws an exception following a predefined pattern. Our assessment of the approach indicates that it can be fully automated, is powerful enough to detect 65% of the faults reported in the bug reports of this kind, and is precise enough that 77% of the detected anomalies correspond to faults fixed by the developers. © 2012 IEEE.",exception handling | Test transformation,50,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-84871325977,10.1145/2393596.2393648,,,Assessing the value of branches with what-if analysis,cp,Conference Paper,Bird C.,60021726,Microsoft Research,Redmond,United States,2,"Bird, Christian;Zimmermann, Thomas",17433640400;16308551800,60021726;60021726,2012-12-24,2012,"Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering, FSE 2012",,21100223523,,Conference Proceeding,,,,,"Branches within source code management systems (SCMs) allow a software project to divide work among its teams for concurrent development by isolating changes. However, this benefit comes with several costs: increased time required for changes to move through the system and pain and error potential when integrating changes across branches. In this paper, we present the results of a survey to characterize how developers use branches in a large industrial project and common problems that they face. One of the major problems mentioned was the long delay that it takes changes to move from one team to another, which is often caused by having too many branches (branchmania). To monitor branch health, we introduce a novel what-if analysis to assess alternative branch structures with respect to two properties, isolation and liveness. We demonstrate with several scenarios how our what-if analysis can support branch decisions. By removing high-cost-low-benefit branches in Windows based on our what-if analysis, changes would each have saved 8.9 days of delay and only introduced 0.04 additional conflicts on average. © 2012 ACM.",branch refactoring | branches | concurrent development | coordination | teams | what-if analysis,87,0,,,,undefined,,FSE Software Engineering
2-s2.0-84864210778,10.1109/ICSE.2012.6227143,,,Automated detection of client-state manipulation vulnerabilities,cp,Conference Paper,Møller A.,60029616,Aarhus Universitet,Aarhus,Denmark,2,"Møller, Anders;Schwarz, Mathias",57195116933;55434007200,60029616;60029616,2012-07-30,2012,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,6227143,749-759,"Web application programmers must be aware of a wide range of potential security risks. Although the most common pitfalls are well described and categorized in the literature, it remains a challenging task to ensure that all guidelines are followed. For this reason, it is desirable to construct automated tools that can assist the programmers in the application development process by detecting weaknesses. Many vulnerabilities are related to web application code that stores references to application state in the generated HTML documents to work around the statelessness of the HTTP protocol. In this paper, we show that such client-state manipulation vulnerabilities are amenable to tool supported detection. We present a static analysis for the widely used frameworks Java Servlets, JSP, and Struts. Given a web application archive as input, the analysis identifies occurrences of client state and infers the information flow between the client state and the shared application state on the server. This makes it possible to check how client-state manipulation performed by malicious users may affect the shared application state and cause leakage or modifications of sensitive information. The warnings produced by the tool help the application programmer identify vulnerabilities. Moreover, the inferred information can be applied to configure a security filter that automatically guards against attacks. Experiments on a collection of open source web applications indicate that the static analysis is able to effectively help the programmer prevent client-state manipulation vulnerabilities. © 2012 IEEE.",information flow analysis | static analysis | Web application security,6,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-84867125855,,,,Bayesian posterior sampling via stochastic gradient fisher scoring,cp,Conference Paper,Ahn S.,60142654,Donald Bren School of Information &amp; Computer Sciences,Irvine,United States,3,"Ahn, Sungjin;Korattikara, Anoop;Welling, Max",55376977200;55208184500;55907170700,60142654;60142654;60142654,2012-10-10,2012,"Proceedings of the 29th International Conference on Machine Learning, ICML 2012",,21100217201,,Conference Proceeding,2,,,1591-1598,"In this paper we address the following question: ""Can we approximately sample from a Bayesian posterior distribution if we are only allowed to touch a small mini-batch of data-items for every sample we generate?"". An algorithm based on the Langevin equation with stochastic gradients (SGLD) was previously proposed to solve this, but its mixing rate was slow. By leveraging the Bayesian Central Limit Theorem, we extend the SGLD algorithm so that at high mixing rates it will sample from a normal approximation of the posterior, while for slow mixing rates it will mimic the behavior of SGLD with a pre-conditioner matrix. As a bonus, the proposed algorithm is reminiscent of Fisher scoring (with stochastic gradients) and as such an efficient optimizer during burn-in. Copyright 2012 by the author(s)/owner(s).",,112,0,,,,undefined,,ICML Machine Learning
2-s2.0-84878166911,,,,Bayesian symbol-refined tree substitution grammars for syntactic parsing,cp,Conference Paper,Shindo H.,60278168;60028928,NTT Communication Science Laboratories;Research Organization of Information and Systems National Institute of Informatics,Seika;Tokyo,Japan;Japan,4,"Shindo, Hiroyuki;Miyao, Yusuke;Fujino, Akinori;Nagata, Masaaki",56567565300;8967499500;10240334000;7402879306,60278168;60028928;60278168;60278168,2012-12-01,2012,"50th Annual Meeting of the Association for Computational Linguistics, ACL 2012 - Proceedings of the Conference",,21100241698,,Conference Proceeding,1,,,440-448,"We propose Symbol-Refined Tree Substitution Grammars (SR-TSGs) for syntactic parsing. An SR-TSG is an extension of the conventional TSG model where each nonterminal symbol can be refined (subcategorized) to fit the training data. We aim to provide a unified model where TSG rules and symbol refinement are learned from training data in a fully automatic and consistent fashion. We present a novel probabilistic SR-TSG model based on the hierarchical Pitman-Yor Process to encode backoff smoothing from a fine-grained SR-TSG to simpler CFG rules, and develop an efficient training method based on Markov Chain Monte Carlo (MCMC) sampling. Our SR-TSG parser achieves an F1 score of 92.4% in the Wall Street Journal (WSJ) English Penn Treebank parsing task, which is a 7.7 point improvement over a conventional Bayesian TSG parser, and better than state-of-the-art discriminative reranking parsers. © 2012 Association for computational Linguistics.",,44,0,,,,undefined,,ACL Natural Language Processing
2-s2.0-84862071970,10.1145/2207676.2208404,,,ClayVision: The (elastic) image of the city,cp,Conference Paper,Takeuchi Y.,60107446;60021784,"Sony Computer Science Laboratories, Inc.;New York University",Tokyo;New York,Japan;United States,2,"Takeuchi, Yuichiro;Perlin, Ken",55182681600;6701707824,60107446;60021784,2012-05-24,2012,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,2411-2420,"In this paper we describe ClayVision, a new quasi-immersive urban navigation system that rethinks the design conventions of existing Augmented Reality (AR) applications, by aggressively incorporating knowledge from non-Computer Science fields-namely Information Design and Urban Planning. Instead of the prevailing approach of pasting ""information bubbles"" onto the existing urban scenery, ClayVision communicates through real-time 3D transformations of city elements. In other words, the system dynamically probes and reassembles the city into a better-designed copy of the original, that is both easier to navigate and tailored to suit the user's needs and preferences. We provide extensive discussions that cover the technical details of the system, the types of city-morphing operations that can be effectively applied, and what people's experiences will be in the newly ""elastic"" city. Copyright 2012 ACM.",Augmented reality | Computer vision | Information design | Urban navigation | Urban planning,26,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84869070337,,,,Cliplets: Juxtaposing still and dynamic imagery,cp,Conference Paper,Joshi N.,60021726;60019647,Microsoft Research;Georgia Institute of Technology,Redmond;Atlanta,United States;United States,7,"Joshi, Neel;Mehta, Sisil;Drucker, Steven;Stollnitz, Eric;Hoppe, Hugues;Uyttendaele, Matt;Cohen, Michael",7202182318;35729089100;35902233200;6602910340;7103057370;56219423800;7405993633,60021726;60021726-60019647;60021726;60021726;60021726;60021726;60021726,2012-11-19,2012,UIST'12 - Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology,,21100219920,,Conference Proceeding,,,,251-260,"We explore creating ""cliplets"", a form of visual media that juxtaposes still image and video segments, both spatially and temporally, to expressively abstract a moment. Much as in ""cinemagraphs"", the tension between static and dynamic elements in a cliplet reinforces both aspects, strongly focusing the viewer's attention. Creating this type of imagery is challenging without professional tools and training. We develop a set of idioms, essentially spatiotemporal mappings, that characterize cliplet elements, and use these idioms in an interactive system to quickly compose a cliplet from ordinary handheld video. One difficulty is to avoid artifacts in the cliplet composition without resorting to extensive manual input. We address this with automatic alignment, looping optimization and feathering, simultaneous matting and compositing, and Laplacian blending. A key user-interface challenge is to provide affordances to define the parameters of the mappings from input time to output time while maintaining a focus on the cliplet being created. We demonstrate the creation of a variety of cliplet types. We also report on informal feedback as well as a more structured survey of users. Copyright 2012 ACM.",Cinemagraphs | Image and video compositing | Image and video editing | Video textures,43,0,,,,undefined,,UIST User Interface
2-s2.0-84862102144,10.1145/2207676.2208619,,,Communitysourcing: Engaging local crowds to perform expert work via physical kiosks,cp,Conference Paper,Heimerl K.,60025038;100550463,"University of California, Berkeley;School of Information",Berkeley;Austin,United States;United States,5,"Heimerl, Kurtis;Gawalt, Brian;Chen, Kuang;Parikh, Tapan S.;Hartmann, Björn",34881702600;36052951400;36480987500;8512994700;15059978800,60025038;60025038;60025038;100550463;60025038,2012-05-24,2012,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1539-1548,"Online labor markets, such as Amazon's Mechanical Turk, have been used to crowdsource simple, short tasks like image labeling and transcription. However, expert knowledge is often lacking in such markets, making it impossible to complete certain classes of tasks. In this work we introduce an alternative mechanism for crowdsourcing tasks that require specialized knowledge or skill: communitysourcing - the use of physical kiosks to elicit work from specific populations. We investigate the potential of communitysourcing by designing, implementing and evaluating Umati: the communitysourcing vending machine. Umati allows users to earn credits by performing tasks using a touchscreen attached to the machine. Physical rewards (in this case, snacks) are dispensed through traditional vending mechanics. We evaluated whether communitysourcing can accomplish expert work by using Umati to grade Computer Science exams. We placed Umati in a university Computer Science building, targeting students with grading tasks for snacks. Over one week, 328 unique users (302 of whom were students) completed 7771 tasks (7240 by students). 80% of users had never participated in a crowdsourcing market before. We found that Umati was able to grade exams with 2% higher accuracy (at the same price) or at 33% lower cost (at equivalent accuracy) than traditional single-expert grading. Mechanical Turk workers had no success grading the same exams. These results indicate that communitysourcing can successfully elicit high-quality expert work from specific communities. Copyright 2012 ACM.",Crowdsourcing | CSCW | Kiosks | Ubiquitous computing,80,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84860169535,10.1137/1.9781611973099.1,,,Computing all maps into a sphere,cp,Conference Paper,Čadek M.,60029543;60025858;60016605;100678911,Masaryk University;ETH Zürich;Charles University;Institut Fourier,Brno;Zurich;Prague;Saint Martin d'Heres,Czech Republic;Switzerland;Czech Republic;France,6,"Čadek, Martin;Krčál, Marek;Matoušek, Jiří;Sergeraert, Francis;Vokřínek, Lukáš;Wagner, Uli",6701836462;25960827800;35599272200;12139911300;55195935700;7201545912,60029543;60016605;60016605-60025858;100678911;60029543;60025858,2012-01-01,2012,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,,,,1-10,"We present an algorithm for computing [X, Y], i.e., all homotopy classes of continuous maps X → Y, where X, Y are topological spaces given as finite simplicial complexes, Y is (d - 1)-connected for some d ≥ 2 (for example, Y can be the d-dimensional sphere Sd), and dim X ≤ 2d - 2. These conditions on X, Y guarantee that [X, Y] has a natural structure of a finitely generated Abelian group, and the algorithm finds generators and relations for it. We combine several tools and ideas from homotopy theory (such as Postnikov systems, simplicial sets, and obstruction theory) with algorithmic tools from effective algebraic topology (objects with effective homology). We hope that a further extension of the methods developed here will yield an algorithm for computing, in some cases of interest, the ℤ2-index, which is a quantity playing a prominent role in Borsuk-Ulam style applications of topology in combinatorics and geometry, e.g., in topological lower bounds for the chromatic number of a graph. In a certain range of dimensions, deciding the embeddability of a simplicial complex into ℝd also amounts to a ℤ2-index computation. This is the main motivation of our work. We believe that investigating the computational complexity of questions in homotopy theory and similar areas presents a fascinating research area, and we hope that our work may help bridge the cultural gap between algebraic topology and theoretical computer science. Copyright © SIAM.",,4,0,repositoryam,Green,FP7,267165,Seventh Framework Programme,SODA Theory
2-s2.0-84863451085,10.1145/2254064.2254114,,,Concurrent data representation synthesis,cp,Conference Paper,Hawkins P.,60141508;60023143;60006320;60005681,Stanford Engineering;Tufts University;MIT Computer Science &amp; Artificial Intelligence Laboratory;Tel Aviv University,Stanford;Medford;Cambridge;Tel Aviv-Yafo,United States;United States;United States;Israel,5,"Hawkins, Peter;Aiken, Alex;Fisher, Kathleen;Rinard, Martin;Sagiv, Mooly",8543566500;57203049517;57214548612;7003321126;7004822914,60141508;60141508;60023143;60006320;60005681,2012-07-09,2012,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,417-427,"We describe an approach for synthesizing data representations for concurrent programs. Our compiler takes as input a program written using concurrent relations and synthesizes a representation of the relations as sets of cooperating data structures as well as the placement and acquisition of locks to synchronize concurrent access to those data structures. The resulting code is correct by construction: individual relational operations are implemented correctly and the aggregate set of operations is serializable and deadlock free. The relational specification also permits a high-level optimizer to choose the best performing of many possible legal data representations and locking strategies, which we demonstrate with an experiment autotuning a graph benchmark. Copyright © 2012 ACM.",Lock placement | Synthesis,37,0,repositoryvor,Green,,undefined,,PLDI Programming Languages
2-s2.0-84860864011,10.1145/2187836.2187922,,,"Counting beyond a Yottabyte, or how SPARQL 1.1 property paths will prevent adoption of the standard",cp,Conference Paper,Arenas M.,60029681;60012464,Pontificia Universidad Católica de Chile;Universidad de Chile,Santiago;Santiago,Chile;Chile,3,"Arenas, Marcelo;Conca, Sebastián;Pérez, Jorge",7005937486;55213969900;57195967788,60029681;60029681;60012464,2012-05-16,2012,WWW'12 - Proceedings of the 21st Annual Conference on World Wide Web,,21100201984,,Conference Proceeding,,,,629-638,"SPARQL -the standard query language for querying RDF- provides only limited navigational functionalities, although these features are of fundamental importance for graph data formats such as RDF. This has led the W3C to include the property path feature in the upcoming version of the standard, SPARQL 1.1. We tested several implementations of SPARQL 1.1 handling property path queries, and we observed that their evaluation methods for this class of queries have a poor performance even in some very simple scenarios. To formally explain this fact, we conduct a theoretical study of the computational complexity of property paths evaluation. Our results imply that the poor performance of the tested implementations is not a problem of these particular systems, but of the specification itself. In fact, we show that any implementation that adheres to the SPARQL 1.1 specification (as of November 2011) is doomed to show the same behavior, the key issue being the need for counting solutions imposed by the current specification. We provide several intractability results, that together with our empirical results, provide strong evidence against the current semantics of SPARQL 1.1 property paths. Finally, we put our results in perspective, and propose a natural alternative semantics with tractable evaluation, that we think may lead to a wide adoption of the language by practitioners, developers and theoreticians.",Bag semantics | Counting complexity | Property paths | Sparql 1.1,101,0,,,,undefined,,WWW World Wide Web
2-s2.0-84869013273,,,,CrowdScape: Interactively visualizing user behavior and output,cp,Conference Paper,Rzeszotarski J.M.,60136640,School of Computer Science,Pittsburgh,United States,2,"Rzeszotarski, Jeffrey M.;Kittur, Aniket",35734782600;24923233700,60136640;60136640,2012-11-19,2012,UIST'12 - Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology,,21100219920,,Conference Proceeding,,,,55-62,"Crowdsourcing has become a powerful paradigm for accomplishing work quickly and at scale, but involves significant challenges in quality control. Researchers have developed algorithmic quality control approaches based on either worker outputs (such as gold standards or worker agreement) or worker behavior (such as task fingerprinting), but each approach has serious limitations, especially for complex or creative work. Human evaluation addresses these limitations but does not scale well with increasing numbers of workers. We present CrowdScape, a system that supports the human evaluation of complex crowd work through interactive visualization and mixed initiative machine learning. The system combines information about worker behavior with worker outputs, helping users to better understand and harness the crowd. We describe the system and discuss its utility through grounded case studies. We explore other contexts where CrowdScape's visualizations might be useful, such as in user studies. Copyright 2012 ACM.",Crowdsourcing | Event logging | Interfaces | Performance | Quality control | User behavior | Visualization,69,0,,,,undefined,,UIST User Interface
2-s2.0-84863730251,10.14778/2168651.2168658,,,Dense subgraph maintenance under streaming edge weight updates for realtime story identification,ar,Article,Angel A.,60016849;60014300,University of Toronto;AT&amp;T Inc.,Toronto;San Antonio,Canada;United States,4,"Angel, Albert;Koudas, Nick;Sarkas, Nikos;Srivastava, Divesh",34879487000;6603908248;11140689400;58161615400,60016849;60016849;60016849;60014300,2012-01-01,February 2012,Proceedings of the VLDB Endowment,,21100199855,21508097,Conference Proceeding,5,6,,574-585,"Recent years have witnessed an unprecedented proliferation of social media. People around the globe author, every day, millions of blog posts, micro-blog posts, social network status updates, etc. This rich stream of information can be used to identify, on an ongoing basis, emerging stories, and events that capture popular attention. Stories can be identified via groups of tightly-coupled realworld entities, namely the people, locations, products, etc., that are involved in the story. The sheer scale, and rapid evolution of the data involved necessitate highly efficient techniques for identifying important stories at every point of time. The main challenge in real-time story identification is the maintenance of dense subgraphs (corresponding to groups of tightlycoupled entities) under streaming edge weight updates (resulting from a stream of user-generated content). This is the first work to study the efficient maintenance of dense subgraphs under such streaming edge weight updates. For a wide range of definitions of density, we derive theoretical results regarding the magnitude of change that a single edge weight update can cause. Based on these, we propose a novel algorithm, DYNDENS, which outperforms adaptations of existing techniques to this setting, and yields meaningful results. Our approach is validated by a thorough experimental evaluation on large-scale real and synthetic datasets. © 2012 VLDB Endowment.",,112,0,repositoryam,Green,,undefined,,VLDB Databases
2-s2.0-84862091086,10.1145/2207676.2207744,,,Detecting Error-Related Negativity for interaction design,cp,Conference Paper,Vi C.,60020650,University of Bristol,Bristol,United Kingdom,2,"Vi, Chi Thanh;Subramanian, Sriram",55247108300;35389893300,60020650;60020650,2012-05-24,2012,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,493-502,This paper examines the ability to detect a characteristic brain potential called the Error-Related Negativity (ERN) using off-the-shelf headsets and explores its applicability to HCI. ERN is triggered when a user either makes a mistake or the application behaves differently from their expectation. We first show that ERN can be seen on signals captured by EEG headsets like Emotiv™ when doing a typical multiple choice reaction time (RT) task - Flanker task. We then present a single-trial online ERN algorithm that works by pre-computing the coefficient matrix of a logistic regression classifier using some data from a multiple choice reaction time task and uses it to classify incoming signals of that task on a single trial of data. We apply it to an interactive selection task that involved users selecting an object under time pressure. Furthermore the study was conducted in a typical office environment with ambient noise. Our results show that online single trial ERN detection is possible using off-the-shelf headsets during tasks that are typical of interactive applications. We then design a Superflick experiment with an integrated module mimicking an ERN detector to evaluate the accuracy of detecting ERN in the context of assisting users in interactive tasks. Based on these results we discuss and present several HCI scenarios for use of ERN. Copyright 2012 ACM.,Brain Computer Interface | EEG | Electroencephalography | Error Related Negativity | Flick | User interface,46,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84868295095,,,,Document summarization based on data reconstruction,cp,Conference Paper,He Z.,60117933;60117751,"State Key Lab of CAD&amp;CG, Zhejiang University;College of Computer Science and Technology, Zhejiang University",Hangzhou;Hangzhou,China;China,7,"He, Zhanying;Chen, Chun;Bu, Jiajun;Wang, Can;Zhang, Lijun;Cai, Deng;He, Xiaofei",55445467800;56174479100;55684269900;56017252400;10045230800;35228598300;36164098600,60117751;60117751;60117751;60117751;60117751;60117933;60117933,2012-11-07,2012,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,1,,,620-626,"Document summarization is of great value to many real world applications, such as snippets generation for search results and news headlines generation. Traditionally, document summarization is implemented by extracting sentences that cover the main topics of a document with a minimum redundancy. In this paper, we take a different perspective from data reconstruction and propose a novel framework named Document Summarization based on Data Reconstruction (DSDR). Specifically, our approach generates a summary which consist of those sentences that can best reconstruct the original document. To model the relationship among sentences, we introduce two objective functions: (1) linear reconstruction, which approximates the document by linear combinations of the selected sentences; (2) nonnegative linear reconstruction, which allows only additive, not subtractive, linear combinations. In this framework, the reconstruction error becomes a natural criterion for measuring the quality of the summary. For each objective function, we develop an efficient algorithm to solve the corresponding optimization problem. Extensive experiments on summarization benchmark data sets DUC 2006 and DUC 2007 demonstrate the effectiveness of our proposed approach. Copyright © 2012, Association for the Advancement of Artificial Intelligence. All rights reserved.",,71,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-84870578272,10.1109/SP.2012.18,,,Don't trust satellite phones: A security analysis of two satphone standards,cp,Conference Paper,Driessen B.,60005322,Ruhr-Universitat Bochum,Bochum,Germany,5,"Driessen, Benedikt;Hund, Ralf;Willems, Carsten;Paar, Christof;Holz, Thorsten",25654804500;55734438400;23135965300;7004505375;53263832100,60005322;60005322;60005322;60005322;60005322,2012-01-01,2012,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,,,6234409,128-142,"There is a rich body of work related to the security aspects of cellular mobile phones, in particular with respect to the GSM and UMTS systems. To the best of our knowledge, however, there has been no investigation of the security of satellite phones (abbr. sat phones). Even though a niche market compared to the G2 and G3 mobile systems, there are several 100,000 sat phone subscribers worldwide. Given the sensitive nature of some of their application domains (e.g., natural disaster areas or military campaigns), security plays a particularly important role for sat phones. In this paper, we analyze the encryption systems used in the two existing (and competing) sat phone standards, GMR-1 and GMR-2. The first main contribution is that we were able to completely reverse engineer the encryption algorithms employed. Both ciphers had not been publicly known previously. We describe the details of the recovery of the two algorithms from freely available DSP-firmware updates for sat phones, which included the development of a custom disassembler and tools to analyze the code, and extending prior work on binary analysis to efficiently identify cryptographic code. We note that these steps had to be repeated for both systems, because the available binaries were from two entirely different DSP processors. Perhaps somewhat surprisingly, we found that the GMR-1 cipher can be considered a proprietary variant of the GSM A5/2 algorithm, whereas the GMR-2 cipher is an entirely new design. The second main contribution lies in the cryptanalysis of the two proprietary stream ciphers. We were able to adopt known A5/2 cipher text-only attacks to the GMR-1 algorithm with an average case complexity of 232 steps. With respect to the GMR-2 cipher, we developed a new attack which is powerful in a known-plaintext setting. In this situation, the encryption key for one session, i.e., one phone call, can be recovered with approximately 50-65 bytes of key stream and a moderate computational complexity. A major finding of our work is that the stream ciphers of the two existing satellite phone systems are considerably weaker than what is state-of-the-art in symmetric cryptography. © 2012 IEEE.",Binary Analysis | Cryptanalysis | Mobile Security | Satellite Phone Systems,33,0,,,,undefined,,S&P Security and Privacy
2-s2.0-84862060034,10.1145/2207676.2207749,,,"Empathy, participatory design and people with dementia",cp,Conference Paper,Lindsay S.,60006222,Newcastle University,Newcastle,United Kingdom,6,"Lindsay, Stephen;Jackson, Daniel;Ladha, Cas;Ladha, Karim;Brittain, Katie;Olivier, Patrick",56744169000;57198414941;24724532400;37052538300;56367519800;57209133100,60006222;60006222;60006222;60006222;60006222;60006222,2012-05-24,2012,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,521-530,"We describe the development, application and evaluation of a design method tailored for working with people with mild to moderate dementia. Our experiences with the approach highlighted areas where designers and participants held radically different views. The tenet of our approach was that to overcome these differences we needed to create an empathic relationship between participants and designers. To achieve this we modified participatory design techniques to foster respectful engagement with participants in the development of a digital aid to facilitate 'safe walking'. The process begins with broad qualitative scoping and design work then moves to developing personally tailored, individual designs to further exploration of the experiential elements of the domain while reducing the need for the participants to engage in abstract thought. Reflection highlights a number of important areas that demand consideration when undertaking research in this area and, more generally, when performing design work with people with dementia. Copyright 2012 ACM.",Cognitive impairment | Dementia | Empathy | Experience | Participatory design | Prompting,171,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84871033301,10.1145/2396761.2396795,,,"Gelling, and melting, large graphs by edge manipulation",cp,Conference Paper,Tong H.,60119141;60029526;60027950;60027090;60017366,"Rutgers University–New Brunswick;University of California, Riverside;Carnegie Mellon University;Virginia Polytechnic Institute and State University;IBM Thomas J. Watson Research Center",New Brunswick;Riverside;Pittsburgh;Blacksburg;Yorktown Heights,United States;United States;United States;United States;United States,5,"Tong, Hanghang;Prakash, B. Aditya;Eliassi-Rad, Tina;Faloutsos, Michalis;Faloutsos, Christos",7201360533;35113606100;6507223439;6603752200;7006005166,60017366;60027090;60119141;60029526;60027950,2012-12-19,2012,ACM International Conference Proceeding Series,,11600154611,,Conference Proceeding,,,,245-254,"Controlling the dissemination of an entity (e.g., meme, virus, etc) on a large graph is an interesting problem in many disciplines. Examples include epidemiology, computer security, marketing, etc. So far, previous studies have mostly focused on removing or inoculating nodes to achieve the desired outcome. We shift the problem to the level of edges and ask: which edges should we add or delete in order to speed-up or contain a dissemination? First, we propose effective and scalable algorithms to solve these dissemination problems. Second, we conduct a theoretical study of the two problems and our methods, including the hardness of the problem, the accuracy and complexity of our methods, and the equivalence between the different strategies and problems. Third and lastly, we conduct experiments on real topologies of varying sizes to demonstrate the effectiveness and scalability of our approaches. © 2012 ACM.",edge manipulation | graph mining | immunization | scalability,162,0,repositoryam,Green,,undefined,,CIKM Knowledge Management
2-s2.0-84862644813,10.1145/2213836.2213866,,,High-performance complex event processing over XML streams,cp,Conference Paper,Mozafari B.,60027550,"University of California, Los Angeles",Los Angeles,United States,3,"Mozafari, Barzan;Zeng, Kai;Zaniolo, Carlo",25028687800;55162994000;35610506100,60027550;60027550;60027550,2012-06-28,2012,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,253-264,"Much research attention has been given to delivering high-performance systems that are capable of complex event processing (CEP) in a wide range of applications. However, many current CEP systems focus on processing efficiently data having a simple structure, and are otherwise limited in their ability to support efficiently complex continuous queries on structured or semi-structured information. However, XML streams represent a very popular form of data exchange, comprising large portions of social network and RSS feeds, financial records, configuration files, and similar applications requiring advanced CEP queries. In this paper, we present the XSeq language and system that support CEP on XML streams, via an extension of XPath that is both powerful and amenable to an efficient implementation. Specifically, the XSeq language extends XPath with natural operators to express sequential and Kleene-*patterns over XML streams, while remaining highly amenable to efficient implementation. XSeq is designed to take full advantage of recent advances in the field of automata on Visibly Pushdown Automata (VPA), where higher expressive power can be achieved without compromising efficiency (whereas the amenability to efficient implementation was not demonstrated in XPath extensions previously proposed). We illustrate XSeq's power for CEP applications through examples from different domains, and provide formal results on its expressiveness and complexity. Finally, we present several optimization techniques for XSeq queries. Our extensive experiments indicate that XSeq brings outstanding performance to CEP applications: two orders of magnitude improvement are obtained over the same queries executed in general-purpose XML engines. © 2012 ACM.",complex event processing | visibly pushdown automata | xml,40,0,repositoryam,Green,,undefined,,SIGMOD Databases
2-s2.0-84864191006,10.1109/ICSE.2012.6227188,,,How do professional developers comprehend software?,cp,Conference Paper,Roehm T.,60019722;60008293,Technische Universität München;Universität Bremen,Munich;Bremen,Germany;Germany,4,"Roehm, Tobias;Tiarks, Rebecca;Koschke, Rainer;Maalej, Walid",55320885900;35226744100;6602106142;25928659900,60019722;60008293;60008293;60019722,2012-07-30,2012,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,6227188,255-265,"Research in program comprehension has considerably evolved over the past two decades. However, only little is known about how developers practice program comprehension under time and project pressure, and which methods and tools proposed by researchers are used in industry. This paper reports on an observational study of 28 professional developers from seven companies, investigating how developers comprehend software. In particular we focus on the strategies followed, information needed, and tools used. We found that developers put themselves in the role of end users by inspecting user interfaces. They try to avoid program comprehension, and employ recurring, structured comprehension strategies depending on work context. Further, we found that standards and experience facilitate comprehension. Program comprehension was considered a subtask of other maintenance tasks rather than a task by itself. We also found that face-to-face communication is preferred to documentation. Overall, our results show a gap between program comprehension research and practice as we did not observe any use of state of the art comprehension tools and developers seem to be unaware of them. Our findings call for further careful analysis and for reconsidering research agendas. © 2012 IEEE.",context awareness | empirical studies | maintenance | program comprehension | software documentation,178,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84862087828,10.1145/2207676.2207713,,,Improving command selection with CommandMaps,cp,Conference Paper,Scarr J.,60020585;60015186;60009697,University of Canterbury;University of Saskatchewan;University of Manitoba,Christchurch;Saskatoon;Winnipeg,New Zealand;Canada;Canada,4,"Scarr, Joey;Cockburn, Andy;Gutwin, Carl;Bunt, Andrea",55725914300;7004557137;35587413900;8971348500,60020585;60020585;60015186;60009697,2012-05-24,2012,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,257-266,"Designers of GUI applications typically arrange commands in hierarchical structures, such as menus, due to screen space limitations. However, hierarchical organisations are known to slow down expert users. This paper proposes the use of spatial memory in combination with hierarchy flattening as a means of improving GUI performance. We demonstrate these concepts through the design of a command selection interface, called CommandMaps, and analyse its theoretical performance characteristics. We then describe two studies evaluating CommandMaps against menus and Microsoft's Ribbon interface for both novice and experienced users. Results show that for novice users, there is no significant performance difference between CommandMaps and traditional interfaces - but for experienced users, CommandMaps are significantly faster than both menus and the Ribbon. Copyright 2012 ACM.",Commands | Expertise | Hierarchies | Spatial memory,62,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84869076156,,,,Jamming user interfaces: Programmable particle stiffness and sensing for malleable and shape-changing devices,cp,Conference Paper,Follmer S.,60022195;60002243,Massachusetts Institute of Technology;MIT Media Lab,Cambridge;Cambridge,United States;United States,5,"Follmer, Sean;Leithinger, Daniel;Olwal, Alex;Cheng, Nadia;Ishii, Hiroshi",26430822900;23035442100;7801329807;36460688000;26660877000,60002243;60002243;60002243;60022195;60002243,2012-11-19,2012,UIST'12 - Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology,,21100219920,,Conference Proceeding,,,,519-528,"Malleable and organic user interfaces have the potential to enable radically new forms of interactions and expressiveness through flexible, free-form and computationally controlled shapes and displays. This work, specifically focuses on particle jamming as a simple, effective method for flexible, shape-changing user interfaces where programmatic control of material stiffness enables haptic feedback, deformation, tunable affordances and control gain. We introduce a compact, low-power pneumatic jamming system suitable for mobile devices, and a new hydraulic-based technique with fast, silent actuation and optical shape sensing. We enable jamming structures to sense input and function as interaction devices through two contributed methods for high-resolution shape sensing using: 1) index-matched particles and fluids, and 2) capacitive and electric field sensing. We explore the design space of malleable and organic user interfaces enabled by jamming through four motivational prototypes that highlight jamming's potential in HCI, including applications for tabletops, tablets and for portable shape-changing mobile devices. Copyright 2012 ACM.",Haptic feedback | Jamming | Malleable Input | Organic user interfaces | Variable stiffness,201,0,,,,undefined,,UIST User Interface
2-s2.0-84868297532,,,,Learning SVM classifiers with indefinite kernels,cp,Conference Paper,Gu S.,60149322,Department of Computer and Information Sciences,Philadelphia,United States,2,"Gu, Suicheng;Guo, Yuhong",58355527100;10240222700,60149322;60149322,2012-11-07,2012,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,2,,,942-948,"Recently, training support vector machines with indefinite kernels has attracted great attention in the machine learning community. In this paper, we tackle this problem by formulating a joint optimization model over SVM classifications and kernel principal component analysis. We first reformulate the kernel principal component analysis as a general kernel transformation framework, and then incorporate it into the SVM classification to formulate a joint optimization model. The proposed model has the advantage of making consistent kernel transformations over training and test samples. It can be used for both binary classification and multiclass classification problems. Our experimental results on both synthetic data sets and real world data sets show the proposed model can significantly outperform related approaches. Copyright © 2012, Association for the Advancement of Artificial Intelligence. All rights reserved.",,22,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-84862620949,10.1145/2213977.2213988,,,Linear vs. semidefinite extended formulations: Exponential separation and strong lower bounds,cp,Conference Paper,Fiorini S.,60002483;60000765;60000145,Universiteit van Amsterdam;Friedrich-Alexander-Universität Erlangen-Nürnberg;Université Libre de Bruxelles,Amsterdam;Erlangen;Brussels,Netherlands;Germany;Belgium,5,"Fiorini, Samuel;Massar, Serge;Pokutta, Sebastian;Tiwary, Hans Raj;De Wolf, Ronald",6603912360;7003869116;23019856800;22837078900;6701691445,60000145;60000145;60000765;60000145;60002483,2012-06-26,2012,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,95-106,"We solve a 20-year old problem posed by Yannakakis and prove that there exists no polynomial-size linear program (LP) whose associated polytope projects to the traveling salesman polytope, even if the LP is not required to be symmetric. Moreover, we prove that this holds also for the cut polytope and the stable set polytope. These results were discovered through a new connection that we make between one-way quantum communication protocols and semidefinite programming reformulations of LPs. © 2012 ACM.",combinatorial optimization | communication complexity | linear programming | quantum communication complexity | semidefinite programming,139,0,,,,undefined,,STOC Theory
2-s2.0-84862086430,10.1145/2207676.2207718,,,Looking glass: A field study on noticing interactivity of a shop window,cp,Conference Paper,Müller J.,60015815;60011604,Universität Stuttgart;Technische Universität Berlin,Stuttgart;Berlin,Germany;Germany,5,"Müller, Jörg;Walter, Robert;Bailly, Gilles;Nischt, Michael;Alt, Florian",57191035823;36195691700;23395749200;14008084000;27267528900,60011604;60011604;60011604;60011604;60015815,2012-05-24,2012,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,297-306,"In this paper we present our findings from a lab and a field study investigating how passers-by notice the interactivity of public displays. We designed an interactive installation that uses visual feedback to the incidental movements of passersby to communicate its interactivity. The lab study reveals: (1) Mirrored user silhouettes and images are more effective than avatar-like representations. (2) It takes time to notice the interactivity (approximately 1.2s). In the field study, three displays were installed during three weeks in shop windows, and data about 502 interaction sessions were collected. Our observations show: (1) Significantly more passers-by interact when immediately showing the mirrored user image (+90%) or silhouette (+47%) compared to a traditional attract sequence with call-to-action. (2) Passers-by often notice interactivity late and have to walk back to interact (the landing effect). (3) If somebody is already interacting, others begin interaction behind the ones already interacting, forming multiple rows (the honeypot effect). Our findings can be used to design public display applications and shop windows that more effectively communicate interactivity to passers-by. Copyright 2012 ACM.",Interactivity | Noticing interactivity | Public displays | User representation,247,0,repositoryvor,Green,FP7,215893,Seventh Framework Programme,CHI Human-Computer Interaction
2-s2.0-84866524258,10.1145/2342356.2342358,,,Multi-resource fair queueing for packet processing,cp,Conference Paper,Ghodsi A.,60033010;60025038;60002014,"Intel Corporation;University of California, Berkeley;The Royal Institute of Technology (KTH)",Santa Clara;Berkeley;Stockholm,United States;United States;Sweden,4,"Ghodsi, Ali;Sekar, Vyas;Zaharia, Matei;Stoica, Ion",55522191698;8835481500;15064891400;7007009125,60025038-60002014;60033010;60025038;60025038,2012-09-26,2012,"SIGCOMM'12 - Proceedings of the ACM SIGCOMM 2012 Conference Applications, Technologies, Architectures, and Protocols for Computer Communication",,21100216313,,Conference Proceeding,,,,1-12,"Middleboxes are ubiquitous in today's networks and perform a variety of important functions, including IDS, VPN, firewalling, and WAN optimization. These functions differ vastly in their requirements for hardware resources (e.g., CPU cycles and memory bandwidth). Thus, depending on the functions they go through, different flows can consume different amounts of a middlebox's resources. While there is much literature on weighted fair sharing of link bandwidth to isolate flows, it is unclear how to schedule multiple resources in a middlebox to achieve similar guarantees. In this paper, we analyze several natural packet scheduling algorithms for multiple resources and show that they have undesirable properties. We propose a new algorithm, Dominant Resource Fair Queuing (DRFQ), that retains the attractive properties that fair sharing provides for one resource. In doing so, we generalize the concept of virtual time in classical fair queuing to multi-resource settings. The resulting algorithm is also applicable in other contexts where several resources need to be multiplexed in the time domain. © 2012 ACM.",fair queueing | fairness | middleboxes | scheduling,110,1,publisherfree2read,Bronze,,undefined,,SIGCOMM Networking
2-s2.0-84861627307,10.1109/INFCOM.2012.6195481,,,Multi-resource allocation: Fairness-efficiency tradeoffs in a unifying framework,cp,Conference Paper,Joe-Wong C.,60141924;60141284,The George Washington University School of Engineering and Applied Science;School of Engineering and Applied Science,"Washington, D.C.;Princeton",United States;United States,4,"Joe-Wong, Carlee;Sen, Soumya;Lan, Tian;Chiang, Mung",47962256600;55821610600;57204717871;7102873398,60141284;60141284;60141924;60141284,2012-06-04,2012,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,,,6195481,1206-1214,"Quantifying the notion of fairness is under-explored when users request different ratios of multiple distinct resource types. A typical example is datacenters processing jobs with heterogeneous resource requirements on CPU, memory, etc. A generalization of max-min fairness to multiple resources was recently proposed in [1], but may suffer from significant loss of efficiency. This paper develops a unifying framework addressing this fairness-efficiency tradeoff with multiple resource types. We develop two families of fairness functions which provide different tradeoffs, characterize the effect of user requests' heterogeneity, and prove conditions under which these fairness measures satisfy the Pareto efficiency, sharing incentive, and envy-free properties. Intuitions behind the analysis are explained in two visualizations of multi-resource allocation. © 2012 IEEE.",,115,0,repositoryam,Green,,undefined,,INFOCOM Networking
2-s2.0-84862099321,10.1145/2207676.2208658,,,Observational and experimental investigation of typing behaviour using virtual keyboards on mobile devices,cp,Conference Paper,Henze N.,60023643;60020306;60014264,Lancaster University;Universität Oldenburg;Universität Duisburg-Essen,Lancaster;Oldenburg;Duisburg,United Kingdom;Germany;Germany,3,"Henze, Niels;Rukzio, Enrico;Boll, Susanne",23396769800;18233783900;14522025600,60020306;60014264-60023643;60020306,2012-05-24,2012,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,2659-2668,"With the rise of current smartphones, virtual keyboards for touchscreens became the dominant mobile text entry technique. We developed a typing game that records how users touch on the standard Android keyboard to investigate users' typing behaviour. 47,770,625 keystrokes from 72,945 installations have been collected by publishing the game. By visualizing the touch distribution we identified a systematic skew and derived a function that compensates this skew by shifting touch events. By updating the game we conduct an experiment that investigates the effect of shifting touch events, changing the keys' labels, and visualizing the touched position. Results based on 6,603,659 keystrokes and 13,013 installations show that visualizing the touched positions using a simple dot decreases the error rate of the Android keyboard by 18.3% but also decreases the speed by 5.2% with no positive effect on learnability. The Android keyboard outperforms the control condition but the constructed shift function further improves the performance by 2.2% and decreases the error rate by 9.1%. We argue that the shift function can improve existing keyboards at no costs. Copyright 2012 ACM.",Mobile phone | Public study | Touchscreen | Virtual keyboard,74,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84864194189,10.1109/ICSE.2012.6227159,,,Partial models: Towards modeling and reasoning with uncertainty,cp,Conference Paper,Famelis M.,60016849,University of Toronto,Toronto,Canada,3,"Famelis, Michaiis;Salay, Rick;Chechik, Marsha",54974297900;6504783762;6603893035,60016849;60016849;60016849,2012-07-30,2012,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,6227159,573-583,"Models are good at expressing information about software but not as good at expressing modelers' uncertainty about it. The highly incremental and iterative nature of software development nonetheless requires the ability to express uncertainty and reason with models containing it. In this paper, we build on our earlier work on expressing uncertainty using partial models, by elaborating an approach to reasoning with such models. We evaluate our approach by experimentally comparing it to traditional strategies for dealing with uncertainty as well as by conducting a case study using open source software. We conclude that we are able to reap the benefits of well-managed uncertainty while incurring minimal additional cost. © 2012 IEEE.",,124,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-84862089419,10.1145/2207676.2208572,,,Personas and decision making in the design process: An ethnographic case study,cp,Conference Paper,Friess E.,60024438,University of North Texas,Denton,United States,1,"Friess, Erin",22834144000,60024438,2012-05-24,2012,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1209-1218,"Personas have become a well-lauded method to aid designers in keeping the needs of the intended user population at the forefront of the design process. However, few studies have ethnographically observed design teams that use personas, and fewer studies have looked specifically at how designers linguistically invoke personas in their decision-making sessions. This discourse analysis of the decision-making sessions of designers at a top tier design firm reveals that although the designers dedicate much time researching, developing, and refining personas, personas themselves make relatively few appearances in the designers' language during decision-making sessions. This study shows that, for persuasive ends, these designers, who are advocates of personas, routinely use other less precise and more designer-centric linguistic mechanisms in lieu of personas. Despite the scarcity of personas in the decisionmaking sessions, this ethnographic case study also explores the value of personas for this team even when the personas are not explicitly linguistically invoked. Copyright 2012 ACM.",Design decision-making | Discourse analysis | Ethnography | Personas | User-centered design,117,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85040175609,,,,Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing,cp,Conference Paper,Zaharia M.,60025038,"University of California, Berkeley",Berkeley,United States,9,"Zaharia, Matei;Chowdhury, Mosharaf;Das, Tathagata;Dave, Ankur;Ma, Justin;McCauley, Murphy;Franklin, Michael J.;Shenker, Scott;Stoica, Ion",15064891400;36102149200;15131117000;54683684600;15136281100;57215308852;7202284265;35593393300;7007009125,60025038;60025038;60025038;60025038;60025038;60025038;60025038;60025038;60025038,2012-01-01,2012,Proceedings of NSDI 2012: 9th USENIX Symposium on Networked Systems Design and Implementation,,21100959191,,Conference Proceeding,,,,15-28,"We present Resilient Distributed Datasets (RDDs), a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a fault-tolerant manner. RDDs are motivated by two types of applications that current computing frameworks handle inefficiently: iterative algorithms and interactive data mining tools. In both cases, keeping data in memory can improve performance by an order of magnitude. To achieve fault tolerance efficiently, RDDs provide a restricted form of shared memory, based on coarse-grained transformations rather than fine-grained updates to shared state. However, we show that RDDs are expressive enough to capture a wide class of computations, including recent specialized programming models for iterative jobs, such as Pregel, and new applications that these models do not capture. We have implemented RDDs in a system called Spark, which we evaluate through a variety of user applications and benchmarks.",,3211,0,,,DARPA,8650-11-C-7136,Defense Advanced Research Projects Agency,NSDI Networking
2-s2.0-84862063767,10.1145/2207676.2208280,,,Revisiting the Jacquard loom: Threads of history and current patterns in HCI,cp,Conference Paper,Fernaeus Y.,60028378;60021136;60002014,Stockholms universitet;Södertörn University;The Royal Institute of Technology (KTH),Stockholm;Huddinge;Stockholm,Sweden;Sweden;Sweden,3,"Fernaeus, Ylva;Jonsson, Martin;Tholander, Jakob",14035371000;24080241600;56157562400,60002014;60021136;60028378,2012-05-24,2012,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1593-1602,"In the recent developments of human computer interaction, one central challenge has been to find and to explore alternatives to the legacy of the desktop computer paradigm for interaction design. To investigate this issue further we have conducted an analysis on a fascinating piece of machinery often referred to as one of the predecessors of the modern day computer, the Jacquard loom. In analysing the Jacquard loom we look at qualities in design and interaction from some different perspectives: how historical tools, crafts, and practices can inform interaction design, the role of physicality, materiality, and whole-body interaction in order to rethink some current conceptions of interaction and design of computational devices. Copyright 2012 ACM.",History of HCI | Materiality | Sustainable interaction design | Whole body interaction,43,0,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84871283617,10.1145/2393596.2393637,,,Scalable test data generation from multidimensional models,cp,Conference Paper,Torlak E.,60025038,"University of California, Berkeley",Berkeley,United States,1,"Torlak, Emina",23089529200,60025038,2012-12-24,2012,"Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering, FSE 2012",,21100223523,,Conference Proceeding,,,,,"Multidimensional data models form the core of modern decision support software. The need for this kind of software is significant, and it continues to grow with the size and variety of datasets being collected today. Yet real multidimensional instances are often unavailable for testing and benchmarking, and existing data generators can only produce a limited class of such structures. In this paper, we present a new framework for scalable generation of test data from a rich class of multidimensional models. The framework provides a small, expressive language for specifying such models, and a novel solver for generating sample data from them. While the satisfiability problem for the language is NP-hard, we identify a polynomially solvable fragment that captures most practical modeling patterns. Given a model and, optionally, a statistical specification of the desired test dataset, the solver detects and instantiates a maximal subset of the model within this fragment, generating data that exhibits the desired statistical properties. We use our framework to generate a variety of high-quality test datasets from real industrial models, which cannot be correctly instantiated by existing data generators, or as effectively solved by general-purpose constraint solvers. © 2012 ACM.",constraint solving | multidimensional models | specification | test data generation,14,0,,,,undefined,,FSE Software Engineering
2-s2.0-84866037385,10.1145/2339530.2339576,,,Searching and mining trillions of time series subsequences under dynamic time warping,cp,Conference Paper,Rakthanmanon T.,60029526;60016782;60008088,"University of California, Riverside;Brigham and Women's Hospital;Universidade de São Paulo",Riverside;Boston;Sao Paulo,United States;United States;Brazil,8,"Rakthanmanon, Thanawin;Campana, Bilson;Mueen, Abdullah;Batista, Gustavo;Westover, Brandon;Zhu, Qiang;Zakaria, Jesin;Keogh, Eamonn",6507628421;36665852500;35243537000;55062789000;55384180400;35114386900;55354823800;7006166198,60029526;60029526;60029526;60008088;60016782;60029526;60029526;60029526,2012-09-14,2012,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,101510,,Conference Proceeding,,,,262-270,"Most time series data mining algorithms use similarity search as a core subroutine, and thus the time taken for similarity search is the bottleneck for virtually all time series data mining algorithms. The difficulty of scaling search to large datasets largely explains why most academic work on time series data mining has plateaued at considering a few millions of time series objects, while much of industry and science sits on billions of time series objects waiting to be explored. In this work we show that by using a combination of four novel ideas we can search and mine truly massive time series for the first time. We demonstrate the following extremely unintuitive fact; in large datasets we can exactly search under DTW much more quickly than the current state-of-the-art Euclidean distance search algorithms. We demonstrate our work on the largest set of time series experiments ever attempted. In particular, the largest dataset we consider is larger than the combined size of all of the time series datasets considered in all data mining papers ever published. We show that our ideas allow us to solve higher-level time series data mining problem such as motif discovery and clustering at scales that would otherwise be untenable. In addition to mining massive datasets, we will show that our ideas also have implications for real-time monitoring of data streams, allowing us to handle much faster arrival rates and/or use cheaper and lower powered devices than are currently possible. © 2012 ACM.",lower bounds | similarity search | time series,815,0,repositoryam,Green,CISE,0803410,Directorate for Computer and Information Science and Engineering,KDD Data Mining
2-s2.0-84871345410,10.1145/2393596.2393661,,,Seeking the ground truth: A retroactive study on the evolution and migration of software libraries,cp,Conference Paper,Cossette B.,60002306,University of Calgary,Calgary,Canada,2,"Cossette, Bradley E.;Walker, Robert J.",24469708200;7404928760,60002306;60002306,2012-12-24,2012,"Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering, FSE 2012",,21100223523,,Conference Proceeding,,,,,"Application programming interfaces (APIs) are a common and industrially-relevant means for third-party software developers to reuse external functionality. Several techniques have been proposed to help migrate client code between library versions with incompatible APIs, but it is not clear how well these perform in an absolute sense. We present a retroactive study into the presence and nature of API incompatibilities between several versions of a set of Java-based software libraries; for each, we perform a detailed, manual analysis to determine what the correct adaptations are to migrate from the older to the newer version. In addition, we investigate whether any of a set of adaptation recommender techniques is capable of identifying the correct adaptations for library migration. We find that a given API incompatibility can typically be addressed by only one or two recommender techniques, but sometimes none serve. Furthermore, those techniques give correct recommendations, on average, in only about 20% of cases. © 2012 ACM.",adaptive change | API | recommendation systems,96,0,,,,undefined,,FSE Software Engineering
2-s2.0-85065170765,,,,Spanner: Google's globally-distributed database,cp,Conference Paper,Corbett J.C.,60006191,Google LLC,Mountain View,United States,26,"Corbett, James C.;Dean, Jeffrey;Epstein, Michael;Fikes, Andrew;Frost, Christopher;Furman, J. J.;Ghemawat, Sanjay;Gubarev, Andrey;Heiser, Christopher;Hochschild, Peter;Hsieh, Wilson;Kanthak, Sebastian;Kogan, Eugene;Li, Hongyi;Lloyd, Alexander;Melnik, Sergey;Mwaura, David;Nagle, David;Quinlan, Sean;Rao, Rajesh;Rolig, Lindsay;Saito, Yasushi;Szymaniak, Michal;Taylor, Christopher;Wang, Ruth;Woodford, Dale",7402399468;16427311000;57206529035;24174045000;55847007300;52363522800;6507434941;42261796000;55847120300;6602791276;7203083164;15046758400;55846987100;55846970100;52364453700;57207509651;57204485371;55846733300;7003889533;55847219600;55847162200;55466440400;8749682000;55847031200;55846770900;55846972700,60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191,2012-01-01,2012,"Proceedings of the 10th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2012",,21100959953,,Conference Proceeding,,,,251-264,"Spanner is Google's scalable, multi-version, globally-distributed, and synchronously-replicated database. It is the first system to distribute data at global scale and support externally-consistent distributed transactions. This paper describes how Spanner is structured, its feature set, the rationale underlying various design decisions, and a novel time API that exposes clock uncertainty. This API and its implementation are critical to supporting external consistency and a variety of powerful features: non-blocking reads in the past, lock-free read-only transactions, and atomic schema changes, across all of Spanner.",,606,0,,,,undefined,,OSDI Operating Systems
2-s2.0-84864718143,10.1145/2254756.2254778,,,Temperature management in data centers: Why some (might) like it hot,cp,Conference Paper,El-Sayed N.,60016849,University of Toronto,Toronto,Canada,5,"El-Sayed, Nosayba;Stefanovici, Ioan A.;Amvrosiadis, George;Hwang, Andy A.;Schroeder, Bianca",57201841124;55129251500;55329374000;55129789000;7102055268,60016849;60016849;60016849;60016849;60016849,2012-08-13,2012,Performance Evaluation Review,01635999,26742,,Conference Proceeding,40,1 SPEC. ISS.,,163-174,"The energy consumed by data centers is starting to make up a significant fraction of the world's energy consumption and carbon emissions. A large fraction of the consumed energy is spent on data center cooling, which has motivated a large body of work on temperature management in data centers. Interestingly, a key aspect of temperature management has not been well understood: controlling the setpoint temperature at which to run a data center's cooling system. Most data centers set their thermostat based on (conservative) suggestions by manufacturers, as there is limited understanding of how higher temperatures will affect the system. At the same time, studies suggest that increasing the temperature setpoint by just one degree could save 2-5% of the energy consumption. This paper provides a multi-faceted study of temperature management in data centers. We use a large collection of field data from different production environments to study the impact of temperature on hardware reliability, including the reliability of the storage subsystem, the memory subsystem and server reliability as a whole. We also use an experimental testbed based on a thermal chamber and a large array of benchmarks to study two other potential issues with higher data center temperatures: the effect on server performance and power. Based on our findings, we make recommendations for temperature management in data centers, that create the potential for saving energy, while limiting negative effects on system reliability and performance. © 2012 ACM.",CPU | data center | DRAM | energy | fans | hard drive | LSE | memory | performance | reliability | temperature,141,0,,,,undefined,,SIGMETRICS Performance
2-s2.0-84862613422,10.1145/2213977.2213987,,,The cell probe complexity of dynamic range counting,cp,Conference Paper,Larsen K.G.,60029616,Aarhus Universitet,Aarhus,Denmark,1,"Larsen, Kasper Green",36701713800,60029616,2012-06-26,2012,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,85-94,"In this paper we develop a new technique for proving lower bounds on the update time and query time of dynamic data structures in the cell probe model. With this technique, we prove the highest lower bound to date for any explicit problem, namely a lower bound of t q=Ω((lg n/lg(wt u)) 2). Here n is the number of update operations, w the cell size, t q the query time and t u the update time. In the most natural setting of cell size w=Θ(lg n), this gives a lower bound of t q=Ω((lg n/lg lg n) 2) for any polylogarithmic update time. This bound is almost a quadratic improvement over the highest previous lower bound of Ω(lg n), due to Patrascu and Demaine [SICOMP'06]. We prove our lower bound for the fundamental problem of weighted orthogonal range counting. In this problem, we are to support insertions of two-dimensional points, each assigned a Θ(lg n)-bit integer weight. A query to this problem is specified by a point q=(x,y), and the goal is to report the sum of the weights assigned to the points dominated by q, where a point (x′,y′) is dominated by q if x′ ≤ x and y′ ≤ y. In addition to being the highest cell probe lower bound to date, our lower bound is also tight for data structures with update time t u = Ω(lg 2+εn), where ε>0 is an arbitrarily small constant. © 2012 ACM.",cell probe | computational geometry | lower bounds | range searching,54,0,repositoryam,Green,,undefined,,STOC Theory
2-s2.0-84862107186,10.1145/2207676.2208285,,,"The normal, natural troubles of driving with GPS",cp,Conference Paper,Brown B.,60028378;60027272,Stockholms universitet;The University of Edinburgh,Stockholm;Edinburgh,Sweden;United Kingdom,2,"Brown, Barry;Laurier, Eric",9234195400;6701537810,60028378;60027272,2012-05-24,2012,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1621-1630,"In-car GPS based satellite navigation systems are now a common part of driving, providing turn-by-turn navigation instructions on smartphones, portable units or in-car dashboard navigation systems. This paper uses interactional analysis of video data from fifteen naturalistically recorded journeys with GPS to understand the navigational practices deployed by drivers and passengers. The paper documents five types of 'trouble' where GPS systems cause issues and confusion for drivers around: destinations, routes, maps & sensors, timing and relevance and legality. The paper argues that to design GPS systems better we need to move beyond the notion of a docile driver who follows GPS command blindly, to a better understanding of how drivers, passengers and GPS systems work together. We develop this in discussing how technology might better support 'instructed action'. Copyright 2012 ACM.",Driving | GPS | Interaction analysis | SatNav | Video analysis,78,0,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84866603223,10.1145/2348283.2348300,,,Time-based calibration of effectiveness measures,cp,Conference Paper,Smucker M.D.,60014171,University of Waterloo,Waterloo,Canada,2,"Smucker, Mark D.;Clarke, Charles L.A.",15045946800;7401438213,60014171;60014171,2012-09-28,2012,SIGIR'12 - Proceedings of the International ACM SIGIR Conference on Research and Development in Information Retrieval,,21100216503,,Conference Proceeding,,,,95-104,"Many current effectiveness measures incorporate simplifying assumptions about user behavior. These assumptions prevent the measures from reflecting aspects of the search process that directly impact the quality of retrieval results as experienced by the user. In particular, these measures implicitly model users as working down a list of retrieval results, spending equal time assessing each document. In reality, even a careful user, intending to identify as much relevant material as possible, must spend longer on some documents than on others. Aspects such as document length, duplicates and summaries all influence the time required. In this paper, we introduce a time-biased gain measure, which explicitly accommodates such aspects of the search process. By conducting an appropriate user study, we calibrate and validate the measure against the TREC 2005 Robust Track test collection. We examine properties of the measure, contrasting it to traditional effectiveness measures, and exploring its extension to other aspects and environments. As its primary benefit, the measure allows us to evaluate system performance in human terms, while maintaining the simplicity and repeatability of system-oriented tests. Overall, we aim to achieve a clearer connection between user-oriented studies and system-oriented tests, allowing us to better transfer insights and outcomes from one to the other. © 2012 ACM.",information retrieval | search evaluation,170,0,,,,undefined,,SIGIR Information Retrieval
2-s2.0-84862069121,10.1145/2207676.2207743,,,"Touché: Enhancing touch interaction on humans, screens, liquids, and everyday objects",cp,Conference Paper,Sato M.,60136640;60032776;60025272,School of Computer Science;The Walt Disney Company;The University of Tokyo,Pittsburgh;Burbank;Tokyo,United States;United States;Japan,3,"Sato, Munehiko;Poupyrev, Ivan;Harrison, Chris",25723720000;6603553340;35792227900,60032776-60025272;60032776;60032776-60136640,2012-05-24,2012,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,483-492,"Touché proposes a novel Swept Frequency Capacitive Sensing technique that can not only detect a touch event, but also recognize complex configurations of the human hands and body. Such contextual information significantly enhances touch interaction in a broad range of applications, from conventional touchscreens to unique contexts and materials. For example, in our explorations we add touch and gesture sensitivity to the human body and liquids. We demonstrate the rich capabilities of Touché with five example setups from different application domains and conduct experimental studies that show gesture classification accuracies of 99% are achievable with our technology. Copyright 2012 ACM.",Gestures | Mobile devices | On-body computing | Sensors | Touch | Ubiquitous interfaces,257,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84862099625,10.1145/2207676.2208347,,,Uncomfortable interactions,cp,Conference Paper,Benford S.,60026479;60015138,University of Exeter;University of Nottingham,Exeter;Nottingham,United Kingdom;United Kingdom,6,"Benford, Steve;Greenhalgh, Chris;Giannachi, Gabriella;Walker, Brendan;Marshall, Joe;Rodden, Tom",7006887786;7005591570;23396898600;35732429300;23025020900;7003488009,60015138;60015138;60026479;60015138;60015138;60015138,2012-05-24,2012,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,2005-2014,"We argue for deliberately and systematically creating uncomfortable interactions as part of powerful cultural experiences. We identify the potential benefits of uncomfortable interactions under the general headings of entertainment, enlightenment and sociality. We then review artworks and performances that have employed discomfort, including two complementary examples from the worlds of entertainment and performance. From this, we articulate a suite of tactics for designing four primary forms of discomfort referred to as visceral, cultural, control and intimate. We discuss how moments of discomfort need to be embedded into an overall experience which requires a further consideration of the dramatic acts of exposition, rising action, climax, falling action, and dénouement. Finally, we discuss an ethical framework for uncomfortable interactions which leads us to revisit key issues of consent, withdrawal, privacy and risk. Copyright 2012 ACM.",Control | Culture | Discomfort | Entertainment | Ethics | Live art | Pain | Performance | Rides | Suffering | Visceral | Voyeurism,204,0,,,EPSRC,EP/G065802/1,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-84864257990,10.1109/ICSE.2012.6227142,,,Understanding integer overflow in C/C++,cp,Conference Paper,Dietz W.,60158506;60150772,The Grainger College of Engineering;John and Marcia Price College of Engineering,Urbana;Salt Lake City,United States;United States,4,"Dietz, Will;Li, Peng;Regehr, John;Adve, Vikram",8145918800;55696813100;6602188226;6701828487,60158506;60150772;60150772;60158506,2012-07-30,2012,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,6227142,760-770,"Integer overflow bugs in C and C++ programs are difficult to track down and may lead to fatal errors or exploitable vulnerabilities. Although a number of tools for finding these bugs exist, the situation is complicated because not all overflows are bugs. Better tools need to be constructed - but a thorough understanding of the issues behind these errors does not yet exist. We developed IOC, a dynamic checking tool for integer overflows, and used it to conduct the first detailed empirical study of the prevalence and patterns of occurrence of integer overflows in C and C++ code. Our results show that intentional uses of wraparound behaviors are more common than is widely believed; for example, there are over 200 distinct locations in the SPEC CINT2000 benchmarks where overflow occurs. Although many overflows are intentional, a large number of accidental overflows also occur. Orthogonal to programmers' intent, overflows are found in both well-defined and undefined flavors. Applications executing undefined operations can be, and have been, broken by improvements in compiler optimizations. Looking beyond SPEC, we found and reported undefined integer overflows in SQLite, PostgreSQL, SafeInt, GNU MPC and GMP, Firefox, GCC, LLVM, Python, BIND, and OpenSSL; many of these have since been fixed. Our results show that integer overflow issues in C and C++ are subtle and complex, that they are common even in mature, widely used programs, and that they are widely misunderstood by developers. © 2012 IEEE.",integer overflow | integer wraparound | undefined behavior,102,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84864217843,10.1109/ICSE.2012.6227149,,,Using dynamic analysis to discover polynomial and array invariants,cp,Conference Paper,Nguyen T.V.,60152865;60033021,University of Virginia School of Engineering and Applied Science;The University of New Mexico,Charlottesville;Albuquerque,United States;United States,4,"Nguyen, Thanh Vu;Kapur, Deepak;Weimer, Westley;Forrest, Stephanie",57212283994;7005306427;7003629741;57203256556,60033021;60033021;60152865;60033021,2012-07-30,2012,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,6227149,683-693,"Dynamic invariant analysis identifies likely properties over variables from observed program traces. These properties can aid programmers in refactoring, documenting, and debugging tasks by making dynamic patterns visible statically. Two useful forms of invariants involve relations among polynomials over program variables and relations among array variables. Current dynamic analysis methods support such invariants in only very limited forms. We combine mathematical techniques that have not previously been applied to this problem, namely equation solving, polyhedra construction, and SMT solving, to bring new capabilities to dynamic invariant detection. Using these methods, we show how to find equalities and inequalities among nonlinear polynomials over program variables, and linear relations among array variables of multiple dimensions. Preliminary experiments on 24 mathematical algorithms and an implementation of AES encryption provide evidence that the approach is effective at finding these invariants. © 2012 IEEE.",array invariants | dynamic analysis | invariant generation | nonlinear invariants | program analysis,68,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84862059412,10.1145/2207676.2208579,,,Using rhythmic patterns as an input method,cp,Conference Paper,Ghomi E.,60106017;60013373;60008134,Université Paris-Saclay;INRIA Institut National de Recherche en Informatique et en Automatique;CNRS Centre National de la Recherche Scientifique,Gif-sur-Yvette;Le Chesnay;Paris,France;France;France,5,"Ghomi, Emilien;Faure, Guillaume;Huot, Stéphane;Chapuis, Olivier;Beaudouin-Lafon, Michel",55247285900;35095191000;56241026900;55919438800;6602828964,60106017-60008134-60013373;60106017-60008134-60013373;60106017-60008134-60013373;60106017-60008134-60013373;60106017-60008134-60013373,2012-05-24,2012,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1253-1262,"While interaction techniques that use the temporal dimension have been used for a long time, such as multiple clicks or spring-loaded widgets, more advanced uses of rhythmic patterns have received little attention in HCI. Using such temporal structures to convey information can be particularly useful in situations where the visual channel is overloaded or even not available. In this paper we introduce Rhythmic Interaction as the use of rhythms for input. We report the results of two experiments that show that (i) rhythmic patterns can be efficiently reproduced by novice users and recognized by computer algorithms, and (ii) rhythmic patterns can be memorized as efficiently as traditional shortcuts when associating them with visual commands. Overall, these results demonstrate the potential of Rhythmic Interaction and open the way to a richer repertoire of interaction techniques. Copyright 2012 ACM.",Hotkeys | Learning | Morse code | Patterns | Rhythm | Taping,29,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84862629195,10.1145/2213556.2213565,,,Worst-case optimal join algorithms,cp,Conference Paper,Ngo H.,60032179;60032083;60002765,"University of Wisconsin-Madison;University at Buffalo, The State University of New York;Bar-Ilan University",Madison;Buffalo;Ramat Gan,United States;United States;Israel,4,"Ngo, Hung Q.;Porat, Ely;Ré, Christopher;Rudra, Atri",7005488530;6603716381;10739281400;8974616700,60032083;60002765;60032179;60032083,2012-06-26,2012,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,37-48,"Efficient join processing is one of the most fundamental and well-studied tasks in database research. In this work, we examine algorithms for natural join queries over many relations and describe a novel algorithm to process these queries optimally in terms of worst-case data complexity. Our result builds on recent work by Atserias, Grohe, and Marx, who gave bounds on the size of a full conjunctive query in terms of the sizes of the individual relations in the body of the query. These bounds, however, are not constructive: they rely on Shearer's entropy inequality which is information-theoretic. Thus, the previous results leave open the question of whether there exist algorithms whose running time achieve these optimal bounds. An answer to this question may be interesting to database practice, as we show in this paper that any project-join plan is polynomially slower than the optimal bound for some queries. We construct an algorithm whose running time is worst-case optimal for all natural join queries. Our result may be of independent interest, as our algorithm also yields a constructive proof of the general fractional cover bound by Atserias, Grohe, and Marx without using Shearer's inequality. In addition, we show that this bound is equivalent to a geometric inequality by Bollobás and Thomason, one of whose special cases is the famous Loomis-Whitney inequality. Hence, our results algorithmically prove these inequalities as well. Finally, we discuss how our algorithm can be used to compute a relaxed notion of joins. © 2012 ACM.",bollobás-thomason inequality | fractional cover bound | join algorithms | loomis-whitney inequality,125,0,repositoryam,Green,CISE,1054009,Directorate for Computer and Information Science and Engineering,PODS Databases
2-s2.0-85076714582,,,,F10: A fault-tolerant engineered network,cp,Conference Paper,Liu V.,60015481,University of Washington,Seattle,United States,4,"Liu, Vincent;Halperin, Daniel;Krishnamurthy, Arvind;Anderson, Thomas",54684321900;35988896200;7005516119;35560665700,60015481;60015481;60015481;60015481,2013-01-01,2013,"Proceedings of the 10th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2013",,21101017662,,Conference Proceeding,,,,399-412,"The data center network is increasingly a cost, reliability and performance bottleneck for cloud computing. Although multi-tree topologies can provide scalable bandwidth and traditional routing algorithms can provide eventual fault tolerance, we argue that recovery speed can be dramatically improved through the co-design of the network topology, routing algorithm and failure detector. We create an engineered network and routing protocol that directly address the failure characteristics observed in data centers. At the core of our proposal is a novel network topology that has many of the same desirable properties as FatTrees, but with much better fault recovery properties. We then create a series of failover protocols that benefit from this topology and are designed to cascade and complement each other. The resulting system, F10, can almost instantaneously reestablish connectivity and load balance, even in the presence of multiple failures. Our results show that following network link and switch failures, F10 has less than 1/7th the packet loss of current schemes. A trace-driven evaluation of MapReduce performance shows that F10's lower packet loss yields a median application-level 30% speedup.",,161,0,,,NSF,CNS-0963754,National Science Foundation,NSDI Networking
2-s2.0-84880103729,10.1145/2499370.2462163,,,A general constraint-centric scheduling framework for spatial architectures,cp,Conference Paper,Nowatzki T.,60032179;113729129,University of Wisconsin-Madison;Qualcomm Research Silicon Valley,Madison;,United States;United States,6,"Nowatzki, Tony;Sartin-Tarm, Michael;De Carli, Lorenzo;Sankaralingam, Karthikeyan;Estan, Cristian;Robatmili, Behnam",55200649300;55792604800;35147610600;7801506314;6505960670;8639153400,60032179;60032179;60032179;60032179;;113729129,2013-06-01,June 2013,ACM SIGPLAN Notices,15232867,19700185000,,Journal,48,6,,495-506,"Specialized execution using spatial architectures provides energy efficient computation, but requires effective algorithms for spatially scheduling the computation. Generally, this has been solved with architecture-specific heuristics, an approach which suffers from poor compiler/architect productivity, lack of insight on optimality, and inhibits migration of techniques between architectures. Our goal is to develop a scheduling framework usable for all spatial architectures. To this end, we expresses spatial scheduling as a constraint satisfaction problem using Integer Linear Programming (ILP). We observe that architecture primitives and scheduler responsibilities can be related through five abstractions: placement of computation, routing of data, managing event timing, managing resource utilization, and forming the optimization objectives. We encode these responsibilities as 20 general ILP constraints, which are used to create schedulers for the disparate TRIPS, DySER, and PLUG architectures. Our results show that a general declarative approach using ILP is implementable, practical, and typically matches or outperforms specialized schedulers.",Integer Linear Programming | Spatial Architecture Scheduling | Spatial Architectures,35,0,,,NSF,CCF-0845751,National Science Foundation,PLDI Programming Languages
2-s2.0-84876027564,10.1137/1.9781611973105.30,,,A simple algorithm for the graph minor decomposition - Logic meets structural graph theory -,cp,Conference Paper,Grohe M.,60110719;60028928;60016653;60002494,"Laboratoire d'Informatique, Signaux et Systèmes de Sophia-Antipolis;Research Organization of Information and Systems National Institute of Informatics;Rheinisch-Westfälische Technische Hochschule Aachen;Université McGill",Sophia Antipolis;Tokyo;Aachen;Montreal,France;Japan;Germany;Canada,3,"Grohe, Martin;Kawarabayashi, Ken Ichi;Reed, Bruce",7004249112;7004831911;57203031628,60016653;60028928;60002494-60110719,2013-01-01,2013,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,,,,414-431,"A key result of Robertson and Seymour's graph minor theory is a structure theorem stating that all graphs excluding some fixed graph as a minor have a tree decomposition into pieces that are almost embeddable in a fixed surface. Most algorithmic applications of graph minor theory rely on an algorithmic version of this result. However, the known algorithms for computing such graph minor decompositions heavily rely on the very long and complicated proofs of the existence of such decompositions, essentially they retrace these proofs and show that all steps are algorithmic. In this paper, we give a simple quadratic time algorithm for computing graph minor decompositions. The best previously known algorithm due to Kawarabayashi and Wollan runs in cubic time and is far more complicated. Our algorithm combines techniques from logic and structural graph theory, or more precisely, a variant of Courcelle's Theorem stating that monadic second-order logic formulas can be evaluated in linear time on graphs of bounded tree width and Robertson and Seymour's so called Weak Structure Theorem. Copyright © SIAM.",,33,0,,,,undefined,,SODA Theory
2-s2.0-84895741559,,,,A memory frontier for complex synapses,cp,Conference Paper,Lahiri S.,60012708,Stanford University,Stanford,United States,2,"Lahiri, Subhaneil;Ganguli, Surya",23389523100;8422780800,60012708;60012708,2013-01-01,2013,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,,,,,"An incredible gulf separates theoretical models of synapses, often described solely by a single scalar value denoting the size of a postsynaptic potential, from the immense complexity of molecular signaling pathways underlying real synapses. To understand the functional contribution of such molecular complexity to learning and memory, it is essential to expand our theoretical conception of a synapse from a single scalar to an entire dynamical system with many internal molecular functional states. Moreover, theoretical considerations alone demand such an expansion; network models with scalar synapses assuming finite numbers of distinguishable synaptic strengths have strikingly limited memory capacity. This raises the fundamental question, how does synaptic complexity give rise to memory? To address this, we develop new mathematical theorems elucidating the relationship between the structural organization and memory properties of complex synapses that are themselves molecular networks. Moreover, in proving such theorems, we uncover a framework, based on first passage time theory, to impose an order on the internal states of complex synaptic models, thereby simplifying the relationship between synaptic structure and function.",,35,0,,,,undefined,,NeurIPS Machine Learning
2-s2.0-84891620764,10.1145/2534169.2486015,,,Ambient backscatter: Wireless communication out of thin air,cp,Conference Paper,Liu V.,60015481,University of Washington,Seattle,United States,6,"Liu, Vincent;Parks, Aaron;Talla, Vamsi;Gollakota, Shyamnath;Wetherall, David;Smith, Joshua R.",54684321900;38361877700;25026338200;24449959700;6603912779;54421256200,60015481;60015481;60015481;60015481;60015481;60015481,2013-12-01,2013,Computer Communication Review,01464833,13683,19435819,Conference Proceeding,43,4,,39-50,"We present the design of a communication system that enables two devices to communicate using ambient RF as the only source of power. Our approach leverages existing TV and cellular transmissions to eliminate the need for wires and batteries, thus enabling ubiquitous communication where devices can communicate among themselves at unprecedented scales and in locations that were previously inaccessible. To achieve this, we introduce ambient backscatter, a new communication primitive where devices communicate by backscattering ambient RF signals. Our design avoids the expensive process of generating radio waves; backscatter communication is orders of magnitude more power-efficient than traditional radio communication. Further, since it leverages the ambient RF signals that are already around us, it does not require a dedicated power infrastructure as in traditional backscatter communication. To show the feasibility of our design, we prototype ambient backscatter devices in hardware and achieve information rates of 1 kbps over distances of 2.5 feet and 1.5 feet, while operating outdoors and indoors respectively. We use our hardware prototype to implement proof-of-concepts for two previously infeasible ubiquitous communication applications. © 2013 ACM.",backscatter | energy harvesting | internet of things | wireless,775,0,,,,undefined,,SIGCOMM Networking
2-s2.0-84877932376,10.1145/2470654.2466158,,,Analyzing user-generated YouTube videos to understand touchscreen use by people with motor impairments,cp,Conference Paper,Anthony L.,60024997;60020304,"University of Maryland, Baltimore County (UMBC);University of Maryland, College Park",Baltimore;College Park,United States;United States,3,"Anthony, Lisa;Kim, Yoo Jin;Findlater, Leah",16244221000;55735536400;10040303000,60024997;60020304;60020304,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1223-1232,"Most work on the usability of touchscreen interaction for people with motor impairments has focused on lab studies with relatively few participants and small cross-sections of the population. To develop a richer characterization of use, we turned to a previously untapped source of data: YouTube videos. We collected and analyzed 187 noncommercial videos uploaded to YouTube that depicted a person with a physical disability interacting with a mainstream mobile touchscreen device. We coded the videos along a range of dimensions to characterize the interaction, the challenges encountered, and the adaptations being adopted in daily use. To complement the video data, we also invited the video uploaders to complete a survey on their ongoing use of touchscreen technology. Our findings show that, while many people with motor impairments find these devices empowering, accessibility issues still exist. In addition to providing implications for more accessible touchscreen design, we reflect on the application of usergenerated content to study user interface design. Copyright © 2013 ACM.",Assistive technology | IPad | IPhone | Motor impairments | Physical disabilities | Touchscreen | YouTube,109,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84879808674,10.1145/2488608.2488665,,,Approximation resistance from pairwise independent subgroups,cp,Conference Paper,Chan S.O.,60025038,"University of California, Berkeley",Berkeley,United States,1,"Chan, Siu On",55647746000,60025038,2013-07-11,2013,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,447-456,"We show optimal (up to constant factor) NP-hardness for Max-k-CSP over any domain, whenever k is larger than the domain size. This follows from our main result concerning predicates over abelian groups. We show that a predicate is approximation resistant if it contains a subgroup that is balanced pairwise independent. This gives an unconditional analogue of Austrin-Mossel hardness result, bypassing the Unique-Games Conjecture for predicates with an abelian subgroup structure. Our main ingredient is a new gap-amplification technique inspired by XOR-lemmas. Using this technique, we also improve the NP-hardness of approximating Independent-Set on bounded-degree graphs, Almost-Coloring, Two-Prover-One- Round-Game, and various other problems. Copyright 2013 ACM.",Inapproximability | Integrality gaps | Maximum constraint satisfaction problem | Probabilistically checkable proofs,51,0,,,NSF,DMS-1106999,National Science Foundation,STOC Theory
2-s2.0-84886412175,10.1109/ICSE.2013.6606586,,,Assisting developers of big data analytics applications when deploying on Hadoop clouds,cp,Conference Paper,Shang W.,60019141;60016005,Polytechnique Montréal;Queen’s University,Montreal;Kingston,Canada;Canada,6,"Shang, Weiyi;Jiang, Zhen Ming;Hemmati, Hadi;Adams, Brain;Hassan, Ahmed E.;Martin, Patrick",35093168200;15764976200;15046849800;15134994200;7402686972;56653858600,60016005;60016005;60016005;60019141;60016005;60016005,2013-10-30,2013,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,6606586,402-411,"Big data analytics is the process of examining large amounts of data (big data) in an effort to uncover hidden patterns or unknown correlations. Big Data Analytics Applications (BDA Apps) are a new type of software applications, which analyze big data using massive parallel processing frameworks (e.g., Hadoop). Developers of such applications typically develop them using a small sample of data in a pseudo-cloud environment. Afterwards, they deploy the applications in a large-scale cloud environment with considerably more processing power and larger input data (reminiscent of the mainframe days). Working with BDA App developers in industry over the past three years, we noticed that the runtime analysis and debugging of such applications in the deployment phase cannot be easily addressed by traditional monitoring and debugging approaches. In this paper, as a first step in assisting developers of BDA Apps for cloud deployments, we propose a lightweight approach for uncovering differences between pseudo and large-scale cloud deployments. Our approach makes use of the readily-available yet rarely used execution logs from these platforms. Our approach abstracts the execution logs, recovers the execution sequences, and compares the sequences between the pseudo and cloud deployments. Through a case study on three representative Hadoop-based BDA Apps, we show that our approach can rapidly direct the attention of BDA App developers to the major differences between the two deployments. Knowledge of such differences is essential in verifying BDA Apps when analyzing big data in the cloud. Using injected deployment faults, we show that our approach not only significantly reduces the deployment verification effort, but also provides very few false positives when identifying deployment failures. © 2013 IEEE.",Big-Data Analytics Application | Cloud Computing | Hadoop | Log Analysis | Monitoring and Debugging,123,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84877938074,10.1145/2470654.2466152,,,At home with agents: Exploring attitudes towards future smart energy infrastructures,cp,Conference Paper,Rodden T.,60015138,University of Nottingham,Nottingham,United Kingdom,5,"Rodden, Tom A.;Fischer, Joel E.;Pantidi, Nadia;Bachour, Khaled;Moran, Stuart",7003488009;36095705300;34880591500;25651707200;35190831300,60015138;60015138;60015138;60015138;60015138,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1173-1182,"Energy systems researchers are proposing a broad range of future smart energy infrastructures to promote more efficient management of energy resources. This paper considers how consumers might relate to these future smart grids within the UK. To address this challenge we exploited a combination of demonstration and animated sketches to convey the nature of a future smart energy infrastructure based on software agents. Users' reactions suggested that although they felt an obligation to engage with energy issues, they were principally disinterested. Users showed a considerable lack of trust in energy companies raising a dilemma of design. While users might welcome agents to help in engaging with complex energy infrastructures, they had little faith in those that might provide them. This suggests the need to consider how to design software agents to enhance trust in these socio-economic settings. Copyright © 2013 ACM.",Agent-based systems | Envisioning | Focus groups | Participatory design | Sketching | Smart grid | Whiteboard animations,81,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84886385527,10.1109/ICSE.2013.6606626,,,Automatic patch generation learned from human-written patches,cp,Conference Paper,Kim D.,60008592,Hong Kong University of Science and Technology,Hong Kong,Hong Kong,4,"Kim, Dongsun;Nam, Jaechang;Song, Jaewoo;Kim, Sunghun",55742964600;47061768300;55902470900;12241083400,60008592;60008592;60008592;60008592,2013-01-01,2013,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,6606626,802-811,"Patch generation is an essential software maintenance task because most software systems inevitably have bugs that need to be fixed. Unfortunately, human resources are often insufficient to fix all reported and known bugs. To address this issue, several automated patch generation techniques have been proposed. In particular, a genetic-programming-based patch generation technique, GenProg, proposed by Weimer et al., has shown promising results. However, these techniques can generate nonsensical patches due to the randomness of their mutation operations. To address this limitation, we propose a novel patch generation approach, Pattern-based Automatic program Repair (Par), using fix patterns learned from existing human-written patches. We manually inspected more than 60,000 human-written patches and found there are several common fix patterns. Our approach leverages these fix patterns to generate program patches automatically. We experimentally evaluated Par on 119 real bugs. In addition, a user study involving 89 students and 164 developers confirmed that patches generated by our approach are more acceptable than those generated by GenProg. Par successfully generated patches for 27 out of 119 bugs, while GenProg was successful for only 16 bugs. © 2013 IEEE.",,497,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-84896058897,,,,Bayesian optimization in high dimensions via random embeddings,cp,Conference Paper,Wang Z.,60025641;60010365;60002483,Universität Freiburg;The University of British Columbia;Universiteit van Amsterdam,Freiburg im Breisgau;Vancouver;Amsterdam,Germany;Canada;Netherlands,5,"Wang, Ziyu;Zoghiy, Masrour;Hutterz, Frank;Matheson, David;De Freitas, Nando",55588083600;55376776400;55931808800;56066637000;6602751682,60010365;60002483;60025641;60010365;60010365,2013-12-01,2013,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,1778-1784,"Bayesian optimization techniques have been successfully applied to robotics, planning, sensor placement, recommendation, advertising, intelligent user interfaces and automatic algorithm configuration. Despite these successes, the approach is restricted to problems of moderate dimension, and several workshops on Bayesian optimization have identified its scaling to high dimensions as one of the holy grails of the field. In this paper, we introduce a novel random embedding idea to attack this problem. The resulting Random EMbedding Bayesian Optimization (REMBO) algorithm is very simple and applies to domains with both categorical and continuous variables. The experiments demonstrate that REMBO can effectively solve high-dimensional problems, including automatic parameter configuration of a popular mixed integer linear programming solver.",,200,0,,,,undefined,,IJCAI Artificial Intelligence
2-s2.0-84883083332,10.1145/2484028.2484053,,,Beliefs and biases in web search,cp,Conference Paper,White R.,60021726,Microsoft Research,Redmond,United States,1,"White, Ryen W.",7501422012,60021726,2013-09-02,2013,SIGIR 2013 - Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval,,21100255302,,Conference Proceeding,,,,3-12,"People's beliefs, and unconscious biases that arise from those beliefs, influence their judgment, decision making, and actions, as is commonly accepted among psychologists. Biases can be observed in information retrieval in situations where searchers seek or are presented with information that significantly deviates from the truth. There is little understanding of the impact of such biases in search. In this paper we study search-related biases via multiple probes: an exploratory retrospective survey, human labeling of the captions and results returned by a Web search engine, and a large-scale log analysis of search behavior on that engine. Targeting yes-no questions in the critical domain of health search, we show that Web searchers exhibit their own biases and are also subject to bias from the search engine. We clearly observe searchers favoring positive information over negative and more than expected given base rates based on consensus answers from physicians. We also show that search engines strongly favor a particular, usually positive, perspective, irrespective of the truth. Importantly, we show that these biases can be counterproductive and affect search outcomes; in our study, around half of the answers that searchers settled on were actually incorrect. Our findings have implications for search engine design, including the development of ranking algorithms that consider the desire to satisfy searchers (by validating their beliefs) and providing accurate answers and properly considering base rates. Incorporating likelihood information into search is particularly important for consequential tasks, such as those with a medical focus. Copyright © 2013 ACM.",Beliefs | Biases | Health search | Search interaction,130,0,repositoryam,Green,,undefined,,SIGIR Information Retrieval
2-s2.0-84883060129,10.1145/2462156.2462167,,,CLAP: Recording local executions to reproduce concurrency failures,cp,Conference Paper,Huang J.,60017366;60008592,IBM Thomas J. Watson Research Center;Hong Kong University of Science and Technology,Yorktown Heights;Hong Kong,United States;Hong Kong,3,"Huang, Jeff;Zhang, Charles;Dolby, Julian",57013582200;7405494017;8837002700,60008592;60008592;60017366,2013-09-02,2013,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,141-151,"We present CLAP, a new technique to reproduce concurrency bugs. CLAP has two key steps. First, it logs thread local execution paths at runtime. Second, offline, it computes memory dependencies that accord with the logged execution and are able to reproduce the observed bug. The second step works by combining constraints from the thread paths and constraints based on a memory model, and computing an execution with a constraint solver. CLAP has four major advantages. First, logging purely local execution of each thread is substantially cheaper than logging memory interactions, which enables CLAP to be efficient compared to previous approaches. Second, our logging does not require any synchronization and hence with no added memory barriers or fences; this minimizes perturbation and missed bugs due to extra synchronizations foreclosing certain racy behaviors. Third, since it uses no synchronization, we extend CLAP to work on a range of relaxed memory models, such as TSO and PSO, in addition to sequential consistency. Fourth, CLAP can compute a much simpler execution than the original one, that reveals the bug with minimal thread context switches. To mitigate the scalability issues, we also present an approach to parallelize constraint solving, which theoretically scales our technique to programs with arbitrary execution length. Experimental results on a variety of multithreaded benchmarks and real world concurrent applications validate these advantages by showing that our technique is effective in reproducing concurrency bugs even under relaxed memory models; furthermore, it is significantly more efficient than a state-of-the-art technique that records shared memory dependencies, reducing execution time overhead by 45% and log size by 88% on average. Copyright © 2013 ACM.",Bug Reproduction | Concurrency | Constraint Solving | Local Execution,108,0,,,,undefined,,PLDI Programming Languages
2-s2.0-84883681660,10.1109/ICSE.2013.6606575,,,Data clone detection and visualization in spreadsheets,cp,Conference Paper,Hermans F.,60006288,Delft University of Technology,Delft,Netherlands,4,"Hermans, Felienne;Sedee, Ben;Pinzger, Martin;Van Deursen, Arie",35573133300;36459200100;8244701600;7003969355,60006288;60006288;60006288;60006288,2013-10-30,2013,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,6606575,292-301,"Spreadsheets are widely used in industry: it is estimated that end-user programmers outnumber programmers by a factor 5. However, spreadsheets are error-prone, numerous companies have lost money because of spreadsheet errors. One of the causes for spreadsheet problems is the prevalence of copy-pasting. In this paper, we study this cloning in spreadsheets. Based on existing text-based clone detection algorithms, we have developed an algorithm to detect data clones in spreadsheets: formulas whose values are copied as plain text in a different location. To evaluate the usefulness of the proposed approach, we conducted two evaluations. A quantitative evaluation in which we analyzed the EUSES corpus and a qualitative evaluation consisting of two case studies. The results of the evaluation clearly indicate that 1) data clones are common, 2) data clones pose threats to spreadsheet quality and 3) our approach supports users in finding and resolving data clones. © 2013 IEEE.",clone detection | code smells | spreadsheet smells | spreadsheets,51,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-84923675419,,,,The disc diversity model,cp,Conference Paper,Drosou M.,60004716,University of Ioannina,Ioannina,Greece,2,"Drosou, Marina;Pitoura, Evaggelia",36026576500;7003835880,60004716;60004716,2014-01-01,2014,CEUR Workshop Proceedings,16130073,21100218356,,Conference Proceeding,1133,,,173-175,"In this paper, we summarize our work on diversification based on dissimilarity and coverage (DisC diversity) by presenting our main theoretical results and contributions.",,2,0,,,,undefined,,VLDB Databases
2-s2.0-84886438896,10.1109/ICSE.2013.6606591,,,Dual ecological measures of focus in software development,cp,Conference Paper,Posnett D.,60014439,"University of California, Davis",Davis,United States,4,"Posnett, Daryl;D'Souza, Raissa;Devanbu, Premkumar;Filkov, Vladimir",36133726100;15724297700;35583833100;6603001620,60014439;60014439;60014439;60014439,2013-10-30,2013,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,6606591,452-461,"Work practices vary among software developers. Some are highly focused on a few artifacts; others make wideranging contributions. Similarly, some artifacts are mostly authored, or 'owned', by one or few developers; others have very wide ownership. Focus and ownership are related but different phenomena, both with strong effect on software quality. Prior studies have mostly targeted ownership; the measures of ownership used have generally been based on either simple counts, information-theoretic views of ownership, or social-network views of contribution patterns. We argue for a more general conceptual view that unifies developer focus and artifact ownership. We analogize the developer-artifact contribution network to a predator-prey food web, and draw upon ideas from ecology to produce a novel, and conceptually unified view of measuring focus and ownership. These measures relate to both cross-entropy and Kullback-Liebler divergence, and simultaneously provide two normalized measures of focus from both the developer and artifact perspectives. We argue that these measures are theoretically well-founded, and yield novel predictive, conceptual, and actionable value in software projects. We find that more focused developers introduce fewer defects than defocused developers. In contrast, files that receive narrowly focused activity are more likely to contain defects than other files. © 2013 IEEE.",,71,0,,,NSF,0964703,National Science Foundation,ICSE Software Engineering
2-s2.0-84876020673,10.1137/1.9781611973105.81,,,Dynamic graph connectivity in polylogarithmic worst case time,cp,Conference Paper,Kapron B.M.,60003122,University of Victoria,Victoria,Canada,3,"Kapron, Bruce M.;King, Valerie;Mountjoy, Ben",6603561490;7103398301;55647972600,60003122;60003122;60003122,2013-01-01,2013,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,,,,1131-1142,"The dynamic graph connectivity problem is the following: given a graph on a fixed set of n nodes which is undergoing a sequence of edge insertions and deletions, answer queries of the form q(a, b): ""Is there a path between nodes a and b?"" While data structures for this problem with polylogarithmic amortized time per operation have been known since the mid-1990's, these data structures have Θ(n) worst case time. In fact, no previously known solution has worst case time per operation which is o(√n). We present a solution with worst case times O(log4 n) per edge insertion, O(log5 n) per edge deletion, and O(log n/ log log n) per query. The answer to each query is correct if the answer is ""yes"" and is correct with high probability if the answer is ""no"". The data structure is based on a simple novel idea which can be used to quickly identify an edge in a cutset. Our technique can be used to simplify and significantly speed up the preprocessing time for the emergency planning problem while matching previous bounds for an update, and to approximate the sizes of cutsets of dynamic graphs in time Õ(min{|S|, |V \ S|}) for an oblivious adversary. Copyright © SIAM.",,133,0,,,,undefined,,SODA Theory
2-s2.0-85076709246,,,,Embassies: Radically refactoring the web,cp,Conference Paper,Howell J.,60021726,Microsoft Research,Redmond,United States,3,"Howell, Jon;Parno, Bryan;Douceur, John R.",7402273498;57203245130;6602278425,60021726;60021726;60021726,2013-01-01,2013,"Proceedings of the 10th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2013",,21101017662,,Conference Proceeding,,,,529-545,"Web browsers ostensibly provide strong isolation for the client-side components of web applications. Unfortunately, this isolation is weak in practice; as browsers add increasingly rich APIs to please developers, these complex interfaces bloat the trusted computing base and Erode cross-app isolation boundaries. We reenvision the web interface based on the notion of a pico-datacenter, the client-side version of a shared server datacenter. Mutually untrusting vendors run their code on the user's computer in low-level native code containers that communicate with the outside world only via IP. Just as in the cloud datacenter, the simple semantics makes isolation tractable, yet native code gives vendors the freedom to run any software stack. Since the datacenter model is designed to be robust to malicious tenants, it is never dangerous for the user to click a link and invite a possibly-hostile party onto the client.",,32,0,,,,undefined,,NSDI Networking
2-s2.0-84897505165,,,,Fast semidifferential-based submodular function optimization,cp,Conference Paper,Iyer R.,60025038;60015481,"University of California, Berkeley;University of Washington",Berkeley;Seattle,United States;United States,3,"Iyer, Rishabh;Jegelka, Stefanie;Bilmes, Jeff",56111913800;33867573000;7003705752,60015481;60025038;60015481,2013-01-01,2013,"30th International Conference on Machine Learning, ICML 2013",,21100301423,,Conference Proceeding,,PART 3,,1892-1900,"We present a practical and powerful new framework for both unconstrained and constrained submodular function optimization based on discrete semidifferentials (sub- and super-differentials). The resulting algorithms, which repeatedly compute and then efficiently optimize submodular semigradients, offer new and generalize many old methods for submodular optimization. Our approach, moreover, takes steps towards providing a unifying paradigm applicable to both submodular minimization and maximization, problems that historically have been treated quite distinctly. The practicality of our algorithms is important since interest in submodularity, owing to its natural and wide applicability, has recently been in ascendance within machine learning. We analyze theoretical properties of our algorithms for minimization and maximization, and show that many state-of-the-art maximization algorithms are special cases. Lastly, we complement our theoretical analyses with supporting empirical experiments. Copyright 2013 by the author(s).",,58,0,,,,IIS-1162606,,ICML Machine Learning
2-s2.0-84887378604,10.1109/CVPR.2013.237,,,"Fast, accurate detection of 100,000 object classes on a single machine",cp,Conference Paper,Dean T.,60006191,Google LLC,Mountain View,United States,6,"Dean, Thomas;Ruzon, Mark A.;Segal, Mark;Shlens, Jonathon;Vijayanarasimhan, Sudheendra;Yagnik, Jay",57213722747;6505780802;57197503844;8632398500;24829626900;23135805700,60006191;60006191;60006191;60006191;60006191;60006191,2013-11-15,2013,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,,,6619081,1814-1821,"Many object detection systems are constrained by the time required to convolve a target image with a bank of filters that code for different aspects of an object's appearance, such as the presence of component parts. We exploit locality-sensitive hashing to replace the dot-product kernel operator in the convolution with a fixed number of hash-table probes that effectively sample all of the filter responses in time independent of the size of the filter bank. To show the effectiveness of the technique, we apply it to evaluate 100,000 deformable-part models requiring over a million (part) filters on multiple scales of a target image in less than 20 seconds using a single multi-core processor with 20GB of RAM. This represents a speed-up of approximately 20,000 times - four orders of magnitude - when compared with performing the convolutions explicitly on the same hardware. While mean average precision over the full set of 100,000 object classes is around 0.16 due in large part to the challenges in gathering training data and collecting ground truth for so many classes, we achieve a mAP of at least 0.20 on a third of the classes and 0.30 or better on about 20% of the classes. © 2013 IEEE.",deformable part models | locality-sensitive hashing | object detection,254,0,repositoryam,Green,,undefined,,CVPR Computer Vision
2-s2.0-84887578962,10.1145/2501988.2502021,,,Fiberio: A touchscreen that senses fingerprints,cp,Conference Paper,Holz C.,60106550,Hasso-Plattner-Institut für Softwaresystemtechnik GmbH,Potsdam,Germany,2,"Holz, Christian;Baudisch, Patrick",56070704000;10039576700,60106550;60106550,2013-11-20,2013,UIST 2013 - Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology,,21100266905,,Conference Proceeding,,,,41-50,"We present Fiberio, a rear-projected multitouch table that identifies users biometrically based on their fingerprints during each touch interaction. Fiberio accomplishes this using a new type of screen material: a large fiber optic plate. The plate diffuses light on transmission, thereby allowing it to act as projection surface. At the same time, the plate reflects light specularly, which produces the contrast required for fingerprint sensing. In addition to offering all the functionality known from traditional dif-fused illumination systems, Fiberio is the first interactive tabletop system that authenticates users during touch interaction-unobtrusively and securely using the biometric features of fingerprints, which eliminates the need for users to carry any identification tokens. Copyright © 2013 ACM.",Fingerprints | Multitouch | Touchscreens | User identification,72,0,,,,undefined,,UIST User Interface
2-s2.0-84896061225,,,,Flexibility and decoupling in the simple temporal problem,cp,Conference Paper,Wilson M.,60006288,Delft University of Technology,Delft,Netherlands,4,"Wilson, Michel;Klos, Tomas;Witteveen, Cees;Huisman, Bob",57209629697;56024337900;7004099713;24604914500,60006288;60006288;60006288;60006288,2013-12-01,2013,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,2422-2428,"In this paper we concentrate on finding a suitable metric to determine the flexibility of a Simple Temporal Problem (STP). After reviewing some flexibility metrics that have been proposed, we conclude that these metrics fail to capture the correlation between events specified in the STP, resulting in an overestimation of the available flexibility in the system. We propose to use an intuitively more acceptable flexibility metric based upon uncorrelated time-intervals for the allowed starting times of events in an STP. This metric is shown to be computable in low-polynomial time. As a byproduct of the flexibility computation, we get a decomposition of the STN almost for free: for every possible k-partitioning of the event space, a decomposition can be computed in O(κ)-time. Even more importantly, we show that contrary to popular belief, such a decomposition does not affect the flexibility of the original STP.",,7,0,,,,undefined,,IJCAI Artificial Intelligence
2-s2.0-84898828265,10.1109/ICCV.2013.344,,,From large scale image categorization to entry-level categories,cp,Conference Paper,Ordonez V.,60026415;60025111;60012708,Stony Brook University;The University of North Carolina at Chapel Hill;Stanford University,Stony Brook;Chapel Hill;Stanford,United States;United States;United States,5,"Ordonez, Vicente;Deng, Jia;Choi, Yejin;Berg, Alexander C.;Berg, Tamara L.",31767588800;36617097900;36172231400;36099870600;8731264900,60025111;60012708;60026415;60025111;60025111,2013-01-01,2013,Proceedings of the IEEE International Conference on Computer Vision,,110561,,Conference Proceeding,,,6751455,2768-2775,Entry level categories-the labels people will use to name an object-were originally defined and studied by psychologists in the 1980s. In this paper we study entry-level categories at a large scale and learn the first models for predicting entry-level categories for images. Our models combine visual recognition predictions with proxies for word 'naturalness' mined from the enormous amounts of text on the web. We demonstrate the usefulness of our models for predicting nouns (entry-level words) associated with images by people. We also learn mappings between concepts predicted by existing visual recognition systems and entry-level concepts that could be useful for improving human-focused applications such as natural language image description or retrieval. © 2013 IEEE.,categories | categorization | entry-level | images | language | prediction | retrieval,81,0,,,,undefined,,ICCV Computer Vision
2-s2.0-84897743886,,,,Grounded language learning from video described with sentences,cp,Conference Paper,Yu H.,60148444,College of Engineering,West Lafayette,United States,2,"Yu, Haonan;Siskind, Jeffrey Mark",55923716500;6701590426,60148444;60148444,2013-01-01,2013,"ACL 2013 - 51st Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference",,21100334851,,Conference Proceeding,1,,,53-63,"We present a method that learns representations for word meanings from short video clips paired with sentences. Unlike prior work on learning language from symbolic input, our input consists of video of people interacting with multiple complex objects in outdoor environments. Unlike prior computer-vision approaches that learn from videos with verb labels or images with noun labels, our labels are sentences containing nouns, verbs, prepositions, adjectives, and adverbs. The correspondence between words and concepts in the video is learned in an unsupervised fashion, even when the video depicts simultaneous events described by multiple sentences or when different aspects of a single event are described with multiple sentences. The learned word meanings can be subsequently used to automatically generate description of new video. © 2013 Association for Computational Linguistics.",,92,0,,,,undefined,,ACL Natural Language Processing
2-s2.0-84893391288,,,,HC-search: Learning heuristics and cost functions for structured prediction,cp,Conference Paper,Doppa J.R.,60013402,Oregon State University,Corvallis,United States,3,"Doppa, Janardhan Rao;Fern, Alan;Tadepalli, Prasad",35324430700;12141549500;6602111069,60013402;60013402;60013402,2013-12-01,2013,"Proceedings of the 27th AAAI Conference on Artificial Intelligence, AAAI 2013",,21100285716,,Conference Proceeding,,,,253-259,"Structured prediction is the problem of learning a function from structured inputs to structured outputs. Inspired by the recent successes of search-based structured prediction, we introduce a new framework for structured prediction called HC-Search. Given a structured input, the framework uses a search procedure guided by a learned heuristic H to uncover high quality candidate outputs and then uses a separate learned cost function C to select a final prediction among those outputs. We can decompose the regret of the overall approach into the loss due to H not leading to high quality outputs, and the loss due to C not selecting the best among the generated outputs. Guided by this decomposition, we minimize the overall regret in a greedy stagewise manner by first training H to quickly uncover high quality outputs via imitation learning, and then training C to correctly rank the outputs generated via H according to their true losses. Experiments on several benchmark domains show that our approach significantly outperforms the state-of-the-art methods. Copyright © 2013, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,8,0,,,NSF,IIS 1219258,National Science Foundation,AAAI Artificial Intelligence
2-s2.0-84877972715,10.1145/2470654.2466112,,,IllumiRoom: Peripheral projected illusions for interactive experiences,cp,Conference Paper,Jones B.,60021726;60000745,Microsoft Research;University of Illinois Urbana-Champaign,Redmond;Urbana,United States;United States,4,"Jones, Brett R.;Benko, Hrvoje;Ofek, Eyal;Wilson, Andrew D.",56325280500;9737287100;10139546600;57199229209,60021726-60000745;60021726;60021726;60021726,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,869-878,"IllumiRoom is a proof-of-concept system that augments the area surrounding a television with projected visualizations to enhance traditional gaming experiences. We investigate how projected visualizations in the periphery can negate, include, or augment the existing physical environment and complement the content displayed on the television screen. Peripheral projected illusions can change the appearance of the room, induce apparent motion, extend the field of view, and enable entirely new physical gaming experiences. Our system is entirely self-calibrating and is designed to work in any room. We present a detailed exploration of the design space of peripheral projected illusions and we demonstrate ways to trigger and drive such illusions from gaming content. We also contribute specific feedback from two groups of target users (10 gamers and 15 game designers); providing insights for enhancing game experiences through peripheral projected illusions. Copyright © 2013 ACM.",Apparent motion | Augmented reality | Gaming | Immersion | Projection mapping | Spatial augmented reality,197,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84878002469,10.1145/2470654.2481323,,,Improving navigation-based file retrieval,cp,Conference Paper,Fitchett S.,60020585;60015186,University of Canterbury;University of Saskatchewan,Christchurch;Saskatoon,New Zealand;Canada,3,"Fitchett, Stephen;Cockburn, Andy;Gutwin, Carl",36091178800;7004557137;35587413900,60020585;60020585;60015186,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,2329-2338,"Navigating through a file hierarchy is one of the most common methods for accessing files, yet it can be slow and repetitive. New algorithms that predict upcoming file accesses have the potential to improve navigation-based file retrieval, but it is unknown how best to present their predictions to users. We present three design goals aiming to improve navigation-based file retrieval interfaces: minimise the time spent at each hierarchical level en route to the target file; reduce the number of levels traversed by providing shortcuts; and promote rehearsal of the retrieval mechanics to facilitate expertise. We introduce three interfaces that augment standard file browsers based on each of these goals: Icon Highlights give greater prominence to predicted items in the current folder; Hover Menus provide shortcuts to predicted folder content; and Search Directed Navigation uses predictive highlighting to guide users through the hierarchy in response to query terms. Results from a user evaluation show that all three interfaces improve file retrieval times, with Icon Highlights and Hover Menus best suited for frequently accessed items and Search Directed Navigation best suited for infrequent ones. We also show that the benefits are larger when folder content is spatially unstable. Finally, we discuss how the interfaces could be combined and deployed in existing file browsers. Copyright 2013 ACM.",File navigation | File retrieval | Prediction | Revisitation,31,0,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84886428616,10.1109/ICSE.2013.6606564,,,Interaction-based test-suite minimization,cp,Conference Paper,Blue D.,60026303;60021293,IBM Research - Haifa;International Business Machines,Haifa;Armonk,Israel;United States,4,"Blue, Dale;Segall, Itai;Tzoref-Brill, Rachel;Zlotnick, Aviad",27267507100;23089409800;35185578400;36867827500,60021293;60026303;60026303;60026303,2013-10-30,2013,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,6606564,182-191,"Combinatorial Test Design (CTD) is an effective test planning technique that reveals faults resulting from feature interactions in a system. The standard application of CTD requires manual modeling of the test space, including a precise definition of restrictions between the test space parameters, and produces a test suite that corresponds to new test cases to be implemented from scratch. In this work, we propose to use Interaction-based TestSuite Minimization (ITSM) as a complementary approach to standard CTD. ITSM reduces a given test suite without impacting its coverage of feature interactions. ITSM requires much less modeling effort, and does not require a definition of restrictions. It is appealing where there has been a significant investment in an existing test suite, where creating new tests is expensive, and where restrictions are very complex. We discuss the tradeoffs between standard CTD and ITSM, and suggest an efficient algorithm for solving the latter. We also discuss the challenges and additional requirements that arise when applying ITSM to real-life test suites. We introduce solutions to these challenges and demonstrate them through two real-life case studies. © 2013 IEEE.",,36,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84877968627,10.1145/2470654.2481389,,,Job opportunities through entertainment : Virally spread speech -based services for low-literate users,cp,Conference Paper,Raza A.A.,60136640;60042311;60028628,School of Computer Science;Lahore University of Management Sciences;Northeastern University,Pittsburgh;Lahore;Boston,United States;Pakistan;United States,7,"Raza, Agha Ali;Ul Haq, Farhan;Tariq, Zain;Pervaiz, Mansoor;Razaq, Samia;Saif, Umar;Rosenfeld, Roni",26666232500;57193954187;57214275480;34267818700;55146010500;15045559000;56817994700,60136640;60042311;60042311;60028628;60042311;60042311;60136640,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,2803-2812,"We explore how telephone-based services might be mass adopted by low-literate users in the developing world. We focus on speech and push-button dialog systems requiring neither literacy nor training. Building on the success of Polly, a simple telephone-based voice manipulation and forwarding system that was first tested in 2011, we report on its first large-scale sustained deployment. In 24/7 operation in Pakistan since May 9, 2012, as of mid-September Polly has spread to 85,000 users, engaging them in 495,000 interactions, and is continuing to spread to 1,000 new people daily. It has also attracted 27,000 people to a job search service, who in turn listened 279,000 times to job ads and forwarded them 22,000 times to their friends. We report users' activity over time and across demographics, analyze user behavior within several randomized controlled trials, and describe lessons learned regarding spread, scalability and sustainability of telephone-based speech-based services. Copyright © 2013 ACM.",Cellular phones | Communication services | Entertainment | HCI4D | ICT4D | Illiteracy | Information services | Job search | Low-literate | Low-skill jobs | Mobile phones | Speech interfaces | Telephone | Viral,50,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84877954275,10.1145/2470654.2470745,,,Labor dynamics in a mobile micro-task market,cp,Conference Paper,Musthag M.,60152130,Manning College of Information &amp; Computer Sciences,Amherst,United States,2,"Musthag, Mohamed;Ganesan, Deepak",53364190600;10739214500,60152130;60152130,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,641-650,"The ubiquity of smartphones has led to the emergence of mobile crowdsourcing markets, where smartphone users participate to perform tasks in the physical world. Mobile crowdsourcing markets are uniquely different from their online counterparts in that they require spatial mobility, and are therefore impacted by geographic factors and constraints that are not present in the online case. Despite the emergence and importance of such mobile marketplaces, little to none is known about the labor dynamics and mobility patterns of agents. This paper provides an in-depth exploration of labor dynamics in mobile task markets based on a year-long dataset from a leading mobile crowdsourcing platform. We find that a small core group of workers (< 10%) account for a disproportionately large proportion of activity (> 80%) generated in the market. We find that these super agents are more efficient than other agents across several dimensions: a) they are willing to move longer distances to perform tasks, yet they amortize travel across more tasks, b) they work and search for tasks more efficiently, c) they have higher data quality in terms of accepted submissions, and d) they improve in almost all of these efficiency measures over time. We find that super agent efficiency stems from two simple optimizations - they are 3× more likely than other agents to chain tasks and they pick fewer lower priced tasks than other agents. We compare mobile and online micro-task markets, and discuss differences in demographics, data quality, and time of use, as well as similarities in super agent behavior. We conclude with a discussion of how a mobile micro-task market might leverage some of our results to improve performance. Copyright © 2013 ACM.",Crowdsourcing | Labor mobility | Micro task markets | Mobile crowdsourcing,89,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84878000918,10.1145/2470654.2481358,,,LaserOrigami: Laser-cutting 3D objects,cp,Conference Paper,Mueller S.,60106550,Hasso-Plattner-Institut für Softwaresystemtechnik GmbH,Potsdam,Germany,3,"Mueller, Stefanie;Kruck, Bastian;Baudisch, Patrick",55479874800;55734730400;10039576700,60106550;60106550;60106550,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,2585-2592,"We present LaserOrigami, a rapid prototyping system that produces 3D objects using a laser cutter. LaserOrigami is substantially faster than traditional 3D fabrication techniques such as 3D printing and unlike traditional laser cutting the resulting 3D objects require no manual assembly. The key idea behind LaserOrigami is that it achieves three-dimensionality by folding and stretching the workpiece, rather than by placing joints, thereby eliminating the need for manual assembly. LaserOrigami achieves this by heating up selected regions of the workpiece until they become compliant and bend down under the force of gravity. LaserOrigami administers the heat by defocusing the laser, which distributes the laser's power across a larger surface. LaserOrigami implements cutting and bending in a single integrated process by automatically moving the cutting table up and down-when users take out the workpiece, it is already fully assembled. We present the three main design elements of LaserOrigami: the bend, the suspender, and the stretch, and demonstrate how to use them to fabricate a range of physical objects. Finally, we demonstrate an interactive fabrication version of LaserOrigami, a process in which user interaction and fabrication alternate step-by-step. Copyright © 2013 ACM.",3D | Interactive fabrication | Laser cutting | Physical prototyping | Rapid prototyping,109,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84879805132,10.1145/2488608.2488620,,,Low rank approximation and regression in input sparsity time,cp,Conference Paper,Clarkson K.,60009253,IBM Research - Almaden,San Jose,United States,2,"Clarkson, Kenneth L.;Woodruff, David P.",7004182557;35407448600,60009253;60009253,2013-07-11,2013,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,81-90,"We design a new distribution over poly(rε-1) × n matrices S so that for any fixed n×d matrix A of rank r, with probability at least 9/10, SAx 2 = (1± ε) Ax 2 simultaneously for all x ∈ Rd. Such a matrix S is called a subspace embedding. Furthermore, SA can be computed in O(nnz(A))time, where nnz(A) is the number of non-zero entries of A. This improves over all previous subspace embeddings, which required at least Ω(nd log d) time to achieve this property. We call our matrices S sparse embedding matrices. Using our sparse embedding matrices, we obtain the fastest known algorithms for overconstrained least-squares regression, low-rank approximation, approximating all leverage scores, and p-regression: • to output an xfor which Ax - b 2 ≤ (1 + ε)min x Ax - b 2 for an n × d matrix A and an n × 1 column vector b, we obtain an algorithm running in O(nnz(A)) + ̃O (d3ε-2) time, and another in O(nnz(A) log(1/ε)) + ̃O (d3 log(1/ε)) time. (Here ̃O(f) = f · logO(1)(f).) • to obtain a decomposition of an n×n matrix A into a product of an n×k matrix L, a k ×k diagonal matrix D, and a n × k matrix W, for which A - LDW F ≤ (1 + ε) A - Ak F , where Ak is the best rank-k approximation, our algorithm runs in O(nnz(A)) +̃O(nk2ε-4 log n+k3ε-5 log 2 n) time. • to output an approximation to all leverage scores of an n×d input matrix A simultaneously, with constant relative error, our algorithms run in O(nnz(A) log n)+ ̃O (r3) time. • to output an x for which Ax - b p ≤ (1 + ε)min x Ax - b p for an n × d matrix A and an n × 1 column vector b, we obtain an algorithm running in O(nnz(A) log n) + poly(rε-1) time, for any constant 1 ≤ p < ∞. We optimize the polynomial factors in the above stated running times, and show various tradeoffs. Finally, we provide preliminary experimental results which suggest that our algorithms are of interest in practice. Copyright 2013 ACM.",Algorithms | Theory,300,0,repositoryam,Green,DARPA,undefined,Defense Advanced Research Projects Agency,STOC Theory
2-s2.0-84880552788,10.1145/2463676.2463704,,,Massive graph triangulation,cp,Conference Paper,Hu X.,60032144;60002798,Korea Advanced Institute of Science and Technology;Chinese University of Hong Kong,Daejeon;Hong Kong,South Korea;Hong Kong,3,"Hu, Xiaocheng;Tao, Yufei;Chung, Chin Wan",55648231800;7402420191;7403613348,60002798;60002798-60032144;60032144,2013-07-29,2013,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,325-336,"This paper studies I/O-efficient algorithms for settling the classic triangle listing problem, whose solution is a basic operator in dealing with many other graph problems. Specifically, given an undirected graph G, the objective of triangle listing is to find all the cliques involving 3 vertices in G. The problem has been well studied in internal memory, but remains an urgent difficult challenge when G does not fit in memory, rendering any algorithm to entail frequent I/O accesses. Although previous research has attempted to tackle the challenge, the state-of-the-art solutions rely on a set of crippling assumptions to guarantee good performance. Motivated by this, we develop a new algorithm that is provably I/O and CPU efficient at the same time, without making any assumption on the input G at all. The algorithm uses ideas drastically different from all the previous approaches, and outperformed the existing competitors by a factor over an order of magnitude in our extensive experimentation. Copyright © 2013 ACM.",Graph | I/O-efficient algorithm | Triangle,89,0,,,,undefined,,SIGMOD Databases
2-s2.0-84877951933,10.1145/2470654.2466452,,,"Mind the theoretical gap: Interpreting, using, and developing behavioral theory in HCI research",cp,Conference Paper,Hekler E.B.,60025778;60020304;60003892,"University of Michigan, Ann Arbor;University of Maryland, College Park;Arizona State University",Ann Arbor;College Park;Tempe,United States;United States;United States,4,"Hekler, Eric B.;Klasnja, Predrag;Froehlich, Jon E.;Buman, Matthew P.",23034393200;22834990200;7101665384;23388260400,60003892;60025778;60020304;60003892,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,3307-3316,"Researchers in HCI and behavioral science are increasingly exploring the use of technology to support behavior change in domains such as health and sustainability. This work, however, remain largely siloed within the two communities. We begin to address this silo problem by attempting to build a bridge between the two disciplines at the level of behavioral theory. Specifically, we define core theoretical terms to create shared understanding about what theory is, discuss ways in which behavioral theory can be used to inform research on behavior change technologies, identify shortcomings in current behavioral theories, and outline ways in which HCI researchers can not only interpret and utilize behavioral science theories but also contribute to improving them. Copyright © 2013 ACM.",Behavior change | Behavior change technologies | Behavioral science | Health | Persuasive technology | Sustainability | Theory,206,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84889658377,10.1145/2517349.2522738,,,Naiad: A timely dataflow system,cp,Conference Paper,Murray D.G.,60021726,Microsoft Research,Redmond,United States,6,"Murray, Derek G.;McSherry, Frank;Isaacs, Rebecca;Isard, Michael;Barham, Paul;Abadi, Martín",26531525200;6603207363;7102281545;6601968991;7006307649;35618320100,60021726;60021726;60021726;60021726;60021726;60021726,2013-12-12,2013,SOSP 2013 - Proceedings of the 24th ACM Symposium on Operating Systems Principles,,21100273205,,Conference Proceeding,,,,439-455,"Naiad is a distributed system for executing data parallel, cyclic dataflow programs. It offers the high throughput of batch processors, the low latency of stream processors, and the ability to perform iterative and incremental computations. Although existing systems offer some of these features, applications that require all three have relied on multiple platforms, at the expense of efficiency, maintainability, and simplicity. Naiad resolves the complexities of combining these features in one framework. A new computational model, timely dataflow, underlies Naiad and captures opportunities for parallelism across a wide class of algorithms. This model enriches dataflow computation with timestamps that represent logical points in the computation and provide the basis for an efficient, lightweight coordination mechanism. We show that many powerful high-level programming models can be built on Naiad's low-level primitives, enabling such diverse tasks as streaming data analysis, iterative machine learning, and interactive graph mining. Naiad outperforms specialized systems in their target application domains, and its unique features enable the development of new high-performance applications. © 2013 ACM.",,552,1,publisherfree2read,Bronze,,undefined,,SOSP Operating Systems
2-s2.0-84893495424,10.1109/FOCS.2013.35,,,"Navigating central path with electrical flows: From flows to Matchings, and back (Extended Abstract)",cp,Conference Paper,Ma̧dry A.,60028186,École Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,1,"Ma̧dry, Aleksander",24171757000,60028186,2013-12-01,2013,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,,,6686161,253-262,"We present an Õ (m 10/7 ) = Õ (m1.43)-time algorithm for the maximum s-t flow and the minimum s-t cut problems in directed graphs with unit capacities. This is the first improvement over the sparse-graph case of the long-standing O(mmin{ √ m, n2/3}) running time bound due to Even and Tarjan [16]. By well-known reductions, this also establishes an Õ(m 10/7 )-time algorithm for the maximumcardinality bipartite matching problem. That, in turn, gives an improvement over the celebrated O(m √ n) running time bound of Hopcroft and Karp [25] whenever the input graph is sufficiently sparse. At a very high level, our results stem from acquiring a deeper understanding of interior-point methods - A powerful tool in convex optimization - in the context of flow problems, as well as, utilizing certain interplay between maximum flows and bipartite matchings. Copyright © 2013 by The Institute of Electrical and Electronics Engineers, Inc.",Bipartite matchings | Central path | Electrical flows | Interior-point methods | Laplacian linear systems | Maximum flow problem | Minimum s-t cut problem,160,0,repositoryam,Green,,undefined,,FOCS Theory
2-s2.0-84893030055,,,,No country for old members: User lifecycle and linguistic change in online communities,cp,Conference Paper,Danescu-Niculescu-Mizil C.,60012708,Stanford University,Stanford,United States,5,"Danescu-Niculescu-Mizil, Cristian;West, Robert;Jurafsky, Dan;Leskovec, Jure;Potts, Christopher",36172404900;57217665120;6602872553;12241436100;57206534134,60012708;60012708;60012708;60012708;60012708,2013-12-01,2013,WWW 2013 - Proceedings of the 22nd International Conference on World Wide Web,,21100285017,,Conference Proceeding,,,,307-317,"Vibrant online communities are in constant flux. As members join and depart, the interactional norms evolve, stimulating further changes to the membership and its social dynamics. Linguistic change-in the sense of innovation that becomes accepted as the norm-is essential to this dynamic process: it both facilitates individual expression and fosters the emergence of a collective identity. We propose a framework for tracking linguistic change as it happens and for understanding how specific users react to these evolving norms. By applying this framework to two large online communities we show that users follow a determined two-stage lifecycle with respect to their susceptibility to linguistic change: a linguistically innovative learning phase in which users adopt the language of the community followed by a conservative phase in which users stop changing and the evolving community norms pass them by. Building on this observation, we show how this framework can be used to detect, early in a user's career, how long she will stay active in the community. Thus, this work has practical significance for those who design and maintain online communities. It also yields new theoretical insights into the evolution of linguistic norms and the complex interplay between community-level and individual-level linguistic change. Copyright is held by the International World Wide Web Conference Committee (IW3C2).",Community norms | Conventions | Language | Lifecycle | Linguistic change | Reviews | Social influence | User abandonment,266,0,,,NSF,IIS-1016909,National Science Foundation,WWW World Wide Web
2-s2.0-84893446521,10.1109/FOCS.2013.62,,,On kinetic delaunay triangulations: A near quadratic bound for unit speed motions,cp,Conference Paper,Rubin N.,60030718,Freie Universität Berlin,Berlin,Germany,1,"Rubin, Natan",23390464700,60030718,2013-12-01,2013,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,,,6686188,519-528,"Let P be a collection of n points in the plane, each moving along some straight line at unit speed. We obtain an almost tight upper bound of O(n 2+ε), for any ε > 0, on the maximum number of discrete changes that the Delaunay triangulation DT(P) of P experiences during this motion. Our analysis is cast in a purely topological setting, where we only assume that (i) any four points can be co-circular at most three times, and (ii) no triple of points can be collinear more than twice; these assumptions hold for unit speed motions. Copyright © 2013 by The Institute of Electrical and Electronics Engineers, Inc.",Combinatorial complexity | Delaunay triangulation | Discrete changes | Moving points | Voronoi diagram,5,0,repositoryam,Green,,undefined,,FOCS Theory
2-s2.0-84883056237,10.1109/INFCOM.2013.6566874,,,On the steady-state of cache networks,cp,Conference Paper,Rosensweig E.J.,60152130;60000036,Manning College of Information &amp; Computer Sciences;Universidade Federal do Rio de Janeiro,Amherst;Rio de Janeiro,United States;Brazil,3,"Rosensweig, Elisha J.;Menasche, Daniel S.;Kurose, Jim",35079246200;8555897400;57205296035,60152130;60000036;60152130,2013-09-02,2013,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,,,6566874,863-871,"Over the past few years Content-Centric Networking, a networking model in which host-to-content communication protocols are introduced, has been gaining much attention. A central component of such an architecture is a large-scale interconnected caching system. To date, the way these Cache Networks operate and perform is still poorly understood. In this work, we demonstrate that certain cache networks are non-ergodic in that their steady-state characterization depends on the initial state of the system. We then establish several important properties of cache networks, in the form of three independently-sufficient conditions for a cache network to comprise a single ergodic component. Each property targets a different aspect of the system - topology, admission control and cache replacement policies. Perhaps most importantly we demonstrate that cache replacement can be grouped into equivalence classes, such that the ergodicity (or lack-thereof) of one policy implies the same property holds for all policies in the class. © 2013 IEEE.",,66,0,,,,undefined,,INFOCOM Networking
2-s2.0-84889583799,10.1145/2505515.2505680,,,"Penguins in sweaters, or serendipitous entity search on user-generated content",cp,Conference Paper,Bordino I.,60085104,Yahoo Research Barcelona,Barcelona,Spain,3,"Bordino, Ilaria;Mejova, Yelena;Lalmas, Mounia",26325355900;35230579200;6603685753,60085104;60085104;60085104,2013-12-11,2013,"International Conference on Information and Knowledge Management, Proceedings",,55826,,Conference Proceeding,,,,109-118,"In many cases, when browsing the Web users are searching for specific information or answers to concrete questions. Sometimes, though, users find unexpected, yet interesting and useful results, and are encouraged to explore further. What makes a result serendipitous? We propose to answer this question by exploring the potential of entities extracted from two sources of user-generated content - Wikipedia, a user-curated online encyclopedia, and Yahoo! Answers, a more unconstrained question/answering forum - in promoting serendipitous search. In this work, the content of each data source is represented as an entity network, which is further enriched with metadata about sentiment, writing quality, and topical category. We devise an algorithm based on lazy random walk with restart to retrieve entity recommendations from the networks. We show that our method provides novel results from both datasets, compared to standard web search engines. However, unlike previous research, we find that choosing highly emotional entities does not increase user interest for many categories of entities, suggesting a more complex relationship between topic matter and the desirable metadata attributes in serendipitous search. Copyright 2013 ACM.",Entity networks | Entity search | Interesting-ness | Metadata | Serendipity,34,0,,,,undefined,,CIKM Knowledge Management
2-s2.0-84881259359,10.1109/SP.2013.47,,,Pinocchio: Nearly practical verifiable computation,cp,Conference Paper,Parno B.,60021726;60011048,Microsoft Research;IBM Research,Redmond;Yorktown Heights,United States;United States,4,"Parno, Bryan;Howell, Jon;Gentry, Craig;Raykova, Mariana",57203245130;7402273498;57203084724;24729640400,60021726;60021726;60011048;60011048,2013-08-13,2013,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,,,6547113,238-252,"To instill greater confidence in computations outsourced to the cloud, clients should be able to verify the correctness of the results returned. To this end, we introduce Pinocchio, a built system for efficiently verifying general computations while relying only on cryptographic assumptions. With Pinocchio, the client creates a public evaluation key to describe her computation; this setup is proportional to evaluating the computation once. The worker then evaluates the computation on a particular input and uses the evaluation key to produce a proof of correctness. The proof is only 288 bytes, regardless of the computation performed or the size of the inputs and outputs. Anyone can use a public verification key to check the proof. Crucially, our evaluation on seven applications demonstrates that Pinocchio is efficient in practice too. Pinocchio's verification time is typically 10ms: 5-7 orders of magnitude less than previous work; indeed Pinocchio is the first general-purpose system to demonstrate verification cheaper than native execution (for some apps). Pinocchio also reduces the worker's proof effort by an additional 19-60x. As an additional feature, Pinocchio generalizes to zero-knowledge proofs at a negligible cost over the base protocol. Finally, to aid development, Pinocchio provides an end-to-end toolchain that compiles a subset of C into programs that implement the verifiable computation protocol. © 2013 IEEE.",,638,1,repositoryam,Green,NSF,1017660,National Science Foundation,S&P Security and Privacy
2-s2.0-84887600584,10.1145/2501988.2502037,,,PneUI: Pneumatically actuated soft composite materials for shape changing interfaces,cp,Conference Paper,Yao L.,60022195;60002243,Massachusetts Institute of Technology;MIT Media Lab,Cambridge;Cambridge,United States;United States,6,"Yao, Lining;Niiyama, Ryuma;Ou, Jifei;Follmer, Sean;Silva, Clark Della;Ishii, Hiroshi",58342540100;23009680300;55929061600;26430822900;55928433000;26660877000,60002243;60002243;60002243;60002243;60022195;60002243,2013-11-20,2013,UIST 2013 - Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology,,21100266905,,Conference Proceeding,,,,13-22,"This paper presents PneUI, an enabling technology to build shape-changing interfaces through pneumatically-actuated soft composite materials. The composite materials integrate the capabilities of both input sensing and active shape output. This is enabled by the composites' multi-layer structures with different mechanical or electrical properties. The shape changing states are computationally controllable through pneumatics and pre-defined structure. We explore the design space of PneUI through four applications: height changing tangible phicons, a shape changing mobile, a transformable tablet case and a shape shifting lamp. Copyright © 2013 ACM.",Human-material interaction | Organic user interface | Pneumatic system | Radical atoms | Shape changing interface | Soft actuator | Soft composite material | Soft robotics,258,0,repositoryvor,Green,,undefined,,UIST User Interface
2-s2.0-84880234083,10.1145/2494232.2465757,,,Queueing system topologies with limited flexibility,cp,Conference Paper,Tsitsiklis J.,60022195,Massachusetts Institute of Technology,Cambridge,United States,2,"Tsitsiklis, John N.;Xu, Kuang",7005129479;57203516711,60022195;60022195,2013-07-22,2013,Performance Evaluation Review,01635999,26742,,Conference Proceeding,41,1 SPEC. ISS.,,167-178,"We study a multi-server model with n flexible servers and rn queues, connected through a fixed bipartite graph, where the level of flexibility is captured by the average degree, d(n), of the queues. Applications in content replication in data centers, skill-based routing in call centers, and flexible supply chains are among our main motivations. We focus on the scaling regime where the system size n tends to infinity, while the overall traffic intensity stays fixed. We show that a large capacity region (robustness) and diminishing queueing delay (performance) are jointly achievable even under very limited flexibility (d(n) << n). In particular, when d(n) >> lnn, a family of random-graph-based interconnection topologies is (with high probability) capable of stabilizing all admissible arrival rate vectors (under a bounded support assumption), while simultaneously ensuring a diminishing queueing delay, of order In n/d(n), as n → ∞. Our analysis is centered around a new class of virtual-queue-based scheduling policies that rely on dynamically constructed partial matchings on the connectivity graph. Copyright © 2013 ACM.",Asymptotics | Expander graph | Flexibility | Partial resource pooling | Queueing system | Random graph,17,0,repositoryam,Green,,undefined,,SIGMETRICS Performance
2-s2.0-84877991330,10.1145/2470654.2466190,,,Reasons to question seven segment displays,cp,Conference Paper,Thimbleby H.,60004572,Swansea University,Swansea,United Kingdom,1,"Thimbleby, Harold",7005826808,60004572,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1431-1440,"Seven segment number displays are ubiquitous and popular. They are simple and familiar. They seem to make economic sense, and with only seven segments they require little wiring and electronics to support. They are cheap to buy and cheap to use; they make seemingly effective and unproblematic products. This paper illustrates many examples of problematic uses of seven segment displays that could have been better managed or even avoided. More generally, the paper raises design questions and some solutions to be considered when designing numerical displays, and certainly before uncritically using seven segment displays. Although there are markets and applications where cost may be an overriding consideration, for safety critical and other dependable types of use (including general purpose devices that may sometimes be used for critical tasks) more legible alternatives than standard seven segment displays should be preferred. Copyright © 2013 ACM.",Calculators | Dependable interaction | Number display | Number error | Procurement | Seven segment display,16,0,,,EPSRC,EP/G059063/1,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-84880121543,10.1145/2499370.2462194,,,Reconciling exhaustive pattern matching with objects,cp,Conference Paper,Isradisaikul C.,60278093,Cornell Ann S. Bowers College of Computing and Information Science,Ithaca,United States,2,"Isradisaikul, Chinawat;Myers, Andrew C.",55791943300;7202743179,60278093;60278093,2013-06-01,June 2013,ACM SIGPLAN Notices,15232867,19700185000,,Journal,48,6,,343-353,"Pattern matching, an important feature of functional languages, is in conflict with data abstraction and extensibility, which are central to object-oriented languages. Modal abstraction offers an integration of deep pattern matching and convenient iteration abstractions into an object-oriented setting; however, because of data abstraction, it is challenging for a compiler to statically verify properties such as exhaustiveness. In this work, we extend modal abstraction in the JMatch language to support static, modular reasoning about exhaustiveness and redundancy. New matching specifications allow these properties to be checked using an SMT solver. We also introduce expressive pattern-matching constructs. Our evaluation shows that these new features enable more concise code and that the performance of checking exhaustiveness and redundancy is acceptable.",Data abstraction | Equality constructor | Exhaustiveness | Java | JMatch | Matching specification | Modal abstraction | Named constructor | Pattern matching | Redundancy | Subtyping,4,0,repositoryam,Green,ONR,N00014-09-1-0652,Office of Naval Research,PLDI Programming Languages
2-s2.0-84893386313,,,,SMILe: Shuffled multiple-instance learning,cp,Conference Paper,Doran G.,60144130,Case School of Engineering,Cleveland,United States,2,"Doran, Gary;Ray, Soumya",55966255700;36606659300,60144130;60144130,2013-12-01,2013,"Proceedings of the 27th AAAI Conference on Artificial Intelligence, AAAI 2013",,21100285716,,Conference Proceeding,,,,260-266,"Resampling techniques such as bagging are often used in supervised learning to produce more accurate classifiers. In this work, we show that multiple-instance learning admits a different form of resampling, which we call ""shuffling."" In shuffling, we resample instances in such a way that the resulting bags are likely to be correctly labeled. We show that resampling results in both a reduction of bag label noise and a propagation of additional informative constraints to a multiple-instance classifier. We empirically evaluate shuffling in the context of multiple-instance classification and multiple-instance active learning and show that the approach leads to significant improvements in accuracy. © 2013, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,3,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-84877958910,10.1145/2470654.2481283,,,SPRWeb: Preserving subjective responses to website colour schemes through automatic recolouring,cp,Conference Paper,Flatla D.,60015186;60009982,University of Saskatchewan;Harvard University,Saskatoon;Cambridge,Canada;United States,4,"Flatla, David R.;Reinecke, Katharina;Gutwin, Carl;Gajos, Krzysztof Z.",36141533300;24605497700;35587413900;8375653300,60015186;60009982;60015186;60009982,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,2069-2078,"Colours are an important part of user experiences on the Web. Colour schemes influence the aesthetics, first impressions and long-term engagement with websites. However, five percent of people perceive a subset of all colours because they have colour vision deficiency (CVD), resulting in an unequal and less-rich user experience on the Web. Traditionally, people with CVD have been supported by recolouring tools that improve colour differentiability, but do not consider the subjective properties of colour schemes while recolouring. To address this, we developed SPRWeb, a tool that recolours websites to preserve subjective responses and improve colour differentiability - thus enabling users with CVD to have similar online experiences. To develop SPRWeb, we extended existing models of non-CVD subjective responses to CVD, then used this extended model to steer the recolouring process. In a lab study, we found that SPRWeb did significantly better than a standard recolouring tool at preserving the temperature and naturalness of websites, while achieving similar weight and differentiability preservation. We also found that recolouring did not preserve activity, and hypothesize that visual complexity influences activity more than colour. SPRWeb is the first tool to automatically preserve the subjective and perceptual properties of website colour schemes thereby equalizing the colour-based web experience for people with CVD. Copyright 2013 ACM.",Automatic recolouring | Colour | Colour vision deficiency,40,0,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84899000472,,,,Scalable influence estimation in continuous-time diffusion networks,cp,Conference Paper,Du N.,60030569;60019647,Max Planck Institute for Intelligent Systems;Georgia Institute of Technology,Tubingen;Atlanta,Germany;United States,4,"Du, Nan;Song, Le;Gomez-Rodriguezy, Manuel;Zha, Hongyuan",23479332200;55587150100;56121809300;57201737688,60019647;60019647;60030569;60019647,2013-01-01,2013,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,,,,,"If a piece of information is released from a media site, can we predict whether it may spread to one million web pages, in a month ? This influence estimation problem is very challenging since both the time-sensitive nature of the task and the requirement of scalability need to be addressed simultaneously. In this paper, we propose a randomized algorithm for influence estimation in continuous-time diffusion networks. Our algorithm can estimate the influence of every node in a network with |V| nodes and |E| edges to an accuracy of ε using n = O(1=7epsi;2) randomizations and up to logarithmic factors O(n|E|+n|V|) computations. When used as a subroutine in a greedy influence maximization approach, our proposed algorithm is guaranteed to find a set of C nodes with the influence of at least (1 - 1/e)OPT-2Cε, where OPT is the optimal value. Experiments on both synthetic and real-world data show that the proposed algorithm can easily scale up to networks of millions of nodes while significantly improves over previous state-of-the-arts in terms of the accuracy of the estimated influence and the quality of the selected nodes in maximizing the influence.",,187,0,,,NIGMS,R01GM108341,National Institute of General Medical Sciences,NeurIPS Machine Learning
2-s2.0-84877966985,10.1145/2470654.2466227,,,Screenfinity: Extending the perception area of content on very large public displays,cp,Conference Paper,Schmidt C.,60011604;60006809,Technische Universität Berlin;Universität der Künste Berlin,Berlin;Berlin,Germany;Germany,3,"Schmidt, Constantin;Müller, Jörg;Bailly, Gilles",55735031000;57191035823;23395749200,60011604;60011604-60006809;60011604,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1719-1728,"We propose and validate a model of the perception area of content on public displays in order to predict from where users can read. From this model, we derive Screenfinity, a technique to rotate, translate, and zoom content in order to enable reading while passing by very large displays. Screenfinity is comfortable to read when close, supports different content for different users, does not waste screen real estate and allows expert passers-by to read content while walking. A laboratory study shows that expert users are able to perceive content when it moves. A field study evaluates the effect of Screenfinity on novice users in an ecologically valid setting. We find (1) first time users can read content without slowing down or stopping; (2) Passers-by stopping did so to explore the technology. Users explore the interaction, the limits of the system, manipulate the technology, and look behind the screen. Copyright © 2013 ACM.",Large public displays | Perception area | Visual acuity,34,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84980400461,10.1145/2487575.2487623,,,Simple and deterministic matrix sketching,cp,Conference Paper,Liberty E.,60075274,Yahoo Research Labs,Sunnyvale,United States,1,"Liberty, Edo",23393332700,60075274,2013-08-11,11 August 2013,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,21100824567,,Conference Proceeding,Part F128815,,2487623,581-588,"A sketch of a matrix A is another matrix B which is significantly smaller than A, but still approximates it well. Finding such sketches efficiently is an important building block in modern algorithms for approximating, for example, the PCA of massive matrices. This task is made more challenging in the streaming model, where each row of the input matrix can be processed only once and storage is severely limited. In this paper, we adapt a well known streaming algorithm for approximating item frequencies to the matrix sketching setting. The algorithm receives n rows of a large matrix A ∈ Rn×m one after the other, in a streaming fashion. It maintains a sketch B ∈ Rℓ×m containing only L ≪ n rows but still guarantees that ATA ≈ BTB. More accurately, ∀x, ∥x∥ = 1 0 ≤ ∥Ax∥2 - ∥Bx∥2 ≤ 2∥A∥2 f /ℓ Or BTB ≺ ATA and ∥ATA - BTB∥ ≤ 2∥A∥2f/ℓ . This algorithm's error decays proportionally to 1/ℓ using O(mℓ) space. In comparison, random-projection, hashing or sampling based algorithms produce convergence bounds proportional to 1/√ℓ. Sketch updates per row in A require amortized O(mℓ) operations and the algorithm is perfectly parallelizable. Our experiments corroborate the algorithm's scalability and improved convergence rate. The presented algorithm also stands out in that it is deterministic, simple to implement, and elementary to prove.",Frequent items | Matrix sketching | Streaming,192,0,repositoryam,Green,,undefined,,KDD Data Mining
2-s2.0-84883071637,10.1145/2462156.2462179,,,Static analysis for probabilistic programs: Inferring whole program properties from finitely many paths,cp,Conference Paper,Sankaranarayanan S.,60021726;60000221,Microsoft Research;University of Colorado Boulder,Redmond;Boulder,United States;United States,3,"Sankaranarayanan, Sriram;Chakarov, Aleksandar;Gulwani, Sumit",7007143213;35175606500;55901318200,60000221;60000221;60021726,2013-09-02,2013,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,447-458,"We propose an approach for the static analysis of probabilistic programs that sense, manipulate, and control based on uncertain data. Examples include programs used in risk analysis, medical decision making and cyber-physical systems. Correctness properties of such programs take the form of queries that seek the probabilities of assertions over program variables. We present a static analysis approach that provides guaranteed interval bounds on the values (assertion probabilities) of such queries. First, we observe that for probabilistic programs, it is possible to conclude facts about the behavior of the entire program by choosing a finite, adequate set of its paths. We provide strategies for choosing such a set of paths and verifying its adequacy. The queries are evaluated over each path by a combination of symbolic execution and probabilistic volume-bound computations. Each path yields interval bounds that can be summed up with a ""coverage"" bound to yield an interval that encloses the probability of assertion for the program as a whole. We demonstrate promising results on a suite of benchmarks from many different sources including robotic manipulators and medical decision making programs. Copyright © 2013 ACM.",Monte-Carlo Sampling | Probabilistic Programming | Program Verification | Symbolic Execution | Volume Bounding,75,0,,,,undefined,,PLDI Programming Languages
2-s2.0-84898975039,,,,Submodular optimization with submodular cover and submodular knapsack constraints,cp,Conference Paper,Iyer R.,60015481,University of Washington,Seattle,United States,2,"Iyer, Rishabh;Bilmes, Jeff",56111913800;7003705752,60015481;60015481,2013-01-01,2013,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,,,,,"We investigate two new optimization problems-minimizing a submodular function subject to a submodular lower bound constraint (submodular cover) and maximizing a submodular function subject to a submodular upper bound constraint (submodular knapsack). We are motivated by a number of real-world applications in machine learning including sensor placement and data subset selection, which require maximizing a certain submodular function (like coverage or diversity) while simultaneously minimizing another (like cooperative cost). These problems are often posed as minimizing the difference between submodular functions [9, 25] which is in the worst case inapproximable. We show, however, that by phrasing these problems as constrained optimization, which is more natural for many applications, we achieve a number of bounded approximation guarantees. We also show that both these problems are closely related and an approximation algorithm solving one can be used to obtain an approximation guarantee for the other. We provide hardness results for both problems thus showing that our approximation factors are tight up to log-factors. Finally, we empirically demonstrate the performance and good scalability properties of our algorithms.",,182,0,,,,undefined,,NeurIPS Machine Learning
2-s2.0-84877941777,10.1145/2470654.2466155,,,The Dubuque Electricity Portal: Evaluation of a city-scale residential electricity consumption feedback system,cp,Conference Paper,Erickson T.,60017366,IBM Thomas J. Watson Research Center,Yorktown Heights,United States,8,"Erickson, Thomas;Li, Ming;Kim, Younghun;Deshpande, Ajay;Sahu, Sambit;Chao, Tian;Sukaviriya, Piyawadee;Naphade, Milind",7005246729;55635105500;57219191631;23396698200;7202907631;56206835900;6507599099;56948387100,60017366;60017366;60017366;60017366;60017366;60017366;60017366;60017366,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1203-1212,"This paper describes the Dubuque Electricity Portal, a cityscale system aimed at supporting voluntary reductions of electricity consumption. The Portal provided each household with fine-grained feedback on its electricity use, as well as using incentives, comparisons, and goal setting to encourage conservation. Logs, a survey and interviews were used to evaluate the user experience of the Portal during a 20-week pilot with 765 volunteer households. Although the volunteers had already made a wide range of changes to conserve electricity prior to the pilot, those who used the Portal decreased their electricity use by about 3.7%. They also reported increased understanding of their usage, and reported taking an array of actions - both changing their behavior and their electricity infrastructure. The paper discusses the experience of the system's users, and describes challenges for the design of ECF systems, including balancing accessibility and security, a preference for time-based visualizations, and the advisability of multiple modes of feedback, incentives and information presentation. Copyright © 2013 ACM.",Behavior change | Consumption feedback systems | ECF | Electricity | Smart meters | Social comparison | Sustainability,53,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84877961483,10.1145/2470654.2470718,,,The efficacy of human post-editing for language translation,cp,Conference Paper,Green S.,60141508,Stanford Engineering,Stanford,United States,3,"Green, Spence;Heer, Jeffrey;Manning, Christopher D.",51664773200;6603794736;35280197500,60141508;60141508;60141508,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,439-448,"Language translation is slow and expensive, so various forms of machine assistance have been devised. Automatic machine translation systems process text quickly and cheaply, but with quality far below that of skilled human translators. To bridge this quality gap, the translation industry has investigated postediting, or the manual correction of machine output. We present the first rigorous, controlled analysis of post-editing and find that post-editing leads to reduced time and, surprisingly, improved quality for three diverse language pairs (English to Arabic, French, and German). Our statistical models and visualizations of experimental data indicate that some simple predictors (like source text part of speech counts) predict translation time, and that post-editing results in very different interaction patterns. From these results we distill implications for the design of new language translation interfaces. Copyright © 2013 ACM.",Experiment | Language translation | Modeling | Post-editing,133,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84889667686,10.1145/2517349.2522712,,,The scalable commutativity rule: Designing scalable software for multicore processors,cp,Conference Paper,Clements A.T.,60009982;60006320,Harvard University;MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge;Cambridge,United States;United States,5,"Clements, Austin T.;Kaashoek, M. Frans;Zeldovich, Nickolai;Morris, Robert T.;Kohler, Eddie",24079661600;57207515364;35225644900;7404059170;9133554700,60006320;60006320;60006320;60006320;60009982,2013-12-12,2013,SOSP 2013 - Proceedings of the 24th ACM Symposium on Operating Systems Principles,,21100273205,,Conference Proceeding,,,,1-17,"What fundamental opportunities for scalability are latent in interfaces, such as system call APIs? Can scalability opportunities be identified even before any implementation exists, simply by considering interface specifications? To answer these questions this paper introduces the following rule: Whenever interface operations commute, they can be implemented in a way that scales. This rule aids developers in building more scalable software starting from interface design and carrying on through implementation, testing, and evaluation. To help developers apply the rule, a new tool named Commuter accepts high-level interface models and generates tests of operations that commute and hence could scale. Using these tests, Commuter can evaluate the scalability of an implementation. We apply Commuter to 18 POSIX calls and use the results to guide the implementation of a new research operating system kernel called sv6. Linux scales for 68% of the 13,664 tests generated by Commuter for these calls, and Commuter finds many problems that have been observed to limit application scalability. sv6 scales for 99% of the tests. © 2013 ACM.",,84,1,repositoryam,Green,NSF,undefined,National Science Foundation,SOSP Operating Systems
2-s2.0-84887587781,10.1145/2501988.2501989,,,Touch &amp; Activate: Adding interactivity to existing objects using active acoustic sensing,cp,Conference Paper,Ono M.,60014256,University of Tsukuba,Tsukuba,Japan,3,"Ono, Makoto;Shizuki, Buntarou;Tanaka, Jiro",55928860100;6507626386;35103690300,60014256;60014256;60014256,2013-11-20,2013,UIST 2013 - Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology,,21100266905,,Conference Proceeding,,,,31-40,"In this paper, we present a novel acoustic touch sensing technique called Touch & Activate. It recognizes a rich context of touches including grasp on existing objects by attaching only a vibration speaker and a piezo-electric microphone paired as a sensor. It provides easy hardware configuration for prototyping interactive objects that have touch input capability. We conducted a controlled experiment to measure the accuracy and trade-off between the accuracy and number of training rounds for our technique. From its results, per-user recognition accuracies with five touch gestures for a plastic toy as a simple example and six hand postures for the posture recognition as a complex example were 99.6% and 86.3%, respectively. Walk up user recognition accuracies for the two applications were 97.8% and 71.2%, respectively. Since the results of our experiment showed a promising accuracy for the recognition of touch gestures and hand postures, Touch & Activate should be feasible for prototyping interactive objects that have touch input capability. Copyright © 2013 ACM.",Acoustic classification | Gestures | Grasp | Machine learning | Piezo-electric sensor | Prototyping | Sensors | Support vector machine | Tangibles | Touch,130,0,,,,undefined,,UIST User Interface
2-s2.0-84889684785,10.1145/2517349.2522728,,,Towards optimization-safe systems: Analyzing the impact of undefined behavior,cp,Conference Paper,Wang X.,60006320,MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge,United States,4,"Wang, Xi;Zeldovich, Nickolai;Kaashoek, M. Frans;Solar-Lezama, Armando",56562766700;35225644900;57207515364;12141220900,60006320;60006320;60006320;60006320,2013-12-12,2013,SOSP 2013 - Proceedings of the 24th ACM Symposium on Operating Systems Principles,,21100273205,,Conference Proceeding,,,,260-275,"This paper studies an emerging class of software bugs called optimization-unstable code: code that is unexpectedly discarded by compiler optimizations due to undefined behavior in the program. Unstable code is present in many systems, including the Linux kernel and the Postgres database. The consequences of unstable code range from incorrect functionality to missing security checks. To reason about unstable code, this paper proposes a novel model, which views unstable code in terms of optimizations that leverage undefined behavior. Using this model, we introduce a new static checker called Stack that precisely identifies unstable code. Applying Stack to widely used systems has uncovered 160 new bugs that have been confirmed and fixed by developers. © 2013 ACM.",,109,1,repositoryam,Green,DARPA,undefined,Defense Advanced Research Projects Agency,SOSP Operating Systems
2-s2.0-84877960208,10.1145/2470654.2470742,,,Turkopticon: Interrupting worker invisibility in Amazon Mechanical Turk,cp,Conference Paper,Irani L.C.,60007278;110546338,"University of California, Irvine;Bureau of Economic Interpretation",Irvine;San Francisco,United States;United States,2,"Irani, Lilly C.;Silberman, M. Six",8438130700;36096079700,60007278;110546338,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,611-620,"As HCI researchers have explored the possibilities of human computation, they have paid less attention to ethics and values of crowdwork. This paper offers an analysis of Amazon Mechanical Turk, a popular human computation system, as a site of technically mediated worker-employer relations. We argue that human computation currently relies on worker invisibility. We then present Turkopticon, an activist system that allows workers to publicize and evaluate their relationships with employers. As a common infrastructure, Turkopticon also enables workers to engage one another in mutual aid. We conclude by discussing the potentials and challenges of sustaining activist technologies that intervene in large, existing socio-technical systems. Copyright © 2013 ACM.",Activism | Amazon Mechanical Turk | Design | Ethics | Human computation | Infrastructure,535,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84886379183,10.1109/ICSE.2013.6606618,,,UML in practice,cp,Conference Paper,Petre M.,60012113,The Open University,Milton Keynes,United Kingdom,1,"Petre, Marian",32667998900,60012113,2013-10-30,2013,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,6606618,722-731,UML has been described by some as 'the lingua franca of software engineering'. Evidence from industry does not necessarily support such endorsements. How exactly is UML being used in industry - if it is? This paper presents a corpus of interviews with 50 professional software engineers in 50 companies and identifies 5 patterns of UML use. © 2013 IEEE.,empirical studies | notation | software design | software development | UML,198,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-84897546637,,,,Vanishing component analysis,cp,Conference Paper,Livni R.,60010574;60007903,Hewlett Packard Laboratories;Hebrew University of Jerusalem,Palo Alto;Jerusalem,United States;Israel,6,"Livni, Roi;Lehavi, David;Schein, Sagi;Nachlieli, Hila;Shalev-Shwartz, Shai;Globerson, Amir",56096564800;58029597300;7003517456;20434179800;6507998544;18934352000,60007903;60010574;60010574;60010574;60007903;60007903,2013-01-01,2013,"30th International Conference on Machine Learning, ICML 2013",,21100301423,,Conference Proceeding,,PART 1,,597-605,"The vanishing ideal of a set of points, S ⊂ ℝn, is the set of all polynomials that attain the value of zero on all the points in S. Such ideals can be compactly represented using a small set of polynomials known as generators of the ideal. Here we describe and analyze an efficient procedure that constructs a set of generators of a vanishing ideal. Our procedure is numerically stable, and can be used to find approximately vanishing polynomials. The resulting polynomials capture nonlinear structure in data, and can for example be used within supervised learning. Empirical comparison with kernel methods show that our method constructs more compact classifiers with comparable accuracy. Copyright 2013 by the author(s).",,28,0,,,,undefined,,ICML Machine Learning
2-s2.0-84880564869,10.1145/2463664.2465228,,,Verification of database-driven systems via amalgamation,cp,Conference Paper,Bojańczyk M.,60013756;60013373,University of Warsaw;INRIA Institut National de Recherche en Informatique et en Automatique,Warsaw;Le Chesnay,Poland;France,3,"Bojańczyk, Mikołaj;Segoufin, Luc;Torunczyk, Szymon",11540205100;55965366000;36474276600,60013756;60013373;60013756,2013-07-29,2013,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,63-74,"We describe a general framework for static verification of systems that base their decisions upon queries to databases. The database is specified using constraints, typically a schema, and is not modified during a run of the system. The system is equipped with a finite number of registers for storing intermediate information from the database and the specification consists of a transition table described using quantifier-free formulas that can query either the database or the registers. Our main result concerns systems querying XML databases - modeled as data trees - using quantifier-free formulas with predicates such as the descendant axis or comparison of data values. In this scenario we show an ExpSpace algorithm for deciding reachability. Our technique is based on the notion of amalgamation and is quite general. For instance it also applies to relational databases (with an optimal PSpace algorithm). We also show that minor extensions of the model lead to undecidability. Copyright 2013 ACM.",Amalgamation | Database-driven Systems | Fraïssé classes | Register Automata,19,0,repositoryam,Green,FP7,239850,Seventh Framework Programme,PODS Databases
2-s2.0-84877933416,10.1145/2470654.2466420,,,Webzeitgeist: Design mining the Web,cp,Conference Paper,Kumar R.,60033010;60022195;60012708,Intel Corporation;Massachusetts Institute of Technology;Stanford University,Santa Clara;Cambridge;Stanford,United States;United States;United States,7,"Kumar, Ranjitha;Satyanarayan, Arvind;Torres, Cesar;Lim, Maxine;Ahmad, Salman;Klemmer, Scott R.;Talton, Jerry O.",55480578200;55193351500;57197189270;55480813700;39361112200;6603250689;22036874300,60012708;60012708;60012708;60012708;60022195;60012708;60033010,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,3083-3092,"Advances in data mining and knowledge discovery have transformed the way Web sites are designed. However, while visual presentation is an intrinsic part of the Web, traditional data mining techniques ignore render-time page structures and their attributes. This paper introduces design mining for the Web: using knowledge discovery techniques to understand design demographics, automate design curation, and support data-driven design tools. This idea is manifest in Webzeitgeist, a platform for large-scale design mining comprising a repository of over 100,000 Web pages and 100 million design elements. This paper describes the principles driving design mining, the implementation of the Webzeitgeist architecture, and the new class of data-driven design applications it enables. Copyright 2013 ACM.",Data mining | Web design,95,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84877951643,10.1145/2470654.2470724,,,Weighted graph comparison techniques for brain connectivity analysis,cp,Conference Paper,Alper B.,60029241;60021726;60013373,"University of California, Santa Barbara;Microsoft Research;INRIA Institut National de Recherche en Informatique et en Automatique",Santa Barbara;Redmond;Le Chesnay,United States;United States;France,5,"Alper, Basak;Bach, Benjamin;Henry Riche, Nathalie;Isenberg, Tobias;Fekete, Jean Daniel",54384738400;37103551800;36457833900;6506341607;7005772385,60029241;60013373;60021726;60013373;60013373,2013-01-01,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,483-492,"The analysis of brain connectivity is a vast field in neuroscience with a frequent use of visual representations and an increasing need for visual analysis tools. Based on an in-depth literature review and interviews with neuroscientists, we explore high-level brain connectivity analysis tasks that need to be supported by dedicated visual analysis tools. A significant example of such a task is the comparison of different connectivity data in the form of weighted graphs. Several approaches have been suggested for graph comparison within information visualization, but the comparison of weighted graphs has not been addressed. We explored the design space of applicable visual representations and present augmented adjacency matrix and node-link visualizations. To assess which representation best support weighted graph comparison tasks, we performed a controlled experiment. Our findings suggest that matrices support these tasks well, outperforming node-link diagrams. These results have significant implications for the design of brain connectivity analysis tools that require weighted graph comparisons. They can also inform the design of visual analysis tools in other domains, e.g. comparison of weighted social networks or biological pathways. Copyright © 2013 ACM.",Brain connectivity analysis | Brain connectivity visualization | Graph comparison,129,0,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84877997201,10.1145/2470654.2466451,,,"What is ""critical"" about critical design?",cp,Conference Paper,Bardzell J.,60021121,Indiana University Bloomington,Bloomington,United States,2,"Bardzell, Jeffrey;Bardzell, Shaowen",17345062400;17345284300,60021121;60021121,2013-05-27,2013,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,3297-3306,"Critical design is a research through design methodology that foregrounds the ethics of design practice, reveals potentially hidden agendas and values, and explores alternative design values. While it seems to be a timely fit for today's socially, aesthetically, and ethically oriented approaches to HCI, its adoption seems surprisingly limited. We argue that its central concepts and methods are unclear and difficult to adopt. Rather than merely attempting to decode the intentions of its originators, Dunne and Raby, we instead turn to traditions of critical thought in the past 150 years to explore a range of critical ideas and their practical uses. We then suggest ways that these ideas and uses can be leveraged as practical resources for HCI researchers interested in critical design. We also offer readings of two designs, which are not billed as critical designs, but which we argue are critical using a broader formulation of the concept than the one found in the current literature. Copyright © 2013 ACM.",Critical design | Critical theory | Design methodology | HCI,249,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84887122819,10.1145/2500423.2500436,,,Whole-home gesture recognition using wireless signals,cp,Conference Paper,Pu Q.,60015481,University of Washington,Seattle,United States,4,"Pu, Qifan;Gupta, Sidhant;Gollakota, Shyamnath;Patel, Shwetak",55841232900;55389087400;24449959700;8450420300,60015481;60015481;60015481;60015481,2013-11-11,2013,"Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM",,70461,,Conference Proceeding,,,,27-38,"This paper presents WiSee, a novel gesture recognition system that leverages wireless signals (e.g., Wi- Fi) to enable whole-home sensing and recognition of human gestures. Since wireless signals do not require line-of-sight and can traverse through walls, WiSee can enable wholehome gesture recognition using few wireless sources. Further, it achieves this goal without requiring instrumentation of the human body with sensing devices. We implement a proof-ofconcept prototype of WiSee using USRP-N210s and evaluate it in both an office environment and a two-bedroom apartment. Our results show that WiSee can identify and classify a set of nine gestures with an average accuracy of 94%. © 2013 by the Association for Computing Machinery, Inc.",Gesture recognition | Wireless sensing,852,0,repositoryam,Green,,undefined,,MOBICOM Mobile
2-s2.0-84900420076,10.1145/2556288.2557197,,,"""Narco"" emotions: Affect and desensitization in social media during the Mexican Drug War",cp,Conference Paper,De Choudhury M.,60142654;60021726,Donald Bren School of Information &amp; Computer Sciences;Microsoft Research,Irvine;Redmond,United States;United States,3,"De Choudhury, Munmun;Monroy-Hernández, Andrés;Mark, Gloria",18433530100;23973552900;57203083029,60021726;60021726;60142654,2014-01-01,2014,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,3563-3572,"Social media platforms have emerged as prominent information sharing ecosystems in the context of a variety of recent crises, ranging from mass emergencies, to wars and political conflicts. We study affective responses in social media and how they might indicate desensitization to violence experienced in communities embroiled in an armed conflict. Specifically, we examine three established affect measures: Negative affect, activation, and dominance as observed on Twitter in relation to a number of statistics on protracted violence in four major cities afflicted by the Mexican Drug War. During a two year period (Aug 2010- Dec 2012), while violence was on the rise in these regions, our findings show a decline in negative emotional expression as well as a rise in emotional arousal and dominance in Twitter posts: Aspects known to be psychological markers of desensitization. We discuss the implications of our work for behavioral health, facilitating rehabilitation efforts in communities enmeshed in an acute and persistent urban warfare, and the impact on civic engagement.",Affect | Crisis informatics | Desensitization | Social media,69,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84993660496,10.1145/2568225.2568309,,,A study and toolkit for asynchronous programming in c#,cp,Conference Paper,Okur S.,60013402;60006288;60000745,Oregon State University;Delft University of Technology;University of Illinois Urbana-Champaign,Corvallis;Delft;Urbana,United States;Netherlands;United States,4,"Okur, Semih;Hartveld, David L.;Dig, Danny;Deursen, Arie Van",55532653900;57215879600;13404654100;7003969355,60000745;60006288;60006288;60013402,2014-05-31,31 May 2014,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,1,,1117-1127,"Asynchronous programming is in demand today, because responsiveness is increasingly important on all modern devices. Yet, we know little about how developers use asynchronous programming in practice. Without such knowledge, developers, researchers, language and library designers, and tool providers can make wrong assumptions. We present the first study that analyzes the usage of asynchronous programming in a large experiment. We analyzed 1378 open source Windows Phone (WP) apps, comprising 12M SLOC, produced by 3376 developers. Using this data, we answer 2 research questions about use and misuse of asynchronous constructs. Inspired by these findings, we developed (i) Asyncifier, an automated refactoring tool that converts callback-based asynchronous code to use async/await; (ii) Corrector, a tool that finds and corrects common misuses of async/await. Our empirical evaluation shows that these tools are (i) applicable and (ii) efficient. Developers accepted 314 patches generated by our tools.",asynchronous | C# | Program transformation,48,0,repositoryvor,Green,NSF,CCF-1213091,National Science Foundation,ICSE Software Engineering
2-s2.0-84937874785,,,,A<sup>∗</sup> sampling,cp,Conference Paper,Maddison C.J.,60021726;60016849,Microsoft Research;University of Toronto,Redmond;Toronto,United States;Canada,3,"Maddison, Chris J.;Tarlow, Daniel;Minka, Tom",56122100500;36840330700;6603659884,60016849;60021726;60021726,2014-01-01,2014,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,4,January,,3086-3094,"The problem of drawing samples from a discrete distribution can be converted into a discrete optimization problem [1, 2, 3, 4]. In this work, we show how sampling from a continuous distribution can be converted into an optimization problem over continuous space. Central to the method is a stochastic process recently described in mathematical statistics that we call the Gumbel process. We present a new construction of the Gumbel process and A∗ Sampling, a practical generic sampling algorithm that searches for the maximum of a Gumbel process using A∗ search. We analyze the correctness and convergence time of A∗ Sampling and demonstrate empirically that it makes more efficient use of bound and likelihood evaluations than the most closely related adaptive rejection sampling-based algorithms.",,190,0,,,NSERC,undefined,Natural Sciences and Engineering Research Council of Canada,NeurIPS Machine Learning
2-s2.0-84986905092,10.1145/2635868.2635885,,,AI: A lightweight system for tolerating concurrency bugs,cp,Conference Paper,Zhang M.,60032179;60025278;60000745,University of Wisconsin-Madison;Tsinghua University;University of Illinois Urbana-Champaign,Madison;Beijing;Urbana,United States;China;United States,6,"Zhang, Mingxing;Wu, Yongwei;Lu, Shan;Qi, Shanxiang;Ren, Jinglei;Zheng, Weimin",56733793100;8417507400;35199803400;35183892300;56168271500;24451602300,60025278;60025278;60032179;60000745;60025278;60025278,2014-11-16,16 November 2014,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100778601,,Conference Proceeding,16-21-November-2014,,,330-340,"Concurrency bugs are notoriously difficult to eradicate during software testing because of their non-deterministic nature. Moreover, fixing concurrency bugs is time-consuming and error-prone. Thus, tolerating concurrency bugs during production runs is an attractive complementary approach to bug detection and testing. Unfortunately, existing bug-tolerating tools are usually either 1) constrained in types of bugs they can handle or 2) requiring roll-back mechanism, which can hitherto not be fully achieved efficiently without hardware supports. This paper presents a novel program invariant, called Anticipating Invariant (AI), which can help anticipate bugs before any irreversible changes are made. Benefiting from this ability of anticipating bugs beforehand, our software-only system is able to forestall the failures with a simple thread stalling technique, which does not rely on execution roll-back and hence has good performance Experiments with 35 real-world concurrency bugs demonstrate that AI is capable of detecting and tolerating most types of concurrency bugs, including both atomicity and order violations. Two new bugs have been detected and confirmed by the corresponding developers. Performance evaluation with 6 representative parallel programs shows that AI incurs negligible overhead (< 1%) for many nontrivial desktop and server applications.",Bug tolerating | Concurrency bugs | Software reliability,14,0,repositoryam,Green,NSFC,2013zx01039-002-002,National Natural Science Foundation of China,FSE Software Engineering
2-s2.0-84902105483,10.1137/1.9781611973402.16,,,"An almost-linear-time algorithm for approximate max flow in undirected graphs, and its multicommodity generalizations",cp,Conference Paper,Kelner J.A.,60022195,Massachusetts Institute of Technology,Cambridge,United States,4,"Kelner, Jonathan A.;Lee, Yin Tat;Orecchia, Lorenzo;Sidford, Aaron",6603724487;55785529000;57204370654;55785590400,60022195;60022195;60022195;60022195,2014-01-01,2014,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,,,,217-226,"In this paper, we introduce a new framework for approximately solving flow problems in capacitated, undirected graphs and apply it to provide asymptotically faster algorithms for the maximum s-t flow and maximum concurrent multicommodity flow problems. For graphs with n vertices and m edges, it allows us to find an e-approximate maximum s-t flow in time O(m1+0(1)ε-2), improving on the previous best bound of Õ(mn1/3poly(ε -1)). Applying the same framework in the multicommodity setting solves a maximum concurrent multicommodity flow problem with k commodities in O(m1+0(1)ε-2k2) time, improving on the existing bound of Õ(m4/3poly(K,ε -1)). Our algorithms utilize several new technical tools that we believe may be of independent interest: We give a non-Euclidean generalization of gradient descent and provide bounds on its performance. Using this, we show how to reduce approximate maximum flow and maximum concurrent flow to oblivious routing. We define and provide an efficient construction of a new type of flow sparsifier. Previous sparsifier constructions approximately preserved the size of cuts and, by duality, the value of the maximum flows as well. However, they did not provide any direct way to route flows in the sparsifier G' back in the original graph G, leading to a longstanding gap between the efficacy of sparsification on flow and cut problems. We ameliorate this by constructing a sparsifier G' that can be embedded (very efficiently) into G with low congestion, allowing one to transfer flows from G' back to G. We give the first almost-linear-time construction of an O(m0(1) )-competitive oblivious routing scheme. No previous such algorithm ran in time better than Q(mn). By reducing the running time to almost-linear, our work provides a powerful new primitive for constructing very fast graph algorithms. The interested reader is referred to the full version of the paper [8] for a more complete treatment of these results. Copyright © 2014 by the Society for Industrial and Applied Mathematics.",,168,0,repositoryam,Green,,0843915,,SODA Theory
2-s2.0-84986916261,10.1145/2635868.2635876,,,Architecture challenges for internal software ecosystems: A large-scale industry case study,cp,Conference Paper,Schultis K.,60028673;60000765,Siemens AG;Friedrich-Alexander-Universität Erlangen-Nürnberg,Munich;Erlangen,Germany;Germany,3,"Schultis, Klaus Benedikt;Elsner, Christoph;Lohmann, Daniel",55892994700;35112916000;8936829100,60028673;60028673;60000765,2014-11-16,16 November 2014,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100778601,,Conference Proceeding,16-21-November-2014,,,542-552,"The idea of software ecosystems encourages organizations to open software projects for external businesses, governing the cross-organizational development by architectural and other measures. Even within a single organization, this paradigm can be of high value for large-scale decentralized software projects that involve various internal, yet self-contained organizational units. However, this intraorganizational decentralization causes architecture challenges that must be understood to reason about suitable architectural measures. We present an in-depth case study on collaboration and architecture challenges in two of these large-scale software projects at Siemens. We performed a total of 46 hours of semi-structured interviews with 17 leading software architects from all involved organizational units. Our major findings are: (1) three collaboration models on a continuum that ranges from high to low coupling, (2) a classification of architecture challenges, together with (3) a qualitative and quantitative exposure of the identified recurring issues along each collaboration model. Our study results provide valuable insights for both industry and academia: Practitioners that find themselves in one of the collaboration models can use empirical evidence on challenges to make informed decisions about counteractive measures. Researchers can focus their attention on challenges faced by practitioners to make software engineering more effective.",Case study | Collaboration | Decentralized software engineering | Software architecture | Software ecosystem | Software product line,19,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-84986917794,10.1145/2635868.2635929,,,Are mutants a valid substitute for real faults in software testing?,cp,Conference Paper,Just R.,60015481;60014171;60001881,University of Washington;University of Waterloo;The University of Sheffield,Seattle;Waterloo;Sheffield,United States;Canada;United Kingdom,6,"Just, René;Jalali, Darioush;Inozemtseva, Laura;Ernst, Michael D.;Holmes, Reid;Fraser, Gordon",24832785800;56880275200;55848984300;36916423000;56220448900;9247521200,60015481;60015481;60014171;60015481;60014171;60001881,2014-11-16,16 November 2014,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100778601,,Conference Proceeding,16-21-November-2014,,,654-665,"A good test suite is one that detects real faults. Because the set of faults in a program is usually unknowable, this definition is not useful to practitioners who are creating test suites, nor to researchers who are creating and evaluating tools that generate test suites. In place of real faults, testing research often uses mutants, which are artificial faults - each one a simple syntactic variation - that are systematically seeded throughout the program under test. Mutation analysis is appealing because large numbers of mutants can be automatically-generated and used to compensate for low quantities or the absence of known real faults. Unfortunately, there is little experimental evidence to support the use of mutants as a replacement for real faults. This paper investigates whether mutants are indeed a valid substitute for real faults, i.e., whether a test suite's ability to detect mutants is correlated with its ability to detect real faults that developers have fixed. Unlike prior studies, these investigations also explicitly consider the conflating effects of code coverage on the mutant detection rate. Our experiments used 357 real faults in 5 open-source applications that comprise a total of 321,000 lines of code. Furthermore, our experiments used both developer-written and automaticallygenerated test suites. The results show a statistically significant correlation between mutant detection and real fault detection, independently of code coverage. The results also give concrete suggestions on how to improve mutation analysis and reveal some inherent limitations.",Code coverage | Mutation analysis | Real faults | Test effectiveness,453,0,repositoryam,Green,DARPA,FA8750-12-2-0107,Defense Advanced Research Projects Agency,FSE Software Engineering
2-s2.0-85076880509,,,,Arrakis: The operating system is the control plane,cp,Conference Paper,Peter S.,60025858;60015481,ETH Zürich;University of Washington,Zurich;Seattle,Switzerland;United States,8,"Peter, Simon;Li, Jialin;Zhang, Irene;Ports, Dan R.K.;Woos, Doug;Krishnamurthy, Arvind;Anderson, Thomas;Roscoe, Timothy",56231946100;56429011800;56644434500;13009197800;54387610200;7005516119;35560665700;7003533216,60015481;60015481;60015481;60015481;60015481;60015481;60015481;60025858,2014-01-01,2014,"Proceedings of the 11th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2014",,21100962659,,Conference Proceeding,,,,1-16,"Recent device hardware trends enable a new approach to the design of network server operating systems. In a traditional operating system, the kernel mediates access to device hardware by server applications, to enforce process isolation as well as network and disk security. We have designed and implemented a new operating system, Arrakis, that splits the traditional role of the kernel in two. Applications have direct access to virtualized I/O devices, allowing most I/O operations to skip the kernel entirely, while the kernel is re-engineered to provide network and disk protection without kernel mediation of every operation. We describe the hardware and software changes needed to take advantage of this new abstraction, and we illustrate its power by showing improvements of 2-5× in latency and 9× in throughput for a popular persistent NoSQL store relative to a well-tuned Linux implementation.",,208,0,,,NSF,undefined,National Science Foundation,OSDI Operating Systems
2-s2.0-84937868714,,,,Asymmetric LSH (ALSH) for sublinear time Maximum Inner Product Search (MIPS),cp,Conference Paper,Shrivastava A.,60120529;60007776,Department of Computer Science;Cornell University,Piscataway;Ithaca,United States;United States,2,"Shrivastava, Anshumali;Li, Ping",55208300100;56558930800,60007776;60120529,2014-01-01,2014,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,3,January,,2321-2329,"We present the first provably sublinear time hashing algorithm for approximate Maximum Inner Product Search (MIPS). Searching with (un-normalized) inner product as the underlying similarity measure is a known difficult problem and finding hashing schemes for MIPS was considered hard. While the existing Locality Sensitive Hashing (LSH) framework is insufficient for solving MIPS, in this paper we extend the LSH framework to allow asymmetric hashing schemes. Our proposal is based on a key observation that the problem of finding maximum inner products, after independent asymmetric transformations, can be converted into the problem of approximate near neighbor search in classical settings. This key observation makes efficient sublinear hashing scheme for MIPS possible. Under the extended asymmetric LSH (ALSH) framework, this paper provides an example of explicit construction of provably fast hashing scheme for MIPS. Our proposed algorithm is simple and easy to implement. The proposed hashing scheme leads to significant computational savings over the two popular conventional LSH schemes: (i) Sign Random Projection (SRP) and (ii) hashing based on p-stable distributions for L<inf>2</inf> norm (L2LSH), in the collaborative filtering task of item recommendations on Netflix and Movielens (10M) datasets.",,293,0,,,,FA9550-13-1-0137,,NeurIPS Machine Learning
2-s2.0-84907324602,10.1145/2619239.2626306,,,Balancing accountability and privacy in the network,cp,Conference Paper,Naylor D.,60027950,Carnegie Mellon University,Pittsburgh,United States,3,"Naylor, David;Mukerjee, Matthew K.;Steenkiste, Peter",55363214600;36617523400;7003885160,60027950;60027950;60027950,2014-01-01,2014,SIGCOMM 2014 - Proceedings of the 2014 ACM Conference on Special Interest Group on Data Communication,,21100334869,,Conference Proceeding,,,,75-86,"Though most would agree that accountability and privacy are both valuable, today's Internet provides little support for either. Previous efforts have explored ways to offer stronger guarantees for one of the two, typically at the expense of the other; indeed, at first glance accountability and privacy appear mutually exclusive. At the center of the tussle is the source address: in an accountable Internet, source addresses undeniably link packets and senders so hosts can be punished for bad behavior. In a privacy-preserving Internet, source addresses are hidden as much as possible. In this paper, we argue that a balance is possible. We introduce the Accountable and Private Internet Protocol (APIP), which splits source addresses into two separate fields - an accountability address and a return address - and introduces independent mechanisms for managing each. Accountability addresses, rather than pointing to hosts, point to accountability delegates, which agree to vouch for packets on their clients' behalves, taking appropriate action when misbehavior is reported. With accountability handled by delegates, senders are now free to mask their return addresses; we discuss a few techniques for doing so. © 2014 ACM.",accountability | privacy | source address,26,1,repositoryvor,Green,,CNS-1040801,,SIGCOMM Networking
2-s2.0-84901812859,10.14778/2732951.2732959,,,Building efficient query engines in a highlevel language,cp,Conference Paper,Klonatos Y.,60028186;60027758,École Polytechnique Fédérale de Lausanne;Oracle Corporation,Lausanne;Austin,Switzerland;United States,4,"Klonatos, Yannis;Koch, Christoph;Rompf, Tiark;Chafi, Hassan",36170534800;56353512400;35107892800;12345392800,60028186;60028186;60028186-60027758;60027758,2014-01-01,2014,Proceedings of the VLDB Endowment,,21100199855,21508097,Conference Proceeding,7,10,,853-864,"In this paper we advocate that it is time for a radical rethinking of database systems design. Developers should be able to leverage high-level programming languages without having to pay a price in efficiency. To realize our vision of abstraction without regret, we present LegoBase, a query engine written in the high-level programming language Scala. The key technique to regain efficiency is to apply generative programming: the Scala code that constitutes the query engine, despite its high-level appearance, is actually a program generator that emits specialized, low-level C code. We show how the combination of high-level and generative programming allows to easily implement a wide spectrum of optimizations that are difficult to achieve with existing low-level query compilers, and how it can continuously optimize the query engine. We evaluate our approach with the TPC-H benchmark and show that: (a) with all optimizations enabled, our architecture significantly outperforms a commercial in-memory database system as well as an existing query compiler, (b) these performance improvements require programming just a few hundred lines of high-level code instead of complicated low-level code that is required by existing query compilers and, finally, that (c) the compilation overhead is low compared to the overall execution time, thus making our approach usable in practice for efficiently compiling query engines. © 2014 VLDB Endowment.",,93,0,repositoryam,Green,FP7,279804,Seventh Framework Programme,VLDB Databases
2-s2.0-84907356352,10.1145/2619239.2626316,,,CONGA: Distributed congestion-aware load balancing for datacenters,cp,Conference Paper,Alizadeh M.,60030003;60026532;60006191,Cisco Systems;Microsoft Corporation;Google LLC,San Jose;Redmond;Mountain View,United States;United States;United States,11,"Alizadeh, Mohammad;Edsall, Tom;Dharmapurikar, Sarang;Vaidyanathan, Ramanan;Chu, Kevin;Fingerhut, Andy;Lam, Vinh The;Matus, Francis;Pan, Rong;Yadav, Navindra;Varghese, George",55658057154;55949332800;7801627132;56368575100;56367208600;56367816700;57206272847;7003464673;56367370600;58596167400;15038288800,60030003;60030003;60030003;60030003;60030003;60030003;60006191;60030003;60030003;60030003;60026532,2014-01-01,2014,SIGCOMM 2014 - Proceedings of the 2014 ACM Conference on Special Interest Group on Data Communication,,21100334869,,Conference Proceeding,,,,503-514,"We present the design, implementation, and evaluation of CONGA, a network-based distributed congestion-aware load balancing mechanism for datacenters. CONGA exploits recent trends including the use of regular Clos topologies and overlays for network virtualization. It splits TCP flows into flowlets, estimates real-time congestion on fabric paths, and allocates flowlets to paths based on feedback from remote switches. This enables CONGA to efficiently balance load and seamlessly handle asymmetry, without requiring any TCP modifications. CONGA has been implemented in custom ASICs as part of a new datacenter fabric. In testbed experiments, CONGA has 5x better flow completion times than ECMP even with a single link failure and achieves 2-8x better throughput than MPTCP in Incast scenarios. Further, the Price of Anarchy for CONGA is provably small in Leaf-Spine topologies; hence CONGA is nearly as effective as a centralized scheduler while being able to react to congestion in microseconds. Our main thesis is that datacenter fabric load balancing is best done in the network, and requires global schemes such as CONGA to handle asymmetry. © 2014 ACM.",datacenter fabric | distributed | load balancing,411,0,,,,undefined,,SIGCOMM Networking
2-s2.0-84994099386,10.1145/2568225.2568229,,,Characterizing and detecting performance bugs for smartphone applications,cp,Conference Paper,Liu Y.,60033100;60008592,Nanjing University;Hong Kong University of Science and Technology,Nanjing;Hong Kong,China;Hong Kong,3,"Liu, Yepang;Xu, Chang;Cheung, Shing Chi",55540648000;56870592600;7202472792,60008592;60033100;60008592,2014-05-31,31 May 2014,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,1,,1013-1024,"Smartphone applications performance has a vital impact on user experience. However, many smartphone applications suffer from bugs that cause significant performance degradation, thereby losing their competitive edge. Unfortunately, people have little understanding of these performance bugs. They also lack effective techniques to fight with such bugs. To bridge this gap, we conducted a study of 70 real-world performance bugs collected from eight large-scale and popular Android applications. We studied the characteristics (e.g., bug types and how they manifested) of these bugs and identified their common patterns. These findings can support follow-up research on performance bug avoidance, testing, debugging and analysis for smartphone applications. To demonstrate the usefulness of our findings, we implemented a static code analyzer, PerfChecker, to detect our identified performance bug patterns. We experimentally evaluated PerfChecker by applying it to 29 popular Android applications, which comprise 1.1 million lines of Java code. PerfChecker successfully detected 126 matching instances of our performance bug patterns. Among them, 68 were quickly confirmed by developers as previously-unknown issues that affect application performance, and 20 were fixed soon afterwards by following our optimization suggestions.",Empirical study | performance bug | static analysis | testing,215,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84901594801,10.1145/2594291.2594334,,,Compiler validation via equivalence modulo inputs,cp,Conference Paper,Le V.,60153736,College of Engineering,Davis,United States,3,"Le, Vu;Afshari, Mehrdad;Su, Zhendong",55602744500;55497113000;7402248744,60153736;60153736;60153736,2014-01-01,2014,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,216-226,"We introduce equivalence modulo inputs (EMI), a simple, widely applicable methodology for validating optimizing compilers. Our key insight is to exploit the close interplay between (1) dynamically executing a program on some test inputs and (2) statically compiling the program to work on all possible inputs. Indeed, the test inputs induce a natural collection of the original program's EMI variants, which can help differentially test any compiler and specifically target the difficult-to-find miscompilations. To create a practical implementation of EMI for validating C compilers, we profile a program's test executions and stochastically prune its unexecuted code. Our extensive testing in eleven months has led to 147 confirmed, unique bug reports for GCC and LLVM alone. The majority of those bugs are miscompilations, and more than 100 have already been fixed. Beyond testing compilers, EMI can be adapted to validate program transformation and analysis systems in general. This work opens up this exciting, new direction. Copyright © 2014 ACM.",Automated testing | Compiler testing | Equivalent program variants | Miscompilation,208,0,repositoryam,Green,,0917392,,PLDI Programming Languages
2-s2.0-84955595871,10.1145/2637364.2591987,,,Concave switching in single and multihop networks,cp,Conference Paper,Walton N.,60002483,Universiteit van Amsterdam,Amsterdam,Netherlands,1,"Walton, Neil",35091640800,60002483,2014-06-20,20 June 2014,Performance Evaluation Review,01635999,26742,,Conference Proceeding,42,1,,139-151,"Switched queueing networks model wireless networks, input queued switches and numerous other networked communications systems. For single-hop networks, we consider a (ff; g)-switch policy which combines the MaxWeight policies with bandwidth sharing networks - a further well studied model of Internet congestion. We prove the maximum stability property for this class of randomized policies. Thus these policies have the same first order behavior as the MaxWeight policies. However, for multihop networks some of these generalized polices address a number of critical weakness of the MaxWeight/BackPressure policies. For multihop networks with fixed routing, we consider the Proportional Scheduler (or (1,log)-policy). In this setting, the BackPressure policy is maximum stable, but must maintain a queue for every route-destination, which typically grows rapidly with a network's size. However, this proportionally fair policy only needs to maintain a queue for each outgoing link, which is typically bounded in number. As is common with Internet routing, by maintaining per-link queueing each node only needs to know the next hop for each packet and not its entire route. Further, in contrast to BackPressure, the Proportional Scheduler does not compare downstream queue lengths to determine weights, only local link information is required. This leads to greater potential for decomposed implementations of the policy. Through a reduction argument and an entropy argument, we demonstrate that, whilst maintaining substantially less queueing overhead, the Proportional Scheduler achieves maximum throughput stability.",BackPressure | Fluid limit | Maximum stable | MaxWeight | Proportional fairness | Stability | Switch network,10,0,repositoryam,Green,,undefined,,SIGMETRICS Performance
2-s2.0-84900451190,10.1145/2556288.2557130,,,Consumed endurance: A metric to quantify arm fatigue of mid-air interactions,cp,Conference Paper,Hincapié-Ramos J.D.,60009697,University of Manitoba,Winnipeg,Canada,4,"Hincapié-Ramos, Juan David;Guo, Xiang;Moghadasian, Paymahn;Irani, Pourang",36095742000;56157190700;55863591000;6603711401,60009697;60009697;60009697;60009697,2014-01-01,2014,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1063-1072,"Mid-air interactions are prone to fatigue and lead to a feeling of heaviness in the upper limbs, a condition casually termed as the gorilla-arm effect. Designers have often associated limitations of their mid-air interactions with arm fatigue, but do not possess a quantitative method to assess and therefore mitigate it. In this paper we propose a novel metric, Consumed Endurance (CE), derived from the biomechanical structure of the upper arm and aimed at characterizing the gorilla-arm effect. We present a method to capture CE in a non-intrusive manner using an off-the-shelf camera-based skeleton tracking system, and demonstrate that CE correlates strongly with the Borg CR10 scale of perceived exertion. We show how designers can use CE as a complementary metric for evaluating existing and designing novel mid-air interactions, including tasks with repetitive input such as mid-air text-entry. Finally, we propose a series of guidelines for the design of fatigue-efficient mid-air interfaces.",Consumed endurance | Endurance | Gorilla-arm | Mid-air interactions | Mid-air text-entry | SEATO mid-air keyboard,294,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84994086611,10.1145/2568225.2568271,,,Coverage is not strongly correlated with test suite effectiveness,cp,Conference Paper,Inozemtseva L.,60014171,University of Waterloo,Waterloo,Canada,2,"Inozemtseva, Laura;Holmes, Reid",55848984300;56220448900,60014171;60014171,2014-05-31,31 May 2014,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,1,,435-445,"The coverage of a test suite is often used as a proxy for its ability to detect faults. However, previous studies that investigated the correlation between code coverage and test suite effectiveness have failed to reach a consensus about the nature and strength of the relationship between these test suite characteristics. Moreover, many of the studies were done with small or synthetic programs, making it unclear whether their results generalize to larger programs, and some of the studies did not account for the confounding influence of test suite size. In addition, most of the studies were done with adequate suites, which are are rare in practice, so the results may not generalize to typical test suites. We have extended these studies by evaluating the relationship between test suite size, coverage, and effectiveness for large Java programs. Our study is the largest to date in the literature: we generated 31,000 test suites for five systems consisting of up to 724,000 lines of source code. We measured the statement coverage, decision coverage, and modified condition coverage of these suites and used mutation testing to evaluate their fault detection effectiveness. We found that there is a low to moderate correlation between coverage and effectiveness when the number of test cases in the suite is controlled for. In addition, we found that stronger forms of coverage do not provide greater insight into the effectiveness of the suite. Our results suggest that coverage, while useful for identifying under-tested parts of a program, should not be used as a quality target because it is not a good indicator of test suite effectiveness.",Coverage | test suite effectiveness | test suite quality,302,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84994106753,10.1145/2568225.2568226,,,"Cowboys, ankle sprains, and keepers of quality: How is video game development different from software development?",cp,Conference Paper,Murphy-Hill E.,60021726;60004923,Microsoft Research;NC State University,Redmond;Raleigh,United States;United States,3,"Murphy-Hill, Emerson;Zimmermann, Thomas;Nagappan, Nachiappan",16307910100;16308551800;8261920700,60004923;60021726;60021726,2014-05-31,31 May 2014,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,1,,1-11,"Video games make up an important part of the software industry, yet the software engineering community rarely studies video games. This imbalance is a problem if video game development differs from general software development, as some game experts suggest. In this paper we describe a study with 14 interviewees and 364 survey respondents. The study elicited substantial differences between video game development and other software development. For example, in game development, cowboy coders are necessary to cope with the continuous interplay between creative desires and technical constraints. Consequently, game developers are hesitant to use automated testing because of these tests rapid obsolescence in the face of shifting creative desires of game designers. These differences between game and non-game development have implications for research, industry, and practice. For instance, as a starting point for impacting game development, researchers could create testing tools that enable game developers to create tests that assert flexible behavior with little up-front investment.",games | practices | Software engineering,132,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-84937499639,10.1145/2661829.2661910,,,Cross-device search,cp,Conference Paper,Montañez G.D.,60027950;60026532;60021726,Carnegie Mellon University;Microsoft Corporation;Microsoft Research,Pittsburgh;Redmond;Redmond,United States;United States;United States,3,"Montañez, George D.;White, Ryen W.;Huang, Xiao",36096960800;7501422012;55604726200,60027950;60021726;60026532,2014-11-03,3 November 2014,CIKM 2014 - Proceedings of the 2014 ACM International Conference on Information and Knowledge Management,,21100399714,,Conference Proceeding,,,,1669-1678,"Ownership and use of multiple devices such as desktop computers, smartphones, and tablets is increasing rapidly. Search is popular and people often perform search tasks that span device boundaries. Understanding how these devices are used and how people transition between them during information seeking is essential in developing search support for a multi-device world. In this paper, we study search across devices and propose models to predict aspects of cross-device search transitions. We characterize multi-device search across four device types, including aspects of search behavior on each device (e.g., topics of interest) and characteristics of device transitions. Building on the characterization, we learn models to predict various aspects of cross-device search, including the next device used for search. This enables many applications. For example, accurately forecasting the device used for the next query lets search engines proactively retrieve device-appropriate content (e.g., short documents for smartphones), while knowledge of the current device combined with device-specific topical interest models may assist in better query-sense disambiguation.",Cross-device search | Game console search | Multi-device user,42,0,,,NSF,1207759,National Science Foundation,CIKM Knowledge Management
2-s2.0-84900434886,10.1145/2556288.2557178,,,"Designing for slowness, anticipation and re-visitation: A long term field study of the photobox",cp,Conference Paper,Odom W.,60098463;60027950;60015138;60006222,Microsoft Research Cambridge;Carnegie Mellon University;University of Nottingham;Newcastle University,Cambridge;Pittsburgh;Nottingham;Newcastle,United Kingdom;United States;United Kingdom;United Kingdom,8,"Odom, William;Sellen, Abigail;Banks, Richard;Kirk, David;Regan, Tim;Selby, Mark;Forlizzi, Jodi;Zimmerman, John",6701770018;7004040846;36913193200;27169862100;36091690800;57198344511;6602845027;7401859828,60027950;60098463;60098463;60006222;60098463;60015138;60027950;60027950,2014-01-01,2014,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1961-1970,"We describe the design, implementation and deployment of Photobox, a domestic technology that prints four or five randomly selected photos from the owner's Flickr collection at random intervals each month. We deployed Photobox in three homes for fourteen months to explore how the slow pace at which it operates could support experiences of anticipation and re-visitation of the past. Findings reveal changes in attitude toward the device, from frustration to eventual acceptance. Participants drew on the photos to reflect on past life events and reactions indicated a renewed interest for their Flickr collection. Photobox also provoked reflection on technology in and around the home. These findings suggest several opportunities, such as designing for anticipation, better supporting reflection on the past, and, more generally, expanding the slow technology research program within the HCI community. Copyright © ACM.",Design | Home | Interaction Design | Slow Technology,141,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84900392244,10.1145/2556288.2556955,,,Duet: Exploring joint interactions on a smart phone and a smart watch,cp,Conference Paper,Chen X.A.,60136640;60074802;60016849,School of Computer Science;Autodesk Inc.;University of Toronto,Pittsburgh;San Francisco;Toronto,United States;United States;Canada,4,"Chen, Xiang Anthony;Grossman, Tovi;Wigdor, Daniel;Fitzmaurice, George",55146512600;7003520062;6507569914;7005241818,60074802-60136640;60074802;60016849;60074802,2014-01-01,2014,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,159-168,"The emergence of smart devices (e.g., smart watches and smart eyewear) is redefining mobile interaction from the solo performance of a smart phone, to a symphony of multiple devices. In this paper, we present Duet- an interactive system that explores a design space of interactions between a smart phone and a smart watch. Based on the devices' spatial configurations, Duet coordinates their motion and touch input, and extends their visual and tactile output to one another. This transforms the watch into an active element that enhances a wide range of phone-based interactive tasks, and enables a new class of multi-device gestures and sensing techniques. A technical evaluation shows the accuracy of these gestures and sensing techniques, and a subjective study on Duet provides insights, observations, and guidance for future work.",Duet | Joint interaction | Smart phone | Smart watch,143,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84900385835,10.1145/2556288.2557020,,,Effects of display size and navigation type on a classification task,cp,Conference Paper,Liu C.,60106017;60072950;60013373,Université Paris-Saclay;Laboratoire Traitement et Communication de l'Information;INRIA Institut National de Recherche en Informatique et en Automatique,Gif-sur-Yvette;Palaiseau;Le Chesnay,France;France;France,5,"Liu, Can;Chapuis, Olivier;Beaudouin-Lafon, Michel;Lecolinet, Eric;Mackay, Wendy",55247039300;55919438800;6602828964;6602267161;7102699682,60106017-60013373-60072950;60106017-60013373;60106017-60013373;60072950;60106017-60013373,2014-01-01,2014,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,4147-4156,"The advent of ultra-high resolution wall-size displays and their use for complex tasks require a more systematic analysis and deeper understanding of their advantages and drawbacks compared with desktop monitors. While previous work has mostly addressed search, visualization and sense-making tasks, we have designed an abstract classification task that involves explicit data manipulation. Based on our observations of real uses of a wall display, this task represents a large category of applications. We report on a controlled experiment that uses this task to compare physical navigation in front of a wall-size display with virtual navigation using panand- zoom on the desktop. Our main finding is a robust interaction effect between display type and task difficulty: While the desktop can be faster than the wall for simple tasks, the wall gains a sizable advantage as the task becomes more difficult. A follow-up study shows that other desktop techniques (overview+detail, lens) do not perform better than pan-andzoom and are therefore slower than the wall for difficult tasks. Copyright © 2014 ACM.",Classification task | Lenses | Pan-and-zoom | Physical navigation | Wall-size display,66,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84909632662,10.1145/2566486.2568017,,,Efficient estimation for high similarities using odd sketches,cp,Conference Paper,Mitzenmacher M.,60018567;60009982,IT-Universitetet i København;Harvard University,Copenhagen;Cambridge,Denmark;United States,3,"Mitzenmacher, Michael;Pagh, Rasmus;Pham, Ninh",56277534400;6602880411;36158489500,60009982;60018567;60018567,2014-04-07,7 April 2014,WWW 2014 - Proceedings of the 23rd International Conference on World Wide Web,,21100344984,,Conference Proceeding,,,,109-118,"Estimating set similarity is a central problem in many computer applications. In this paper we introduce the Odd Sketch, a compact binary sketch for estimating the Jaccard similarity of two sets. The exclusive-or of two sketches equals the sketch of the symmetric difference of the two sets. This means that Odd Sketches provide a highly space-efficient estimator for sets of high similarity, which is relevant in applications such as web duplicate detection, collaborative filtering, and association rule learning. The method extends to weighted Jaccard similarity, relevant e.g. for TFIDF vector comparison. We present a theoretical analysis of the quality of estimation to guarantee the reliability of Odd Sketch-based estimators. Our experiments confirm this efficiency, and demonstrate the efficiency of Odd Sketches in comparison with b-bit minwise hashing schemes on association rule learning and web duplicate detection tasks. Copyright is held by the International World Wide Web Conference Committee (IW3C2).",Bloom filters | Minwise hashing | Set similarity,49,0,repositoryam,Green,,undefined,,WWW World Wide Web
2-s2.0-84900417685,10.1145/2556288.2557132,,,"Emerging sites of HCI innovation: Hackerspaces, hardware startups &amp; incubators",cp,Conference Paper,Lindtner S.,60142654;60009860,Donald Bren School of Information &amp; Computer Sciences;Fudan University,Irvine;Shanghai,United States;China,3,"Lindtner, Silvia;Hertz, Garnet;Dourish, Paul",24778286400;36195495200;7003544364,60009860-60142654;60142654;60142654,2014-01-01,2014,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,439-448,"In this paper, we discuss how a flourishing scene of DIY makers is turning visions of tangible and ubiquitous computing into products. Drawing on long-term multi-sited ethnographic research and active participation in DIY making, we provide insights into the social, material, and economic processes that undergird this transition from prototypes to products. The contribution of this paper is three-fold. First, we show how DIY maker practice is illustrative of a broader ""return to"" and interest in physical materials. This has implications for HCI research that investigates questions of materiality. Second, we shed light on how hackerspaces and hardware start-ups are experimenting with new models of manufacturing and entrepreneurship. We argue that we have to take seriously these maker practices, not just as hobbyist or leisure practice, but as a professionalizing field functioning in parallel to research and industry labs. Finally, we end with reflections on the role of HCI researchers and designers as DIY making emerges as a site of HCI innovation. We argue that HCI is positioned to provide critical reflection, paired with a sensibility for materials, tools and design methods.",China | Critical making | DIY | Hackerspace | IoT | Make | Making cultures | Manufacturing | Materiality,172,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84994164461,10.1145/2568225.2568293,,,Enhancing symbolic execution with veritesting,cp,Conference Paper,Avgerinos T.,60027950,Carnegie Mellon University,Pittsburgh,United States,4,"Avgerinos, Thanassis;Rebert, Alexandre;Cha, Sang Kil;Brumley, David",35182448000;55751473800;36668251100;36023497900,60027950;60027950;60027950;60027950,2014-05-31,31 May 2014,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,1,,1083-1094,"We present MergePoint, a new binary-only symbolic execution system for large-scale and fully unassisted testing of commodity off-the-shelf (COTS) software. MergePoint introduces veritesting, a new technique that employs static symbolic execution to amplify the effect of dynamic symbolic execution. Veritesting allows MergePoint to find twice as many bugs, explore orders of magnitude more paths, and achieve higher code coverage than previous dynamic symbolic execution systems. MergePoint is currently running daily on a 100 node cluster analyzing 33,248 Linux binaries; has generated more than 15 billion SMT queries, 200 million test cases, 2,347,420 crashes, and found 11,687 bugs in 4,379 distinct applications.",Symbolic Execution | Verification | Veritesting,160,0,,,NSF,1228765,National Science Foundation,ICSE Software Engineering
2-s2.0-84900403664,10.1145/2556288.2557181,,,Estimating the social costs of friend sourcing,cp,Conference Paper,Rzeszotarski J.M.,60136640;60021726,School of Computer Science;Microsoft Research,Pittsburgh;Redmond,United States;United States,2,"Rzeszotarski, Jeffrey M.;Morris, Meredith Ringel",35734782600;8619759600,60021726-60136640;60021726,2014-01-01,2014,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,2735-2744,"Every day users of social networking services ask their followers and friends millions of questions. These friendsourced questions not only provide informational benefits, but also may reinforce social bonds. However, there is a limit to how much a person may want to friendsource. They may be uncomfortable asking questions that are too private, might not want to expend others' time or effort, or may feel as though they have already accrued too many social debts. These perceived social costs limit the potential benefits of friendsourcing. In this paper we explore the perceived social costs of friendsourcing on Twitter via a monetary choice. We develop a model of how users value the attention and effort of their social network while friendsourcing, compare and contrast it with paid question answering in a crowdsourced labor market, and provide future design considerations for better supporting friendsourcing.",Crowdsourcing | Friendsourcing | SNS Q&amp;A | Twitter,29,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84912020129,10.1145/2642918.2647409,,,Expert crowdsourcing with flash teams,cp,Conference Paper,Retelny D.,60027165;60012708,University of Rochester;Stanford University,Rochester;Stanford,United States;United States,9,"Retelny, Daniela;Robaszkiewicz, Sébastien;To, Alexandra;Lasecki, Walter;Patel, Jay;Rahmati, Negar;Doshi, Tulsee;Valentine, Melissa;Bernstein, Michael S.",36182232500;55481289500;57188762857;54383728900;57210411624;56414763900;55890972200;24765781400;57193014048,60012708;60012708;60012708;60027165;60012708;60012708;60012708;60012708;60012708,2014-10-05,5 October 2014,UIST 2014 - Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology,,21100348535,,Conference Proceeding,,,,75-86,"We introduce flash teams, a framework for dynamically assembling and managing paid experts from the crowd. Flash teams advance a vision of expert crowd work that accomplishes complex, interdependent goals such as engineering and design. These teams consist of sequences of linked modular tasks and handoffs that can be computationally managed. Interactive systems reason about and manipulate these teams'structures: for example, flash teams can be recombined to form larger organizations and authored automatically in response to a user's request. Flash teams can also hire more people elastically in reaction to task needs, and pipeline intermediate output to accelerate completion times. To enable flash teams, we present Foundry, an end-user authoring platform and runtime manager. Foundry allows users to author modular tasks, then manages teams through handoffs of intermediate work. We demonstrate that Foundry and flash teams enable crowdsourcing of a broad class of goals including design prototyping, course development, and film animation, in half the work time of traditional self-managed teams.",Crowdsourcing | Expert crowd work | Flash teams,171,0,,,CISE,1351131,Directorate for Computer and Information Science and Engineering,UIST User Interface
2-s2.0-84906921986,10.3115/v1/p14-1129,,,Fast and robust neural network joint models for statistical machine translation,cp,Conference Paper,Devlin J.,60011761,BBN Technologies,Cambridge,United States,6,"Devlin, Jacob;Zbib, Rabih;Huang, Zhongqiang;Lamar, Thomas;Schwartz, Richard;Makhoul, John",54879967400;6507259855;14026761500;56349931000;7404170783;7007128199,60011761;60011761;60011761;60011761;60011761;60011761,2014-01-01,2014,"52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014 - Proceedings of the Conference",,21100332452,,Conference Proceeding,1,,,1370-1380,"Recent work has shown success in using neural network language models (NNLMs) as features in MT systems. Here, we present a novel formulation for a neural network joint model (NNJM), which augments the NNLM with a source context window. Our model is purely lexicalized and can be integrated into any MT decoder. We also present several variations of the NNJM which provide significant additive improvements. Although the model is quite simple, it yields strong empirical results. On the NIST OpenMT12 Arabic-English condition, the NNJM features produce a gain of +3.0 BLEU on top of a powerful, featurerich baseline which already includes a target-only NNLM. The NNJM features also produce a gain of +6.3 BLEU on top of a simpler baseline equivalent to Chiang's (2007) original Hiero implementation. Additionally, we describe two novel techniques for overcoming the historically high cost of using NNLM-style models in MT decoding. These techniques speed up NNJM computation by a factor of 10,000x, making the model as fast as a standard back-off LM. © 2014 Association for Computational Linguistics.",,369,1,repositoryam,Green,,undefined,,ACL Natural Language Processing
2-s2.0-84900435930,10.1145/2556288.2557196,,,Human values in curating a human rights media archive,cp,Conference Paper,Durrant A.,60015138;60006222,University of Nottingham;Newcastle University,Nottingham;Newcastle,United Kingdom;United Kingdom,3,"Durrant, Abigail;Kirk, David S.;Reeves, Stuart",23024725800;27169862100;7102635630,60006222;60006222;60015138,2014-01-01,2014,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,2685-2694,"Cultural institutions, such as museums, often curate politically and ethically sensitive materials. Increasingly, Internet-enabled, digital technology intersects with these curatorial practices offering new opportunities for public and scholarly engagement. We report on a case study of human rights media archiving at a genocide memorial centre in Rwanda, motivated by our interests in ICT support to memorialisation practices. Through an analysis of our discussions with staff about their work, we report on how accounts of the Rwandan Genocide are being captured and curated to support the centre's humanitarian agenda and associated values. We identify transferable curatorial concerns for human rights media communication amongst scholarly networks and public audiences worldwide, elucidating interaction design challenges for supportive ICT and contributing to HCI discourses on Value Sensitive Design and cultural engagement with sensitive materials.",Curation | Genocide | Human Rights Media | Memorial | Rwanda | Value Sensitive Design,16,0,repositoryam,Green,EPSRC,EP/G065802/1,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-84996437051,,,,IX: A protected dataplane operating system for high throughput and low latency,cp,Conference Paper,Belay A.,60028186;60012708,École Polytechnique Fédérale de Lausanne;Stanford University,Lausanne;Stanford,Switzerland;United States,6,"Belay, Adam;Prekas, George;Klimovic, Ana;Grossman, Samuel;Kozyrakis, Christos;Bugnion, Edouard",36185141400;35345489700;56039431800;56839851600;6602525246;6602775973,60012708;60028186;60012708;60012708;60012708;60028186,2014-01-01,2014,"Proceedings of the 11th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2014",,21100939705,,Conference Proceeding,,,,49-65,"The conventional wisdom is that aggressive networking requirements, such as high packet rates for small messages and microsecond-scale tail latency, are best addressed outside the kernel, in a user-level networking stack. We present IX, a dataplane operating system that provides high I/O performance, while maintaining the key advantage of strong protection offered by existing kernels. IX uses hardware virtualization to separate management and scheduling functions of the kernel (control plane) from network processing (dataplane). The dataplane architecture builds upon a native, zero-copy API and optimizes for both bandwidth and latency by dedicating hardware threads and networking queues to dataplane instances, processing bounded batches of packets to completion, and by eliminating coherence traffic and multi-core synchronization. We demonstrate that IX outperforms Linux and state-of-the-art, user-space network stacks significantly in both throughput and end-to-end latency. Moreover, IX improves the throughput of a widely deployed, key-value store by up to 3.6× and reduces tail latency by more than 2×.",,294,0,,,,undefined,Google,OSDI Operating Systems
2-s2.0-84994140281,10.1145/2568225.2568247,,,Improving automated source code summarization via an eye-tracking study of programmers,cp,Conference Paper,Rodeghero P.,60155914,College of Engineering,Notre Dame,United States,5,"Rodeghero, Paige;McMillan, Collin;McBurney, Paul W.;Bosch, Nigel;D'Mello, Sidney",57188553085;35094348900;57204251886;55790622900;14053463100,60155914;60155914;60155914;60155914;60155914,2014-05-31,31 May 2014,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,1,,390-401,"Source Code Summarization is an emerging technology for automatically generating brief descriptions of code. Current summarization techniques work by selecting a subset of the statements and keywords from the code, and then including information from those statements and keywords in the summary. The quality of the summary depends heavily on the process of selecting the subset: a high-quality selection would contain the same statements and keywords that a programmer would choose. Unfortunately, little evidence exists about the statements and keywords that programmers view as important when they summarize source code. In this paper, we present an eye-tracking study of 10 professional Java programmers in which the programmers read Java methods and wrote English summaries of those methods. We apply the findings to build a novel summarization tool. Then, we evaluate this tool and provide evidence to support the development of source code summarization systems.",program comprehension | source code summaries,146,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84901593820,10.1145/2594291.2594332,,,Improving javascript performance by deconstructing the type system,cp,Conference Paper,Ahn W.,60000745,University of Illinois Urbana-Champaign,Urbana,United States,5,"Ahn, Wonsun;Choi, Jiho;Shull, Thomas;Garzarán, María J.;Torrellas, Josep",15064019700;56184413100;57212198351;6506964205;7003395953,60000745;60000745;60000745;60000745;60000745,2014-01-01,2014,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,496-507,"Increased focus on JavaScript performance has resulted in vast performance improvements for many benchmarks. How- ever, for actual code used in websites, the attained improve- ments often lag far behind those for popular benchmarks. This paper shows that the main reason behind this short- fall is how the compiler understands types. JavaScript has no concept of types, but the compiler assigns types to ob- jects anyway for ease of code generation. We examine the way that the Chrome V8 compiler defines types, and identify two design decisions that are the main reasons for the lack of improvement: (1) the inherited prototype object is part of the current object's type definition, and (2) method bind- ings are also part of the type definition. These requirements make types very unpredictable, which hinders type special- ization by the compiler. Hence, we modify V8 to remove these requirements, and use it to compile the JavaScript code assembled by JSBench from real websites. On average, we reduce the execution time of JSBench by 36%, and the dynamic instruction count by 49%. Copyright © 2014 ACM.",Dynamic typing | Hidden class | Inline caching | Javascript | Prototype | Scripting language | Type spe- cialization,22,0,repositoryvor,Green,,undefined,,PLDI Programming Languages
2-s2.0-84904439242,10.1109/INFOCOM.2014.6848190,,,Joint static and dynamic traffic scheduling in data center networks,cp,Conference Paper,Cao Z.,60021784;60021378,New York University;Nokia Bell Labs,New York;Murray,United States;United States,3,"Cao, Zizhong;Kodialam, Murali;Lakshman, T. V.",55531964600;7003982818;7004712165,60021784;60021378;60021378,2014-01-01,2014,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,,,6848190,2445-2453,"The advent and continued growth of large data centers has led to much interest in switch architectures that can economically meet the high capacities needed for interconnecting the thousands of servers in these data centers. Various multilayer architectures employing thousands of switches have been proposed in the literature. We make use of the observation that the traffic in a data center is a mixture of relatively static and rapidly fluctuating components, and develop a combined scheduler for both these components using a generalization of the load-balanced scheduler. The presence of the known static component introduces asymmetries in the ingress-egress capacities, which preclude the use of a load-balanced scheduler as is. We generalize the load-balanced scheduler and also incorporate an opportunistic scheduler which sends traffic on a direct path when feasible to enhance the overall switch throughput. Our evaluations show that this scheduler works very well despite avoiding the use of a central scheduler for making packet-by-packet scheduling decisions. © 2014 IEEE.",,15,0,,,,undefined,,INFOCOM Networking
2-s2.0-84986880422,10.1145/2635868.2635883,,,Learning NATURAL coding conventions,cp,Conference Paper,Allamanis M.,60027272;60022148;60021726,The University of Edinburgh;University College London;Microsoft Research,Edinburgh;London;Redmond,United Kingdom;United Kingdom;United States,4,"Allamanis, Miltiadis;Barr, Earl T.;Bird, Christian;Sutton, Charles",39361040300;7005643860;17433640400;57204256039,60022148;60027272;60021726;60022148,2014-11-16,16 November 2014,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100778601,,Conference Proceeding,16-21-November-2014,,,281-293,"Every programmer has a characteristic style, ranging from preferences about identifier naming to preferences about object relationships and design patterns. Coding conventions define a consistent syntactic style, fostering readability and hence maintainability. When collaborating, programmers strive to obey a project's coding conventions. However, one third of reviews of changes contain feedback about coding conventions, indicating that programmers do not always follow them and that project members care deeply about adherence. Unfortunately, programmers are often unaware of coding conventions because inferring them requires a global view, one that aggregates the many local decisions programmers make and identifies emergent consensus on style. We present NATURALIZE, a framework that learns the style of a codebase, and suggests revisions to improve stylistic consistency. NATURALIZE builds on recent work in applying statistical natural language processing to source code. We apply NATURALIZE to suggest natural identifier names and formatting conventions. We present four tools focused on ensuring natural code during development and release management, including code review. NATURALIZE achieves 94% accuracy in its top suggestions for identifier names. We used NATURALIZE to generate 18 patches for 5 open source projects: 14 were accepted.",Coding conventions | Naturalness of software,266,0,repositoryam,Green,EPSRC,EP/K024043/1,Microsoft Research,FSE Software Engineering
2-s2.0-84901810315,10.14778/2732951.2732953,,,M4: A visualization-oriented time series data aggregation,cp,Conference Paper,Jugel U.,60072347;60011604,SAP SE;Technische Universität Berlin,Walldorf;Berlin,Germany;Germany,4,"Jugel, Uwe;Jerzak, Zbigniew;Hackenbroich, Gregor;Markl, Volker",35071509100;19337812300;7003713140;6602853794,60072347;60072347;60072347;60011604,2014-01-01,2014,Proceedings of the VLDB Endowment,,21100199855,21508097,Conference Proceeding,7,10,,797-808,"Visual analysis of high-volume time series data is ubiquitous in many industries, including nance, banking, and discrete manufacturing. Contemporary, RDBMS-based systems for visualization of high-volume time series data have diffculty to cope with the hard latency requirements and high ingestion rates of interactive visualizations. Existing solutions for lowering the volume of time series data disregard the semantics of visualizations and result in visualization errors. In this work, we introduce M4, an aggregation-based time series dimensionality reduction technique that provides errorfree visualizations at high data reduction rates. Focusing on line charts, as the predominant form of time series visualization, we explain in detail the drawbacks of existing data reduction techniques and how our approach outperforms state of the art, by respecting the process of line rasterization. We describe how to incorporate aggregation-based dimensionality reduction at the query level in a visualizationdriven query rewriting system. Our approach is generic and applicable to any visualization system that uses an RDBMS as data source. Using real world data sets from high tech manufacturing, stock markets, and sports analytics domains we demonstrate that our visualization-oriented data aggregation can reduce data volumes by up to two orders of magnitude, while preserving perfect visualizations. © 2014 VLDB Endowment.",Dimensionality reduction | Line rasterization | Query rewriting | Relational databases,67,0,,,,undefined,,VLDB Databases
2-s2.0-84900393733,10.1145/2556288.2557380,,,Making sustainability sustainable: Challenges in the design of eco-interaction technologies,cp,Conference Paper,Yang R.,60027950;60025778,"Carnegie Mellon University;University of Michigan, Ann Arbor",Pittsburgh;Ann Arbor,United States;United States,3,"Yang, Rayoung;Newman, Mark W.;Forlizzi, Jodi",39062612700;7401941475;6602845027,60025778;60025778;60027950,2014-01-01,2014,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,823-832,"The smart home is here. One area where smart home devices promise to deliver great benefits is in the control of home heating, ventilation, and cooling (HVAC) systems. In this paper, we seek to inform the design of future heating and cooling systems by investigating users' experiences with the Nest Learning Thermostat, a commercially available smart home device. We conducted a qualitative study where we compared people's interactions with conventional thermostats with interactions with the Nest. A key finding was that the Nest impacted users' pattern of HVAC control, but only for a while, and caused new problems in unrealized energy savings. In leveraging these findings, we create a set of design implications for Eco- Interaction, the design of features and human-system interactions with the goal of saving energy.",Eco-interaction | Smart Home | Sustainability | Thermostat,72,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84904317928,10.1145/2588555.2593678,,,Materialization optimizations for feature selection workloads,cp,Conference Paper,Zhang C.,60032179;60012708,University of Wisconsin-Madison;Stanford University,Madison;Stanford,United States;United States,3,"Zhang, Ce;Kumar, Arun;Ré, Christopher",55703849700;57214420149;10739281400,60032179-60012708;60032179;60012708,2014-01-01,2014,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,265-276,"There is an arms race in the data management industry to support analytics, in which one critical step is feature selection, the process of selecting a feature set that will be used to build a statistical model. Analytics is one of the biggest topics in data management, and feature selection is widely regarded as the most critical step of analytics; thus, we argue that managing the feature selection process is a pressing data management challenge. We study this challenge by describing a feature-selection language and a supporting prototype system that builds on top of current industrial, R-integration layers. From our interactions with analysts, we learned that feature selection is an interactive, human-in-the-loop process, which means that feature selection workloads are rife with reuse opportunities. Thus, we study how to materialize portions of this computation using not only classical database materialization optimizations but also methods that have not previously been used in database optimization, including structural decomposition methods (like QR factorization) and warmstart. These new methods have no analog in traditional SQL systems, but they may be interesting for array and scientific database applications. On a diverse set of data sets and programs, we find that traditional database-style approaches that ignore these new opportunities are more than two orders of magnitude slower than an optimal plan in this new tradeoff space across multiple R-backends. Furthermore, we show that it is possible to build a simple cost-based optimizer to automatically select a near-optimal execution plan for feature selection. © 2014 ACM.",Feature selection | Materialization | Statistical analytics,54,0,,,,undefined,,SIGMOD Databases
2-s2.0-84900428602,10.1145/2556288.2557090,,,MixFab: A mixed-reality environment for personal fabrication,cp,Conference Paper,Weichel C.,60098463;60023643,Microsoft Research Cambridge;Lancaster University,Cambridge;Lancaster,United Kingdom;United Kingdom,5,"Weichel, Christian;Lau, Manfred;Kim, David;Villar, Nicolas;Gellersen, Hans",55735186600;15763019200;56109733800;8419646300;6701531333,60023643;60023643;60098463;60098463;60023643,2014-01-01,2014,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,3855-3864,"Personal fabrication machines, such as 3D printers and laser cutters, are becoming increasingly ubiquitous. However, designing objects for fabrication still requires 3D modeling skills, thereby rendering such technologies inaccessible to a wide user-group. In this paper, we introduce MixFab, a mixed-reality environment for personal fabrication that lowers the barrier for users to engage in personal fabrication. Users design objects in an immersive augmented reality environment, interact with virtual objects in a direct gestural manner and can introduce existing physical objects effortlessly into their designs. We describe the design and implementation of MixFab, a user-defined gesture study that informed this design, show artifacts designed with the system and describe a user study evaluating the system's prototype. Copyright © 2014 ACM.",3D modeling | 3D printing | Direct manipulation | Mixed-reality | Personal fabrication,133,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84901606953,10.1145/2594291.2594327,,,On abstraction refinement for program analyses in datalog,cp,Conference Paper,Zhang X.,60026851;60019647,University of Oxford;Georgia Institute of Technology,Oxford;Atlanta,United Kingdom;United States,5,"Zhang, Xin;Mangal, Ravi;Grigore, Radu;Naik, Mayur;Yang, Hongseok",55792934000;56159583100;23485051200;12140829000;55153940300,60019647;60019647;60026851;60019647;60026851,2014-01-01,2014,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,239-248,"A central task for a program analysis concerns how to efficiently find a program abstraction that keeps only information relevant for proving properties of interest.We present a new approach for finding such abstractions for program analyses written in Datalog. Our approach is based on counterexample-guided abstraction refinement: when a Datalog analysis run fails using an abstraction, it seeks to generalize the cause of the failure to other abstractions, and pick a new abstraction that avoids a similar failure. Our solution uses a boolean satisfiability formulation that is general, complete, and optimal: it is independent of the Datalog solver, it generalizes the failure of an abstraction to as many other abstractions as possible, and it identifies the cheapest refined abstraction to try next. We show the performance of our approach on a pointer analysis and a typestate analysis, on eight real-world Java benchmark programs. Copyright © 2014 ACM.",,57,0,repositoryam,Green,,undefined,,PLDI Programming Languages
2-s2.0-84901781075,10.14778/2732951.2732963,,,On k-path covers and their applications,cp,Conference Paper,Funke S.,60025641;60015815,Universität Freiburg;Universität Stuttgart,Freiburg im Breisgau;Stuttgart,Germany;Germany,3,"Funke, Stefan;Nusser, André;Storandt, Sabine",6701914645;56192814800;53980679400,60015815;60015815;60025641,2014-01-01,2014,Proceedings of the VLDB Endowment,,21100199855,21508097,Conference Proceeding,7,10,,893-902,"For a directed graph G with vertex set V we call a subset C ⊆ V a κ-(All-)Path Cover if C contains a node from any path consisting of k nodes. This paper considers the problem of constructing small κ-Path Covers in the context of road networks with millions of nodes and edges. In many application scenarios the set C and its induced overlay graph constitute a very compact synopsis of G which is the basis for the currently fastest data structure for personalized shortest path queries, visually pleasing overlays of subsampled paths, and efficient reporting, retrieval and aggregation of associated data in spatial network databases. Apart from a theoretical investigation of the problem, we provide efficient algorithms that produce very small κ-Path Covers for large real-world road networks (with a posteriori guarantees via instance-based lower bounds). © 2014 VLDB Endowment.",,42,0,,,,undefined,,VLDB Databases
2-s2.0-84904544053,10.1145/2600428.2609615,,,Partitioned Elias-Fano indexes,cp,Conference Paper,Ottaviano G.,60085207;60028868,Istituto di Scienza e Tecnologie dell'Informazione A. Faedo;Università di Pisa,Pisa;Pisa,Italy;Italy,2,"Ottaviano, Giuseppe;Venturini, Rossano",6701346216;15844697800,60085207;60028868,2014-01-01,2014,SIGIR 2014 - Proceedings of the 37th International ACM SIGIR Conference on Research and Development in Information Retrieval,,21100324962,,Conference Proceeding,,,,273-282,"The Elias-Fano representation of monotone sequences has been recently applied to the compression of inverted indexes, showing excellent query performance thanks to its efficient random access and search operations. While its space occupancy is competitive with some state-of-the-art methods such as -γδ-Golomb codes and PForDelta, it fails to exploit the local clustering that inverted lists usually exhibit, namely the presence of long subsequences of close identifiers. In this paper we describe a new representation based on partitioning the list into chunks and encoding both the chunks and their endpoints with Elias-Fano, hence forming a two-level data structure. This partitioning enables the encoding to better adapt to the local statistics of the chunk, thus exploiting clustering and improving compression. We present two partition strategies, respectively with fixed and variable-length chunks. For the latter case we introduce a linear-time optimization algorithm which identifies the minimum-space partition up to an arbitrarily small approximation factor. We show that our partitioned Elias-Fano indexes offer significantly better compression than plain Elias-Fano, while preserving their query time eficiency. Furthermore, compared with other state-of-the-art compressed encodings, our indexes exhibit the best compression ratio/query time trade-off. Copyright 2014 ACM.",Compression | Dynamic programming | Inverted indexes,103,0,,,,undefined,,SIGIR Information Retrieval
2-s2.0-84904440640,10.1109/INFOCOM.2014.6848208,,,Performance evaluation and asymptotics for Content Delivery Networks,cp,Conference Paper,Shah V.,60013372,The University of Texas at Austin,Austin,United States,2,"Shah, Virag;De Veciana, Gustavo",57213460418;7004363417,60013372;60013372,2014-01-01,2014,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,,,6848208,2607-2615,"Large scale Content Delivery Networks (CDNs) are one of the key components of today's information infrastructure. This paper proposes and analyzes a simple stochastic model for a file-server system wherein servers can work together, as a pooled resource, to meet individual user requests. In such systems basic questions include: How and where to replicate files? What is the impact of dynamic service allocation across request types, and whether it can provide substantial gains over simpler load balancing policies? What are tradeoffs amongst performance, reliability and recovery costs, and energy? The paper provides both explicit and asymptotic approximations for large systems towards addressing these basic questions. © 2014 IEEE.",,19,0,,,,undefined,,INFOCOM Networking
2-s2.0-84902108769,10.1137/1.9781611973402.61,,,Polynomiality for bin packing with a constant number of item types,cp,Conference Paper,Goemans M.X.,60022195,Massachusetts Institute of Technology,Cambridge,United States,2,"Goemans, Michel X.;Rothvoß, Thomas",7003828844;23991787100,60022195;60022195,2014-01-01,2014,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,,,,830-839,"We consider the bin packing problem with d different item sizes Si and item multiplicities ai, where all numbers are given in binary encoding. This problem formulation is also known as the 1-dimensional cutting stock problem. In this work, we provide an algorithm which, for constant d, solves bin packing in polynomial time. This was an open problem for all d ≥ 3. In fact, for constant d our algorithm solves the following problem in polynomial time: given two d- dimensional polytopes P and Q, find the smallest number of integer points in P whose sum lies in Q. Our approach also applies to high multiplicity scheduling problems in which the number of copies of each job type is given in binary encoding and each type comes with certain parameters such as release dates, processing times and deadlines. We show that a variety of high multiplicity scheduling problems can be solved in polynomial time if the number of job types is constant. Copyright © 2014 by the Society for Industrial and Applied Mathematics.",,51,0,repositoryam,Green,NSF,1115849,National Stroke Foundation,SODA Theory
2-s2.0-84986903173,10.1145/2635868.2635894,,,Powering the Static Driver Verifier using Corral,cp,Conference Paper,Lal A.,60021726,Microsoft Research,Redmond,United States,2,"Lal, Akash;Qadeer, Shaz",12143569300;57207615217,60021726;60021726,2014-11-16,16 November 2014,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100778601,,Conference Proceeding,16-21-November-2014,,,202-212,"The application of software-verification technology towards building realistic bug-finding tools requires working through several precision-scalability tradeoffs. For instance, a critical aspect while dealing with C programs is to formally define the treatment of pointers and the heap. A machine-level modeling is often intractable, whereas one that leverages highlevel information (such as types) can be inaccurate. Another tradeoff is modeling integer arithmetic. Ideally, all arithmetic should be performed over bitvector representations whereas the current practice in most tools is to use mathematical integers for scalability. A third tradeoff, in the context of bounded program exploration, is to choose a bound that ensures high coverage without overwhelming the analysis. This paper works through these three tradeoffs when we applied Corral, an SMT-based verifier, inside Microsoft's Static Driver Verifier (SDV). Our decisions were guided by experimentation on a large set of drivers; the total verification time exceeded well over a month. We justify that each of our decisions were crucial in getting value out of Corral and led to Corral being accepted as the engine that powers SDV in the Windows 8.1 release, replacing the SLAM engine that had been used inside SDV for the past decade.",Bitvector reasoning | Device drivers | Language semantics | Loop coverage | SMT | Software verification,29,1,publisherfree2read,Bronze,,undefined,,FSE Software Engineering
2-s2.0-84912027763,10.1145/2642918.2647413,,,PrintScreen: Fabricating highly customizable thin-film touch-displays,cp,Conference Paper,Olberding S.,60033241,Universität des Saarlandes,Saarbrucken,Germany,3,"Olberding, Simon;Wessely, Michael;Steimle, Jürgen",36603168700;56427766100;24825371700,60033241;60033241;60033241,2014-10-05,5 October 2014,UIST 2014 - Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology,,21100348535,,Conference Proceeding,,,,281-290,"PrintScreen is an enabling technology for digital fabrication of customized flexible displays using thin-film electroluminescence (TFEL). It enables inexpensive and rapid fabrication of highly customized displays in low volume, in a simple lab environment, print shop or even at home. We show how to print ultra-thin (120 μm) segmented and passive matrix displays in greyscale or multi-color on a variety of deformable and rigid substrate materials, including PET film, office paper, leather, metal, stone, and wood. The displays can have custom, unconventional 2D shapes and can be bent, rolled and folded to create 3D shapes. We contribute a systematic overview of graphical display primitives for customized displays and show how to integrate them with static print and printed electronics. Furthermore, we contribute a sensing framework, which leverages the display itself for touch sensing. To demonstrate the wide applicability of PrintScreen, we present application examples from ubiquitous, mobile and wearable computing.",Digital fabrication | Electroluminescence | Flexible display | Printed electronics | Rapid prototyping | TFEL | Thin-film display | Touch input | Ubiquitous computing,128,0,,,,undefined,,UIST User Interface
2-s2.0-84900417581,10.1145/2556288.2557210,,,Real-time feedback for improving medication taking,cp,Conference Paper,Lee M.,60027950;60016561,Carnegie Mellon University;Philips Research,Pittsburgh;Eindhoven,United States;Netherlands,2,"Lee, Matthew L.;Dey, Anind K.",23668178100;7101701731,60016561;60027950,2014-01-01,2014,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,2259-2268,"Medication taking is a self-regulatory process that requires individuals to self-monitor their medication taking behaviors, but this can be difficult because medication taking is such a mundane, unremarkable behavior. Ubiquitous sensing systems have the potential to sense everyday behaviors and provide the objective feedback necessary for self-regulation of medication taking. We describe an unobtrusive sensing system consisting of a sensor-augmented pillbox and an ambient display that provides near real-time visual feedback about how well medications are being taken. In contrast to other systems that focus on reminding before medication taking, our approach uses feedback after medication taking to allow the individual to develop their own routines through selfregulation. We evaluated this system in the homes of older adults in a 10-month deployment. Feedback helped improve the consistency of medication-taking behaviors as well as increased ratings of self-efficacy. However, the improved performance did not persist after the feedback display was removed, because individuals had integrated the feedback display into their routines to support their self-awareness, identify mistakes, guide the timing of medication taking, and provide a sense of security that they are taking their medications well. Finally, we reflect on design considerations for feedback systems to support the process of self-regulation of everyday behaviors.",Ambient display | Behavior change | Feedback | Medication adherence | Self-efficacy | Self-regulation | Sensors,54,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84908219215,,,,Recovering from selection bias in causal and statistical inference,cp,Conference Paper,Bareinboim E.,60145790;60027550,"Department of Computer Science;University of California, Los Angeles",Ames;Los Angeles,United States;United States,3,"Bareinboim, Elias;Tian, Jin;Pearl, Judea",24075591200;56314888000;7101604154,60027550;60145790;60027550,2014-01-01,2014,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,4,,,2410-2416,"Selection bias is caused by preferential exclusion of units from the samples and represents a major obstacle to valid causal and statistical inferences; it cannot be removed by randomized experiments and can rarely be detected in either experimental or observational studies. In this paper, we provide complete graphical and algorithmic conditions for recovering conditional probabilities from selection biased data. We also provide graphical conditions for recoverability when unbiased data is available over a subset of the variables. Finally, we provide a graphical condition that generalizes the backdoor criterion and serves to recover causal effects when the data is collected under preferential selection.",,86,0,,,,#IIS-1302448,,AAAI Artificial Intelligence
2-s2.0-84907030865,10.1145/2623330.2623756,,,Reducing the sampling complexity of topic models,cp,Conference Paper,Li A.Q.,60027950;60006191,Carnegie Mellon University;Google LLC,Pittsburgh;Mountain View,United States;United States,4,"Li, Aaron Q.;Ahmed, Amr;Ravi, Sujith;Smola, Alexander J.",56355170000;57206405307;57551243700;6701849799,60027950;60006191;60006191;60006191-60027950,2014-01-01,2014,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,101510,,Conference Proceeding,,,,891-900,"Inference in topic models typically involves a sampling step to associate latent variables with observations. Unfortunately the generative model loses sparsity as the amount of data increases, requiring O(k) operations per word for k topics. In this paper we propose an algorithm which scales linearly with the number of actually instantiated topics kd in the document. For large document collections and in structured hierarchical models kd ≪ k. This yields an order of magnitude speedup. Our method applies to a wide variety of statistical models such as PDP [16,4] and HDP [19]. At its core is the idea that dense, slowly changing distributions can be approximated efficiently by the combination of a Metropolis-Hastings step, use of sparsity, and amortized constant time sampling via Walker's alias method. © 2014 ACM.",alias method | sampling | scalability | topic models,176,0,repositoryam,Green,Intel,undefined,Intel Corporation,KDD Data Mining
2-s2.0-84900401228,10.1145/2556288.2557336,,,RetroDepth: 3D silhouette sensing for high-precision input on and above physical surfaces,cp,Conference Paper,Kim D.,60102151;60026532;60022132;60021726;60012708;60006222,Istituto Italiano di Tecnologia;Microsoft Corporation;University of St Andrews;Microsoft Research;Stanford University;Newcastle University,Genoa;Redmond;St Andrews;Redmond;Stanford;Newcastle,Italy;United States;United Kingdom;United States;United States;United Kingdom,13,"Kim, David;Izadi, Shahram;Dostal, Jakub;Rhemann, Christoph;Keskin, Cem;Zach, Christopher;Shotton, Jamie;Large, Tim;Bathiche, Steven;Nießner, Matthias;Butler, D. Alex;Fanello, Sean;Pradeep, Vivek",56109733800;16426108500;55319136800;8380954300;24477101000;35618052000;23019722900;18133886500;6503964405;35772871600;57198299986;36170215300;57217189069,60021726-60006222;60021726;60022132;60021726;60021726;60021726;60021726;60026532;60026532;60012708;60021726;60102151;60026532,2014-01-01,2014,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1377-1386,"We present RetroDepth, a new vision-based system for accurately sensing the 3D silhouettes of hands, styluses, and other objects, as they interact on and above physical surfaces. Our setup is simple, cheap, and easily reproducible, comprising of two infrared cameras, diffuse infrared LEDs, and any off-the-shelf retro-reflective material. The retro-reflector aids image segmentation, creating a strong contrast between the surface and any object in proximity. A new highly efficient stereo matching algorithm precisely estimates the 3D contours of interacting objects and the retro-reflective surfaces. A novel pipeline enables 3D finger, hand and object tracking, as well as gesture recognition, purely using these 3D contours. We demonstrate high-precision sensing, allowing robust disambiguation between a finger or stylus touching, pressing or interacting above the surface. This allows many interactive scenarios that seamlessly mix together freehand 3D interactions with touch, pressure and stylus input. As shown, these rich modalities of input are enabled on and above any retro-reflective surface, including custom ""physical widgets"" fabricated by users. We compare our system with Kinect and Leap Motion, and conclude with limitations and future work.",3D contours | 3D input | Contour classification | Depth sensing | NUI | Stereo matching | Stylus | Touch | Vision-based UIs,24,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84910660043,10.1109/SP.2014.35,,,Secure multiparty computations on bitcoin,cp,Conference Paper,Andrychowicz M.,60032350;60013756,Sapienza Università di Roma;University of Warsaw,Rome;Warsaw,Italy;Poland,4,"Andrychowicz, Marcin;Dziembowski, Stefan;Malinowski, Daniel;Mazurek, Łukasz",56333296900;14026632000;56333533100;56333140500,60013756;60013756-60032350;60013756;60013756,2014-11-13,13 November 2014,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,,,6956580,443-458,"Bit coin is a decentralized digital currency, introduced in 2008, that has recently gained noticeable popularity. Its main features are: (a) it lacks a central authority that controls the transactions, (b) the list of transactions is publicly available, and (c) its syntax allows more advanced transactions than simply transferring the money. The goal of this paper is to show how these properties of Bit coin can be used in the area of secure multiparty computation protocols (MPCs). Firstly, we show that the Bit coin system provides an attractive way to construct a version of ""timed commitments"", where the committer has to reveal his secret within a certain time frame, or to pay a fine. This, in turn, can be used to obtain fairness in some multiparty protocols. Secondly, we introduce a concept of multiparty protocols that work ""directly on Bit coin"". Recall that the standard definition of the MPCs guarantees only that the protocol ""emulates the trusted third party"". Hence ensuring that the inputs are correct, and the outcome is respected is beyond the scope of the definition. Our observation is that the Bit coin system can be used to go beyond the standard ""emulation-based"" definition, by constructing protocols that link their inputs and the outputs with the real Bit coin transactions. As an instantiation of this idea we construct protocols for secure multiparty lotteries using the Bit coin currency, without relying on a trusted authority (one of these protocols uses the Bit coin-based timed commitments mentioned above). Our protocols guarantee fairness for the honest parties no matter how the loser behaves. For example: if one party interrupts the protocol then her money is transferred to the honest participants. Our protocols are practical (to demonstrate it we performed their transactions in the actual Bit coin system), and can be used in real life as a replacement for the online gambling sites. We think that this paradigm can have also other applications. We discuss some of them.",bitocoin | lottery | multiparty computations,276,1,repositoryam,Green,,undefined,,S&P Security and Privacy
2-s2.0-84986893030,10.1145/2635868.2635877,,,Selection and presentation practices for code example summarization,cp,Conference Paper,Ying A.T.T.,60002494,Université McGill,Montreal,Canada,2,"Ying, Annie T.T.;Robillard, Martin P.",57203349282;7006311463,60002494;60002494,2014-11-16,16 November 2014,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100778601,,Conference Proceeding,16-21-November-2014,,,460-471,"Code examples are an important source for answering questions about software libraries and applications. Many usage contexts for code examples require them to be distilled to their essence: e.g., when serving as cues to longer documents, or for reminding developers of a previously known idiom. We conducted a study to discover how code can be summarized and why. As part of the study, we collected 156 pairs of code examples and their summaries from 16 participants, along with over 26 hours of think-aloud verbalizations detailing the decisions of the participants during their summarization activities. Based on a qualitative analysis of this data we elicited a list of practices followed by the participants to summarize code examples and propose empirically-supported hypotheses justifying the use of specific practices. One main finding was that none of the participants exclusively extracted code verbatim for the summaries, motivating abstractive summarization. The results provide a grounded basis for the development of code example summarization and presentation technology.",Code examples | Summarization,27,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-84912050140,10.1145/2642918.2647379,,,Sensing techniques for tablet+stylus interaction,cp,Conference Paper,Hinckley K.,60028072;60021726;60009697,Cornell University Department of Information Science;Microsoft Research;University of Manitoba,Ithaca;Redmond;Winnipeg,United States;United States;Canada,10,"Hinckley, Ken;Pahud, Michel;Benko, Hrvoje;Irani, Pourang;Guimbretiere, Francois;Gavriliu, Marcel;Chen, Xiang Anthony;Matulic, Fabrice;Buxton, Bill;Wilson, Andy",7003730318;6602493330;9737287100;6603711401;6508204254;56427885500;55146512600;16239407900;7101750777;57199229209,60021726;60021726;60021726;60021726-60009697;60021726-60028072;60021726;60021726;60021726;60021726;60021726,2014-10-05,5 October 2014,UIST 2014 - Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology,,21100348535,,Conference Proceeding,,,,605-614,"We explore grip and motion sensing to afford new techniques that leverage how users naturally manipulate tablet and stylus devices during pen + touch interaction. We can detect whether the user holds the pen in a writing grip or tucked between his fingers. We can distinguish bare-handed inputs, such as drag and pinch gestures produced by the nonpreferred hand, from touch gestures produced by the hand holding the pen, which necessarily impart a detectable motion signal to the stylus. We can sense which hand grips the tablet, and determine the screen's relative orientation to the pen. By selectively combining these signals and using them to complement one another, we can tailor interaction to the context, such as by ignoring unintentional touch inputs while writing, or supporting contextually-appropriate tools such as a magnifier for detailed stroke work that appears when the user pinches with the pen tucked between his fingers. These and other techniques can be used to impart new, previously unanticipated subtleties to pen + touch interaction on tablets.",Bimanual input | Grip | Motion | Pen+touch | Sensing | Tablet,49,0,repositoryam,Green,,undefined,,UIST User Interface
2-s2.0-84952038346,,,,Shielding applications from an untrusted cloud with Haven,cp,Conference Paper,Baumann A.,60021726,Microsoft Research,Redmond,United States,3,"Baumann, Andrew;Peinado, Marcus;Hunt, Galen",26025576700;7005828689;7202673912,60021726;60021726;60021726,2014-01-01,2014,"Proceedings of the 11th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2014",,21100939705,,Conference Proceeding,,,,267-283,"Today's cloud computing infrastructure requires substantial trust. Cloud users rely on both the provider's staff and its globally-distributed software/hardware platform not to expose any of their private data. We introduce the notion of shielded execution, which protects the confidentiality and integrity of a program and its data from the platform on which it runs (i.e., the cloud operator's OS, VM and firmware). Our prototype, Haven, is the first system to achieve shielded execution of unmodified legacy applications, including SQL Server and Apache, on a commodity OS (Windows) and commodity hardware. Haven leverages the hardware protection of Intel SGX to defend against privileged code and physical attacks such as memory probes, but also addresses the dual challenges of executing unmodified legacy binaries and protecting them from a malicious host. This work motivated recent changes in the SGX specification.",,311,0,,,,undefined,,OSDI Operating Systems
2-s2.0-85076886407,,,,Software dataplane verification,cp,Conference Paper,Dobrescu M.,60028186,École Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,2,"Dobrescu, Mihai;Argyraki, Katerina",35268288600;6507197229,60028186;60028186,2014-01-01,2014,"Proceedings of the 11th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2014",,21100962725,,Conference Proceeding,,,,101-114,"Software dataplanes are emerging as an alternative to traditional hardware switches and routers, promising programmability and short time to market. These advantages are set against the risk of disrupting the network with bugs, unpredictable performance, or security vulnerabilities. We explore the feasibility of verifying software dataplanes to ensure smooth network operation. For general programs, verifiability and performance are competing goals; we argue that software dataplanes are different—we can write them in a way that enables verification and preserves performance. We present a verification tool that takes as input a software dataplane, written in a way that meets a given set of conditions, and (dis)proves that the dataplane satisfies crash-freedom, bounded-execution, and filtering properties. We evaluate our tool on stateless and simple stateful Click pipelines; we perform complete and sound verification of these pipelines within tens of minutes, whereas a state-of-the-art general-purpose tool fails to complete the same task within several hours.",,64,0,,,SNF,undefined,Intel Corporation,NSDI Networking
2-s2.0-84907821009,10.1145/2639108.2639111,,,Tagoram: Real-time tracking of mobile RFID tags to high precision using COTS devices,cp,Conference Paper,Yang L.,60280460;60078616;60025278,College of Computing;School of Computer Science and Engineering;Tsinghua University,Chicago;Singapore City;Beijing,United States;Singapore;China,6,"Yang, Lei;Chen, Yekui;Li, Xiang Yang;Xiao, Chaowei;Li, Mo;Liu, Yunhao",57155134900;56380093500;57190744661;58589815900;57213424037;8235471000,60025278;60025278;60025278-60280460;60025278;60078616;60025278,2014-09-07,7 September 2014,"Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM",,70461,,Conference Proceeding,,,,237-248,"In this work, we present an RFID-based system, Tagoram, for object localization and tracking using COTS RFID tags and read- ers. Tracking mobile RFID tags in real time has been a daunting task, especially challenging for achieving high precision. Our sys- tem achieves these three goals by leveraging the phase value of the backscattered signal, provided by the COTS RFID readers, to es- timate the location of the object. In Tagoram, we exploit the tag's mobility to build a virtual antenna array by using readings from a few physical antennas over a time window. To illustrate the basic idea of our system, we firstly focus on a simple scenario where the tag is moving along a fixed track known to the system. We pro- pose Differential Augmented Hologram (DAH) which will facili- tate the instant tracking of the mobile RFID tag to a high precision. We then devise a comprehensive solution to accurately recover the tag's moving trajectories and its locations, relaxing the assumption of knowing tag's track function in advance.",DAH | Localization | RFID | Tagoram | Tracking,669,0,,,,undefined,,MOBICOM Mobile
2-s2.0-84887551372,10.14778/2732228.2732229,,,The uncracked pieces in database cracking,cp,Conference Paper,Schuhknecht F.M.,60033241;60006320,Universität des Saarlandes;MIT Computer Science &amp; Artificial Intelligence Laboratory,Saarbrucken;Cambridge,Germany;United States,3,"Schuhknecht, Felix Martin;Jindal, Alekh;Dittrich, Jens",55927230000;53881488400;10739786000,60033241;60033241-60006320;60033241,2013-01-01,October 2013,Proceedings of the VLDB Endowment,,21100199855,21508097,Journal,7,2,,97-108,"Database cracking has been an area of active research in recent years. The core idea of database cracking is to create indexes adaptively and incrementally as a side-product of query processing. Several works have proposed different cracking techniques for different aspects including updates, tuple-reconstruction, convergence, concurrency-control, and robustness. However, there is a lack of any comparative study of these different methods by an independent group. In this paper, we conduct an experimental study on database cracking. Our goal is to critically review several aspects, identify the potential, and propose promising directions in database cracking. With this study, we hope to expand the scope of database cracking and possibly leverage cracking in database engines other than MonetDB. We repeat several prior database cracking works including the core cracking algorithms as well as three other works on convergence (hybrid cracking), tuple-reconstruction (sideways cracking), and robustness (stochastic cracking) respectively. We evaluate these works and show possible directions to do even better. We further test cracking under a variety of experimental settings, including high selectivity queries, low selectivity queries, and multiple query access patterns. Finally, we compare cracking against different sorting algorithms as well as against different main-memory optimised indexes, including the recently proposed Adaptive Radix Tree (ART). Our results show that: (i) the previously proposed cracking algorithms are repeatable, (ii) there is still enough room to significantly improve the previously proposed cracking algorithms, (iii) cracking depends heavily on query selectivity, (iv) cracking needs to catch up with modern indexing trends, and (v) different indexing algorithms have different indexing signatures. © 2013 VLDB Endowment.",,52,0,repositoryam,Green,,undefined,,VLDB Databases
2-s2.0-84904344976,10.1145/2591796.2591834,,,The matching polytope has exponential extension complexity,cp,Conference Paper,Rothvoss T.,60015481,University of Washington,Seattle,United States,1,"Rothvoss, Thomas",23991787100,60015481,2014-01-01,2014,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,263-272,"A popular method in combinatorial optimization is to express polytopes P, which may potentially have exponentially many facets, as solutions of linear programs that use few extra variables to reduce the number of constraints down to a polynomial. After two decades of standstill, recent years have brought amazing progress in showing lower bounds for the so called extension complexity, which for a polytope P denotes the smallest number of inequalities necessary to describe a higher dimensional polytope Q that can be linearly projected on P. However, the central question in this field remained wide open: can the perfect matching polytope be written as an LP with polynomially many constraints? We answer this question negatively. In fact, the extension complexity of the perfect matching polytope in a complete n-node graph is 2Ω(n). By a known reduction this also improves the lower bound on the extension complexity for the TSP polytope from 2Ω(√ n) to 2 Ω(n). © 2014 ACM.",Combinatorial optimization | Linear programming relaxations | Polytopes,84,0,repositoryam,Green,CISE,1115849,Directorate for Computer and Information Science and Engineering,STOC Theory
2-s2.0-84900405943,10.1145/2556288.2557324,,,Towards accurate and practical predictive models of active-vision-based visual search,cp,Conference Paper,Kieras D.E.,60025778;60012317,"University of Michigan, Ann Arbor;University of Oregon",Ann Arbor;Eugene,United States;United States,2,"Kieras, David E.;Hornof, Anthony J.",6603965096;6603073893,60025778;60012317,2014-01-01,2014,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,3875-3884,"Being able to predict the performance of interface designs using models of human cognition and performance is a long-standing goal of HCI research. This paper presents recent advances in cognitive modeling which permit increasingly realistic and accurate predictions for visual human-computer interaction tasks such as icon search by incorporating an ""active vision"" approach which emphasizes eye movements to visual features based on the availability of features in relationship to the point of gaze. A high fidelity model of a classic visual search task demonstrates the value of incorporating visual acuity functions into models of visual performance. The features captured by the high-fidelity model are then used to formulate a model simple enough for practical use, which is then implemented in an easy-to-use GLEAN modeling tool. Easy-to-use predictive models for complex visual search tasks are thus feasible and should be further developed. Copyright © 2014 ACM.",Cognitive architecture | GOMS | Human performance modeling | Visual acuity | Visual search.,30,0,,,NSF,1017593,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-84994092303,10.1145/2568225.2568308,,,Trading robustness for maintainability: An empirical study of evolving c# programs,cp,Conference Paper,Cacho N.,60032361;60023857,Pontifícia Universidade Católica do Rio de Janeiro;Universidade Federal do Rio Grande do Norte,Rio de Janeiro;Natal,Brazil;Brazil,9,"Cacho, Nélio;César, Thiago;Filipe, Thomas;Soares, Eliezio;Cassio, Arthur;Souza, Rafael;Garcia, Israel;Barbosa, Eiji Adachi;Garcia, Alessandro",17433450200;34871644800;56685802400;56023159100;56684847600;57213483471;43461256700;7101709953;7404608626,60023857;60023857;60023857;60023857;60023857;60023857;60023857;60032361;60032361,2014-05-31,31 May 2014,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,0,1,,584-595,"Mainstream programming languages provide built-in exception handling mechanisms to support robust and maintainable implementation of exception handling in software systems. Most of these modern languages, such as C#, Ruby, Python and many others, are often claimed to have more appropriated exception handling mechanisms. They reduce programming constraints on exception handling to favor agile changes in the source code. These languages provide what we call maintenance-driven exception handling mechanisms. It is expected that the adoption of these mechanisms improve software maintainability without hindering software robustness. However, there is still little empirical knowledge about the impact that adopting these mechanisms have on software robustness. This paper addressed this gap by conducting an empirical study aimed at understanding the relationship between changes in C# programs and their robustness. In particular, we evaluated how changes in the normal and exceptional code were related to exception handling faults. We applied a change impact analysis and a control flow analysis in 119 versions of 16 C# programs. The results showed that: (i) most of the problems hindering software robustness in those programs are caused by changes in the normal code, (ii) many potential faults were introduced even when improving exception handling in C# code, and (iii) faults are often facilitated by the maintenance-driven flexibility of the exception handling mechanism. Moreover, we present a series of change scenarios that decrease the program robustness.",Exception handling | maintainability | robustness,32,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84900421503,10.1145/2556288.2557030,,,Type-hover-swipe in 96 bytes: A motion sensing mechanical keyboard,cp,Conference Paper,Taylor S.,60025858;60021726,ETH Zürich;Microsoft Research,Zurich;Redmond,Switzerland;United States,5,"Taylor, Stuart;Keskin, Cem;Hilliges, Otmar;Izadi, Shahram;Helmes, John",55710416300;24477101000;14041644100;16426108500;34879971800,60021726;60021726;60025858;60021726;60021726,2014-01-01,2014,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1695-1704,"We present a new type of augmented mechanical keyboard, sensing rich and expressive motion gestures performed both on and directly above the device. A low-resolution matrix of infrared (IR) proximity sensors is interspersed with the keys of a regular mechanical keyboard. This results in coarse but high frame-rate motion data. We extend a machine learning algorithm, traditionally used for static classification only, to robustly support dynamic, temporal gestures. We propose the use of motion signatures a technique that utilizes pairs of motion history images and a random forest classifier to robustly recognize a large set of motion gestures. Our technique achieves a mean per-frame classification accuracy of 75:6% in leave-one-subject-out and 89:9% in half-test/half-training cross-validation. We detail hardware and gesture recognition algorithm, provide accuracy results, and demonstrate a large set of gestures designed to be performed with the device. We conclude with qualitative feedback from users, discussion of limitations and areas for future work.",Gesture recognition | Input devices | Keyboard,35,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84994133382,10.1145/2568225.2568268,,,Understanding JavaScript event-based interactions,cp,Conference Paper,Alimadadi S.,60010365,The University of British Columbia,Vancouver,Canada,4,"Alimadadi, Saba;Sequeira, Sheldon;Mesbah, Ali;Pattabiraman, Karthik",36727054000;57189506659;17345931800;8887951000,60010365;60010365;60010365;60010365,2014-05-31,31 May 2014,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,CONFCODENUMBER,,367-377,"Web applications have become one of the fastest growing types of software systems today. Despite their popularity, understanding the behaviour of modern web applications is still a challenging endeavour for developers during development and maintenance tasks. The challenges mainly stem from the dynamic, event-driven, and asynchronous nature of the JavaScript language. We propose a generic technique for capturing low-level event-based interactions in a web application and mapping those to a higher-level behavioural model. This model is then transformed into an interactive visualization, representing episodes of triggered causal and temporal events, related JavaScript code executions, and their impact on the dynamic DOM state. Our approach, implemented in a tool called Clematis, allows developers to easily understand the complex dynamic behaviour of their application at three different semantic levels of granularity. The results of our industrial controlled experiment show that Clematis is capable of improving the task accuracy by 61%, while reducing the task completion time by 47%.",event-based interactions | JavaScript | Program comprehension,53,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84900430803,10.1145/2556288.2557351,,,Understanding multitasking through parallelized strategy exploration and individualized cognitive modeling,cp,Conference Paper,Zhang Y.,60012317,University of Oregon,Eugene,United States,2,"Zhang, Yunfeng;Hornof, Anthony J.",55739903600;6603073893,60012317;60012317,2014-01-01,2014,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,3885-3894,"Human multitasking often involves complex task interactions and subtle tradeoffs which might be best understood through detailed computational cognitive modeling, yet traditional cognitive modeling approaches may not explore a sufficient range of task strategies to reveal the true complexity of multitasking behavior. This study proposes a systematic approach for exploring a large number of strategies using a computer-cluster-based parallelized modeling system. The paper demonstrates the efficacy of the approach for investigating and revealing the effects of different microstrategies on human performance, both within and across individuals, for a time-pressured multimodal dual task. The modeling results suggest that multitasking performance is not simply a matter of interleaving cognitive and sensorimotor processing but is instead heavily influenced by the selection of subtask microstrategies.",Cognitive modeling | High performance computing | Model comparison | Multimodal | Multitasking | Task strategies.,17,0,repositoryam,Green,NSF,1017593,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-84919825362,,,,Understanding the limiting factors of topic modeling via posterior contraction analysis,cp,Conference Paper,Tang J.,60025778;60014966,"University of Michigan, Ann Arbor;Peking University",Ann Arbor;Beijing,United States;China,5,"Tang, Jian;Meng, Zhaoshi;Nguyen, Xuan Long;Mel, Qiaozhu;Zhang, Ming",55713998400;55414689400;35607471500;56461399200;57193650715,60014966;60025778;60025778;60025778;60014966,2014-01-01,2014,"31st International Conference on Machine Learning, ICML 2014",,21100462814,,Conference Proceeding,1,,,337-345,"2014 Topic models such as the latent Dirichlet allocation (LDA) have become a standard staple in the modeling toolbox of machine learning. They have been applied to a vast variety of data sets, contexts, and tasks to varying degrees of success. However, to date there is almost no formal theory explicating the LDA's behavior, and despite its familiarity there is very little systematic analysis of and guidance on the properties of the data that affect the inferential performance of the model. This paper seeks to address this gap, by providing a systematic analysis of factors which characterize the LDA's performance. We present theorems elucidating the posterior contraction rates of the topics as the amount of data increases, and a thorough supporting empirical study using synthetic and real data sets, including news and web-based articles and tweet messages. Based on these results we provide practical guidance on how to identify suitable data sets for topic models, and how to specify particular model parameters.",,91,0,,,,61272343,,ICML Machine Learning
2-s2.0-84994138689,10.1145/2568225.2568248,,,Unit test virtualization with VMVM,cp,Conference Paper,Bell J.,60030162,Columbia University,New York,United States,2,"Bell, Jonathan;Kaiser, Gail",55472337600;7202982863,60030162;60030162,2014-05-31,31 May 2014,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,1,,550-561,"Testing large software packages can become very time intensive. To address this problem, researchers have investigated techniques such as Test Suite Minimization. Test Suite Minimization reduces the number of tests in a suite by removing tests that appear redundant, at the risk of a reduction in fault-finding ability since it can be difficult to identify which tests are truly redundant. We take a completely different approach to solving the same problem of long running test suites by instead reducing the time needed to execute each test, an approach that we call Unit Test Virtualization. With Unit Test Virtualization, we reduce the overhead of isolating each unit test with a lightweight virtualization container. We describe the empirical analysis that grounds our approach and provide an implementation of Unit Test Virtualization targeting Java applications. We evaluated our implementation, VMVM, using 20 real-world Java applications and found that it reduces test suite execution time by up to 97% (on average, 62%) when compared to traditional unit test execution. We also compared VMVM to a well known Test Suite Minimization technique, finding the reduction provided by VMVM to be four times greater, while still executing every test with no loss of fault-finding ability.",test optimization | Testing | unit test virtualization,70,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-84904360628,10.1145/2594538.2594541,,,Weaker forms of monotonicity for declarative networking: A more fine-grained answer to the CALM-conjecture,cp,Conference Paper,Ameloot T.,60110887;60018869;60010413,LogicBlox Inc;Universiteit Maastricht;Universiteit Hasselt,Atlanta;Maastricht;Hasselt,United States;Netherlands;Belgium,4,"Ameloot, Tom J.;Ketsman, Bas;Neven, Frank;Zinn, Daniel",42760965800;56272656400;6701415938;36886154300,60010413-60018869;60010413-60018869;60010413-60018869;60110887,2014-01-01,2014,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,64-75,"The CALM-conjecture, first stated by Hellerstein [23] and proved in its revised form by Ameloot et al. [13] within the framework of relational transducer networks, asserts that a query has a coordination-free execution strategy if and only if the query is monotone. Zinn et al. [32] extended the framework of relational transducer networks to allow for specific data distribution strategies and showed that the nonmonotone win-move query is coordination-free for domainguided data distributions. In this paper, we complete the story by equating increasingly larger classes of coordinationfree computations with increasingly weaker forms of monotonicity and make Datalog variants explicit that capture each of these classes. One such fragment is based on stratified Datalog where rules are required to be connected with the exception of the last stratum. In addition, we characterize coordination- freeness as those computations that do not require knowledge about all other nodes in the network, and therefore, can not globally coordinate. The results in this paper can be interpreted as a more fine-grained answer to the CALM-conjecture. Copyright 2014 ACM.",Cloud programming | Consistency | Coordination | Distributed database | Expressive power | Relational transducer,17,0,,,,undefined,,PODS Databases
2-s2.0-84906334162,10.1109/CVPR.2014.279,,,What camera motion reveals about shape with unknown BRDF,cp,Conference Paper,Chandraker M.,60018008,"NEC Laboratories America, Inc.",Princeton,United States,1,"Chandraker, Manmohan",14015347100,60018008,2014-09-24,24 September 2014,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,,,6909676,2179-2186,"Psychophysical studies show motion cues inform about shape even with unknown reflectance. Recent works in computer vision have considered shape recovery for an object of unknown BRDF using light source or object motions. This paper addresses the remaining problem of determining shape from the (small or differential) motion of the camera, for unknown isotropic BRDFs. Our theory derives a differential stereo relation that relates camera motion to depth of a surface with unknown isotropic BRDF, which generalizes traditional Lambertian assumptions. Under orthographic projection, we show shape may not be constrained in general, but two motions suffice to yield an invariant for several restricted (still unknown) BRDFs exhibited by common materials. For the perspective case, we show that three differential motions suffice to yield surface depth for unknown isotropic BRDF and unknown directional lighting, while additional constraints are obtained with restrictions on BRDF or lighting. The limits imposed by our theory are intrinsic to the shape recovery problem and independent of choice of reconstruction method. We outline with experiments how potential reconstruction methods may exploit our theory. We illustrate trends shared by theories on shape from motion of light, object or camera, relating reconstruction hardness to imaging complexity.",,20,0,,,,undefined,,CVPR Computer Vision
2-s2.0-84896835469,10.14778/2732286.2732291,,,EpiC: An extensible and scalable system for processing big data,cp,Conference Paper,Jiang D.,60117751;60017161,"College of Computer Science and Technology, Zhejiang University;National University of Singapore",Hangzhou;Singapore City,China;Singapore,5,"Jiang, Dawei;Chen, Gang;Ooi, Beng Chin;Tan, Kian Lee;Wu, Sai",56152358900;57114035800;55665418900;7403999714;24726343700,60017161;60117751;60017161;60017161;60117751,2014-01-01,March 2014,Proceedings of the VLDB Endowment,,21100199855,21508097,Journal,7,7,,541-552,"The Big Data problem is characterized by the so called 3V features: Volume - a huge amount of data, Velocity - a high data ingestion rate, and Variety - a mix of structured data, semi-structured data, and unstructured data. The state-of-the-art solutions to the Big Data problem are largely based on the MapReduce framework (aka its open source implementation Hadoop). Although Hadoop handles the data volume challenge successfully, it does not deal with the data variety well since the programming interfaces and its associated data processing model is inconvenient and inefficient for handling structured data and graph data. This paper presents epiC, an extensible system to tackle the Big Data's data variety challenge. epiC introduces a general Actor-like concurrent programming model, independent of the data processing models, for specifying parallel computations. Users process multi-structured datasets with appropriate epiC extensions, the implementation of a data processing model best suited for the data type and auxiliary code for mapping that data processing model into epiC's concurrent programming model. Like Hadoop, programs written in this way can be automatically parallelized and the runtime system takes care of fault tolerance and inter-machine communications. We present the design and implementation of epiC's concurrent programming model. We also present two customized data processing model, an optimized MapReduce extension and a relational model, on top of epiC. Experiments demonstrate the effectiveness and efficiency of our proposed epiC. © 2014 VLDB Endowment.",,51,0,,,,undefined,,VLDB Databases
2-s2.0-84951142438,10.1145/2702123.2702556,,,"I always assumed that I wasn't really that close to [her]"": Reasoning about invisible algorithms in news feeds",cp,Conference Paper,Eslami M.,60025778;60002526;60000745,"University of Michigan, Ann Arbor;California State University, Fresno;University of Illinois Urbana-Champaign",Ann Arbor;Fresno;Urbana,United States;United States;United States,8,"Eslami, Motahhare;Rickman, Aimee;Vaccaro, Kristen;Aleyasen, Amirhossein;Vuong, Andy;Karahalios, Karrie;Hamilton, Kevin;Sandvig, Christian",56159566300;57015111900;57015000300;56160047900;57014970400;23397392600;56468831600;7801370310,60000745;60002526;60000745;60000745;60000745;60000745;60000745;60025778,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,153-162,"Our daily digital life is full of algorithmically selected content such as social media feeds, recommendations and personalized search results. These algorithms have great power to shape users' experiences, yet users are often unaware of their presence. Whether it is useful to give users insight into these algorithms' existence or functionality and how such insight might affect their experience are open questions. To address them, we conducted a user study with 40 Facebook users to examine their perceptions of the Facebook News Feed curation algorithm. Surprisingly, more than half of the participants (62.5%) were not aware of the News Feed curation algorithm's existence at all. Initial reactions for these previously unaware participants were surprise and anger. We developed a system, FeedVis, to reveal the difference between the algorithmically curated and an unadulterated News Feed to users, and used it to study how users perceive this difference. Participants were most upset when close friends and family were not shown in their feeds. We also found participants often attributed missing stories to their friends' decisions to exclude them rather than to Facebook News Feed algorithm. By the end of the study, however, participants were mostly satisfied with the content on their feeds. Following up with participants two to six months after the study, we found that for most, satisfaction levels remained similar before and after becoming aware of the algorithm's presence, however, algorithmic awareness led to more active engagement with Facebook and bolstered overall feelings of control on the site.",Algorithm awareness | Algorithms | Hidden processes | News feeds,388,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84958779720,10.1145/2746539.2746546,,,2-server PIR with sub-polynomial communication,cp,Conference Paper,Dvir Z.,60003269,Princeton University,Princeton,United States,2,"Dvir, Zeev;Gopi, Sivakanth",8916143900;55480761500,60003269;60003269,2015-06-14,14 June 2015,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,14-17-June-2015,,,577-584,"A 2-server Private Information Retrieval (PIR) scheme allows a user to retrieve the ith bit of an n-bit database replicated among two non-communicating servers, while not revealing any information about i to either server. In this work we construct a 2-server PIR scheme with total communication cost nO√log log n/log n. This improves over current 2-server protocols which all require Ω(n1/3) communication. Our construction circumvents the n1/3 barrier of Razborov and Yekhanin [21] which holds for the restricted model of bilinear group-based schemes (covering all previous 2-server schemes). The improvement comes from reducing the number of servers in existing protocols, based on Matching Vector Codes, from 3 or 4 servers to 2. This is achieved by viewing these protocols in an algebraic way (using polynomial interpolation) and extending them using partial derivatives.",Locally Decodable Codes | Private Information Retrieval,39,0,repositoryam,Green,CISE,0832797,Directorate for Computer and Information Science and Engineering,STOC Theory
2-s2.0-84940995903,10.1109/SP.2015.39,,,A messy state of the union: Taming the composite state machines of TLS,cp,Conference Paper,Beurdouche B.,60121727;60032401;60026651;60021726,IMDEA Software Institute;INRIA Rocquencourt;Ecole des Ponts ParisTech;Microsoft Research,Pozuelo de Alarcon;Le Chesnay;Marne-la-Vallee;Redmond,Spain;France;France;United States,8,"Beurdouche, Benjamin;Bhargavan, Karthikeyan;Delignat-Lavaud, Antoine;Fournet, Cédric;Kohlweiss, Markulf;Pironti, Alfredo;Strub, Pierre Yves;Zinzindohoue, Jean Karim",56922344900;6602428438;55608557900;55909934900;17434840500;55316402300;23391365800;56922180200,60032401;60032401;60032401;60021726;60021726;60032401;60121727;60032401-60026651,2015-07-17,17 July 2015,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2015-July,,7163046,535-552,"Implementations of the Transport Layer Security (TLS) protocol must handle a variety of protocol versions and extensions, authentication modes, and key exchange methods. Confusingly, each combination may prescribe a different message sequence between the client and the server. We address the problem of designing a robust composite state machine that correctly multiplexes between these different protocol modes. We systematically test popular open-source TLS implementations for state machine bugs and discover several critical security vulnerabilities that have lain hidden in these libraries for years, and have now finally been patched due to our disclosures. Several of these vulnerabilities, including the recently publicized FREAK flaw, enable a network attacker to break into TLS connections between authenticated clients and servers. We argue that state machine bugs stem from incorrect compositions of individually correct state machines. We present the first verified implementation of a composite TLS state machine in C that can be embedded into OpenSSL and accounts for all its supported cipher suites. Our attacks expose the need for the formal verification of core components in cryptographic protocol libraries, our implementation demonstrates that such mechanized proofs are within reach, even for mainstream TLS implementations.",cryptographic protocols | formal methods | man-in-the-middle attacks | software verification | Transport Layer Security,181,1,repositoryam,Green,H2020,259639,Horizon 2020 Framework Programme,S&P Security and Privacy
2-s2.0-84969759651,,,,A nearly-linear time framework for graph-structured sparsity,cp,Conference Paper,Hegde C.,60022195,Massachusetts Institute of Technology,Cambridge,United States,3,"Hegde, Chinmay;Indyk, Piotr;Schmidt, Ludwig",58593216500;7003517536;56198602500,60022195;60022195;60022195,2015-01-01,2015,"32nd International Conference on Machine Learning, ICML 2015",,21100462814,,Conference Proceeding,2,,,928-937,"We introduce a framework for sparsity structures defined via graphs. Our approach is flexible and generalizes several previously studied sparsity models. Moreover, we provide efficient projection algorithms for our sparsity model that run in nearly-linear time. In the context of sparse recovery, we show that our framework achieves an information-theoretically optimal sample complexity for a wide range of parameters. We complement our theoretical analysis with experiments demonstrating that our algorithms also improve on prior work in practice.",,67,0,,,,undefined,,ICML Machine Learning
2-s2.0-84960421046,10.1145/2786805.2786851,,,A user-guided approach to program analysis,cp,Conference Paper,Mangal R.,60021726;60019647,Microsoft Research;Georgia Institute of Technology,Redmond;Atlanta,United States;United States,4,"Mangal, Ravi;Zhang, Xin;Nori, Aditya V.;Naik, Mayur",56159583100;55792934000;15832336400;12140829000,60019647;60019647;60021726;60019647,2015-08-30,30 August 2015,"2015 10th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE 2015 - Proceedings",,21100450024,,Conference Proceeding,,,,462-473,"Program analysis tools often produce undesirable output due to various approximations. We present an approach and a system Eugene that allows user feedback to guide such approximations towards producing the desired output. We formulate the problem of user-guided program analysis in terms of solving a combination of hard rules and soft rules: hard rules capture soundness while soft rules capture degrees of approximations and preferences of users. Our technique solves the rules using an off-the-shelf solver in a manner that is sound (satisfies all hard rules), optimal (max- imally satisfies soft rules), and scales to real-world analyses and programs. We evaluate Eugene on two different analyses with labeled output on a suite of seven Java pro- grams of size 131{198 KLOC. We also report upon a user study involving nine users who employ Eugene to guide an information-flow analysis on three Java micro-benchmarks. In our experiments, Eugene significantly reduces misclassi- fied reports upon providing limited amounts of feedback.",Program analysis | Report classification | User feedback,59,0,,,CISE,1253867,Directorate for Computer and Information Science and Engineering,FSE Software Engineering
2-s2.0-84951073164,10.1145/2702123.2702414,,,"Acoustruments: Passive, acoustically-driven, interactive controls for handheld devices",cp,Conference Paper,Laput G.,60032776;60027950,The Walt Disney Company;Carnegie Mellon University,Burbank;Pittsburgh,United States;United States,4,"Laput, Gierad;Brockmeyer, Eric;Hudson, Scott E.;Harrison, Chris",55258463300;55481738100;7201375469;35792227900,60027950-60032776;60032776;60027950-60032776;60027950-60032776,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,2161-2170,"We introduce Acoustruments: Low-cost, passive, and powerless mechanisms, made from plastic, that can bring rich, tangible functionality to handheld devices. Through a structured exploration, we identified an expansive vocabulary of design primitives, providing building blocks for the construction of tangible interfaces utilizing smartphones' existing audio functionality. By combining design primitives, familiar physical mechanisms can all be constructed from passive elements. On top of these, we can create end-user applications with rich, tangible interactive functionalities. Our experiments show that Acoustruments can achieve 99% accuracy with minimal training, is robust to noise, and can be rapidly prototyped. Acoustruments adds a new method to the toolbox HCI practitioners and researchers can draw upon, while introducing a cheap and passive method for adding interactive controls to consumer products.",Acoustic sensing | Fabrication | Mechanisms and controls | Mobile and handheld devices,81,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84951150654,10.1145/2702123.2702128,,,Affordance++: Allowing objects to communicate dynamic use,cp,Conference Paper,Lopes P.,60106550,Hasso-Plattner-Institut für Softwaresystemtechnik GmbH,Potsdam,Germany,3,"Lopes, Pedro;Jonell, Patrik;Baudisch, Patrick",55480857700;57015381900;10039576700,60106550;60106550;60106550,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,2515-2524,"We propose extending the affordance of objects by allowing them to communicate dynamic use, such as (1) motion (e.g., spray can shakes when touched), (2) multi-step processes (e.g., spray can sprays only after shaking), and (3) behaviors that change over time (e.g., empty spray can does not allow spraying anymore). Rather than enhancing objects directly, however, we implement this concept by enhancing the user. We call this affordance++. By stimulating the user's arms using electrical muscle stimulation, our prototype allows objects not only to make the user actuate them, but also perform required movements while merely approaching the object, such as not to touch objects that do not ""want"" to be touched. In our user study, affordance++ helped participants to successfully operate devices of poor natural affordance, such as a multi-functional slicer tool or a magnetic nail sweeper, and to stay away from cups filled with hot liquids.",Affordance | Electrical muscle stimulation,104,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84951827062,10.1109/ICSE.2015.77,,,Alloy∗: A general-purpose higher-order relational constraint solver,cp,Conference Paper,Milicevic A.,60022195,Massachusetts Institute of Technology,Cambridge,United States,4,"Milicevic, Aleksandar;Near, Joseph P.;Kang, Eunsuk;Jackson, Daniel",57201650649;35761458800;23389819800;7404288974,60022195;60022195;60022195;60022195,2015-08-12,12 August 2015,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,1,,7194610,609-619,"The last decade has seen a dramatic growth in the use of constraint solvers as a computational mechanism, not only for analysis of software, but also at runtime. Solvers are available for a variety of logics but are generally restricted to first-order formulas. Some tasks, however, most notably those involving synthesis, are inherently higher order; these are typically handled by embedding a first-order solver (such as a SAT or SMT solver) in a domain-specific algorithm. Using strategies similar to those used in such algorithms, we show how to extend a first-order solver (in this case Kodkod, a model finder for relational logic used as the engine of the Alloy Analyzer) so that it can handle quantifications over higherorder structures. The resulting solver is sufficiently general that it can be applied to a range of problems; it is higher order, so that it can be applied directly, without embedding in another algorithm; and it performs well enough to be competitive with specialized tools. Just as the identification of first-order solvers as reusable backends advanced the performance of specialized tools and simplified their architecture, factoring out higher-order solvers may bring similar benefits to a new class of tools.",,49,0,repositoryam,Green,,CCF- 1138967,,ICSE Software Engineering
2-s2.0-84960470484,10.1109/FOCS.2015.67,,,An Average-Case Depth Hierarchy Theorem for Boolean Circuits,cp,Conference Paper,Rossman B.,60030162;116430648;110271454,Columbia University;Simons Institute;NII,New York;;Nii,United States;Japan;Japan,3,"Rossman, Benjamin;Servedio, Rocco A.;Tan, Li Yang",23061787100;7003731706;36176512100,110271454;60030162;116430648,2015-12-11,11 December 2015,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2015-December,,7354441,1030-1048,"We prove an average-case depth hierarchy theorem for Boolean circuits over the standard basis of AND, OR, and NOT gates. Our hierarchy theorem says that for every d ≥ 2, there is an explicit n-variable Boolean function f, computed by a linear-size depth-d formula, which is such that any depth-(d - 1) circuit that agrees with f on (1/2 + on(1)) fraction of all inputs must have size exp(nΩ(1/d)). This answers an open question posed by Has tad in his Ph.D. Thesis [Has86b]. Our average-case depth hierarchy theorem implies that the polynomial hierarchy is infinite relative to a random oracle with probability 1, confirming a conjecture of Has tad [Has86a], Cai [Cai86], and Babai [Bab87]. We also use our result to show that there is no 'approximate converse' to the results of Linial, Mansour, Nisan [LMN93] and Boppana [Bop97] on the total influence of constant-depth circuits, thus answering a question posed by Kalai [Kal12] and Hatami [Hat14]. A key ingredient in our proof is a notion of random projections which generalize random restrictions.",average-case | depth hierarchy theorem | Polynomial Hierarchy | random projections | Small-depth circuits,27,0,repositoryam,Green,CISE,1319788,Directorate for Computer and Information Science and Engineering,FOCS Theory
2-s2.0-84958254447,10.1145/2806416.2806490,,,Assessing the impact of syntactic and semantic structures for answer passages reranking,cp,Conference Paper,Tymoshenko K.,60104768;60015986,Qatar Computing Research Institute;Università di Trento,Doha;Trento,Qatar;Italy,2,"Tymoshenko, Kateryna;Moschitti, Alessandro",36163592300;6507876429,60015986;60104768-60015986,2015-10-17,17 October 2015,"International Conference on Information and Knowledge Management, Proceedings",,55826,,Conference Proceeding,19-23-Oct-2015,,,1451-1460,"In this paper, we extensively study the use of syntactic and semantic structures obtained with shallow and deeper syntactic parsers in the answer passage reranking task. We propose several dependency-based structures enriched with Linked Open Data (LD) knowledge for representing pairs of questions and answer passages. We use such tree structures in learning to rank (L2R) algorithms based on tree kernel. The latter can represent questions and passages in a tree fragment space, where each substructure represents a powerful syntactic/semantic feature. Additionally since we define links between structures, tree kernels also generate relational features spanning question and passage structures. We derive very important findings, which can be useful to build state-of-the-art systems: (i) full syntactic dependencies can outperform shallow models also using external knowledge and (ii) the semantic information should be derived by effective and high-coverage resources, e.g., LD, and incorporated in syntactic structures to be effective. We demonstrate our findings by carrying out an extensive comparative experimentation on two different TREC QA corpora and one community question answer dataset, namely Answerbag. Our comparative analysis on well-defined answer selection benchmarks consistently demonstrates that our structural semantic models largely outperform the state of the art in passage reranking.",Kernel methods | Learning to rank | Linked data | Question answering | Structural kernels,49,0,,,H2020,671625,Horizon 2020 Framework Programme,CIKM Knowledge Management
2-s2.0-84951777639,10.1145/2737924.2737959,,,Automatically improving accuracy for floating point expressions,cp,Conference Paper,Panchekha P.,60015481,University of Washington,Seattle,United States,4,"Panchekha, Pavel;Sachez-Stern, Alex;Wilcox, James R.;Tatlock, Zachary",55814057100;57015624100;57014485000;26429019900,60015481;60015481;60015481;60015481,2015-06-03,3 June 2015,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,2015-June,,,1-11,"Scientific and engineering applications depend on floating point arithmetic to approximate real arithmetic. This approximation introduces rounding error, which can accumulate to produce unacceptable results. While the numerical methods literature provides techniques to mitigate rounding error, applying these techniques requires manually rearranging expressions and understanding the finer details of floating point arithmetic. We introduce Herbie, a tool which automatically discovers the rewrites experts perform to improve accuracy. Herbie's heuristic search estimates and localizes rounding error using sampled points (rather than static error analysis), applies a database of rules to generate improvements, takes series expansions, and combines improvements for different input regions. We evaluated Herbie on examples from a classic numerical methods textbook, and found that Herbie was able to improve accuracy on each example, some by up to 60 bits, while imposing a median performance overhead of 40%. Colleagues in machine learning have used Herbie to significantly improve the results of a clustering algorithm, and a mathematical library has accepted two patches generated using Herbie.",Floating point | Numerical accuracy | Program rewriting,117,0,,,,undefined,,PLDI Programming Languages
2-s2.0-84951209222,10.1145/2702123.2702246,,,Base lase: An interactive focus + context laser floor,cp,Conference Paper,Müller J.,60029616;60011604,Aarhus Universitet;Technische Universität Berlin,Aarhus;Berlin,Denmark;Germany,3,"Müller, Jörg;Eberle, Dieter;Schmidt, Constantin",57191035823;56158013400;55735031000,60029616-60011604;60011604;60011604,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,3869-3878,"We present BaseLase, an interactive laser projected focus + context floor display. In order to provide a transportable system that works in areas where there are no ceilings, we provide an integrated unit (1:3m height) that stands on the floor. One unsolved challenge for laser projectors is to cover large projection areas while providing high resolution at the same time. Our focus + context laser projector solves this problem. BaseLase can cover a large context area in low resolution, while providing three movable high-resolution focus spots. We provide a convex mirror design that enables the laser to reach a large area (75m2) with low resolution while decreasing the beam dispersion compared to spherical or parabolic mirrors. This hyperboloidal mirror shape approximately equalizes the point size on the floor independent from the projected location. We propose to add a number of planar mirrors on pan-tilt units to create dynamic zones of high resolution that can adjust to the user behavior. We provide example applications for BaseLase and report on user experience in preliminary trials.",,15,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84949748958,,,,Bayesian active learning for posterior estimation,cp,Conference Paper,Kandasamy K.,60027950,Carnegie Mellon University,Pittsburgh,United States,3,"Kandasamy, Kirthevasan;Schneider, Jeff;Póczos, Barnabás",56462389200;57194307511;6506649041,60027950;60027950;60027950,2015-01-01,2015,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2015-January,,,3605-3611,This paper studies active posterior estimation in a Bayesian setting when the likelihood is expensive to evaluate. Existing techniques for posterior estimation are based on generating samples representative of the posterior. Such methods do not consider efficiency in terms of likelihood evaluations. In order to be query efficient we treat posterior estimation in an active regression framework. We propose two myopic query strategies to choose where to evaluate the likelihood and implement them using Gaussian processes. Via experiments on a series of synthetic and real examples we demonstrate that our approach is significantly more query efficient than existing techniques and other heuristics for posterior estimation.,,28,0,,,,undefined,,IJCAI Artificial Intelligence
2-s2.0-84951840695,10.1109/ICSE.2015.100,,,CARAMEL: Detecting and fixing performance problems that have non-intrusive fixes,cp,Conference Paper,Nistor A.,60032179;60029278;60016569;60000745,University of Wisconsin-Madison;The University of Chicago;Chapman University;University of Illinois Urbana-Champaign,Madison;Chicago;Orange;Urbana,United States;United States;United States;United States,4,"Nistor, Adrian;Chang, Po Chun;Radoi, Cosmin;Lu, Shan",26029950300;57208771094;35225282400;35199803400,60016569;60032179;60000745;60029278,2015-08-12,12 August 2015,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,1,,7194636,902-912,"Performance bugs are programming errors that slow down program execution. While existing techniques can detect various types of performance bugs, a crucial and practical aspect of performance bugs has not received the attention it deserves: how likely are developers to fix a performance bug? In practice, fixing a performance bug can have both benefits and drawbacks, and developers fix a performance bug only when the benefits outweigh the drawbacks. Unfortunately, for many performance bugs, the benefits and drawbacks are difficult to assess accurately. This paper presents CARAMEL, a novel static technique that detects and fixes performance bugs that have non-intrusive fixes likely to be adopted by developers. Each performance bug detected by CARAMEL is associated with a loop and a condition. When the condition becomes true during the loop execution, all the remaining computation performed by the loop is wasted. Developers typically fix such performance bugs because these bugs waste computation in loops and have nonintrusive fixes: when some condition becomes true dynamically, just break out of the loop. Given a program, CARAMEL detects such bugs statically and gives developers a potential sourcelevel fix for each bug. We evaluate CARAMEL on real-world applications, including 11 popular Java applications (e.g., Groovy, Log4J, Lucene, Struts, Tomcat, etc) and 4 widely used C/C++ applications (Chromium, GCC, Mozilla, and MySQL). CARAMEL finds 61 new performance bugs in the Java applications and 89 new performance bugs in the C/C++ applications. Based on our bug reports, developers so far have fixed 51 and 65 performance bugs in the Java and C/C++ applications, respectively. Most of the remaining bugs are still under consideration by developers.",,96,0,,,,undefined,Alfred P. Sloan Foundation,ICSE Software Engineering
2-s2.0-84962225742,10.1145/2785956.2787497,,,Central control over distributed routing,cp,Conference Paper,Vissicchio S.,60025858;60003269;60000874,ETH Zürich;Princeton University;Université Catholique de Louvain,Zurich;Princeton;Louvain-la-Neuve,Switzerland;United States;Belgium,4,"Vissicchio, Stefano;Tilmans, Olivier;Vanbever, Laurent;Rexford, Jennifer",35220581300;56516959800;25927686300;7003493334,60000874;60000874;60025858;60003269,2015-08-17,17 August 2015,SIGCOMM 2015 - Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication,,21100455111,,Conference Proceeding,,,,43-56,"Centralizing routing decisions offers tremendous flexibility, but sacrifices the robustness of distributed protocols. In this paper, we present Fibbing, an architecture that achieves both flexibility and robustness through central control over distributed routing. Fibbing introduces fake nodes and links into an underlying link- state routing protocol, so that routers compute their own forwarding tables based on the augmented topology. Fibbing is expressive, and readily supports flexible load balancing, trafic engineering, and backup routes. Based on high-level forwarding requirements, the Fibbing controller computes a compact augmented topology and injects the fake components through standard routing-protocol messages. Fibbing works with any unmodified routers speaking OSPF. Our experiments also show that it can scale to large networks with many forwarding requirements, introduces minimal overhead, and quickly reacts to network and controller failures.",Fibbing | Link-state routing | SDN,103,1,repositoryam,Green,,undefined,,SIGCOMM Networking
2-s2.0-84950971898,10.1145/2702123.2702578,,,ColourID: Improving colour identification for people with impaired colour vision,cp,Conference Paper,Flatla D.R.,60015186;60008877,University of Saskatchewan;University of Dundee,Saskatoon;Dundee,Canada;United Kingdom,5,"Flatla, David R.;Andrade, Alan R.;Teviotdale, Ross D.;Knowles, Dylan L.;Stewart, Craig",36141533300;57014394600;57015456100;55051853600;56945033900,60008877;60008877;60008877;60015186;60008877,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,3543-3552,"Being able to identify colours is a fundamental human activity; colour identification helps us work, get dressed, prepare food, and keep safe. But for the 5% of the world with impaired colour vision (ICV), colour identification is often a challenge, resulting in frustration and confusion with sometimes dangerous consequences. Colour namer tools have been proposed as a solution, however these are often slow to use and imprecise. To address these shortcomings, we developed three new colour identification techniques (Colour- Names, ColourMeters, ColourPopper) using a new colour name dictionary based on the largest colour naming experiment to date. We compared our techniques to colour namers using participants with ICV in desktop and mobile conditions, and found that ColourNames and ColourPopper resulted in 99% colour identification accuracy (10% higher than the colour namer), ColourMeters and ColourPopper were three times faster, and ColourPopper had lower perceived effort and was ranked significantly higher. With the benefits provided by our new colour identification techniques, people with ICV are one step closer to seeing the world like everyone else.",Colour identification | Colour namers | Colour vision deficiency | Colourblindness | Impaired colour vision,27,1,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84965154935,,,,Competitive distribution estimation: Why is Good-Turing good,cp,Conference Paper,Orlitsky A.,60030612,"University of California, San Diego",La Jolla,United States,2,"Orlitsky, Alon;Suresh, Ananda Theertha",57202117395;57201292214,60030612;60030612,2015-01-01,2015,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,2015-January,,,2143-2151,"Estimating distributions over large alphabets is a fundamental machine-learning tenet. Yet no method is known to estimate all distributions well. For example, add-constant estimators are nearly min-max optimal but often perform poorly in practice, and practical estimators such as absolute discounting, Jelinek-Mercer, and Good-Turing are not known to be near optimal for essentially any distribution. We describe the first universally near-optimal probability estimators. For every discrete distribution, they are provably nearly the best in the following two competitive ways. First they estimate every distribution nearly as well as the best estimator designed with prior knowledge of the distribution up to a permutation. Second, they estimate every distribution nearly as well as the best estimator designed with prior knowledge of the exact distribution, but as all natural estimators, restricted to assign the same probability to all symbols appearing the same number of times. Specifically, for distributions over k symbols and n samples, we show that for both comparisons, a simple variant of Good-Turing estimator is always within KL divergence of (3 + on(1))/n1/3 from the best estimator, and that a more involved estimator is within On (min(k/n, 1/√n)). Conversely, we show that any estimator must have a KL divergence at least Ωn (min(k/n, 1/n2/3)) over the best estimator for the first comparison, and at least Ωn(min(k/n, 1/√n)) for the second.",,50,0,,,,undefined,,NeurIPS Machine Learning
2-s2.0-84906670985,10.14778/2735461.2735468,,,Constructing an interactive natural language interface for relational databases,ar,Article,Li F.,60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,2,"Li, Fei;Jagadish, H. V.",57222750543;35242128300,60025778;60025778,2014-01-01,2014,Proceedings of the VLDB Endowment,,21100199855,21508097,Conference Proceeding,8,1,,73-84,"Natural language has been the holy grail of query interface designers, but has generally been considered too hard to work with, except in limited specic circumstances. In this paper, we describe the architecture of an interactive natural language query interface for relational databases. Through a carefully limited interaction with the user, we are able to correctly interpret complex natural language queries, in a generic manner across a range of domains. By these means, a logically complex English language sentence is correctly translated into a SQL query, which may include aggregation, nesting, and various types of joins, among other things, and can be evaluated against an RDBMS.We have constructed a system, NaLIR (Natural Language Interface for Relational databases), embodying these ideas. Our experimental assessment, through user studies, demonstrates that NaLIR is good enough to be usable in practice: even naive users are able to specify quite complex ad-hoc queries. © 2014 VLDB.",,299,0,repositoryam,Green,,IIS 1017296,,VLDB Databases
2-s2.0-84957971552,10.1145/2815400.2815409,,,COZ: Finding code that counts with causal profiling,cp,Conference Paper,Curtsinger C.,60152130;60028806,Manning College of Information &amp; Computer Sciences;Grinnell College,Amherst;Grinnell,United States;United States,2,"Curtsinger, Charlie;Berger, Emery D.",54785853700;7202374093,60028806;60152130,2015-10-04,4 October 2015,SOSP 2015 - Proceedings of the 25th ACM Symposium on Operating Systems Principles,,21100446022,,Conference Proceeding,,,,184-197,"Improving performance is a central concern for software developers. To locate optimization opportunities, developers rely on software profilers. However, these profilers only report where programs spent their time: optimizing that code may have no impact on performance. Past profilers thus both waste developer time and make it difficult for them to uncover significant optimization opportunities. This paper introduces causal profiling. Unlike past profiling approaches, causal profiling indicates exactly where programmers should focus their optimization efforts, and quantifies their potential impact. Causal profiling works by running performance experiments during program execution. Each experiment calculates the impact of any potential optimization by virtually speeding up code: inserting pauses that slow down all other code running concurrently. The key insight is that this slowdown has the same relative effect as running that line faster, thus ""virtually"" speeding it up. We present COZ, a causal profiler, which we evaluate on a range of highly-tuned applications: Memcached, SQLite, and the PARSEC benchmark suite. COZ identifies previously unknown optimization opportunities that are both significant and targeted. Guided by COZ, we improve the performance of Memcached by 9%, SQLite by 25%, and accelerate six PARSEC applications by as much as 68%; in most cases, these optimizations involve modifying under 10 lines of code.",,86,0,repositoryam,Green,NSF,CCF-1012195,National Science Foundation,SOSP Operating Systems
2-s2.0-84957575155,10.1145/2723372.2737792,,,"DBSCAN revisited: Mis-claim, un-fixability, and approximation.",cp,Conference Paper,Gan J.,60002798,Chinese University of Hong Kong,Hong Kong,Hong Kong,2,"Gan, Junhao;Tao, Yufei",57102706500;7402420191,60002798;60002798,2015-05-27,27 May 2015,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,2015-May,,,519-530,"DBSCAN is a popular method for clustering multi-dimensional objects. Just as notable as the method's vast success is the research community's quest for its efficient computation. The original KDD'96 paper claimed an algorithm with O(n log n) running time, where n is the number of objects. Unfortunately, this is a mis-claim; and that algorithm actually requires O(n2) time. There has been a fix in 2D space, where a genuine O(n log n)-time algorithm has been found. Looking for a fix for dimensionality d ≥ 3 is currently an important open problem. In this paper, we prove that for d ≥ 3, the DBSCAN problem requires Ω(n4/3) time to solve, unless very significant breakthroughs.ones widely believed to be impossible.could be made in theoretical computer science. This (i) explains why the community's search for fixing the aforementioned mis-claim has been futile for d ≥ 3, and (ii) indicates (sadly) that all DBSCAN algorithms must be intolerably slow even on moderately large n in practice. Surprisingly, we show that the running time can be dramatically brought down to O(n) in expectation regardless of the dimensionality d, as soon as slight inaccuracy in the clustering results is permitted. We formalize our findings into the new notion of ρ-approximate DBSCAN, which we believe should replace DBSCAN on big data due to the latter's computational intractability.",Algorithm | DBSCAN | Density-based clustering,184,0,,,,undefined,,SIGMOD Databases
2-s2.0-84973896955,10.1109/ICCV.2015.172,,,Deep neural decision forests,cp,Conference Paper,Kontschieder P.,60098463;60083112;60027950,Microsoft Research Cambridge;Bruno Kessler Foundation;Carnegie Mellon University,Cambridge;Trento;Pittsburgh,United Kingdom;Italy;United States,4,"Kontschieder, Peter;Fiterau, Madalina;Criminisi, Antonio;Bulo, Samuel Rota",36622256000;35867893700;6603756861;15622916500,60098463;60027950;60098463;60098463-60083112,2015-02-17,17 February 2015,Proceedings of the IEEE International Conference on Computer Vision,15505499,110561,,Conference Proceeding,"2015 International Conference on Computer Vision, ICCV 2015",,7410529,1467-1475,"We present Deep Neural Decision Forests - a novel approach that unifies classification trees with the representation learning functionality known from deep convolutional networks, by training them in an end-to-end manner. To combine these two worlds, we introduce a stochastic and differentiable decision tree model, which steers the representation learning usually conducted in the initial layers of a (deep) convolutional network. Our model differs from conventional deep networks because a decision forest provides the final predictions and it differs from conventional decision forests since we propose a principled, joint and global optimization of split and leaf node parameters. We show experimental results on benchmark machine learning datasets like MNIST and ImageNet and find on-par or superior results when compared to state-of-the-art deep models. Most remarkably, we obtain Top5-Errors of only 7.84%/6.38% on ImageNet validation data when integrating our forests in a single-crop, single/seven model GoogLeNet architecture, respectively. Thus, even without any form of training data set augmentation we are improving on the 6.67% error obtained by the best GoogLeNet architecture (7 models, 144 crops).",,334,0,,,,undefined,,ICCV Computer Vision
2-s2.0-84966784718,,,,Designing distributed systems using approximate synchrony in data center networks,cp,Conference Paper,Ports D.R.K.,60015481,University of Washington,Seattle,United States,5,"Ports, Dan R.K.;Li, Jialin;Liu, Vincent;Sharma, Naveen Kr;Krishnamurthy, Arvind",13009197800;56429011800;54684321900;55413605600;7005516119,60015481;60015481;60015481;60015481;60015481,2015-01-01,2015,"Proceedings of the 12th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2015",,21100457899,,Conference Proceeding,,,,43-57,"Distributed systems are traditionally designed independently from the underlying network, making worst-case assumptions (e.g., complete asynchrony) about its behavior. However, many of today's distributed applications are deployed in data centers, where the network is more reliable, predictable, and extensible. In these environments, it is possible to co-design distributed systems with their network layer, and doing so can offer substantial benefits. This paper explores network-level mechanisms for providing Mostly-Ordered Multicast (MOM): a best-effort ordering property for concurrent multicast operations. Using this primitive, we design Speculative Paxos, a state machine replication protocol that relies on the network to order requests in the normal case. This approach leads to substantial performance benefits: under realistic data center conditions, Speculative Paxos can provide 40% lower latency and 2.6× higher throughput than the standard Paxos protocol. It offers lower latency than a latencyoptimized protocol (Fast Paxos) with the same throughput as a throughput-optimized protocol (batching).",,85,0,,,,undefined,,NSDI Networking
2-s2.0-84951044754,10.1145/2702123.2702403,,,Designing political deliberation environments to support interactions in the public sphere,cp,Conference Paper,Semaan B.,60151330;60142654;60118345;60013791,Department of Information and Computer Sciences;Donald Bren School of Information &amp; Computer Sciences;School of Information Studies;University of Hawaiʻi at Mānoa,Honolulu;Irvine;Syracuse;Honolulu,United States;United States;United States;United States,5,"Semaan, Bryan;Faucett, Heather;Robertson, Scott P.;Maruyama, Misa;Douglas, Sara",27868197800;56122799600;35220420400;55322137100;57212698182,60118345;60142654;60151330;60013791;60013791,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,3167-3176,"Little is known about the challenges and successes people face when piecing together multiple social media to interact in the online public sphere when: Seeking information, disseminating information, and engaging in political discussions. We interviewed 29 US citizens and conducted 17 talk-out-loud sessions with people who were using one or more social media technologies, such as Facebook and Twitter, to interact in the online public sphere. We identified a number of challenges and workarounds related to public sphere interactions, and used our findings to formulate requirements for new political environments that support the interactions in the public sphere. Through evolving requirements generation, we developed a new political deliberation technology, dubbed Poli, which is an integrated social media environment with the potential to enable more effective interactions in the public sphere. We discuss several remaining questions and limitations to our tool that will drive future work.",Design | Political deliberation | Public sphere | Social media,51,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84951849440,10.1145/2737924.2738009,,,Diagnosing type errors with class,cp,Conference Paper,Zhang D.,60278093;60098463,Cornell Ann S. Bowers College of Computing and Information Science;Microsoft Research Cambridge,Ithaca;Cambridge,United States;United Kingdom,4,"Zhang, Danfeng;Myers, Andrew C.;Vytiniotis, Dimitrios;Peyton-Jones, Simon",36669774100;7202743179;8847084300;8328527700,60278093;60278093;60098463;60098463,2015-06-03,3 June 2015,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,2015-June,,,12-21,"Type inference engines often give terrible error messages, and the more sophisticated the type system the worse the problem. We show that even with the highly expressive type system implemented by the Glasgow Haskell Compiler (GHC)-including type classes, GADTs, and type families-it is possible to identify the most likely source of the type error, rather than the first source that the inference engine trips over. To determine which are the likely error sources, we apply a simple Bayesian model to a graph representation of the typing constraints; the satisfiability or unsatisfiability of paths within the graph provides evidence for or against possible explanations. While we build on prior work on error diagnosis for simpler type systems, inference in the richer type system of Haskell requires extending the graph with new nodes. The augmentation of the graph creates challenges both for Bayesian reasoning and for ensuring termination. Using a large corpus of Haskell programs, we show that this error localization technique is practical and significantly improves accuracy over the state of the art.",Error diagnosis | Haskell | Type inference,18,0,repositoryam,Green,,CCF-0964409,,PLDI Programming Languages
2-s2.0-84958227024,10.1109/CVPR.2015.7298631,,,DynamicFusion: Reconstruction and tracking of non-rigid scenes in real-time,cp,Conference Paper,Newcombe R.A.,60015481,University of Washington,Seattle,United States,3,"Newcombe, Richard A.;Fox, Dieter;Seitz, Steven M.",36445070000;7402074129;7004774929,60015481;60015481;60015481,2015-10-14,14 October 2015,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,07-12-June-2015,,7298631,343-352,"We present the first dense SLAM system capable of reconstructing non-rigidly deforming scenes in real-time, by fusing together RGBD scans captured from commodity sensors. Our DynamicFusion approach reconstructs scene geometry whilst simultaneously estimating a dense volumetric 6D motion field that warps the estimated geometry into a live frame. Like KinectFusion, our system produces increasingly denoised, detailed, and complete reconstructions as more measurements are fused, and displays the updated model in real time. Because we do not require a template or other prior scene model, the approach is applicable to a wide range of moving objects and scenes.",,731,0,,,,undefined,,CVPR Computer Vision
2-s2.0-84960380012,10.1145/2786805.2786818,,,Effective test suites for mixed discrete-continuous stateflow controllers,cp,Conference Paper,Matinnejad R.,60072562;118240404,University of Luxembourg;Delphi Automotive Systems,Esch-sur-Alzette;Luxembourg,Luxembourg;Luxembourg,4,"Matinnejad, Reza;Nejati, Shiva;Briand, Lionel C.;Bruckmann, Thomas",54407157800;18038340600;7006613079;55871375400,60072562;60072562;60072562;118240404,2015-08-30,30 August 2015,"2015 10th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE 2015 - Proceedings",,21100450024,,Conference Proceeding,,,,84-95,"Modeling mixed discrete-continuous controllers using Stateflow is common practice and has a long tradition in the embedded software system industry. Testing Stateflow models is complicated by expensive and manual test oracles that are not amenable to full automation due to the complex continuous behaviors of such models. In this paper, we reduce the cost of manual test oracles by providing test case selection algorithms that help engineers develop small test suites with high fault revealing power for Stateflow models. We present six test selection algorithms for discrete-continuous Stateflows: An adaptive random test selection algorithm that diversifies test inputs, two white-box coverage-based algorithms, a black-box algorithm that diversifies test outputs, and two search-based blackbox algorithms that aim to maximize the likelihood of presence of continuous output failure patterns. We evaluate and compare our test selection algorithms, and find that our three output-based algorithms consistently outperform the coverage- And input-based algorithms in revealing faults in discrete-continuous Stateflow models. Further, we show that our output-based algorithms are complementary as the two search-based algorithms perform best in revealing specific failures with small test suites, while the output diversity algorithm is able to identify different failure types better than other algorithms when test suites are above a certain size.",Failure-based testing | Mixed discrete-continuous behaviors | Output diversity | Stateflow testing | Structural coverage,26,0,,,,undefined,,FSE Software Engineering
2-s2.0-84954171111,10.1145/2783258.2783354,,,Efficient algorithms for public-private social networks,cp,Conference Paper,Chierichetti F.,60032350;60011460;60006191,Sapienza Università di Roma;Brown University;Google LLC,Rome;Providence;Mountain View,Italy;United States;United States,5,"Chierichetti, Flavio;Epasto, Alessandro;Kumar, Ravi;Lattanzi, Silvio;Mirrokni, Vahab",22937002700;55815902000;7406018609;24081026500;6602331710,60032350;60011460;60006191;60006191;60006191,2015-08-10,10 August 2015,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,101510,,Conference Proceeding,2015-August,,,139-148,"We introduce the public-private model of graphs. In this model, we have a public graph and each node in the public graph has an associated private graph. The motivation for studying this model stems from social networks, where the nodes are the users, the public graph is visible to everyone, and the private graph at each node is visible only to the user at the node. From each node's viewpoint, the graph is just a union of its private graph and the public graph. We consider the problem of efficiently computing various properties of the graphs from each node's point of view, with minimal amount of recomputation on the public graph. To illustrate the richness of our model, we explore two powerful computational paradigms for studying large graphs, namely, sketching and sampling, and focus on some key problems in social networks and show efficient algorithms in the public-private graph model. In the sketching model, we show how to efficiently approximate the neighborhood function, which in turn can be used to approximate various notions of centrality. In the sampling model, we focus on all-pair shortest path distances, node similarities, and correlation clustering.",Graph algorithms | Privacy | Social networks,24,1,publisherfree2read,Bronze,,undefined,,KDD Data Mining
2-s2.0-84958774397,10.1145/2746539.2746572,,,Exponential separation of information and communication for boolean functions,cp,Conference Paper,Ganor A.,60027485;60017563,Institute for Advanced Study;Weizmann Institute of Science Israel,Princeton;Rehovot,United States;Israel,3,"Ganor, Anat;Kol, Gillat;Raz, Ran",56464186100;23967597300;7102829173,60017563;60027485;60017563-60027485,2015-06-14,14 June 2015,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,14-17-June-2015,,,557-566,"We show an exponential gap between communication complexity and information complexity for boolean functions, by giving an explicit example of a partial function with information complexity ≤ O(k), and distributional communication complexity ≥ 2k. This shows that a communication protocol for a partial boolean function cannot always be compressed to its internal information. By a result of Braverman [3], our gap is the largest possible. By a result of Braverman and Rao [4], our example shows a gap between communication complexity and amortized communication complexity, implying that a tight direct sum result for distributional communication complexity of boolean functions cannot hold, answering a long standing open problem. Our techniques build on [13], that proved a similar result for relations with very long outputs (double exponentially long in k). In addition to the stronger result, the current work gives a simpler proof, benefiting from the short output length of boolean functions. Another (conceptual) contribution of our work is the relative discrepancy method, a new rectangle-based method for proving communication complexity lower bounds for boolean functions, powerful enough to separate information complexity and communication complexity.",Amortized communication complexity | Communication complexity | Communication compression | Direct sum | Information complexity,20,0,,,ISF,1402/14,Israel Science Foundation,STOC Theory
2-s2.0-84965105869,,,,Fast convergence of regularized learning in games,cp,Conference Paper,Syrgkanis V.,60021726;60003269,Microsoft Research;Princeton University,Redmond;Princeton,United States;United States,4,"Syrgkanis, Vasilis;Agarwal, Alekh;Luo, Haipeng;Schapire, Robert E.",36722250400;14831143400;56167826900;7003469333,60021726;60021726;60003269;60021726,2015-01-01,2015,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,2015-January,,,2989-2997,"We show that natural classes of regularized learning algorithms with a form of recency bias achieve faster convergence rates to approximate efficiency and to coarse correlated equilibria in multiplayer normal form games. When each player in a game uses an algorithm from our class, their individual regret decays at O(T-3/4), while the sum of utilities converges to an approximate optimum at O(T-1)-an improvement upon the worst case O(T-1/2) rates. We show a blackbox reduction for any algorithm in the class to achieve Õ (T-1/2) rates against an adversary, while maintaining the faster rates against algorithms in the class. Our results extend those of Rakhlin and Shridharan [17] and Daskalakis et al. [4], who only analyzed two-player zero-sum games for specific algorithms.",,108,0,,,,undefined,,NeurIPS Machine Learning
2-s2.0-84950978653,10.1145/2702123.2702231,,,Fluid grouping: Quantifying group engagement around interactive tabletop exhibits in the wild,cp,Conference Paper,Block F.,60077572;60026306;60025778;60019788;60019674;60014717;60007363;101888213,"Harvard John A. Paulson School of Engineering and Applied Sciences;University of Nebraska–Lincoln;University of Michigan, Ann Arbor;University of Nebraska State Museum;Boston University;Marywood University;Northwestern University;TERC",Cambridge;Lincoln;Ann Arbor;Lincoln;Boston;Scranton;Evanston;Tempe,United States;United States;United States;United States;United States;United States;United States;United States,9,"Block, Florian;Hammerman, James;Horn, Michael;Spiegel, Amy;Christiansen, Jonathan;Phillips, Brenda;Diamond, Judy;Evans, E. Margaret;Shen, Chia",22333857300;35769385300;35931772700;36934183300;57014295900;55247710900;7201899724;7401611742;8594330100,60077572;101888213;60007363;60026306;60014717;60019674;60019788;60025778;60077572,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,867-876,"Interactive surfaces are increasingly common in museums and other informal learning environments where they are seen as a medium for promoting social engagement. However, despite their increasing prevalence, we know very little about factors that contribute to collaboration and learning around interactive surfaces. In this paper we present analyses of visitor engagement around several multi-touch tabletop science exhibits. Observations of 629 visitors were collected through two widely used techniques: Video study and shadowing. We make four contributions: 1) we present an algorithm for identifying groups within a dynamic flow of visitors through an exhibit hall; 2) we present measures of group-level engagement along with methods for statistically analyzing these measures; 3) we assess the effect of observational techniques on visitors' engagement, demonstrating that consented video studies do not necessarily reflect visitor behavior in more naturalistic circumstances; and 4) we present an analysis showing that groups of two, groups with both children and adults, and groups that take turns spend longer at the exhibits and engage more with scientific concepts.",Learning | Multi-touch tabletops | Museums | Quantitative methods,46,0,,,EHR,1010889,Directorate for Education and Human Resources,CHI Human-Computer Interaction
2-s2.0-84959309045,10.1145/2807442.2807494,,,Foldio: Digital fabrication of interactive and shape-changing objects with foldable printed electronics,cp,Conference Paper,Olberding S.,60000256,Max Planck Institute for Informatics,Saarbrucken,Germany,4,"Olberding, Simon;Ortega, Sergio Soto;Hildebrandt, Klaus;Steimle, Jürgen",36603168700;57143985600;6701493600;24825371700,60000256;60000256;60000256;60000256,2015-11-05,5 November 2015,UIST 2015 - Proceedings of the 28th Annual ACM Symposium on User Interface Software and Technology,,21100446436,,Conference Proceeding,,,,223-232,"Foldios are foldable interactive objects with embedded input sensing and output capabilities. Foldios combine the advantages of folding for thin, lightweight and shape-changing objects with the strengths of thin-film printed electronics for embedded sensing and output. To enable designers and end-users to create highly custom interactive foldable objects, we contribute a new design and fabrication approach. It makes it possible to design the foldable object in a standard 3D environment and to easily add interactive high-level controls, eliminating the need to manually design a fold pattern and low-level circuits for printed electronics. Second, we contribute a set of printable user interface controls for touch input and display output on folded objects. Moreover, we contribute controls for sensing and actuation of shape-changeable objects. We demonstrate the versatility of the approach with a variety of interactive objects that have been fabricated with this framework.",Digital fabrication | Folding | Input sensing | Paper computing | Printed electronics | Rapid prototyping | Shape displays | Shape-changing interfaces | Thin-film actuator,107,0,,,,undefined,,UIST User Interface
2-s2.0-84961214742,,,,From non-negative to general operator cost partitioning,cp,Conference Paper,Pommerening F.,60023588,Universität Basel,Basel,Switzerland,4,"Pommerening, Florian;Helmert, Malte;Röger, Gabriele;Seipp, Jendrik",35485066600;57203118510;23009803800;55361565700,60023588;60023588;60023588;60023588,2015-06-01,1 June 2015,Proceedings of the National Conference on Artificial Intelligence,,78337,,Conference Proceeding,5,,,3335-3341,Operator cost partitioning is a well-known technique to make admissible heuristics additive by distributing the operator costs among individual heuristics. Planning tasks are usually defined with non-negative operator costs and therefore it appears natural to demand the same for the distributed costs. We argue that this requirement is not necessary and demonstrate the benefit of using general cost partitioning. We show that LP heuristics for operator-counting constraints are cost-partitioned heuristics and that the state equation heuristic computes a cost partitioning over atomic projections. We also introduce a new family of potential heuristics and show their relationship to general cost partitioning.,,60,0,,,SNSF,undefined,Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung,AAAI Artificial Intelligence
2-s2.0-84951070652,10.1145/2702123.2702412,,,From user-centered to adoption-centered design: A case study of an HCI research innovation becoming a product,cp,Conference Paper,Chilana P.K.,60015481;60014171,University of Washington;University of Waterloo,Seattle;Waterloo,United States;Canada,3,"Chilana, Parmit K.;Ko, Andrew J.;Wobbrock, Jacob O.",35069141700;7007018374;6603152369,60014171;60015481;60015481,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,1749-1758,"As we increasingly strive for scientific rigor and generalizability in HCI research, should we entertain any hope that by doing good science, our discoveries will eventually be more transferrable to industry? We present an in-depth case study of how an HCI research innovation goes through the process of transitioning from a university project to a revenue- Generating startup financed by venture capital. The innovation is a novel contextual help system for the Web, and we reflect on the different methods used to evaluate it and how research insights endure attempted dissemination as a commercial product. Although the extent to which any innovation succeeds commercially depends on a number of factors like market forces, we found that our HCI innovation with user-centered origins was in a unique position to gain traction with customers and garner buy-in from investors. However, since end users were not the buyers of our product, a strong user-centered focus obfuscated other critical needs of the startup and pushed out perspectives of nonuser- Centered stakeholders. To make the research-toproduct transition, we had to focus on adoption-centered design, the process of understanding and designing for adopters and stakeholders of the product. Our case study raises questions about how we evaluate the novelty and research contributions of HCI innovations with respect to their potential for commercial impact.",Adoption-centered design | Commercialization | Dissemination | Productization | Research impact | Technology transfer,42,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84951764091,10.1109/ICSE.2015.54,,,How much up-front? A grounded theory of agile architecture,cp,Conference Paper,Waterman M.,60002316;116155762,Victoria University of Wellington;Specialised Architecture Services Ltd,Wellington;Wellington,New Zealand;New Zealand,3,"Waterman, Michael;Noble, James;Allan, George",57197480842;7202238195;7202156426,116155762;60002316;60002316,2015-08-12,12 August 2015,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,1,,7194587,347-357,"The tension between software architecture and agility is not well understood by agile practitioners or researchers. If an agile software team spends too little time designing architecture up-front then the team faces increased risk and higher chance of failure; if the team spends too much time the delivery of value to the customer is delayed, and responding to change can become extremely difficult. This paper presents a grounded theory of agile architecture that describes how agile software teams answer the question of how much upfront architecture design effort is enough. This theory, based on grounded theory research involving 44 participants, presents six forces that affect the team's context and five strategies that teams use to help them determine how much effort they should put into up-front design.",,43,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-84960466779,10.1145/2786805.2786809,,,How practitioners perceive the relevance of software engineering research,cp,Conference Paper,Lo D.,60021726;60018933,Microsoft Research;Singapore Management University,Redmond;Singapore City,United States;Singapore,3,"Lo, David;Nagappan, Nachiappan;Zimmermann, Thomas",35269388000;8261920700;16308551800,60018933;60021726;60021726,2015-08-30,30 August 2015,"2015 10th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE 2015 - Proceedings",,21100450024,,Conference Proceeding,,,,415-425,"The number of software engineering research papers over the last few years has grown significantly. An important question here is: how relevant is software engineering research to practitioners in the field? To address this question, we conducted a survey at Microsoft where we invited 3,000 industry practitioners to rate the relevance of research ideas contained in 571 ICSE, ESEC/FSE and FSE papers that were published over a five year period. We received 17,913 ratings by 512 practitioners who labelled ideas as essential, worthwhile, unimportant, or unwise. The results from the survey suggest that practitioners are positive towards studies done by the software engineering research community: 71% of all ratings were essential or worthwhile. We found no correlation between the citation counts and the relevance scores of the papers. Through a qualitative analysis of free text responses, we identify several reasons why practitioners considered certain research ideas to be unwise. The survey approach described in this paper is lightweight: on average, a participant spent only 22.5 minutes to respond to the survey. At the same time, the results can provide useful insight to conference organizers, authors, and participating practitioners.",Industry | Software engineering research | Survey,96,0,repositoryvor,Green,,undefined,,FSE Software Engineering
2-s2.0-84968820466,10.1145/2736277.2741080,,,HypTrails: A Bayesian approach for comparing hypotheses about human trails on the web,cp,Conference Paper,Singer P.,60019663;60012689;60006429,Technische Universitat Graz;Julius-Maximilians-Universität Würzburg;Universität Koblenz-Landau,Graz;Wurzburg;Koblenz,Austria;Germany;Germany,4,"Singer, Philipp;Helic, Denis;Hotho, Andreas;Strohmaier, Markus",55317172300;6506005845;8227931000;57205900668,60019663;60019663;60012689;60006429,2015-05-18,18 May 2015,WWW 2015 - Proceedings of the 24th International Conference on World Wide Web,,21100461371,,Conference Proceeding,,,,1003-1013,"When users interact with theWeb today, they leave sequential digital trails on a massive scale. Examples of such human trails include Web navigation, sequences of online restaurant reviews, or online music play lists. Understanding the factors that drive the production of these trails can be useful for e.g., improving underlying network structures, predicting user clicks or enhancing recommendations. In this work, we present a general approach called HypTrails for comparing a set of hypotheses about human trails on theWeb, where hypotheses represent beliefs about transitions between states. Our approach utilizes Markov chain models with Bayesian inference. The main idea is to incorporate hypotheses as informative Dirichlet priors and to leverage the sensitivity of Bayes factors on the prior for comparing hypotheses with each other. For eliciting Dirichlet priors from hypotheses, we present an adaption of the so-called (trial) roulette method. We demonstrate the general mechanics and applicability of HypTrails by performing experiments with (i) synthetic trails for which we control the mechanisms that have produced them and (ii) empirical trails stemming from different domains including website navigation, business reviews and online music played. Our work expands the repertoire of methods available for studying human trails on the Web.",Bayesian Statistics | Human Trails | Hypotheses | Markov Chain | Paths | Sequences | Sequential Human Behavior | Web,45,0,repositoryam,Green,DFG,196648487,Deutsche Forschungsgemeinschaft,WWW World Wide Web
2-s2.0-84943798555,10.3115/v1/p15-1174,,,Improving evaluation of machine translation quality estimation,cp,Conference Paper,Graham Y.,60011149,Trinity College Dublin,Dublin,Ireland,1,"Graham, Yvette",55032504500,60011149,2015-01-01,2015,"ACL-IJCNLP 2015 - 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, Proceedings of the Conference",,21100415618,,Conference Proceeding,1,,,1804-1813,"Quality estimation evaluation commonly takes the form of measurement of the error that exists between predictions and gold standard labels for a particular test set of translations. Issues can arise during comparison of quality estimation prediction score distributions and gold label distributions, however. In this paper, we provide an analysis of methods of comparison and identify areas of concern with respect to widely used measures, such as the ability to gain by prediction of aggregate statistics specific to gold label distributions or by optimally conservative variance in prediction score distributions. As an alternative, we propose the use of the unit-free Pearson correlation, in addition to providing an appropriate method of significance testing improvements over a baseline. Components ofWMT-13 andWMT-14 quality estimation shared tasks are replicated to reveal substantially increased conclusivity in system rankings, including identification of outright winners of tasks.",,35,1,publisherhybridgold,Hybrid Gold,,undefined,,ACL Natural Language Processing
2-s2.0-84943756278,10.3115/v1/p15-1015,,,Learning dynamic feature selection for fast sequential prediction,cp,Conference Paper,Strubell E.,60152130,Manning College of Information &amp; Computer Sciences,Amherst,United States,4,"Strubell, Emma;Vilnis, Luke;Silverstein, Kate;McCallum, Andrew",56898917300;56896163100;56898772300;7003773569,60152130;60152130;60152130;60152130,2015-01-01,2015,"ACL-IJCNLP 2015 - 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, Proceedings of the Conference",,21100415618,,Conference Proceeding,1,,,146-155,"We present paired learning and inference algorithms for significantly reducing computation and increasing speed of the vector dot products in the classifiers that are at the heart of many NLP components. This is accomplished by partitioning the features into a sequence of templates which are ordered such that high confidence can often be reached using only a small fraction of all features. Parameter estimation is arranged to maximize accuracy and early confidence in this sequence. Our approach is simpler and better suited to NLP than other related cascade methods. We present experiments in left-to-right part-of-speech tagging, named entity recognition, and transition-based dependency parsing. On the typical benchmarking datasets we can preserve POS tagging accuracy above 97% and parsing LAS above 88.5% both with over a five-fold reduction in run-time, and NER F1 above 88 with more than 2x increase in speed.",,8,1,repositoryam,Green,CISE,0958392,Directorate for Computer and Information Science and Engineering,ACL Natural Language Processing
2-s2.0-84951128822,10.1145/2702123.2702172,,,Lightweight relief shearing for enhanced terrain perception on interactive maps,cp,Conference Paper,Willett W.,60013402;60002306,Oregon State University;University of Calgary,Corvallis;Calgary,United States;Canada,4,"Willett, Wesley;Jenny, Bernhard;Isenberg, Tobias;Dragicevic, Pierre",22958981500;36447460000;6506341607;55906779900,60002306;60013402;;,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,3563-3572,"We explore interactive relief shearing, a set of non-intrusive, direct manipulation interactions that expose depth and shape information in terrain maps using ephemeral animations. Reading and interpreting topography and relief on terrain maps is an important aspect of map use, but extracting depth information from 2D maps is notoriously difficult. Modern mapping software attempts to alleviate this limitation by presenting digital terrain using 3D views. However, 3D views introduce occlusion, complicate distance estimations, and typically require more complex interactions. In contrast, our approach reveals depth information via shearing animations on 2D maps, and can be paired with existing interactions such as pan and zoom. We examine explicit, integrated, and hybrid interactions for triggering relief shearing and present a version that uses device tilt to control depth effects. Our evaluation shows that these interactive techniques improve depth perception when compared to standard 2D and perspective views.",Depth perception | Interaction | Plan oblique relief | Relief shearing | Terrain maps,34,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84958760481,10.1145/2746539.2746599,,,Lower bounds on the size of semidefinite programming relaxations,cp,Conference Paper,Lee J.R.,60025038;60015481,"University of California, Berkeley;University of Washington",Berkeley;Seattle,United States;United States,3,"Lee, James R.;Raghavendra, Prasad;Steurer, David",7601476272;23390082900;24512792300,60015481;60025038;,2015-06-14,14 June 2015,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,14-17-June-2015,,,567-576,"We introduce a method for proving lower bounds on the efficacy of semidefinite programming (SDP) relaxations for combinatorial problems. In particular, we show that the cut, TSP, and stable set polytopes on n-vertex graphs are not the linear image of the feasible region of any SDP (i.e., any spectrahedron) of dimension less than 2nδ , for some constant δ > 0. This result yields the first super-polynomial lower bounds on the semidefinite extension complexity of any explicit family of polytopes. Our results follow from a general technique for proving lower bounds on the positive semidefinite rank of a matrix. To this end, we establish a close connection between arbitrary SDPs and those arising from the sum-of-squares SDP hierarchy. For approximating maximum constraint satisfaction problems, we prove that SDPs of polynomial-size are equivalent in power to those arising from degree-O(1) sum-of-squares relaxations. This result implies, for instance, that no family of polynomial-size SDP relaxations can achieve better than a 7/8-approximation for max 3-sat.",Approximation complexity | Lower bounds on positive-semidefinite rank | Polynomial optimization | Quantum learning | Semidefinite programming | Sum-of-squares method,123,0,repositoryam,Green,CISE,1407779,Directorate for Computer and Information Science and Engineering,STOC Theory
2-s2.0-84960421324,10.1145/2786805.2786848,,,Measure it? Manage it? Ignore it? Software practitioners and technical debt,cp,Conference Paper,Ernst N.A.,60141178;60076258,Khoury College of Computer Sciences;Software Engineering Institute,Boston;Pittsburgh,United States;United States,5,"Ernst, Neil A.;Bellomo, Stephany;Ozkaya, Ipek;Nord, Robert L.;Gorton, Ian",16835944600;24511988000;22981245900;7003525991;35588730100,60076258;60076258;60076258;60076258;60141178,2015-08-30,30 August 2015,"2015 10th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE 2015 - Proceedings",,21100450024,,Conference Proceeding,,,,50-60,"The technical debt metaphor is widely used to encapsulate numerous software quality problems. The metaphor is attractive to practitioners as it communicates to both technical and nontechnical audiences that if quality problems are not addressed, things may get worse. However, it is unclear whether there are practices that move this metaphor beyond a mere communication mechanism. Existing studies of tech- nical debt have largely focused on code metrics and small surveys of developers. In this paper, we report on our survey of 1,831 participants, primarily software engineers and architects working in long-lived, software-intensive projects from three large organizations, and follow-up interviews of seven software engineers. We analyzed our data using both nonparametric statistics and qualitative text analysis. We found that architectural decisions are the most important source of technical debt. Furthermore, while respondents believe the metaphor is itself important for communication, existing tools are not currently helpful in managing the de- Tails. We use our results to motivate a technical debt time- line to focus management and tooling approaches.",Architecture | Survey | Technical debt,173,0,,,,undefined,,FSE Software Engineering
2-s2.0-84960338841,10.1145/2786805.2786838,,,Modeling readability to improve unit tests,cp,Conference Paper,Daka E.,60021918;60001881,University of Virginia;The University of Sheffield,Charlottesville;Sheffield,United States;United Kingdom,5,"Daka, Ermira;Campos, José;Fraser, Gordon;Dorn, Jonathan;Weimer, Westley",56610178300;35306564600;9247521200;56104113700;7003629741,60001881;60001881;60001881;60021918;60021918,2015-08-30,30 August 2015,"2015 10th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE 2015 - Proceedings",,21100450024,,Conference Proceeding,,,,107-118,"Writing good unit tests can be tedious and error prone, but even once they are written, the job is not done: Developers need to reason about unit tests throughout software development and evolution, in order to diagnose test failures, maintain the tests, and to understand code written by other developers. Unreadable tests are more difficult to maintain and lose some of their value to developers. To overcome this problem, we propose a domain-specific model of unit test readability based on human judgements, and use this model to augment automated unit test generation. The resulting approach can automatically generate test suites with both high coverage and also improved readability. In human studies users prefer our improved tests and are able to answer maintenance questions about them 14% more quickly at the same level of accuracy.",Automated test generation | Readability | Unit testing,89,0,,,NSF,CCF 0905373,National Science Foundation,FSE Software Engineering
2-s2.0-84960421710,10.1145/2786805.2786830,,,MultiSE: Multi-path symbolic execution using value summaries,cp,Conference Paper,Sen K.,60025038,"University of California, Berkeley",Berkeley,United States,4,"Sen, Koushik;Necula, George;Gong, Liang;Choi, Wontae",8226489200;6603766231;42161300700;55936808000,60025038;60025038;60025038;60025038,2015-08-30,30 August 2015,"2015 10th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE 2015 - Proceedings",,21100450024,,Conference Proceeding,,,,842-853,"Dynamic symbolic execution (DSE) has been proposed to effectively generate test inputs for real-world programs. Un- fortunately, DSE techniques do not scale well for large realis- Tic programs, because often the number of feasible execution paths of a program increases exponentially with the increase in the length of an execution path. In this paper, we propose MultiSE, a new technique for merging states incrementally during symbolic execution, without using auxiliary variables. The key idea of MultiSE is based on an alternative representation of the state, where we map each variable, including the program counter, to a set of guarded symbolic expressions called a value summary. MultiSE has several advantages over conventional DSE and conventional state merging techniques: value summaries en- Able sharing of symbolic expressions and path constraints along multiple paths and thus avoid redundant execution. MultiSE does not introduce auxiliary symbolic variables, which enables it to 1) make progress even when merging values not supported by the constraint solver, 2) avoid ex- pensive constraint solver calls when resolving function calls and jumps, and 3) carry out most operations concretely. Moreover, MultiSE updates value summaries incrementally at every assignment instruction, which makes it unnecessary to identify the join points and to keep track of variables to merge at join points. We have implemented MultiSE for JavaScript programs in a publicly available open-source tool. Our evaluation of MultiSE on several programs shows that 1) value summaries are an effective technique to take advantage of the sharing of value along multiple execution path, that 2) MultiSE can run significantly faster than traditional dynamic symbolic execution and, 3) MultiSE saves a substantial number of state merges compared to conventional state-merging techniques.",Concolic testing | Jalangi | Javascript | Multise | Symbolic execution | Test generation | Value summary,84,0,,,NSF,CCF-0747390,National Sleep Foundation,FSE Software Engineering
2-s2.0-84969932744,,,,Optimal and adaptive algorithms for online boosting,cp,Conference Paper,Beygelzimer A.,60141284;60075274,School of Engineering and Applied Science;Yahoo Research Labs,Princeton;Sunnyvale,United States;United States,3,"Beygelzimer, Alina;Kale, Satyen;Luo, Haipeng",8730222100;8336981400;56167826900,60075274;60075274;60141284,2015-01-01,2015,"32nd International Conference on Machine Learning, ICML 2015",,21100358099,,Conference Proceeding,3,,,2313-2321,"We study online boosting, the task of converting any weak online learner into a strong online learner. Based on a novel and natural definition of weak online learnability, we develop two online boosting algorithms. The first algorithm is an online version of boost-by-majority. By proving a matching lower bound, we show that this algorithm is essentially optimal in terms of the number of weak learners and the sample complexity needed to achieve a specified accuracy. The second algorithm is adaptive and parameter-free, albeit not optimal.",,50,0,,,,undefined,,ICML Machine Learning
2-s2.0-84960361827,10.1145/2786805.2786847,,,Optimizing energy consumption of GUIs in android apps: A multi-objective approach,cp,Conference Paper,Linares-Vásquez M.,60016114;60014096;60009914;60004300,William &amp; Mary;Università degli Studi del Molise;Free University of Bozen-Bolzano;Università degli Studi del Sannio,Williamsburg;Campobasso;Bolzano;Benevento,United States;Italy;Italy;Italy,6,"Linares-Vásquez, Mario;Bavota, Gabriele;Bernal-Cárdenas, Carlos;Oliveto, Rocco;Di Penta, Massimiliano;Poshyvanyk, Denys",54684418100;57220148228;55848479200;15136561900;6602794138;13613571900,60016114;60009914;60016114;60014096;60004300;60016114,2015-08-30,30 August 2015,"2015 10th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE 2015 - Proceedings",,21100450024,,Conference Proceeding,,,,143-154,"The wide diffusion of mobile devices has motivated research towards optimizing energy consumption of software systems| including apps|targeting such devices. Besides efforts aimed at dealing with various kinds of energy bugs, the adoption of Organic Light-Emitting Diode (OLED) screens has mo- Tivated research towards reducing energy consumption by choosing an appropriate color palette. Whilst past research in this area aimed at optimizing energy while keeping an acceptable level of contrast, this paper proposes an approach, named GEMMA (Gui Energy Multi-objective optimization for Android apps), for generating color palettes using a multi- objective optimization technique, which produces color solutions optimizing energy consumption and contrast while using consistent colors with respect to the original color palette. An empirical evaluation that we performed on 25 Android apps demonstrates not only significant improvements in terms of the three different objectives, but also confirmed that in most cases users still perceived the choices of colors as attractive. Finally, for several apps we interviewed the original developers, who in some cases expressed the intent to adopt the proposed choice of color palette, whereas in other cases pointed out directions for future improvements.",Empirical study | Energy consumption | Mobile applications,66,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-84959282063,10.1145/2807442.2807499,,,Orbits: Gaze interaction for smart watches using smooth pursuit eye movements,cp,Conference Paper,Esteves A.,60023643;60000256,Lancaster University;Max Planck Institute for Informatics,Lancaster;Saarbrucken,United Kingdom;Germany,4,"Esteves, Augusto;Velloso, Eduardo;Bulling, Andreas;Gellersen, Hans",36674891300;53364337000;6505807414;6701531333,60023643;60023643;60000256;60023643,2015-11-05,5 November 2015,UIST 2015 - Proceedings of the 28th Annual ACM Symposium on User Interface Software and Technology,,21100446436,,Conference Proceeding,,,,457-466,"We introduce Orbits, a novel gaze interaction technique that enables hands-free input on smart watches. The technique relies on moving controls to leverage the smooth pursuit movements of the eyes and detect whether and at which control the user is looking at. In Orbits, controls include targets that move in a circular trajectory in the face of the watch, and can be selected by following the desired one for a small amount of time. We conducted two user studies to assess the technique?s recognition and robustness, which demonstrated how Orbits is robust against false positives triggered by natural eye movements and how it presents a hands-free, high accuracy way of interacting with smart watches using off-the-shelf devices. Finally, we developed three example interfaces built with Orbits: a music player, a notifications face plate and a missed call menu. Despite relying on moving controls ? very unusual in current HCI interfaces ? these were generally well received by participants in a third and final study.",Eye tracking | Gaze input | Gaze interaction | Pursuits | Small devices | Small displays | Smart watches | Wearable computing,168,0,,,,undefined,,UIST User Interface
2-s2.0-84955264933,10.1145/2745754.2745759,,,Parallel-Correctness and Transferability for Conjunctive Queries,cp,Conference Paper,Ameloot T.,60032991;60010413,Technische Universität Dortmund;Universiteit Hasselt,Dortmund;Hasselt,Germany;Belgium,5,"Ameloot, Tom J.;Geck, Gaetano;Ketsman, Bas;Neven, Frank;Schwentick, Thomas",42760965800;57074081500;56272656400;6701415938;56023744700,60010413;60032991;60010413;60010413;60032991,2015-05-20,20 May 2015,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,31,,,47-58,"A dominant cost for query evaluation in modern massively distributed systems is the number of communication rounds. For this reason, there is a growing interest in single-round multiway join algorithms where data is first reshuffled over many servers and then evaluated in a parallel but communication- free way. The reshuffling itself is specified as a distribution policy. We introduce a correctness condition, called parallel-correctness, for the evaluation of queries w.r.t. a distribution policy. We study the complexity of parallelcorrectness for conjunctive queries as well as transferability of parallel-correctness between queries. We also investigate the complexity of transferability for certain families of distribution policies, including, for instance, the Hypercube distribution.",Distributed databases | Distribution policies | One-round evaluation | Parallel query evaluation,11,0,repositoryam,Green,,undefined,,PODS Databases
2-s2.0-84951076066,10.1145/2702123.2702213,,,Patina engraver: Visualizing activity logs as patina in fashionable trackers,cp,Conference Paper,Lee M.H.,60032144,Korea Advanced Institute of Science and Technology,Daejeon,South Korea,3,"Lee, Moon Hwan;Cha, Seijin;Nam, Tek Jin",55734834500;56921271400;23397738200,60032144;60032144;60032144,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,1173-1182,"Despite technological improvements in commercial activity trackers, little attention has been given to their emotional, social, or fashion-related qualities, such as their visual aesthetics and their relationship to self-expression and social connection. As an alternative integrated approach incorporating HCI, fashion, and product design, our project made use of the characteristics of patina to improve activity trackers as fashionable wearables. We developed the Patina Engraving System, which engraves patina-like patterns on an activity tracker according to a user's activity logs. Using a piercing technique, the patina of activity logs has been made abstract, visually rich, gradually emerging, and historically accumulated. During the field trial, we found that the patina motivated the participants to increase exercises for engraving aesthetic patinas. A tracker with patina triggered spontaneous social interactions in face-to-face situations. The participants also cherished the trackers that held their own history. Based on the field trial, we discuss design implications for utilizing patina in designing future fashionable technologies.",Activity tracker | Digital fabrication | Fashion | Patina,28,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84957991492,10.1145/2815400.2815415,,,Pivot tracing: Dynamic causal monitoring for distributed systems,cp,Conference Paper,Mace J.,60011460,Brown University,Providence,United States,3,"Mace, Jonathan;Roelke, Ryan;Fonseca, Rodrigo",57113198400;57113517400;8872461200,60011460;60011460;60011460,2015-10-04,4 October 2015,SOSP 2015 - Proceedings of the 25th ACM Symposium on Operating Systems Principles,,21100446022,,Conference Proceeding,,,,378-393,"Monitoring and troubleshooting distributed systems is notoriously difficult; potential problems are complex, varied, and unpredictable. The monitoring and diagnosis tools commonly used today - logs, counters, and metrics - have two important limitations: what gets recorded is defined a priori, and the information is recorded in a component-or machine-centric way, making it extremely hard to correlate events that cross these boundaries. This paper presents Pivot Tracing, a monitoring framework for distributed systems that addresses both limitations by combining dynamic instrumentation with a novel relational operator: the happened-before join. Pivot Tracing gives users, at runtime, the ability to define arbitrary metrics at one point of the system, while being able to select, filter, and group by events meaningful at other parts of the system, even when crossing component or machine boundaries. We have implemented a prototype of Pivot Tracing for Java-based systems and evaluate it on a heterogeneous Hadoop cluster comprising HDFS, HBase, MapReduce, and YARN. We show that Pivot Tracing can effectively identify a diverse range of root causes such as software bugs, misconfiguration, and limping hardware. We show that Pivot Tracing is dynamic, extensible, and enables cross-tier analysis between inter-operating applications, with low execution overhead.",,141,0,,,CISE,1452712,Directorate for Computer and Information Science and Engineering,SOSP Operating Systems
2-s2.0-84951727613,10.1145/2737924.2737965,,,Provably correct peephole optimizations with Alive,cp,Conference Paper,Lopes N.P.,60119141;60025488;60021726,Rutgers University–New Brunswick;The University of Utah;Microsoft Research,New Brunswick;Salt Lake City;Redmond,United States;United States;United States,4,"Lopes, Nuno P.;Menendez, David;Nagarakatte, Santosh;Regehr, John",35078959800;55368755100;28167714800;6602188226,60021726;60119141;60119141;60025488,2015-06-03,3 June 2015,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,2015-June,,,22-32,"Compilers should not miscompile. Our work addresses problems in developing peephole optimizations that perform local rewriting to improve the efficiency of LLVM code. These optimizations are individually difficult to get right, particularly in the presence of undefined behavior; taken together they represent a persistent source of bugs. This paper presents Alive, a domain-specific language for writing optimizations and for automatically either proving them correct or else generating counterexamples. Furthermore, Alive can be automatically translated into C++ code that is suitable for inclusion in an LLVM optimization pass. Alive is based on an attempt to balance usability and formal methods; for example, it captures-but largely hides-the detailed semantics of three different kinds of undefined behavior in LLVM. We have translated more than 300 LLVM optimizations into Alive and, in the process, found that eight of them were wrong.",Alive | Compiler verification | Peephole optimization,59,0,,,,undefined,,PLDI Programming Languages
2-s2.0-84966785388,,,,Queues don't matter when you can JUMP them!,cp,Conference Paper,Grosvenor M.P.,60119999;60006191,Department of Computer Science and Technology;Google LLC,Cambridge;Mountain View,United Kingdom;United States,7,"Grosvenor, Matthew P.;Schwarzkopf, Malte;Gog, Ionel;Watson, Robert N.M.;Moore, Andrew W.;Hand, Steven;Crowcroft, Jon",55362384100;56704857100;56650895000;55456692300;57202346326;57213446286;57203254211,60119999;60119999;60119999;60119999;60119999;60006191;60119999,2015-01-01,2015,"Proceedings of the 12th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2015",,21100457899,,Conference Proceeding,,,,1-14,"QJUMP is a simple and immediately deployable approach to controlling network interference in datacenter networks. Network interference occurs when congestion from throughput-intensive applications causes queueing that delays traffic from latency-sensitive applications. To mitigate network interference, QJUMP applies Internet QoS-inspired techniques to datacenter applications. Each application is assigned to a latency sensitivity level (or class). Packets from higher levels are rate-limited in the end host, but once allowed into the network can ""jump-the-queue"" over packets from lower levels. In settings with known node counts and link speeds, QJUMP can support service levels ranging from strictly bounded latency (but with low rate) through to line-rate throughput (but with high latency variance). We have implemented QJUMP as a Linux Traffic Control module. We show that QJUMP achieves bounded latency and reduces in-network interference by up to 300×, outperforming Ethernet Flow Control (802.3x), ECN (WRED) and DCTCP. We also show that QJUMP improves average flow completion times, performing close to or better than DCTCP and pFabric.",,138,0,,,,undefined,,NSDI Networking
2-s2.0-84953737686,10.1145/2766462.2767733,,,Quickscorer: A fast algorithm to Rank documents with additive ensembles of regression trees,cp,Conference Paper,Lucchese C.,60085207;60028868;60013494,Istituto di Scienza e Tecnologie dell'Informazione A. Faedo;Università di Pisa;Università Ca' Foscari Venezia,Pisa;Pisa;Venice,Italy;Italy;Italy,6,"Lucchese, Claudio;Nardini, Franco Maria;Orlando, Salvatore;Perego, Raffaele;Tonellotto, Nicola;Venturini, Rossano",8873518400;36942181000;35305588800;7007180170;8964950100;15844697800,60085207;60085207;60013494;60085207;60085207;60028868,2015-08-09,9 August 2015,SIGIR 2015 - Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval,,21100435444,,Conference Proceeding,,,,73-82,"Learning-to-Rank models based on additive ensembles of regression trees have proven to be very effective for ranking query results returned by Web search engines, a scenario where quality and efficiency requirements are very demanding. Unfortunately, the computational cost of these ranking models is high. Thus, several works already proposed solutions aiming at improving the efficiency of the scoring process by dealing with features and peculiarities of modern CPUs and memory hierarchies. In this paper, we present QUICKSCORER, a new algorithm that adopts a novel bitvector representation of the tree-based ranking model, and performs an interleaved traversal of the ensemble by means of simple logical bitwise operations. The performance of the proposed algorithm are unprecedented, due to its cacheaware approach, both in terms of data layout and access patterns, and to a control ow that entails very low branch mis-prediction rates. The experiments on real Learning-to-Rank datasets show that QUICKSCORER is able to achieve speedups over the best state-of-the-art baseline ranging from 2x to 6.5x.",Cache-aware algorithms | Efficiency | Learning to rank,57,0,repositoryam,Green,,undefined,,SIGIR Information Retrieval
2-s2.0-84949772686,,,,Recursive decomposition for nonconvex optimization,cp,Conference Paper,Friesen A.L.,60015481,University of Washington,Seattle,United States,2,"Friesen, Abram L.;Domingos, Pedro",36082366900;7003565655,60015481;60015481,2015-01-01,2015,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2015-January,,,253-259,"Continuous optimization is an important problem in many areas of AI, including vision, robotics, probabilistic inference, and machine learning. Unfortunately, most real-world optimization problems are nonconvex, causing standard convex techniques to find only local optima, even with extensions like random restarts and simulated annealing. We observe that, in many cases, the local modes of the objective function have combinatorial structure, and thus ideas from combinatorial optimization can be brought to bear. Based on this, we propose a problem-decomposition approach to nonconvex optimization. Similarly to DPLL-style SAT solvers and recursive conditioning in probabilistic inference, our algorithm, RDIS, recursively sets variables so as to simplify and decompose the objective function into approximately independent subfunctions, until the remaining functions are simple enough to be optimized by standard techniques like gradient descent. The variables to set are chosen by graph partitioning, ensuring decomposition whenever possible. We show analytically that RDIS can solve a broad class of nonconvex optimization problems exponentially faster than gradient descent with random restarts. Experimentally, RDIS outperforms standard techniques on problems like structure from motion and protein folding.",,22,0,,,,undefined,,IJCAI Artificial Intelligence
2-s2.0-84951151028,10.1145/2702123.2702240,,,Resilience mitigates the negative effects of adolescent internet addiction and online risk exposure,cp,Conference Paper,Wisniewski P.,60001439,Pennsylvania State University,University Park,United States,7,"Wisniewski, Pamela;Jia, Haiyan;Wang, Na;Zheng, Saijing;Xu, Heng;Rosson, Mary Beth;Carroll, John M.",57293685900;36095905700;55467275900;55270186100;55392134500;7003266859;7402034833,60001439;60001439;60001439;60001439;60001439;60001439;60001439,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,4029-4038,"We cannot fully protect adolescents from experiencing online risks; however, we can aim to better understand how online risk experiences impact teens, factors that contribute to or prevent teens from exposure to risk, as well as factors that can protect teens from psychological harm in spite of online risk exposure. Through a web-based survey study of 75 adolescents in the US, we develop and empirically validate a theoretical model of adolescent resilience in the presence of online risks. We show evidence that resilience is a key factor in protecting teens from experiencing online risks, even when teens exhibit high levels of Internet addiction. Resilience also neutralizes the negative psychological effects associated with Internet addiction and online risk exposure. Therefore, we emphasize the importance of design solutions that foster teen resilience and strength building, as opposed to solutions targeted toward parents that often focus on restriction and risk prevention.",Adolescent online safety | Internet addiction | Resilience | Risk,72,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84945180364,10.1109/SP.2015.27,,,Riposte: An anonymous messaging system handling millions of users,cp,Conference Paper,Corrigan-Gibbs H.,60012708,Stanford University,Stanford,United States,3,"Corrigan-Gibbs, Henry;Boneh, Dan;Mazières, David",36668258900;7003748305;55884262500,60012708;60012708;60012708,2015-07-17,17 July 2015,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2015-July,,7163034,321-338,"This paper presents Riposte, a new system for anonymous broadcast messaging. Riposte is the first such system, to our knowledge, that simultaneously protects against traffic-analysis attacks, prevents anonymous denial-of-service by malicious clients, and scales to million-user anonymity sets. To achieve these properties, Riposte makes novel use of techniques used in systems for private information retrieval and secure multi-party computation. For latency-tolerant workloads with many more readers than writers (e.g. Twitter, Wikileaks), we demonstrate that a three-server Riposte cluster can build an anonymity set of 2,895,216 users in 32 hours.",anonymity | messaging | privacy | private information retrieval,116,1,repositoryam,Green,,undefined,,S&P Security and Privacy
2-s2.0-84951132646,10.1145/2702123.2702191,,,Sangeet Swara: A community-moderated voice forum in rural India,cp,Conference Paper,Vashistha A.,60021726;60015481,Microsoft Research;University of Washington,Redmond;Seattle,United States;United States,4,"Vashistha, Aditya;Cutrell, Edward;Borriello, Gaetano;Thies, William",36626584200;57203053744;7006229514;7005832437,60015481;60021726;60015481;60021726,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,417-426,"Interactive voice forums have emerged as a promising platform for people in developing regions to record and share audio messages using low-end mobile phones. However, one of the barriers to the scalability of voice forums is the process of screening and categorizing content, often done by a dedicated team of moderators. We present Sangeet Swara, a voice forum for songs and cultural content that relies on the community of callers to curate high-quality posts that are prioritized for playback to others. An 11-week deployment of Sangeet Swara found broad and impassioned usage, especially among visually impaired users. We also conducted a follow-up experiment, called Talent Hunt, that sought to reduce reliance on toll-free telephone lines. Together, our deployments span about 53,000 calls from 13,000 callers, who submitted 6,000 posts and 150,000 judgments of other content. Using a mixed-methods analysis of call logs, audio content, comparison with outside judges, and 204 automated phone surveys, we evaluate the user experience, the strengths and weaknesses of community moderation, financial sustainability, and the implications for future systems.",HCI4D | ICT4D | India | Interactive voice response | IVR,80,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84951081316,10.1145/2702123.2702525,,,Sharing is caring: Assistive technology designs on thingiverse,cp,Conference Paper,Buehler E.,60154476;60136721;60024997,"College of Engineering and Applied Science;Department of Computer Science;University of Maryland, Baltimore County (UMBC)",Boulder;Fort Collins;Baltimore,United States;United States;United States,7,"Buehler, Erin;Branham, Stacy;Ali, Abdullah;Chang, Jeremy J.;Hofmann, Megan Kelly;Hurst, Amy;Kane, Shaun K.",56104241200;35071095100;57013967200;57013728700;56421347800;16238510200;16241496400,60024997;60024997;60024997;60024997;60136721;60024997;60154476,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,525-534,"An increasing number of online communities support the open-source sharing of designs that can be built using rapid prototyping to construct physical objects. In this paper, we examine the designs and motivations for assistive technology found on Thingiverse.com, the largest of these communities at the time of this writing. We present results from a survey of all assistive technology that has been posted to Thingiverse since 2008 and a questionnaire distributed to the designers exploring their relationship with assistive technology and the motivation for creating these designs. The majority of these designs are intended to be manufactured on a 3D printer and include assistive devices and modifications for individuals with disabilities, older adults, and medication management. Many of these designs are created by the end-users themselves or on behalf of friends and loved ones. These designers frequently have no formal training or expertise in the creation of assistive technology. This paper discusses trends within this community as well as future opportunities and challenges.",3D printing | Assistive technology | Design | Disability | Open-source | Personal-scale fabrication | Prototyping,145,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84955584375,10.1145/2796314.2745866,,,Spy vs. Spy: Rumor source obfuscation,cp,Conference Paper,Fanti G.,60025038;60000745,"University of California, Berkeley;University of Illinois Urbana-Champaign",Berkeley;Urbana,United States;United States,4,"Fanti, Giulia;Kairouz, Peter;Oh, Sewoong;Viswanath, Pramod",36704589000;55652248700;55625388200;7005102472,60025038;60000745;60000745;60000745,2015-06-24,24 June 2015,Performance Evaluation Review,01635999,26742,,Conference Proceeding,43,1,,271-284,"Anonymous messaging platforms, such as Secret, Yik Yak, and Whisper, have emerged as important social media for sharing one's thoughts without the fear of being judged by friends, family, or the public. Further, such anonymous platforms are crucial in nations with authoritarian governments; the right to free expression and sometimes the personal safety of the author of the message depend on anonymity. Whether for fear of judgment or personal endangerment, it is crucial to keep anonymous the identity of the user who initially posted a sensitive message. In this paper, we consider an adversary who observes a snapshot of the spread of a message at a certain time. Recent advances in rumor source detection shows that the existing messaging protocols are vulnerable against such an adversary. We introduce a novel messaging protocol, which we call adaptive diffusion, and show that it spreads the messages fast and achieves a perfect obfuscation of the source when the underlying contact network is an infinite regular tree: all users with the message are nearly equally likely to have been the origin of the message. Experiments on a sampled Facebook network show that it effectively hides the location of the source even when the graph is finite, irregular and has cycles.",Anonymous social media | Privacy | Rumor spreading,36,0,,,,undefined,,SIGMETRICS Performance
2-s2.0-84946124798,,,,The design and implementation of open vSwitch,cp,Conference Paper,Pfaff B.,60103987;116598340,"VMware, Inc;Awake Networks",Palo Alto;Mountain View,United States;United States,12,"Pfaff, Ben;Pettit, Justin;Koponen, Teemu;Jackson, Ethan J.;Zhou, Andy;Rajahalme, Jarno;Gross, Jesse;Wang, Alex;Stringer, Jonathan;Shelar, Pravin;Amidon, Keith;Casado, Martín",57190213352;23052028000;36960068500;56354744600;57189267892;6603069444;57189267799;57189270957;55850036000;57189267830;57189264400;8425783900,60103987;60103987;60103987;60103987;60103987;60103987;60103987;60103987;60103987;60103987;116598340;60103987,2015-01-01,2015,"Proceedings of the 12th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2015",,21100457899,,Conference Proceeding,,,,117-130,"We describe the design and implementation of Open vSwitch, a multi-layer, open source virtual switch for all major hypervisor platforms. Open vSwitch was designed de novo for networking in virtual environments, resulting in major design departures from traditional software switching architectures. We detail the advanced flow classification and caching techniques that Open vSwitch uses to optimize its operations and conserve hypervisor resources. We evaluate Open vSwitch performance, drawing from our deployment experiences over the past seven years of using and improving Open vSwitch.",,892,0,,,,undefined,,NSDI Networking
2-s2.0-84951002719,10.1145/2702123.2702514,,,"The Heart work of wikipedia: Gendered, emotional labor in the world's largest online encyclopedia",cp,Conference Paper,Menking A.,60120056;60015481,School of Communication and Information;University of Washington,New Brunswick;Seattle,United States;United States,2,"Menking, Amanda;Erickson, Ingrid",56780435800;55893501100,60015481;60120056,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,207-210,"This note explores the issue of women's participation in Wikipedia through the lens of emotional labor. Using a grounded theory approach, we detail the kinds of tasks women Wikipedians choose to do and explore why they choose the work they do. We also explore the emotional costs of their labor and their strategies for coping. Our analysis of 20 interviews leads us to posit that the gendered and emotional labor required of many women to participate in Wikipedia's production renders it, problematically, a space of conflicting public and private spheres, motivated by antithetical open and closed values. In addition to other contributions, we believe this insight sheds light on some of the complex dynamics behind Wikipedia's observed gender gap.",Emotional labor | Gender gap | Wikipedia | Women,82,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84938239445,10.1137/1.9781611973730.41,,,The parameterized complexity of κ-Biclique,cp,Conference Paper,Lin B.,60025272,The University of Tokyo,Tokyo,Japan,1,"Lin, Bingkai",56742611600,60025272,2015-01-01,2015,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,2015-January,January,,605-615,"Given a graph G and a parameter k, the κ-Biclique problem asks whether G contains a complete bipartite subgraph Kk,k- This is one of the most easily stated problems on graphs whose parameterized complexity has been long unknown. We prove that κ-BICLIQUE is W[l]-hard by giving an fpt-reduction from κ-CLIQUE to κ-BICLIQUE, thus solving this longstanding open problem. Our reduction uses a class of bipartite graphs with a certain threshold property, which might be of some independent interest. More precisely, for positive integers n, s and t, we consider a bipartite graph G = (A U B,E) such that A can be partitioned into A = V1, U, V2, U ⋯ Vn and for every s distinct indices i1, ⋯ ,is, there exist ∈ Vi1, ⋯ , Vi ∈ Vi, such that , ⋯, Vik have at least t + 1 common neighbors in B; on the other hand, every s + 1 distinct vertices in A have at most t common neighbors in B. We prove that given such threshold bipartite graphs, we can construct an fpt-reduction from κ-Clique to κ-Biclique. Using the Paley-type graphs and Weil's character sum theorem, we show that for t = (s+1)! and n large enough, such threshold bipartite graphs can be computed in polynomial time. One corollary of our reduction is that there is no f(κ) ·no(κ) time algorithm to decide whether a graph contains a subgraph isomorphic to Kk!,k! unless the Exponential Time Hypothesis (ETH) fails. We also provide a probabilistic construction with better parameters t = θ{s2), which indicates that κ-BICLIQUE has no f(k) · no√k-time algorithm unless 3-SAT with m clauses can be solved in 2o(m)-time with high probability. Besides the lower bound for exact computation of κ-Biclique, our result also implies a dichotomy classification of the parameterized complexity of cardinality constraint satisfaction problems and the inapproximability of the maximum κ-intersection problem.",,36,1,repositoryam,Green,,undefined,,SODA Theory
2-s2.0-84954235294,10.1109/INFOCOM.2015.7218487,,,The power of slightly more than one sample in randomized load balancing,cp,Conference Paper,Ying L.,60003892;60000745,Arizona State University;University of Illinois Urbana-Champaign,Tempe;Urbana,United States;United States,3,"Ying, Lei;Srikant, R.;Kang, Xiaohan",35239178600;55405295300;55639024400,60003892;60000745;60003892,2015-08-21,21 August 2015,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,26,,7218487,1131-1139,"In many computing and networking applications, arriving tasks have to be routed to one of many servers, with the goal of minimizing queueing delays. When the number of processors is very large, a popular routing algorithm works as follows: select two servers at random and route an arriving task to the least loaded of the two. It is well-known that this algorithm dramatically reduces queueing delays compared to an algorithm which routes to a single randomly selected server. In recent cloud computing applications, it has been observed that even sampling two queues per arriving task can be expensive and can even increase delays due to messaging overhead. So there is an interest in reducing the number of sampled queues per arriving task. In this paper, we show that the number of sampled queues can be dramatically reduced by using the fact that tasks arrive in batches (called jobs). In particular, we sample a subset of the queues such that the size of the subset is slightly larger than the batch size (thus, on average, we only sample slightly more than one queue per task). Once a random subset of the queues is sampled, we propose a new load balancing method called batch-filling to attempt to equalize the load among the sampled servers. We show that our algorithm dramatically reduces the sample complexity compared to previously proposed algorithms.",,58,0,,,,undefined,,INFOCOM Networking
2-s2.0-84951207345,10.1145/2702123.2702181,,,The social impact of a robot co-worker in industrial settings,cp,Conference Paper,Sauppé A.,60153202,"School of Computer, Data &amp; Information Sciences",Madison,United States,2,"Sauppé, Allison;Mutlu, Bilge",56084504000;15060220700,60153202;60153202,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,3613-3622,"Across history and cultures, robots have been envisioned as assistants working alongside people. Following this vision, an emerging family of products-collaborative manufacturing robots-is enabling human and robot workers to work side by side as collaborators in manufacturing tasks. Their introduction presents an opportunity to better understand people's interactions with and perceptions of a robot ""co-worker"" in a real-world setting to guide the design of these products. In this paper, we present findings from an ethnographic field study at three manufacturing sites and a Grounded Theory analysis of observations and interviews. Our results show that, even in this safety-critical manufacturing setting, workers relate to the robot as a social entity and rely on cues to understand the robot's actions, which we observed to be critical for workers to feel safe when near the robot. These findings contribute to our understanding of interactions with robotic products in real-world settings and offer important design implications.",Collaborative robots | Computer-supported collaborative work | Design guidelines | Human-robot collaboration | Manufacturing | Social cues | Sociality | Technology adoption,135,0,,,NSF,1149970,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-84950991437,10.1145/2702123.2702285,,,Tiree energy pulse: Exploring renewable energy forecasts on the edge of the grid,cp,Conference Paper,Simm W.,60117772;60117606;60116749;60019702,"School of Computing and Communications, Lancaster University;Lancaster Institute for the Contemporary Arts;Lancaster University Management School;University of Birmingham",Lancaster;Lancaster;Lancaster;Birmingham,United Kingdom;United Kingdom;United Kingdom;United Kingdom,7,"Simm, Will;Ferrario, Maria Angela;Friday, Adrian;Newman, Peter;Forshaw, Stephen;Hazas, Mike;Dix, Alan",36171101500;36170468700;7003555568;57191328515;56241626600;23396303700;7005324365,60117772;60116749;60117772;60117772;60117606;60117772;60019702,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,1965-1974,"In many parts of the world, the electricity supply industry makes the task of dealing with unpredictable spikes and dips in production and demand invisible to consumers, maintaining a seemingly unlimited supply. A future increase in reliance on time-variable renewable sources of electricity may lead to greater fluctuations in supply. We engaged remote islanders as equal partners in a research project that investigated through technology-mediated enquiry the topic of synchronising energy consumption with supply, and together built a prototype renewable energy forecast display. A number of participants described a change in their practices, saving high energy tasks for times when local renewable energy was expected to be available, despite having no financial incentive to do so. The main contributions of this paper are in: 1) the results of co-development sessions exploring systems supporting synchronising consumption with supply and 2) the findings arising from the deployment of the prototype.",Electricity | Energy | Forecast | Renewable energy | Social innovation | Sustainability,44,0,,,EPSRC,EP/I033017/1,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-84951015422,10.1145/2702123.2702205,,,Understanding and supporting fathers and fatherhood on social media sites,cp,Conference Paper,Ammari T.,60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,2,"Ammari, Tawfiq;Schoenebeck, Sarita",56014053700;55619369200,60025778;60025778,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,1905-1914,"Fathers are taking on more childcare and household responsibilities than they used to and many non-profit and government organizations have pushed for changes in policies to support fathers. Despite this effort, little research has explored how fathers go online related to their roles as fathers. Drawing on an interview study with 37 fathers, we find that they use social media to document and archive fatherhood, learn how to be a father, and access social support. They also go online to support diverse family needs, such as single fathers' use of Reddit instead of Facebook, fathers raised by single mothers' search for role models online, and stay-at-home fathers' use of father blogs. However, fathers are constrained by privacy concerns and perceptions of judgment relating to sharing content online about their children. Drawing on theories of fatherhood, we present theoretical and design ideas for designing online spaces to better support fathers and fatherhood. We conclude with a call for a research agenda to support fathers online.",Fathers | Internet | Parents | Social media,108,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84951069595,10.1145/2702123.2702520,,,Unequal representation and gender stereotypes in image search results for occupations,cp,Conference Paper,Kay M.,60151858;60015481,College of Engineering and Information Technology;University of Washington,Baltimore;Seattle,United States;United States,3,"Kay, Matthew;Matuszek, Cynthia;Munson, Sean A.",55389474000;10239806100;22835659500,60015481;60151858;60015481,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,3819-3828,"Information environments have the power to affect people's perceptions and behaviors. In this paper, we present the results of studies in which we characterize the gender bias present in image search results for a variety of occupations. We experimentally evaluate the effects of bias in image search results on the images people choose to represent those careers and on people's perceptions of the prevalence of men and women in each occupation. We find evidence for both stereotype exaggeration and systematic underrepre-sentation of women in search results. We also find that peo-ple rate search results higher when they are consistent with stereotypes for a career, and shifting the representation of gender in image search results can shift people's percep-tions about real-world distributions. We also discuss ten-sions between desires for high-quality results and broader societal goals for equality of representation in this space.",Bias | Gender | Image search | Inequality | Representation | Stereotypes,305,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84960419716,10.1145/2786805.2786869,,,Users beware: Preference inconsistencies ahead,cp,Conference Paper,Behrang F.,60097290;60031330,College of Computing;UNL College of Engineering,Atlanta;Lincoln,United States;United States,3,"Behrang, Farnaz;Cohen, Myra B.;Orso, Alessandro",55789905000;8719004300;6603901617,60097290;60031330;60097290,2015-08-30,30 August 2015,"2015 10th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE 2015 - Proceedings",,21100450024,,Conference Proceeding,,,,295-306,"The structure of preferences for modern highly-configurable software systems has become extremely complex, usually consisting of multiple layers of access that go from the user interface down to the lowest levels of the source code. This complexity can lead to inconsistencies between layers, especially during software evolution. For example, there may be preferences that users can change through the GUI, but that have no effect on the actual behavior of the system because the related source code is not present or has been removed going from one version to the next. These inconsistencies may result in unexpected program behaviors, which range in severity from mild annoyances to more critical security or performance problems. To address this problem, we present SCIC (Software Configuration Inconsistency Checker), a static analysis technique that can automatically detect these kinds of inconsistencies. Unlike other configuration analysis tools, SCIC can handle software that (1) is written in multiple programming languages and (2) has a complex preference structure. In an empirical evaluation that we performed on 10 years worth of versions of both the widely used Mozilla Core and Firefox, SCIC was able to find 40 real inconsistencies (some determined as severe), whose lifetime spanned multiple versions, and whose detection required the analysis of code written in multiple languages.",Configurable systems | Software evolution,24,0,,,NSF,CCF-1161767,National Sleep Foundation,FSE Software Engineering
2-s2.0-84957960365,10.1145/2815400.2815402,,,Using Crash Hoare logic for certifying the FSCQ file system,cp,Conference Paper,Chen H.,60006320,MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge,United States,6,"Chen, Haogang;Ziegler, Daniel;Chajed, Tej;Chlipala, Adam;Kaashoek, M. Frans;Zeldovich, Nickolai",54785816600;57113108700;56023207200;10041238300;57207515364;35225644900,60006320;60006320;60006320;60006320;60006320;60006320,2015-10-04,4 October 2015,SOSP 2015 - Proceedings of the 25th ACM Symposium on Operating Systems Principles,,21100446022,,Conference Proceeding,,,,18-37,"FSCQ is the first file system with a machine-checkable proof (using the Coq proof assistant) that its implementation meets its specification and whose specification includes crashes. FSCQ provably avoids bugs that have plagued previous file systems, such as performing disk writes without sufficient barriers or forgetting to zero out directory blocks. If a crash happens at an inopportune time, these bugs can lead to data loss. FSCQ's theorems prove that, under any sequence of crashes followed by reboots, FSCQ will recover the file system correctly without losing data. To state FSCQ's theorems, this paper introduces the Crash Hoare logic (CHL), which extends traditional Hoare logic with a crash condition, a recovery procedure, and logical address spaces for specifying disk states at different abstraction levels. CHL also reduces the proof effort for developers through proof automation. Using CHL, we developed, specified, and proved the correctness of the FSCQ file system. Although FSCQ's design is relatively simple, experiments with FSCQ running as a user-level file system show that it is sufficient to run Unix applications with usable performance. FSCQ's specifications and proofs required significantly more work than the implementation, but the work was manageable even for a small team of a few researchers.",,167,1,repositoryam,Green,,CCF-1253229,,SOSP Operating Systems
2-s2.0-84951004741,10.1145/2702123.2702135,,,Velocitap: Investigating fast mobile text entry using sentence-based decoding of touchscreen keyboard input,cp,Conference Paper,Vertanen K.,60031101;60022132;107572506,University of Cambridge;University of St Andrews;Montana Tech,Cambridge;St Andrews;Butte,United Kingdom;United Kingdom;United States,5,"Vertanen, Keith;Memmi, Haythem;Emge, Justin;Reyal, Shyam;Kristensson, Per Ola",24345666900;55925489100;56159374300;57015313300;6507412583,107572506;107572506;107572506;60022132;60022132-60031101,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,659-668,"We present VelociTap: A state-of-the-art touchscreen keyboard decoder that supports a sentence-based text entry approach. VelociTap enables users to seamlessly choose from three word-delimiter actions: Pushing a space key, swiping to the right, or simply omitting the space key and letting the decoder infer spaces automatically. We demonstrate that VelociTap has a significantly lower error rate than Google's keyboard while retaining the same entry rate. We show that intermediate visual feedback does not significantly affect entry or error rates and we find that using the space key results in the most accurate results. We also demonstrate that enabling flexible word-delimiter options does not incur an error rate penalty. Finally, we investigate how small we can make the keyboard when using VelociTap. We show that novice users can reach a mean entry rate of 41 wpm on a 40mm wide smartwatch-sized keyboard at a 3% character error rate.",Mobile text entry | Sentence decoding | Touchscreen keyboard,92,0,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84951750779,10.1109/ICSE.2015.24,,,Views on internal and external validity in empirical software engineering,cp,Conference Paper,Siegmund J.,60014151,Universität Passau,Passau,Germany,3,"Siegmund, Janet;Siegmund, Norbert;Apel, Sven",55420344200;25825645900;8725218400,60014151;60014151;60014151,2015-08-12,12 August 2015,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,1,,7194557,9-19,"Empirical methods have grown common in software engineering, but there is no consensus on how to apply them properly. Is practical relevance key? Do internally valid studies have any value? Should we replicate more to address the tradeoff between internal and external validity? We asked the community how empirical research should take place in software engineering, with a focus on the tradeoff between internal and external validity and replication, complemented with a literature review about the status of empirical research in software engineering. We found that the opinions differ considerably, and that there is no consensus in the community when to focus on internal or external validity and how to conduct and review replications.",,145,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-84959284844,10.1145/2807442.2807446,,,Webstrates: Shareable dynamic media,cp,Conference Paper,Klokmose C.N.,60106017;60029616;60029116;60013373;60008134,Université Paris-Saclay;Aarhus Universitet;Télécom Paris;INRIA Institut National de Recherche en Informatique et en Automatique;CNRS Centre National de la Recherche Scientifique,Gif-sur-Yvette;Aarhus;Palaiseau;Le Chesnay;Paris,France;Denmark;France;France;France,5,"Klokmose, Clemens N.;Eagan, James R.;Baader, Siemen;Mackay, Wendy;Beaudouin-Lafon, Michel",23392583100;55966189500;56685045700;7102699682;6602828964,60029616;60029116-60008134;60029616;60008134-60013373-60106017;60008134-60013373-60106017,2015-11-05,5 November 2015,UIST 2015 - Proceedings of the 28th Annual ACM Symposium on User Interface Software and Technology,,21100446436,,Conference Proceeding,,,,280-290,"We revisit Alan Kay?s early vision of dynamic media thatblurs the distinction between documents and applications.We introduce shareable dynamic media that are malleable byusers, who may appropriate them in idiosyncratic ways;shareable among users, who collaborate on multiple aspectsof the media; and distributable across diverse devices and platforms. We present Webstrates, an environment for exploring shareable dynamic media. Webstrates augmentweb technology with real-time sharing. They turn web pagesinto substrates, i.e. software entities that act as applicationsor documents depending upon use. We illustrate Webstrates with two implemented case studies: users collaborativelyauthor an article with functionally and visually different editors that they can personalize and extend at run-time; andthey orchestrate its presentation and audience participationwith multiple devices. We demonstrate the simplicity andgenerative power of Webstrates with three additional prototypes and evaluate it from a systems perspective.",Dynamic Media | Real-time Collaborative Documents | Web,105,0,repositoryvor,Green,AU,321135,Aarhus Universitet,UIST User Interface
2-s2.0-84951188462,10.1145/2702123.2702156,,,What makes interruptions disruptive? A process-model account of the effects of the problem state bottleneck on task interruption and resumption,cp,Conference Paper,Borst J.P.,60010023,Rijksuniversiteit Groningen,Groningen,Netherlands,3,"Borst, Jelmer P.;Taatgen, Niels A.;Van Rijn, Hedderik",26026747200;6602372660;21740285500,60010023;60010023;60010023,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,2971-2980,"In this paper we present a computational cognitive model of task interruption and resumption, focusing on the effects of the problem state bottleneck. Previous studies have shown that the disruptiveness of interruptions is for an important part determined by three factors: Interruption duration, interrupting-task complexity, and moment of interruption. However, an integrated theory of these effects is still missing. Based on previous research into multitasking, we propose a first step towards such a theory in the form of a process model that attributes these effects to problem state requirements of both the interrupted and the interrupting task. Subsequently, we tested two predictions of this model in two experiments. The experiments confirmed that problem state requirements are an important predictor for the disruptiveness of interruptions. This suggests that interfaces should be designed to a) interrupt users at lowproblem state moments and b) maintain the problem state for the user when interrupted.",Computational model | Interruptions | Multitasking | Problem state | Working memory,97,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-84951770740,10.1109/ICSE.2015.59,,,When and why your code starts to smell bad,cp,Conference Paper,Tufano M.,60016114;60014096;60009914;60007061;60004300,William &amp; Mary;Università degli Studi del Molise;Free University of Bozen-Bolzano;Università degli Studi di Salerno;Università degli Studi del Sannio,Williamsburg;Campobasso;Bolzano;Salerno;Benevento,United States;Italy;Italy;Italy;Italy,7,"Tufano, Michele;Palomba, Fabio;Bavota, Gabriele;Olivetox, Rocco;Di Penta, Massimiliano;De Lucia, Andrea;Poshyvanyk, Denys",57651427900;55321369000;57220148228;57021693100;6602794138;7003641564;13613571900,60016114;60007061;60009914;60014096;60004300;60007061;60016114,2015-08-12,12 August 2015,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,1,,7194592,403-414,"In past and recent years, the issues related to managing technical debt received significant attention by researchers from both industry and academia. There are several factors that contribute to technical debt. One of these is represented by code bad smells, i.e., symptoms of poor design and implementation choices. While the repercussions of smells on code quality have been empirically assessed, there is still only anecdotal evidence on when and why bad smells are introduced. To fill this gap, we conducted a large empirical study over the change history of 200 open source projects from different software ecosystems and investigated when bad smells are introduced by developers, and the circumstances and reasons behind their introduction. Our study required the development of a strategy to identify smellintroducing commits, the mining of over 0.5M commits, and the manual analysis of 9,164 of them (i.e., those identified as smellintroducing). Our findings mostly contradict common wisdom stating that smells are being introduced during evolutionary tasks. In the light of our results, we also call for the need to develop a new generation of recommendation systems aimed at properly planning smell refactoring activities.",,233,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-84951838553,10.1109/ICSE.2015.83,,,Why good developers write bad code: An observational case study of the impacts of organizational factors on software quality,cp,Conference Paper,Lavallée M.,60019141,Polytechnique Montréal,Montreal,Canada,2,"Lavallée, Mathieu;Robillard, Pierre N.",36992350600;7005790183,60019141;60019141,2015-08-12,12 August 2015,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,1,,7194616,677-687,"How can organizational factors such as structure and culture have an impact on the working conditions of developers? This study is based on ten months of observation of an in-house software development project within a large telecommunications company. The observation was conducted during mandatory weekly status meetings, where technical and managerial issues were raised and discussed. Preliminary results show that many decisions made under the pressure of certain organizational factors negatively affected software quality. This paper describes cases depicting the complexity of organizational factors and reports on ten issues that have had a negative impact on quality, followed by suggested avenues for corrective action.",Observational case study | Organizational factors | Software quality,46,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84949675999,10.1145/2702123.2702391,,,"ISkin: Flexible, stretchable and visually customizable on-body touch sensors for mobile computing",cp,Conference Paper,Weigel M.,60103653;60072950;60033241;60027950,Aalto University;Laboratoire Traitement et Communication de l'Information;Universität des Saarlandes;Carnegie Mellon University,Espoo;Palaiseau;Saarbrucken;Pittsburgh,Finland;France;Germany;United States,6,"Weigel, Martin;Lu, Tong;Bailly, Gilles;Oulasvirta, Antti;Majidi, Carmel;Steimle, Jürgen",56996257900;55586555500;23395749200;13006124600;9743089700;24825371700,60033241;60027950;60072950;60103653;60027950;60033241,2015-04-18,18 April 2015,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2015-April,,,2991-3000,"We propose iSkin, a novel class of skin-worn sensors for touch input on the body. iSkin is a very thin sensor overlay, made of biocompatible materials, and is flexible and stretchable. It can be produced in different shapes and sizes to suit various locations of the body such as the finger, forearm, or ear. Integrating capacitive and resistive touch sensing, the sensor is capable of detecting touch input with two levels of pressure, even when stretched by 30% or when bent with a radius of 0:5 cm. Furthermore, iSkin supports single or multiple touch areas of custom shape and arrangement, as well as more complex widgets, such as sliders and click wheels. Recognizing the social importance of skin, we show visual design patterns to customize functional touch sensors and allow for a visually aesthetic appearance. Taken together, these contributions enable new types of on-body devices. This includes finger-worn devices, extensions to conventional wearable devices, and touch input stickers, all fostering direct, quick, and discreet input for mobile computing.","Electronic skin | Mobile computing | On-body input | Stretchable, flexible sensor | Touch input | Wearable computing",253,0,,,H2020,637991,Horizon 2020 Framework Programme,CHI Human-Computer Interaction
2-s2.0-85014390388,10.1145/2858036.2858192,,,"""I don't want to wear a screen"": Probing perceptions of and possibilities for dynamic displays on clothing",cp,Conference Paper,Devendorf L.,60025038;60006191,"University of California, Berkeley;Google LLC",Berkeley;Mountain View,United States;United States,10,"Devendorf, Laura;Lo, Joanne;Howell, Noura;Lee, Jung Lin;Gong, Nan Wei;Karagozler, M. Emre;Fukuhara, Shiho;Poupyrev, Ivan;Paulos, Eric;Ryokai, Kimiko",55734892700;56427537600;57190256139;57193580799;32067671100;9042183600;57193573171;6603553340;6603491550;22836313100,60025038;60025038;60025038;60025038;60006191;60006191;60006191;60006191;60025038;60025038,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,6028-6039,"This paper explores the role dynamic textile displays play in relation to personal style: What does it mean to wear computationally responsive clothing and why would one be motivated to do so? We developed a novel textile display technology, called Ebb, and created several woven and crochet fabric swatches that explored clothing-specific design possibilities. We engaged fashion designers and nondesigners in imagining how Ebb would integrate into their design practice or personal style of dressing. Participants evaluated the appeal and utility of clothing-based displays according to a very different set of criteria than traditional screen-based computational displays. Specifically, the slowness, low-resolution, and volatility of Ebb tended to be seen as assets as opposed to technical limitations in the context of personal style. Additionally, participants envisioned various ways that ambiguous, ambient, and abstract displays of information could prompt new experiences in their everyday lives. Our paper details the complex relationships between display and personal style and offers a new design metaphor and extension of Gaver et al.'s original descriptions of ambiguity in order to guide the design of clothing-based displays for everyday life.",Ambiguity | Clothing-based display | Crochet | Dynamic textiles | Style | Weaving,162,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-84987642016,10.1109/SP.2016.10,,,A2: Analog Malicious Hardware,cp,Conference Paper,Yang K.,60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,5,"Yang, Kaiyuan;Hicks, Matthew;Dong, Qing;Austin, Todd;Sylvester, Dennis",56110229800;26867761300;7201749062;7101675665;7005550123,60025778;60025778;60025778;60025778;60025778,2016-08-16,16 August 2016,"Proceedings - 2016 IEEE Symposium on Security and Privacy, SP 2016",,21100778649,,Conference Proceeding,,,7546493,18-37,"While the move to smaller transistors has been a boon for performance it has dramatically increased the cost to fabricate chips using those smaller transistors. This forces the vast majority of chip design companies to trust a third party - often overseas - to fabricate their design. To guard against shipping chips with errors (intentional or otherwise) chip design companies rely on post-fabrication testing. Unfortunately, this type of testing leaves the door open to malicious modifications since attackers can craft attack triggers requiring a sequence of unlikely events, which will never be encountered by even the most diligent tester. In this paper, we show how a fabrication-time attacker can leverage analog circuits to create a hardware attack that is small (i.e., requires as little as one gate) and stealthy (i.e., requires an unlikely trigger sequence before effecting a chip's functionality). In the open spaces of an already placed and routed design, we construct a circuit that uses capacitors to siphon charge from nearby wires as they transition between digital values. When the capacitors fully charge, they deploy an attack that forces a victim flip-flop to a desired value. We weaponize this attack into a remotely-controllable privilege escalation by attaching the capacitor to a wire controllable and by selecting a victim flip-flop that holds the privilege bit for our processor. We implement this attack in an OR1200 processor and fabricate a chip. Experimental results show that our attacks work, show that our attacks elude activation by a diverse set of benchmarks, and suggest that our attacks evade known defenses.",analog | attack | malicious hardware | security | Trojan,185,0,,,,undefined,,S&P Security and Privacy
2-s2.0-84997525166,10.1145/2950290.2950333,,,API code recommendation using statistical learning from fine-grained changes,cp,Conference Paper,Nguyen A.T.,60145770;60026532;60019844;60013402,College of Engineering;Microsoft Corporation;University of Evansville;Oregon State University,Ames;Redmond;Evansville;Corvallis,United States;United States;United States;United States,8,"Nguyen, Anh Tuan;Hilton, Michael;Codoban, Mihai;Nguyen, Hoan Anh;Mast, Lily;Rademacher, Eli;Nguyen, Tien N.;Dig, Danny",57194448092;56754178400;54683742800;55459278800;57192108772;57192106846;55386311200;13404654100,60145770;60013402;60026532;60145770;60019844;60013402;60145770;60013402,2016-11-01,1 November 2016,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100787002,,Conference Proceeding,13-18-November-2016,,,511-522,"Learning and remembering how to use APIs is difficult. While codecompletion tools can recommend API methods, browsing a long list of API method names and their documentation is tedious. Moreover, users can easily be overwhelmed with too much information. We present a novel API recommendation approach that taps into the predictive power of repetitive code changes to provide relevant API recommendations for developers. Our approach and tool, APIREC, is based on statistical learning from fine-grained code changes and from the context in which those changes were made. Our empirical evaluation shows that APIREC correctly recommends an API call in the first position 59% of the time, and it recommends the correct API call in the top 5 positions 77% of the time. This is a significant improvement over the state-of-The-Art approaches by 30-160% for top-1 accuracy, and 10-30% for top-5 accuracy, respectively. Our result shows that APIREC performs well even with a one-Time, minimal training dataset of 50 publicly available projects.",API Recommendation | Fine-grained Changes | Statistical Learning,134,0,,,,undefined,,FSE Software Engineering
2-s2.0-84962855280,10.1137/1.9781611974331.ch20,,,An improved distributed algorithm for maximal independent set,cp,Conference Paper,Ghaffari M.,60022195,Massachusetts Institute of Technology,Cambridge,United States,1,"Ghaffari, Mohsen",54388991300,60022195,2016-01-01,2016,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,1,,,270-277,"The Maximal Independent Set (MIS) problem is one of the basics in the study of locality in distributed graph algorithms. This paper presents a very simple randomized algorithm for this problem providing a near-optimal local complexity, which incidentally, when combined with some known techniques, also leads to a near-optimal global complexity. Classical MIS algorithms of Luby [STOC'85] and Alon, Babai and Itai [JALG'86] provide the global complexity guarantee that, with high probability1, all nodes terminate after O(logn) rounds. In contrast, our initial focus is on the local complexity, and our main contribution is to provide a very simple algorithm guaranteeing that each particular node v terminates after O(log deg(v) + log l/ϵ) rounds, with probability at least 1 - ϵ. The degree-dependency in this bound is optimal, due to a lower bound of Kuhn, Moscibroda, and Wattenhofer [PODC'04]. Interestingly, this local complexity smoothly transitions to a global complexity: by adding techniques of Barenboim, Elkin, Pettie, and Schneider [FOCS'12; arXiv: 1202.1983v3], we' get an MIS algorithm with a high probability global complexity of O(logΔ) + 2O(√log log n), where A denotes the maximum degree. This improves over the O(log2 Δ) + 2o(√log log n) result of Barenboim et al., and gets close to the fi(min{log Δ, √log n}) lower bound of Kuhn et al. Corollaries include improved algorithms for MIS in graphs of upper-bounded arboricity, or lower-bounded girth, for Ruling Sets, for MIS in the Local Computation Algorithms (LCA) model, and a faster distributed algorithm for the Lovasz Local Lemma.",,157,1,repositoryam,Green,,undefined,,SODA Theory
2-s2.0-84975801894,10.1145/2908080.2908120,,,Assessing the limits of program-specific garbage collection performance,cp,Conference Paper,Jacek N.,60152130,Manning College of Information &amp; Computer Sciences,Amherst,United States,4,"Jacek, Nicholas;Chiu, Meng Chieh;Marlin, Benjamin;Moss, Eliot",56023721400;55813807500;6506955008;7401487262,60152130;60152130;60152130;60152130,2016-06-02,2 June 2016,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,13-17-June-2016,,,584-598,"We consider the ultimate limits of program-specific garbage collector performance for real programs. We first characterize the GC schedule optimization problem using Markov Decision Processes (MDPs). Based on this characterization, we develop a method of determining, for a given program run and heap size, an optimal schedule of collections for a non-generational collector. We further explore the limits of performance of a generational collector, where it is not feasible to search the space of schedules to prove optimality. Still, we show significant improvements with Least Squares Policy Iteration, a reinforcement learning technique for solving MDPs. We demonstrate that there is considerable promise to reduce garbage collection costs by developing programspecific collection policies.",Least squares policy iteration | Markov decision processes | Optimal garbage collection,5,1,publisherfree2read,Bronze,NSF,1162246,National Science Foundation,PLDI Programming Languages
2-s2.0-84992057114,,,,Bidirectional search that is guaranteed to meet in the middle,cp,Conference Paper,Holte R.C.,60030835;60027161;60015404,University of Alberta;Ben-Gurion University of the Negev;University of Denver,Edmonton;Beer-Sheva;Denver,Canada;Israel;United States,4,"Holte, Robert C.;Felner, Ariel;Sharon, Guni;Sturtevant, Nathan R.",6701843136;57203087828;55445594200;10239070800,60030835;60027161;60027161;60015404,2016-01-01,2016,"30th AAAI Conference on Artificial Intelligence, AAAI 2016",,21100790301,,Conference Proceeding,,,,3411-3417,"We present MM, the first bidirectional heuristic search algorithm whose forward and backward searches are guaranteed to ""meet in the middle"", i.e. never expand a node beyond the solution midpoint. We also present a novel framework for comparing MM, A∗, and brute-force search, and identify conditions favoring each algorithm. Finally, we present experimental results that support our theoretical analysis.",,39,0,,,NSF,1551406,National Science Foundation,AAAI Artificial Intelligence
2-s2.0-85013666860,10.14778/2994509.2994515,,,Compressed linear algebra for largescale machine learning,cp,Conference Paper,Elgohary A.,60020304;60009253,"University of Maryland, College Park;IBM Research - Almaden",College Park;San Jose,United States;United States,5,"Elgohary, Ahmed;Boehm, Matthias;Haas, Peter J.;Reiss, Frederick R.;Reinwald, Berthold",36959424200;25640559600;13307780100;36176274900;6603551763,60020304;60009253;60009253;60009253;60009253,2016-01-01,2016,Proceedings of the VLDB Endowment,,21100199855,21508097,Conference Proceeding,9,12,,960-971,"Large-scale machine learning (ML) algorithms are often-iterative, using repeated read-only data access and I/Obound-matrix-vector multiplications to converge to an optimal-model. It is crucial for performance to fit the data into-single-node or distributed main memory. General-purpose,-heavy- and lightweight compression techniques struggle to-achieve both good compression ratios and fast decompression-speed to enable block-wise uncompressed operations.-Hence, we initiate work on compressed linear algebra (CLA),-in which lightweight database compression techniques are-applied to matrices and then linear algebra operations such-as matrix-vector multiplication are executed directly on the-compressed representations. We contribute effective column-compression schemes, cache-conscious operations, and an efficient sampling-based compression algorithm. Our experiments-show that CLA achieves in-memory operations performance-close to the uncompressed case and good compression-ratios that allow us to fit larger datasets into available memory.-We thereby obtain significant end-to-end performance-improvements up to 26x or reduced memory requirements.",,55,0,,,,undefined,,VLDB Databases
2-s2.0-85015064475,10.1145/2858036.2858317,,,Dear diary: Teens reflect on their weekly online risk experiences,cp,Conference Paper,Wisniewski P.,60154598;60001439,College of Engineering and Computer Science;Pennsylvania State University,Orlando;University Park,United States;United States,5,"Wisniewski, Pamela;Xu, Heng;Rosson, Mary Beth;Perkins, Daniel F.;Carroll, John M.",57293685900;55392134500;7003266859;7201695480;7402034833,60154598;60001439;60001439;60001439;60001439,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,3919-3930,"In our study, 68 teens spend two months reflecting on their weekly online experiences and report 207 separate risk events involving information breaches, online harassment, sexual solicitations, and exposure to explicit content. We conduct a structured, qualitative analysis to characterize the salient dimensions of their risk experiences, such as severity, level of agency, coping strategies, and whether the teens felt like the situation had been resolved. Overall, we found that teens can potentially benefit from lower risk online situations, which allow them to develop crucial interpersonal skills, such as boundary setting, conflict resolution, and empathy. We can also use the dimensions of risk described in this paper to identify potentially harmful risk trajectories before they become high-risk situations. Our end goal is to find a way to empower and protect teens so that they can benefit from online engagement.",Adolescent online safety | Cyberbullying | Diary study | Explicit content | Information breaches | Privacy | Sexual solicitations,71,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-84986274465,10.1109/CVPR.2016.90,,,Deep residual learning for image recognition,cp,Conference Paper,He K.,60021726,Microsoft Research,Redmond,United States,4,"He, Kaiming;Zhang, Xiangyu;Ren, Shaoqing;Sun, Jian",57209052101;58619489100;56333537300;56333360900,60021726;60021726;60021726;60021726,2016-12-09,9 December 2016,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,2016-December,,7780459,770-778,"Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",,137401,0,repositoryam,Green,,undefined,,CVPR Computer Vision
2-s2.0-85009408773,10.1145/2858036.2858070,,,Designing movement-based play with young people using powered wheelchairs,cp,Conference Paper,Gerling K.,60030840;60026830;60025160,Københavns Universitet;University of Lincoln;University College Cork,Copenhagen;Lincoln;Cork,Denmark;United Kingdom;Ireland,5,"Gerling, Kathrin;Hicks, Kieran;Kalyn, Michael;Evans, Adam;Linehan, Conor",51663369500;56159931700;39361632500;57194058814;35096634100,60026830;60026830;60026830;60030840;60025160,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,4447-4458,"Young people using powered wheelchairs have limited access to engaging leisure activities. We address this issue through a two-stage project; 1) the participatory development of a set of wheelchair-controlled, movement-based games (with 9 participants at a school that provides education for young people who have special needs) and 2) three case studies (4 participants) exploring player perspectives on a set of three wheelchair-controlled casual games. Our results show that movement-based playful experiences are engaging for young people using powered wheelchairs. However, the participatory design process and case studies also reveal challenges for game accessibility regarding the integration of movement in games, diversity of abilities among young people using powered wheelchairs, and the representation of disability in games. In our paper, we explore how to address those challenges in the development of accessible, empowering movement-based games, which is crucial to the wider participation of young people using powered wheelchairs in play.",Accessibility | Games | Participatory design,40,0,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84997497035,10.1145/2950290.2950348,,,Detecting sensitive data disclosure via bi-directional text correlation analysis,cp,Conference Paper,Huang J.,60014171;60009254,University of Waterloo;Purdue University,Waterloo;West Lafayette,Canada;United States,3,"Huang, Jianjun;Zhang, Xiangyu;Tan, Lin",55682653253;56336433500;7402233346,60009254;60009254;60014171,2016-11-01,1 November 2016,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100787002,,Conference Proceeding,13-18-November-2016,,,169-180,"Traditional sensitive data disclosure analysis faces two challenges: to identify sensitive data that is not generated by specific API calls, and to report the potential disclosures when the disclosed data is recognized as sensitive only after the sink operations. We address these issues by developing BIDTEXT, a novel static technique to detect sensitive data disclosures. BIDTEXT formulates the problem as a type system, in which variables are typed with the text labels that they encounter (e.g., during key-value pair operations). The type system features a novel bi-directional propagation technique that propagates the variable label sets through forward and backward data-flow. A data disclosure is reported if a parameter at a sink point is typed with a sensitive text label. BIDTEXT is evaluated on 10,000 Android apps. It reports 4,406 apps that have sensitive data disclosures, with 4,263 apps having log based disclosures and 1,688 having disclosures due to other sinks such as HTTP requests. Existing techniques can only report 64.0% of what BIDTEXT reports. And manual inspection shows that the false positive rate for BIDTEXT is 10%.",Android apps | Bi-directional Text Correlation | Sensitive Data Disclosure,15,0,,,,undefined,,FSE Software Engineering
2-s2.0-85012019852,10.1145/2858036.2858448,,,Developing and validating the user burden scale: A tool for assessing user burden in computing systems,cp,Conference Paper,Suh H.,60015481;60003892,University of Washington;Arizona State University,Seattle;Tempe,United States;United States,4,"Suh, Hyewon;Shahriaree, Nina;Hekler, Eric B.;Kientz, Julie A.",56156576300;57193578346;23034393200;11139289600,60015481;60015481;60003892;60015481,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,3988-3999,"Computing systems that place a high level of burden on their users can have a negative affect on initial adoption, retention, and overall user experience. Through an iterative process, we have developed a model for user burden that consists of six constructs: 1) difficulty of use, 2) physical, 3) time and social, 4) mental and emotional, 5) privacy, and 6) financial. If researchers and practitioners can have an understanding of the overall level of burden systems may be having on the user, they can have a better sense of whether and where to target future design efforts that can reduce those burdens. To help assist with understanding and measuring user burden, we have also developed and validated a measure of user burden in computing systems called the User Burden Scale (UBS), which is a 20-item scale with 6 individual sub-scales representing each construct. This paper presents the process we followed to develop and validate this scale for use in evaluating user burden in computing systems. Results indicate that the User Burden Scale has good overall inter-item reliability, convergent validity with similar scales, and concurrent validity when compared to systems abandoned vs. those still in use.",Evaluation | Measuring usability | Technology abandonment | Usability | User burden | User experience | Validated measures,76,1,publisherfree2read,Bronze,NSF,0952623,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-84986607606,10.1145/2934872.2934909,,,Don't mind the gap: Bridging network-wide objectives and device-level configurations,cp,Conference Paper,Beckett R.,60027550;60026532,"University of California, Los Angeles;Microsoft Corporation",Los Angeles;Redmond,United States;United States,5,"Beckett, Ryan;Mahajan, Ratul;Millstein, Todd;Padhye, Jitendra;Walker, David",56354636800;7201500491;57207585055;55955418800;7404440742,;60026532;60027550;60026532;,2016-08-22,22 August 2016,SIGCOMM 2016 - Proceedings of the 2016 ACM Conference on Special Interest Group on Data Communication,,21100778002,,Conference Proceeding,,,2934909,328-341,"We develop Propane, a language and compiler to help network operators with a challenging, error-prone task - bridging the gap between network-wide routing objectives and low-level configurations of devices that run complex, distributed protocols. The language allows operators to specify their objectives naturally, using high-level constraints on both the shape and relative preference of traffic paths. The compiler automatically translates these specifications to router-level BGP configurations, using an effective intermediate representation that compactly encodes the flow of routing information along policy-compliant paths. It guarantees that the compiled configurations correctly implement the specified policy under all possible combinations of failures. We show that Propane can effectively express the policies of datacenter and backbone networks of a large cloud provider; and despite its strong guarantees, our compiler scales to networks with hundreds or thousands of routers.",BGP | Compilation | Distributed systems | Domain-specific language | Fault tolerance | Propane | Synthesis,99,1,publisherfree2read,Bronze,NSF,CNS-1111520,National Science Foundation,SIGCOMM Networking
2-s2.0-84998996757,,,,Dueling Network Architectures for Deep Reinforcement Learning,cp,Conference Paper,Wang Z.,60111161,DeepMind Technologies Limited,London,United Kingdom,6,"Wang, Ziyu;Schaul, Tom;Hessel, Matteo;Van Hasselt, Hado;Lanctot, Marc;De Frcitas, Nando",55588083600;25640175100;56594798000;21744168500;56522887100;6602751682,60111161;60111161;60111161;60111161;60111161;60111161,2016-01-01,2016,"33rd International Conference on Machine Learning, ICML 2016",,21100462814,,Conference Proceeding,4,,,2939-2947,"In recent years there have been many successes of using deep representations in reinforcement learning. Still, many of these applications use conventional architectures, such as convolutional networks, LSTMs, or auto-encoders. In this paper, we present a new neural network architecture for model-free reinforcement learning. Our dueling network represents two separate estimators: one for the state value function and one for the state-dependent action advantage function. The main benefit of this factoring is to generalize learning across actions without imposing any change to the underlying reinforcement learning algorithm. Our results show that this architecture leads to better policy evaluation in the presence of many similar-valued actions. Moreover, the dueling architecture enables our RL agent to outperform the state-of-the-art on the Atari 2600 domain.",,701,0,,,,undefined,,ICML Machine Learning
2-s2.0-85077005425,,,,Early detection of configuration errors to reduce failure damage,cp,Conference Paper,Xu T.,60082946;60030612;60029278,"NetApp, USA;University of California, San Diego;The University of Chicago",Sunnyvale;La Jolla;Chicago,United States;United States;United States,7,"Xu, Tianyin;Jin, Xinxin;Huang, Peng;Zhou, Yuanyuan;Lu, Shan;Jin, Long;Pasupathy, Shankar",24825809900;56704035500;55955579700;7405365838;35199803400;45561248700;23009792300,60030612;60030612;60030612;60030612;60029278;60030612;60082946,2016-01-01,2016,"Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2016",,21100962568,,Conference Proceeding,,,,619-634,"Early detection is the key to minimizing failure damage induced by configuration errors, especially those errors in configurations that control failure handling and fault tolerance. Since such configurations are not needed for initialization, many systems do not check their settings early (e.g., at startup time). Consequently, the errors become latent until their manifestations cause severe damage, such as breaking the failure handling. Such latent errors are likely to escape from sysadmins' observation and testing, and be deployed to production at scale. Our study shows that many of today's mature, widely-used software systems are subject to latent configuration errors (referred to as LC errors) in their critically important configurations-those related to the system's reliability, availability, and serviceability. One root cause is that many (14.0%-93.2%) of these configurations do not have any special code for checking the correctness of their settings at the system's initialization time. To help software systems detect LC errors early, we present a tool named PCHECK that analyzes the source code and automatically generates configuration checking code (called checkers). The checkers emulate the late execution that uses configuration values, and detect LC errors if the error manifestations are captured during the emulated execution. Our results show that PCHECK can help systems detect 75+% of real-world LC errors at the initialization phase, including 37 new LC errors that have not been exposed before. Compared with existing detection tools, it can detect 31% more LC errors.",,97,0,,,NSF,CCF-1439091,National Science Foundation,OSDI Operating Systems
2-s2.0-84971393358,10.1145/2884781.2884832,,,Efficient large-scale trace checking using mapreduce,cp,Conference Paper,Bersani M.M.,60072562;60023256,University of Luxembourg;Politecnico di Milano,Esch-sur-Alzette;Milan,Luxembourg;Italy,5,"Bersani, Marcello M.;Bianculli, Domenico;Ghezzi, Carlo;Krstic, Srdan;Pietro, Pierluigi San",35730853100;21741917400;16512874900;56160057500;6602653537,60023256;60072562;60023256;60023256;60023256,2016-05-14,14 May 2016,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,14-22-May-2016,,,888-898,"The problem of checking a logged event trace against a temporal logic specification arises in many practical cases. Unfortunately, known algorithms for an expressive logic like MTL (Metric Temporal Logic) do not scale with respect to two crucial dimensions: the length of the trace and the size of the time interval of the formula to be checked. The former issue can be addressed by distributed and parallel trace checking algorithms that can take advantage of modern cloud computing and programming frameworks like MapReduce. Still, the latter issue remains open with current stateof-the-art approaches. In this paper we address this memory scalability issue by proposing a new semantics for MTL, called lazy semantics. This semantics can evaluate temporal formulae and boolean combinations of temporal-only formulae at any arbitrary time instant. We prove that lazy semantics is more expressive than point-based semantics and that it can be used as a basis for a correct parametric decomposition of any MTL formula into an equivalent one with smaller, bounded time intervals. We use lazy semantics to extend our previous distributed trace checking algorithm for MTL. The evaluation shows that the proposed algorithm can check formulae with large intervals, on large traces, in a memory-effcient way.",,15,0,repositoryam,Green,H2020,644869,Horizon 2020 Framework Programme,ICSE Software Engineering
2-s2.0-84986626480,10.1145/2934872.2934895,,,Eliminating channel feedback in next-generation cellular networks,cp,Conference Paper,Vasisht D.,60006320,MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge,United States,4,"Vasisht, Deepak;Kumar, Swarun;Rahul, Hariharan;Katabi, Dina",56355108600;55363293000;6508119866;6507046077,60006320;;60006320;60006320,2016-08-22,22 August 2016,SIGCOMM 2016 - Proceedings of the 2016 ACM Conference on Special Interest Group on Data Communication,,21100778002,,Conference Proceeding,,,2934895,398-411,"This paper focuses on a simple, yet fundamental question: ""Can a node infer the wireless channels on one frequency band by observing the channels on a different frequency band?"" This question arises in cellular networks, where the uplink and the downlink operate on different frequencies. Addressing this question is critical for the deployment of key 5G solutions such as massive MIMO, multi-user MIMO, and distributed MIMO, which require channel state information. We introduce R2-F2, a system that enables LTE base stations to infer the downlink channels to a client by observing the uplink channels from that client. By doing so, R2-F2 extends the concept of reciprocity to LTE cellular networks, where downlink and uplink transmissions occur on different frequency bands. It also removes a major hurdle for the deployment of 5G MIMO solutions. We have implemented R2-F2 in software radios and integrated it within the LTE OFDM physical layer. Our results show that the channels computed by R2-F2 deliver accurate MIMO beamforming (to within 0.7 dB of beamforming gains with ground truth channels) while eliminating channel feedback overhead.",FDD systems | LTE,104,1,repositoryam,Green,,undefined,"Lincoln Laboratory, Massachusetts Institute of Technology",SIGCOMM Networking
2-s2.0-85015022494,10.1145/2858036.2858535,,,Empath: Understanding topic signals in large-scale text,cp,Conference Paper,Fast E.,60012708,Stanford University,Stanford,United States,3,"Fast, Ethan;Chen, Binbin;Bernstein, Michael S.",36439437100;57194056969;57193014048,60012708;60012708;60012708,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,4647-4657,"Human language is colored by a broad range of topics, but existing text analysis tools only focus on a small number of them. We present Empath, a tool that can generate and validate new lexical categories on demand from a small set of seed terms (like ""bleed"" and ""punch"" to generate the category violence). Empath draws connotations between words and phrases by deep learning a neural embedding across more than 1.8 billion words of modern fiction. Given a small set of seed words that characterize a category, Empath uses its neural embedding to discover new related terms, then validates the category with a crowd-powered filter. Empath also analyzes text across 200 built-in, pre-validated categories we have generated from common topics in our web dataset, like neglect, government, and social media. We show that Empath's data-driven, human validated categories are highly correlated (r=0.906) with similar categories in LIWC.",Computational social science | Fiction | Social computing,266,0,repositoryam,Green,NSF,undefined,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-84998798222,10.1145/2858036.2858077,,,Enabling designers to foresee which colors users cannot see,cp,Conference Paper,Reinecke K.,60025778;60015481;60008877,"University of Michigan, Ann Arbor;University of Washington;University of Dundee",Ann Arbor;Seattle;Dundee,United States;United States;United Kingdom,3,"Reinecke, Katharina;Flatla, David R.;Brooks, Christopher",24605497700;36141533300;14047887300,60015481;60008877;60025778,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,2693-2704,"Users frequently experience situations in which their ability to differentiate screen colors is affected by a diversity of situations, such as when bright sunlight causes glare, or when monitors are dimly lit. However, designers currently have no way of choosing colors that will be differentiable by users of various demographic backgrounds and abilities and in the wide range of situations where their designs may be viewed. Our goal is to provide designers with insight into the effect of real-world situational lighting conditions on people's ability to differentiate colors in applications and imagery. We therefore developed an online color differentiation test that includes a survey of situational lighting conditions, verified our test in a lab study, and deployed it in an online environment where we collected data from around 30,000 participants. We then created ColorCheck, an image-processing tool that shows designers the proportion of the population they include (or exclude) by their color choices.",Color differentiability | Color vision | Design software | Situational lighting conditions,30,1,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84971430909,10.1145/2884781.2884869,,,Energy profiles of Java collections classes,cp,Conference Paper,Hasan S.,60030835;60019141;60009974,University of Alberta;Polytechnique Montréal;Samuel Ginn College of Engineering,Edmonton;Montreal;Auburn,Canada;Canada;United States,6,"Hasan, Samir;King, Zachary;Hafiz, Munawar;Sayagh, Mohammed;Adams, Bram;Hindle, Abram",57225704476;57213746081;15063972900;57188812459;15134994200;21742620300,60009974;60009974;60009974;60019141;60019141;60030835,2016-05-14,14 May 2016,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,14-22-May-2016,,,225-236,"We created detailed profiles of the energy consumed by common operations done on Java List, Map, and Set abstractions. The results show that the alternative data types for these abstractions di.er significantly in terms of energy consumption depending on the operations. For example, an ArrayList consumes less energy than a LinkedList if items are inserted at the middle or at the end, but consumes more energy than a LinkedList if items are inserted at the start of the list. To explain the results, we explored the memory usage and the bytecode executed during an operation. Expensive computation tasks in the analyzed bytecode traces appeared to have an energy impact, but memory usage did not contribute. We evaluated our profiles by using them to selectively replace Collections types used in six applications and libraries. We found that choosing the wrong Collections type, as indicated by our profiles, can cost even 300% more energy than the most efficient choice. Our work shows that the usage context of a data structure and our measured energy profiles can be used to decide between alternative Collections implementations.",API | Collections | Energy Profile | Java,105,0,,,,undefined,,ICSE Software Engineering
2-s2.0-85015044853,10.1145/2858036.2858382,,,Enhancing cross-device interaction scripting with,cp,Conference Paper,Chi P.Y.,60025038;60006191,"University of California, Berkeley;Google LLC",Berkeley;Mountain View,United States;United States,3,"Chi, Pei Yu;Li, Yang;Hartmann, Björn",55480759100;57277705200;15059978800,60006191-60025038;60006191;60006191-60025038,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,5482-5493,"Cross-device interactions involve input and output on multiple computing devices. Implementing and reasoning about interactions that cover multiple devices with a diversity of form factors and capabilities can be complex. To assist developers in programming cross-device interactions, we created DemoScript, a technique that automatically analyzes a cross-device interaction program while it is being written. DemoScript visually illustrates the step-by-step execution of a selected portion or the entire program with a novel, automatically generated cross-device storyboard visualization. In addition to helping developers understand the behavior of the program, DemoScript also allows developers to revise their program by interactively manipulating the cross-device storyboard. We evaluated DemoScript with 8 professional programmers and found that DemoScript significantly improved development efficiency by helping developers interpret and manage cross-device interaction; it also encourages testing to think through the script in a development process.",Cross-device interaction | Interactive illustration | Scripting | Storyboards,19,1,publisherhybridgold,Hybrid Gold,,undefined,,CHI Human-Computer Interaction
2-s2.0-84998953589,,,,Ensuring rapid mixing and low bias for asynchronous gibbs sampling,cp,Conference Paper,De Sa C.,60141508,Stanford Engineering,Stanford,United States,3,"De Sa, Christopher;Olukotun, Kunle;Re, Christopher",57045695500;35615042200;10739281400,60141508;60141508;60141508,2016-01-01,2016,"33rd International Conference on Machine Learning, ICML 2016",,21100462814,,Conference Proceeding,4,,,2350-2380,"Gibbs sampling is a Markov chain Monte Carlo technique commonly used for estimating marginal distributions. To speed up Gibbs sampling, there has recently been interest in parallelizing it by executing asynchronously. While empirical results suggest that many models can be efficiently sampled asynchronously, traditional Markov chain analysis does not apply to the asynchronous case, and thus asynchronous Gibbs sampling is poorly understood. In this paper, we derive a better understanding of the two main challenges of asynchronous Gibbs: bias and mixing time. We show experimentally that our theoretical results match practical outcomes.",,15,0,,,,undefined,,ICML Machine Learning
2-s2.0-84979231157,10.1145/2897518.2897528,,,Explicit two-source extractors and resilient functions,cp,Conference Paper,Chattopadhyay E.,60013372,The University of Texas at Austin,Austin,United States,2,"Chattopadhyay, Eshan;Zuckerman, David",55342225400;7006754929,60013372;60013372,2016-06-19,19 June 2016,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,19-21-June-2016,,,670-683,"We explicitly construct an extractor for two independent sources on n bits, each with polylogarithmic min-entropy. Our extractor outputs one bit and has polynomially small error. The best previous extractor, by Bourgain, required each source to have min-entropy.499n. A key ingredient in our construction is an explicit construction of a monotone, almost-balanced Boolean functions that are resilient to coalitions. In fact, our construction is stronger in that it gives an explicit extractor for a generalization of non-oblivious bit-fixing sources on n bits, where some unknown n-q bits are chosen almost polylogarithmicwise independently, and the remaining q bits are chosen by an adversary as an arbitrary function of the n-q bits. The best previous construction, by Viola, achieved q quadratically smaller than our result. Our explicit two-source extractor directly implies improved constructions of a K-Ramsey graph over N vertices, improving bounds obtained by Barak et al. and matching independent work by Cohen.",Pseudorandomness | Ramsey graph | Randomness extractor | Resilient function | Two-source extractor,63,0,,,,undefined,,STOC Theory
2-s2.0-84978532543,10.1145/2902251.2902280,,,FAQ: Questions asked frequently,cp,Conference Paper,Abo Khamis M.,60153573;60032083,"School of Engineering and Applied Sciences;University at Buffalo, The State University of New York",Buffalo;Buffalo,United States;United States,3,"Abo Khamis, Mahmoud;Ngo, Hung Q.;Rudra, Atri",57073076300;7005488530;8974616700,60032083;60032083;60153573,2016-06-15,15 June 2016,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,26-June-01-July-2016,,,13-28,"We define and study the Functional Aggregate Query (FAQ) problem, which encompasses many frequently asked questions in constraint satisfaction, databases, matrix operations, probabilistic graphical models and logic. This is our main conceptual contribution. We then present a simple algorithm called InsideOut to solve this general problem. InsideOut is a variation of the traditional dynamic programming approach for constraint programming based on variable elimination. Our variation adds a couple of simple twists to basic variable elimination in order to deal with the generality of FAQ, to take full advantage of Grohe and Marx's fractional edge cover framework, and of the analysis of recent worst-case optimal relational join algorithms. As is the case with constraint programming and graphical model inference, to make InsideOut run efficiently we need to solve an optimization problem to compute an appropriate variable ordering. The main technical contribution of this work is a precise characterization of when a variable ordering is 'semantically equivalent' to the variable ordering given by the input FAQ expression. Then, we design an approximation algorithm to find an equivalent variable ordering that has the best 'fractional FAQ-width'. Our results imply a host of known and a few new results in graphical model inference, matrix operations, relational joins, and logic. We also briefly explain how recent algorithms on beyond worst-case analysis for joins and those for solving SAT and #SAT can be viewed as variable elimination to solve FAQ over compactly represented input functions.",Constraint satisfaction | Join algorithm | Logic | Probabilistic graphical model | Quantified conjunctive query | Semiring,113,1,publisherfree2read,Bronze,NSF,CCF-1319402,National Science Foundation,PODS Databases
2-s2.0-84984941660,10.1145/2939672.2939747,,,FRAUDAR: Bounding graph fraud in the face of camouflage,cp,Conference Paper,Hooi B.,60027950,Carnegie Mellon University,Pittsburgh,United States,6,"Hooi, Bryan;Song, Hyun Ah;Beutel, Alex;Shah, Neil;Shin, Kijung;Faloutsos, Christos",57188563384;57189031374;36701124200;56719006400;56719008000;7006005166,60027950;60027950;60027950;60027950;60027950;60027950,2016-08-13,13 August 2016,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,21100777340,,Conference Proceeding,13-17-August-2016,,,895-904,"Given a bipartite graph of users and the products that they review, or followers and followees, how can we detect fake reviews or follows? Existing fraud detection methods (spectral, etc.) try to identify dense subgraphs of nodes that are sparsely connected to the remaining graph. Fraudsters can evade these methods using camouflage, by adding reviews or follows with honest targets so that they look ""normal"". Even worse, some fraudsters use hijacked accounts from honest users, and then the camouflage is indeed organic. Our focus is to spot fraudsters in the presence of camouflage or hijacked accounts. We propose FRAUDAR, an algorithm that (a) is camouflage-resistant, (b) provides upper bounds on the effectiveness of fraudsters, and (c) is effective in real-world data. Experimental results under various attacks show that FRAUDAR outperforms the top competitor in accuracy of detecting both camouflaged and non-camouflaged fraud. Additionally, in real-world experiments with a Twitter follower-followee graph of 1:47 billion edges, FRAUDAR successfully detected a subgraph of more than 4000 detected accounts, of which a majority had tweets showing that they used follower-buying services.",,224,0,,,,undefined,,KDD Data Mining
2-s2.0-84997428779,10.1145/2950290.2950323,,,Factors influencing code review processes in industry,cp,Conference Paper,Baum T.,60004935,Gottfried Wilhelm Leibniz Universität Hannover,Hannover,Germany,4,"Baum, Tobias;Liskin, Olga;Niklas, Kai;Schneider, Kurt",56576027900;37561634700;56541074700;35276019200,60004935;60004935;60004935;60004935,2016-11-01,1 November 2016,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100787002,,Conference Proceeding,13-18-November-2016,,,85-96,"Code review is known to be an effcient quality assurance technique. Many software companies today use it, usually with a process similar to the patch review process in open source software development. However, there is still a large fraction of companies performing almost no code reviews at all. And the companies that do code reviews have a lot of variation in the details of their processes. For researchers trying to improve the use of code reviews in industry, it is important to know the reasons for these process variations. We have performed a grounded theory study to clarify pro-cess variations and their rationales. The study is based on interviews with software development professionals from 19 companies. These interviews provided insights into the rea-sons and inuencing factors behind the adoption or non-adoption of code reviews as a whole as well as for different process variations. We have condensed these findings into seven hypotheses and a classification of the inuencing fac-tors. Our results show the importance of cultural and social issues for review adoption. They trace many process variations to differences in development context and in desired review effects.",Code Reviews | Empirical Software Engineering,51,0,,,,undefined,,FSE Software Engineering
2-s2.0-85009402308,10.1109/FOCS.2016.36,,,Fast Learning Requires Good Memory: A Time-Space Lower Bound for Parity Learning,cp,Conference Paper,Raz R.,60027485;60017563,Institute for Advanced Study;Weizmann Institute of Science Israel,Princeton;Rehovot,United States;Israel,1,"Raz, Ran",7102829173,60017563-60027485,2016-12-14,14 December 2016,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2016-December,,7782939,266-275,"We prove that any algorithm for learning parities requires either a memory of quadratic size or an exponential number of samples. This proves a recent conjecture of Steinhardt, Valiant and Wager [15] and shows that for some learning problems a large storage space is crucial. More formally, in the problem of parity learning, an unknown string x ϵ {0,1}n was chosen uniformly at random. A learner tries to learn x from a stream of samples (a1, b1), (a2, b2)..., where each at is uniformly distributed over {0,1}n and bt is the inner product of at and x, modulo 2. We show that any algorithm for parity learning, that uses less than n2/25 bits of memory, requires an exponential number of samples. Previously, there was no non-trivial lower bound on the number of samples needed, for any learning problem, even if the allowed memory size is O(n) (where n is the space needed to store one sample). We also give an application of our result in the field of bounded-storage cryptography. We show an encryption scheme that requires a private key of length n, as well as time complexity of n per encryption/decryption of each bit, and is provenly and unconditionally secure as long as the attacker uses less than n2/25 memory bits and the scheme is used at most an exponential number of times. Previous works on bounded-storage cryptography assumed that the memory size used by the attacker is at most linear in the time needed for encryption/decryption.",,25,0,repositoryam,Green,,undefined,,FOCS Theory
2-s2.0-84971393482,10.1145/2884781.2884846,,,Feedback-directed instrumentation for deployed javascript applications,cp,Conference Paper,Madsen M.,60119448;60029616;60025038;60014171,"Samsung Research America;Aarhus Universitet;University of California, Berkeley;University of Waterloo",Mountain View;Aarhus;Berkeley;Waterloo,United States;Denmark;United States;Canada,5,"Madsen, Magnus;Tip, Frank;Andreasen, Esben;Sen, Koushik;Møller, Anders",51663671000;57203108250;56160027800;8226489200;57195116933,60014171;60119448;60029616;60025038;60014171,2016-05-14,14 May 2016,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,14-22-May-2016,,,899-910,"Many bugs in JavaScript applications manifest themselves as objects that have incorrect property values when a failure occurs. For this type of error, stack traces and log files are often insuffcient for diagnosing problems. In such cases, it is helpful for developers to know the control ow path from the creation of an object to a crashing statement. Such crash paths are useful for understanding where the object originated and whether any properties of the object were corrupted since its creation. We present a feedback-directed instrumentation technique for computing crash paths that allows the instrumentation overhead to be distributed over a crowd of users and to re-duce it for users who do not encounter the crash. We imple-mented our technique in a tool, Crowdie, and evaluated it on 10 real-world issues for which error messages and stack traces are insuffcient to isolate the problem. Our results show that feedback-directed instrumentation requires 5% to 25% of the program to be instrumented, that the same crash must be observed 3 to 10 times to discover the crash path, and that feedback-directed instrumentation typically slows down execution by a factor 2x{9x compared to 8x{90x for an approach where applications are fully instrumented.",,16,0,repositoryam,Green,H2020,647544,Horizon 2020 Framework Programme,ICSE Software Engineering
2-s2.0-85015033711,10.1145/2858036.2858473,,,"Finding email in a multi-account, multi-device world",cp,Conference Paper,Cecchinato M.E.,60098463;60022148,Microsoft Research Cambridge;University College London,Cambridge;London,United Kingdom;United Kingdom,4,"Cecchinato, Marta E.;Sellen, Abigail;Shokouhi, Milad;Smyth, Gavin",55851220100;7004040846;14030290500;15046081900,60022148;60098463;60098463;60098463,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1200-1210,"Email is far from dead; in fact the volume of messages exchanged daily, the number of accounts per user, and the number of devices on which email is accessed have been constantly growing. Most previous studies on email have focused on management and retrieval behaviour within a single account and on a single device. In this paper, we examine how people retrieve email in today's ecosystem through an in-depth qualitative diary study with 16 participants. We found that personal and work accounts are managed differently, resulting in diverse retrieval strategies: while work accounts are more structured and thus email is retrieved through folders, personal accounts have fewer folders and users rely primarily on the built-in search option. Moreover, retrieval occurs primarily on laptops and PCs compared to smartphones. We explore the reasons, and uncover barriers and workarounds related to managing multiple accounts and devices. Finally, we consider new design possibilities for email clients to better support how email is used today.",Archiving | Cross-device interaction | Email | Information retrieval | Multi-device | Searching,29,0,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85012027158,10.18653/v1/p16-1225,,,Finding non-arbitrary form-meaning systematicity using string-metric learning for kernel regression,cp,Conference Paper,Gutiérrez E.D.,60030612;60022195,"University of California, San Diego;Massachusetts Institute of Technology",La Jolla;Cambridge,United States;United States,3,"Gutiérrez, E. Dario;Levy, Roger;Bergen, Benjamin K.",57193242189;35397142600;8954474400,60030612;60022195;60030612,2016-01-01,2016,"54th Annual Meeting of the Association for Computational Linguistics, ACL 2016 - Long Papers",,21100794667,,Conference Proceeding,4,,,2379-2388,"Arbitrariness of the sign-the notion that the forms of words are unrelated to their meanings-is an underlying assumption of many linguistic theories. Two lines of research have recently challenged this assumption, but they produce differing characterizations of non-arbitrariness in language. Behavioral and corpus studies have confirmed the validity of localized form-meaning patterns manifested in limited subsets of the lexicon. Meanwhile, global (lexicon-wide) statistical analyses instead find diffuse form-meaning system-aticity across the lexicon as a whole. We bridge the gap with an approach that can detect both local and global form-meaning systematicity in language. In the kernel regression formulation we introduce, form-meaning relationships can be used to predict words' distributional semantic vectors from their forms. Furthermore, we introduce a novel metric learning algorithm that can learn weighted edit distances that minimize kernel regression error. Our results suggest that the English lexicon exhibits far more global form-meaning systematicity than previously discovered, and that much of this systematicity is focused in localized form-meaning patterns.",,20,1,publisherhybridgold,Hybrid Gold,NSF,ACI-1053575,National Science Foundation,ACL Natural Language Processing
2-s2.0-84995762498,10.1145/2858036.2858314,,,FlexCase: Enhancing mobile interaction with a flexible sensing and display cover,cp,Conference Paper,Rendl C.,60021726;60000594;115172782,Microsoft Research;University of Applied Sciences Upper Austria;Joanneum Research,Redmond;Wels;,United States;Austria;United States,8,"Rendl, Christian;Kim, David;Parzer, Patrick;Fanello, Sean;Zirkl, Martin;Scheipl, Gregor;Haller, Michael;Izadi, Shahram",35254220900;56109733800;56427776600;36170215300;8645083300;35811346400;7102872675;16426108500,60000594;60021726;60000594;60021726;115172782;115172782;60000594;60021726,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,5138-5150,"FlexCase is a novel flip cover for smartphones, which brings flexible input and output capabilities to existing mobile phones. It combines an e-paper display with a pressure- and bendsensitive input sensor to augment the capabilities of a phone. Due to the form factor, FlexCase can be easily transformed into several different configurations, each with different interaction possibilities. We can use FlexCase to perform a variety of touch, pressure, grip and bend gestures in a natural manner, much like interacting with a sheet of paper. The secondary e-paper display can act as a mechanism for providing user feedback and persisting content from the main display. In this paper, we explore the rich design space of FlexCase and present a number of different interaction techniques. Beyond, we highlight how touch and flex sensing can be combined to support a novel type of gestures, which we call Grip & Bend. We also describe the underlying technology and gesture sensing algorithms. Numerous applications apply the interaction techniques in real-world examples, including enhanced e-paper reading and interaction, a new copy-and-paste metaphor, high degree of freedom 3D and 2D manipulation, and the ability to transfer content and support input between displays in a natural and flexible manner.",Deformation | Flexible | Grip detection | Input | Output | Sensor,25,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85000500140,10.1145/2858036.2858469,,,Foraging among an overabundance of similar variants,cp,Conference Paper,Ragavan S.S.,60015573;60013402,The University of Tulsa;Oregon State University,Tulsa;Corvallis,United States;United States,6,"Ragavan, Sruti Srinivasa;Kuttal, Sandeep Kaur;Hill, Charles;Sarma, Anita;Piorkowski, David;Burnett, Margaret",57188555414;42262051400;57188558916;7004458190;36997405600;7004960280,60013402;60013402-60015573;60013402;60013402;60013402;60013402,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,3509-3521,"Foraging among too many variants of the same artifact can be problematic when many of these variants are similar. This situation, which is largely overlooked in the literature, is commonplace in several types of creative tasks, one of which is exploratory programming. In this paper, we investigate how novice programmers forage through similar variants. Based on our results, we propose a refinement to Information Foraging Theory (IFT) to include constructs about variation foraging behavior, and propose refinements to computational models of IFT to better account for foraging among variants.",Information foraging theory | Reuse | Variants,35,1,publisherfree2read,Bronze,NSF,undefined,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-84997418614,10.1145/2950290.2950302,,,"Foraging and navigations, fundamentally: Developers' predictions of value and cost",cp,Conference Paper,Piorkowski D.,60028599;60013402,University of Memphis;Oregon State University,Memphis;Corvallis,United States;United States,6,"Piorkowski, David;Henley, Austin Z.;Nabi, Tahmid;Fleming, Scott D.;Scaffidi, Christopher;Burnett, Margaret",36997405600;56158095900;57188928058;23003852100;14052967600;7004960280,60013402;60028599;60013402;60028599;60013402;60013402,2016-11-01,1 November 2016,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100787002,,Conference Proceeding,13-18-November-2016,,,97-108,"Empirical studies have revealed that software developers spend 35%-50% of their time navigating through source code during development activities, yet fundamental questions remain: Are these percentages too high, or simply inherent in the nature of software development? Are there factors that somehow determine a lower bound on how effectively developers can navigate a given information space? Answering questions like these requires a theory that captures the core of developers' navigation decisions. Therefore, we use the central proposition of Information Foraging Theory to investigate developers' ability to predict the value and cost of their navigation decisions. Our results showed that over 50% of developers' navigation choices produced less value than they had predicted and nearly 40% cost more than they had predicted. We used those results to guide a literature analysis, to investigate the extent to which these challenges are met by current research efforts, revealing a new area of inquiry with a rich and crosscutting set of research challenges and open problems.",Information Foraging Theory | Navigation Value And Costs,25,1,publisherfree2read,Bronze,,undefined,,FSE Software Engineering
2-s2.0-84971477005,10.1145/2884781.2884862,,,From word embeddings to document similarities for improved information retrieval in software engineering,cp,Conference Paper,Ye X.,60147635,Russ College of Engineering and Technology,Athens,United States,5,"Ye, Xin;Shen, Hui;Ma, Xiao;Bunescu, Razvan;Liu, Chang",55923886100;57201809789;57189495861;8285251100;57126540900,60147635;60147635;60147635;60147635;60147635,2016-05-14,14 May 2016,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,14-22-May-2016,,,404-415,"The application of information retrieval techniques to search tasks in software engineering is made difficult by the lexi-cal gap between search queries, usually expressed in natural language (e.g. English), and retrieved documents, usually expressed in code (e.g. programming languages). This is often the case in bug and feature location, community ques-tion answering, or more generally the communication be-tween technical personnel and non-technical stake holders in a software project. In this paper, we propose bridging the lexical gap by projecting natural language statements and code snippets as meaning vectors in a shared representation space. In the proposed architecture, word embeddings are first trained on API documents, tutorials, and reference doc-uments, and then aggregated in order to estimate semantic similarities between documents. Empirical evaluations show that the learned vector space embeddings lead to improve-ments in a previously explored bug localization task and a newly defined task of linking API documents to computer programming questions.",API documents | Bug localization | Bug reports | Skip-gram model | Word embeddings,251,0,,,,undefined,,ICSE Software Engineering
2-s2.0-84979238750,10.1145/2897518.2897542,,,Graph isomorphism in quasipolynomial time: [Extended abstract],cp,Conference Paper,Babai L.,60029278,The University of Chicago,Chicago,United States,1,"Babai, László",7005600004,60029278,2016-06-19,19 June 2016,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,19-21-June-2016,,,684-697,"We show that the Graph Isomorphism (GI) problem and the more general problems of String Isomorphism (SI) and Coset Intersection (CI) can be solved in quasipolynomial (exp((logn)O(1))) time. The best previous bound for GI was exp(O(√n log n)), where n is the number of vertices (Luks, 1983); for the other two problems, the bound was similar, exp(Õ(√ n)), where n is the size of the permutation domain (Babai, 1983). Following the approach of Luks's seminal 1980/82 paper, the problem we actually address is SI. This problem takes two strings of length n and a permutation group G of degree n (the ""ambient group"") as input (G is given by a list of generators) and asks whether or not one of the strings can be transformed into the other by some element of G. Luks's divide-and-conquer algorithm for SI proceeds by recursion on the ambient group. We build on Luks's framework and attack the obstructions to efficient Luks recurrence via an interplay between local and global symmetry. We construct group theoretic ""local certificates"" to certify the presence or absence of local symmetry, aggregate the negative certificates to canonical k-ary relations where k = O(log n), and employ combinatorial canonical partitioning techniques to split the k-ary relational structure for efficient divide-andconquer. We show that in a well-defined sense, Johnson graphs are the only obstructions to effective canonical partitioning. The central element of the algorithm is the ""local certificates"" routine which is based on a new group theoretic result, the ""Unaffected stabilizers lemma,"" that allows us to construct global automorphisms out of local information.",Algorithms | Complexity of computation | Divide and conquer | Graph isomorphism | Graphs | Group theory,339,0,,,NSF,1423309,National Science Foundation,STOC Theory
2-s2.0-84971462338,10.1145/2884781.2884843,,,Guiding dynamic symbolic execution toward unverified program executions,cp,Conference Paper,Christakis M.,60025858,ETH Zürich,Zurich,Switzerland,3,"Christakis, Maria;Müller, Peter;Wüstholz, Valentin",35118649600;9434877400;42263063400,60025858;60025858;60025858,2016-05-14,14 May 2016,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,14-22-May-2016,,,144-155,"Most techniques to detect program errors, such as testing, code reviews, and static program analysis, do not fully verify all possible executions of a program. They leave executions unverified when they do not check certain properties, fail to verify properties, or check properties under certain unsound assumptions such as the absence of arithmetic overflow. In this paper, we present a technique to complement partial verification results by automatic test case generation. In contrast to existing work, our technique supports the common case that the verification results are based on unsound assumptions. We annotate programs to reflect which executions have been verified, and under which assumptions. These annotations are then used to guide dynamic symbolic execution toward unverified program executions. Our main technical contribution is a code instrumentation that causes dynamic symbolic execution to abort tests that lead to verified executions, to prune parts of the search space, and to prioritize tests that cover more properties that are not fully verified. We have implemented our technique for the.NET static analyzer Clousot and the dynamic symbolic execution tool Pex. It produces smaller test suites (by up to 19.2%), covers more unverified executions (by up to 7.1%), and reduces testing time (by up to 52.4%) compared to combining Clousot and Pex without our technique.",,69,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-85015045813,10.1145/2858036.2858283,,,HCI research as problem-solving,cp,Conference Paper,Oulasvirta A.,60103653;60030840,Aalto University;Københavns Universitet,Espoo;Copenhagen,Finland;Denmark,2,"Oulasvirta, Antti;Hornbæk, Kasper",13006124600;6602385484,60103653;60030840,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,4956-4967,"This essay contributes a meta-scientific account of human-computer interaction (HCI) research as problem-solving. We build on the philosophy of Larry Laudan, who develops problem and solution as the foundational concepts of science. We argue that most HCI research is about three main types of problem: empirical, conceptual, and constructive. We elaborate upon Laudan's concept of problem-solving capacity as a universal criterion for determining the progress of solutions (outcomes): Instead of asking whether research is 'valid' or follows the 'right' approach, it urges us to ask how its solutions advance our capacity to solve important problems in human use of computers. This offers a rich, generative, and 'discipline-free' view of HCI and resolves some existing debates about what HCI is or should be. It may also help unify efforts across nominally disparate traditions in empirical research, theory, design, and engineering.",Human-computer interaction | Larry Laudan | Problem-solving | Research problem | Scientific progress,95,1,repositoryvor,Green,H2020,637991,Horizon 2020 Framework Programme,CHI Human-Computer Interaction
2-s2.0-85015003024,10.1145/2858036.2858304,,,Haptic wave: A cross-modal interface for visually impaired audio producers,cp,Conference Paper,Tanaka A.,60010964,"Goldsmiths, University of London",London,United Kingdom,2,"Tanaka, Atau;Parkinson, Adam",55330699600;55330645400,60010964;60010964,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,2150-2161,"We present the Haptic Wave, a device that allows cross-modal mapping of digital audio to the haptic domain, intended for use by audio producers/engineers with visual impairments. We describe a series of participatory design activities adapted to non-sighted users where the act of prototyping facilitates dialog. A series of workshops scoping user needs, and testing a technology mock up and lo-fidelity prototype fed into the design of a final high-spec prototype. The Haptic Wave was tested in the laboratory, then deployed in real world settings in recording studios and audio production facilities. The cross-modal mapping is kinesthetic and allows the direct manipulation of sound without the translation of an existing visual interface. The research gleans insight into working with users with visual impairments, and transforms perspective to think of them as experts in non-visual interfaces for all users.",Cross modal mapping | Digital audio production | Haptic interfaces | Multimodal interaction | User centered design,49,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84978696000,10.1109/INFOCOM.2016.7524474,,,Heavy-ball: A new approach to tame delay and convergence in wireless network optimization,cp,Conference Paper,Liu J.,60149838;60019228,College of Engineering;Air Force Research Laboratory,Columbus;Dayton,United States;United States,4,"Liu, Jia;Eryilmaz, Atilla;Shroff, Ness B.;Bentley, Elizabeth S.",52763624900;57207522864;7005989631;36707189500,60149838;60149838;60149838;60019228,2016-07-27,27 July 2016,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2016-July,,7524474,,"The last decade has seen significant advances in optimization-based resource allocation and control approaches for wireless networks. However, the existing work suffer from poor performance in one or more of the metrics of optimality, delay, and convergence speed. To overcome these limitations, in this paper, we introduce a largely overlooked but highly effective heavy-ball optimization method. Based on this heavy-ball technique, we develop a cross-layer optimization framework that offers utility-optimality, fast-convergence, and significant delay reduction. Our contributions are three-fold: i) we propose a heavy-ball joint congestion control and routing/scheduling framework for both single-hop and multi-hop wireless networks; ii) we show that the proposed heavy-ball method offers an elegant three-way trade-off in utility, delay, and convergence, which is achieved under a near index-type simple policy; and more importantly, iii) our work opens the door to an unexplored network control and optimization paradigm that leverages advanced optimization techniques based on memory/momentum information.",,38,0,,,NSF,1444026,National Science Foundation,INFOCOM Networking
2-s2.0-85006172810,,,,Hierarchical finite state controllers for generalized planning,cp,Conference Paper,Segovia-Aguas J.,60032942,Universitat Pompeu Fabra Barcelona,Barcelona,Spain,3,"Segovia-Aguas, Javier;Jimenez, Sergio;Jonsson, Anders",57191269710;49861130800;55174461500,60032942;60032942;60032942,2016-01-01,2016,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2016-January,,,3235-3241,"Finite State Controllers (FSCs) are an effective way to represent sequential plans compactly. By imposing appropriate conditions on transitions, FSCs can also represent generalized plans that solve a range of planning problems from a given domain. In this paper we introduce the concept of hierarchical FSCs for planning by allowing controllers to call other controllers. We show that hierarchical FSCs can represent generalized plans more compactly than individual FSCs. Moreover, our call mechanism makes it possible to generate hierarchical FSCs in a modular fashion, or even to apply recursion. We also introduce a compilation that enables a classical planner to generate hierarchical FSCs that solve challenging generalized planning problems. The compilation takes as input a set of planning problems from a given domain and outputs a single classical planning problem, whose solution corresponds to a hierarchical FSC.",,14,0,,,,undefined,,IJCAI Artificial Intelligence
2-s2.0-84986581353,10.1145/2934872.2934894,,,Inter-technology backscatter: Towards internet connectivity for implanted devices,cp,Conference Paper,Iyer V.,60015481,University of Washington,Seattle,United States,5,"Iyer, Vikram;Talla, Vamsi;Kellogg, Bryce;Gollakota, Shyamnath;Smith, Joshua R.",57191091018;25026338200;56367924600;24449959700;54421256200,60015481;60015481;60015481;60015481;60015481,2016-08-22,22 August 2016,SIGCOMM 2016 - Proceedings of the 2016 ACM Conference on Special Interest Group on Data Communication,,21100778002,,Conference Proceeding,,,2934894,356-369,"We introduce inter-technology backscatter, a novel approach that transforms wireless transmissions from one technology to another, on the air. Specifically, we show for the first time that Bluetooth transmissions can be used to create Wi-Fi and ZigBee-compatible signals using backscatter communication. Since Bluetooth, Wi-Fi and ZigBee radios are widely available, this approach enables a backscatter design that works using only commodity devices. We build prototype backscatter hardware using an FPGA and experiment with various Wi-Fi, Bluetooth and ZigBee devices. Our experiments show we can create 2-11 Mbps Wi-Fi standards-compliant signals by backscattering Bluetooth transmissions. To show the generality of our approach, we also demonstrate generation of standards-complaint ZigBee signals by backscattering Bluetooth transmissions. Finally, we build proof-of-concepts for previously infeasible applications including the first contact lens form-factor antenna prototype and an implantable neural recording interface that communicate directly with commodity devices such as smartphones and watches, thus enabling the vision of Internet connected implanted devices.",Backscatter | Implantable devices | Internet of things,273,0,,,NSF,CNS-1305072,National Science Foundation,SIGCOMM Networking
2-s2.0-84975828271,10.1145/2908080.2908081,,,Into the depths of C: Elaborating the de facto standards,cp,Conference Paper,Memarian K.,60031101,University of Cambridge,Cambridge,United Kingdom,7,"Memarian, Kayvan;Matthiesen, Justus;Lingard, James;Nienhuis, Kyndylan;Chisnall, David;Watson, Robert N.M.;Sewell, Peter",55001822400;56613177600;57189907317;56586196300;14022304500;55456692300;57192110658,60031101;60031101;60031101;60031101;60031101;60031101;60031101,2016-06-02,2 June 2016,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,13-17-June-2016,,,1-15,"C remains central to our computing infrastructure. It is notionally defined by ISO standards, but in reality the properties of C assumed by systems code and those implemented by compilers have diverged, both fromthe ISO standards and from each other, and none of these are clearly understood. We make two contributions to help improve this errorprone situation. First, we describe an in-depth analysis of the design space for the semantics of pointers and memory in C as it is used in practice. We articulate many specific questions, build a suite of semantic test cases, gather experimental data from multiple implementations, and survey what C experts believe about the de facto standards. We identify questions where there is a consensus (either following ISO or differing) and where there are conflicts. We apply all this to an experimental C implemented above capability hardware. Second, we describe a formal model, Cerberus, for large parts of C. Cerberus is parameterised on its memory model; it is linkable either with a candidate de facto memory object model, under construction, or with an operational C11 concurrency model; it is defined by elaboration to a much simpler Core language for accessibility, and it is executable as a test oracle on small examples. This should provide a solid basis for discussion of what mainstream C is now: What programmers and analysis tools can assume and what compilers aim to implement. Ultimately we hope it will be a step towards clear, consistent, and accepted semantics for the various use-cases of C.",C,56,1,repositoryam,Green,DOD,FA8750-10-C-0237,U.S. Department of Defense,PLDI Programming Languages
2-s2.0-84981299802,10.1145/2858036.2858388,,,Learn piano with BACh: An adaptive learning interface that adjusts task difficulty based on brain state,cp,Conference Paper,Yuksel B.F.,60157565;60137601;60020426;60006191,WPI - Computer Science Department;Tufts School of Engineering;Bucknell University;Google LLC,Worcester;Medford;Lewisburg;Mountain View,United States;United States;United States;United States,7,"Yuksel, Beste F.;Oleson, Kurt B.;Harrison, Lane;Peck, Evan M.;Afergan, Daniel;Chang, Remco;Jacob, Robert J.K.",36142319500;57193572472;26666810600;36170923500;42961077700;22957157800;57203050569,60137601;60137601;60137601-60157565;60020426;60137601-60006191;60137601;60137601,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,5372-5384,"We present Brain Automated Chorales (BACh), an adaptive brain-computer system that dynamically increases the levels of difficulty in a musical learning task based on pianists' cognitive workload measured by functional near-infrared spectroscopy. As users' cognitive workload fell below a certain threshold, suggesting that they had mastered the material and could handle more cognitive information, BACh automatically increased the difficulty of the learning task. We found that learners played with significantly increased accuracy and speed in the brain-based adaptive task compared to our control condition. Participant feedback indicated that they felt they learned better with BACh and they liked the timings of the level changes. The underlying premise of BACh can be applied to learning situations where a task can be broken down into increasing levels of difficulty.",Adaptive | Brain-computer interface (BCI) | Cognitive workload | Functional near infrared spectroscopy (fNIRS) | Learning | Music | Piano,99,1,publisherfree2read,Bronze,NSF,IIS-1065154,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85014804385,10.1145/2858036.2858568,,,Lock n' LoL: Group-based limiting assistance app to mitigate smartphone distractions in group activities,cp,Conference Paper,Ko M.,60032144;60025272,Korea Advanced Institute of Science and Technology;The University of Tokyo,Daejeon;Tokyo,South Korea;Japan,4,"Ko, Minsam;Choi, Seungwoo;Yatani, Koji;Lee, Uichin",37104441600;57054348700;55926070600;12646091900,60032144;60032144;60025272;60032144,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,998-1010,"Prior studies have addressed many negative aspects of mobile distractions in group activities. In this paper, we present Lock n' LoL. This is an application designed to help users focus on their group activities by allowing group members to limit their smartphone usage together. In particular, it provides synchronous social awareness of each other's limiting behavior. This synchronous social awareness can arouse feelings of connectedness among group members and can mitigate social vulnerability due to smartphone distraction (e.g., social exclusion) that often results in poor social experiences. After following an iterative prototyping process, we conducted a large-scale user study (n = 976) via real field deployment. The study results revealed how the participants used Lock n' LoL in their diverse contexts and how Lock n' LoL helped them to mitigate smartphone distractions.","Group activity | Smartphone usage, smartphone distraction",82,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84996541585,10.1145/2858036.2858225,,,Momentary pleasure or lasting meaning? Distinguishing eudaimonic and hedonic user experiences,cp,Conference Paper,Mekler E.D.,60030840;60023588,Københavns Universitet;Universität Basel,Copenhagen;Basel,Denmark;Switzerland,2,"Mekler, Elisa D.;Hornbæk, Kasper",55516458900;6602385484,60023588;60030840,2016-01-01,2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2016-January,,,4509-4520,"User experience (UX) research has expanded our notion of what makes interactive technology good, often putting hedonic aspects of use such as fun, affect, and stimulation at the center. Outside of UX, the hedonic is often contrasted to the eudaimonic, the notion of striving towards one's personal best. It remains unclear, however, what this distinction offers to UX research conceptually and empirically. We investigate a possible role for eudaimonia in UX research by empirically examining 266 reports of positive experiences with technology and analyzing its relation to established UX concepts. Compared to hedonic experiences, eudaimonic experiences were about striving towards and accomplishing personal goals through technology use. They were also characterized by increased need fulfillment, positive affect, meaning, and long-term importance. Taken together, our findings suggest that while hedonic UX is about momentary pleasures directly derived from technology use, eudaimonic UX is about meaning from need fulfilment.",Eudaimonia | Hedonic | Meaning | User experience,93,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84997207428,10.1145/2950290.2950356,,,Multi-representational security analysis,cp,Conference Paper,Kang E.,60026532;60025038;60006320,"Microsoft Corporation;University of California, Berkeley;MIT Computer Science &amp; Artificial Intelligence Laboratory",Redmond;Berkeley;Cambridge,United States;United States;United States,3,"Kang, Eunsuk;Milicevic, Aleksandar;Jackson, Daniel",23389819800;57201650649;7404288974,60025038;60026532;60006320,2016-11-01,1 November 2016,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100787002,,Conference Proceeding,13-18-November-2016,,,181-192,"Security attacks often exploit aws that are not anticipated in an abstract design, but are introduced inadvertently when high-level interactions in the design are mapped to low-level behaviors in the supporting platform. This paper proposes a multi-representational approach to security analysis, where models capturing distinct (but possibly overlapping) views of a system are automatically composed in order to enable an end-To-end analysis. This approach allows the designer to incrementally explore the impact of design decisions on security, and discover attacks that span multiple layers of the system. This paper describes Poirot, a prototype imple-mentation of the approach, and reports on our experience on applying Poirot to detect previously unknown security aws in publicly deployed systems.",Composition. | Modeling | Representation | Security | Verifiation,14,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-84963652548,10.1137/1.9781611974331.ch63,,,Near-optimal light spanners,cp,Conference Paper,Chechik S.,60030840;60005681,Københavns Universitet;Tel Aviv University,Copenhagen;Tel Aviv-Yafo,Denmark;Israel,2,"Chechik, Shiri;Wulff-Nilsen, Christian",35112633300;23568967500,60005681;60030840,2016-01-01,2016,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,2,,,883-892,"A spanner if of a weighted undirected graph G is a ""sparse"" subgraph that approximately preserves distances between every pair of vertices in G. We refer to if as a δ-spanner of G for some parameter δ ≥ 1 if the distance in H between every vertex pair is at most a factor δ bigger than in G. In this case, we say that H has stretch δ. Two main measures of the sparseness of a spanner are the size (number of edges) and the total weight (the sum of weights of the edges in the spanner). It is well-known that for any positive integer k, one can efficiently construct a (2k-l)-spanner of G with 0(n1+1/k) edges where n is the number of vertices [2]. This size-stretch tradeoff is conjectured to be optimal based on a girth conjecture of Erdös [17]. However, the current state of the art for the second measure is not yet optimal. Recently Elkin, Neiman and Solomon [ICALP 14] presented an improved analysis of the greedy algorithm, proving that the greedy algorithm admits (2k-1) · (1 + ∈) stretch and total edge weight of Oc((k/logk) · ω(MST(G)) · n1/k), where ω(MST(G)) is the weight of a minimum spanning tree of G. The previous analysis by Chandra et al. [SOCG 92] admitted (2k-1) · (1 + ∈) stretch and total edge weight of Ot(kω(MST(G))nl/k). Hence, Elkin et al. improved the weight of the spanner by a log k factor. In this work, we complectly remove the k factor from the weight, presenting a spanner with (2k-1) · (1 + ∈) stretch, O∈(ω(MST(G))n1/k) total weight, and O(n1+1/k) edges. Up to a (1 + ∈) factor in the stretch this matches the girth conjecture of Erdös [17].",,13,0,,,,undefined,,SODA Theory
2-s2.0-84995760725,10.1145/2858036.2858075,,,Object-Oriented Drawing,cp,Conference Paper,Xia H.,60074802;60016849,Autodesk Inc.;University of Toronto,San Francisco;Toronto,United States;Canada,4,"Xia, Haijun;Araujo, Bruno;Grossman, Tovi;Wigdor, Daniel",56427427600;23396044200;7003520062;6507569914,60016849;60016849;60074802;60016849,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,4610-4621,"We present Object-Oriented Drawing, which replaces most WIMP UI with Attribute Objects. Attribute Objects embody the attributes of digital content as UI objects that can be manipulated through direct touch gestures. In this paper, the fundamental UI concepts are presented, including Attribute Objects, which may be moved, cloned, linked, and freely associated with drawing objects. Other functionalities, such as attribute-level blending and undo, are also demonstrated. We developed a drawing application based on the presented concepts with simultaneous touch and pen input. An expert assessment of our application shows that direct physical manipulation of Attribute Objects enables a user to quickly perform interactions which were previously tedious, or even impossible, with a coherent and consistent interaction experience throughout the entire interface.",,41,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85015108181,10.1145/2858036.2858119,,,On looking at the vagina through Labella,cp,Conference Paper,Almeida T.,60006222,Newcastle University,Newcastle,United Kingdom,5,"Almeida, Teresa;Comber, Rob;Wood, Gavin;Saraf, Dean;Balaam, Madeline",56278424400;55247455300;37053041700;57193572322;36095639700,60006222;60006222;60006222;60006222;60006222,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1810-1821,"Women's understandings of their own intimate anatomy has been identified as critical to women's reproductive health and sexual wellbeing. However, talking about it, seeking medical help when necessary as well as examining oneself in order to 'know' oneself is complicated by social-cultural constructions of the vagina, i.e. it is something private, shameful and not to be talked about. In response to this, we designed Labella, an augmented system that supports intimate bodily knowledge and pelvic fitness in women. It combines a pair of underwear and a mobile phone as a tool for embodied intimate self-discovery. In this paper, we describe Labella, and its evaluation with fourteen women, aged 25-63. We show how through situated embodied perception Labella empowers 'looking'. We highlight how the simple act of augmented looking enables the construction of knowledge which ranges from establishing the 'very basics' through to a nuanced understanding of pelvic muscle structure. Finally, we highlight the role of awkwardness and humour in the design of interactions to overcome taboo.",Feminist hci | Intimate care | Learning | On-body interactions | Pelvic floor muscles | Smartphone technology | Wearables | Wellbeing | Women's experiences | Women's health,78,0,repositoryam,Green,EPSRC,EP/M023001/1,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-84971413838,10.1145/2884781.2884835,,,"On the techniques we create, the tools we build, and their misalignments: A study of KLEE",cp,Conference Paper,Rizzi E.F.,60101641;60026306,"GrammaTech, Inc;University of Nebraska–Lincoln",Ithaca;Lincoln,United States;United States,3,"Rizzi, Eric F.;Elbaum, Sebastian;Dwyer, Matthew B.",57189489814;6604075891;7005193693,60101641;60026306;60026306,2016-05-14,14 May 2016,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,14-22-May-2016,,,132-143,"Our community constantly pushes the state-of-the-art by introducing ""new"" techniques. These techniques often build on top of, and are compared against, existing systems that realize previously published techniques. The underlying assumption is that existing systems correctly represent the techniques they implement. This paper examines that assumption through a study of KLEE, a popular and well-cited tool in our community. We briefly describe six improvements we made to KLEE, none of which can be considered ""new"" techniques, that provide order-of-magnitude performance gains. Given these improvements, we then investigate how the results and conclusions of a sample of papers that cite KLEE are affected. Our findings indicate that the strong emphasis on introducing ""new"" techniques may lead to wasted effort, missed opportunities for progress, an accretion of artifact complexity, and questionable research conclusions (in our study, 27% of the papers that depend on KLEE can be questioned). We conclude by revisiting initiatives that may help to realign the incentives to better support the foundations on which we build.",Replication | Research incentives | Research tools and infrastructure,17,0,,,NSF,1449626,National Science Foundation,ICSE Software Engineering
2-s2.0-85060104679,,,,Passive Wi-Fi: Bringing low power to Wi-Fi transmissions,cp,Conference Paper,Kellogg B.,60015481,University of Washington,Seattle,United States,4,"Kellogg, Bryce;Talla, Vamsi;Gollakota, Shyamnath;Smith, Joshua R.",56367924600;25026338200;24449959700;54421256200,60015481;60015481;60015481;60015481,2016-01-01,2016,"Proceedings of the 13th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2016",,21100962603,,Conference Proceeding,,,,151-164,"Wi-Fi has traditionally been considered a power-consuming communication system and has not been widely adopting in the sensor network and IoT space. We introduce Passive Wi-Fi that demonstrates for the first time that one can generate 802.11b transmissions using backscatter communication, while consuming 3–4 orders of magnitude lower power than existing Wi-Fi chipsets. Passive Wi-Fi transmissions can be decoded on any Wi-Fi device including routers, mobile phones and tablets. Building on this, we also present a network stack design that enables passive Wi-Fi transmitters to coexist with other devices in the ISM band, without incurring the power consumption of carrier sense and medium access control operations. We build prototype hardware and implement all four 802.11b bit rates on an FPGA platform. Our experimental evaluation shows that passive Wi-Fi transmissions can be decoded on off-the-shelf smartphones and Wi-Fi chipsets over distances of 30–100 feet in various line-of- sight and through-the-wall scenarios. Finally, we design a passive Wi-Fi IC that shows that 1 and 11 Mbps transmissions consume 14.5 and 59.2 µW respectively. This translates to 10000x lower power than existing Wi-Fi chipsets and 1000x lower power than Bluetooth LTE and ZigBee.",,285,0,,,NSF,CNS-1407583,National Sleep Foundation,NSDI Networking
2-s2.0-84999048365,,,,Pixel recurrent neural networks,cp,Conference Paper,Van Den Oord A.,60111161,DeepMind Technologies Limited,London,United Kingdom,3,"Van Den Oord, Aäron;Kalchbrenner, Nal;Kavukcuoglu, Koray",55329476300;56349787400;25646533000,60111161;60111161;60111161,2016-01-01,2016,"33rd International Conference on Machine Learning, ICML 2016",,21100462814,,Conference Proceeding,4,,,2611-2620,"Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast two- dimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNel dataset. Samples generated from the model appear crisp, varied and globally coherent.",,509,0,,,,undefined,,ICML Machine Learning
2-s2.0-84991101659,10.1145/2858036.2858176,,,Project Jacquard: Interactive digital textiles at scale,cp,Conference Paper,Poupyrev I.,60006191,Google LLC,Mountain View,United States,6,"Poupyrev, Ivan;Gong, Nan Wei;Fukuhara, Shiho;Karagozler, M. Emre;Schwesig, Carsten;Robinson, Karen E.",6603553340;32067671100;57193573171;9042183600;6508132786;57193574063,60006191;60006191;60006191;60006191;60006191;60006191,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,4216-4227,"Project Jacquard presents manufacturing technologies that enable deploying invisible ubiquitous interactivity at scale. We propose novel interactive textile materials that can be manufactured inexpensively using existing textile weaving technology and equipment. The development of touch-sensitive textiles begins with the design and engineering of a new highly conductive yarn. The yarns and textiles can be produced by standard textile manufacturing processes and can be dyed to any color, made with a number of materials, and designed to a variety of thicknesses and textures to be consistent with garment designers' needs. We describe the development of yarn, textiles, garments, and user interactivity; we present the opportunities and challenges of creating a manufacturable interactive textile for wearable computing.",Conductive yarns | Digital textiles | Manufacturing | Touch interaction | Wearable computing,246,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-84997206922,10.1145/2950290.2950340,,,Proteus: Computing disjunctive loop summary via path dependency analysis,cp,Conference Paper,Xie X.,60019533;60005510;60004354,Tianjin University;Nanyang Technological University;Iowa State University,Tianjin;Singapore City;Ames,China;Singapore;United States,5,"Xie, Xiaofei;Chen, Bihuan;Liu, Yang;Le, Wei;Li, Xiaohong",55268560900;35224542900;56911879800;36789212500;57022407900,60019533;60005510;60005510;60004354;60019533,2016-11-01,1 November 2016,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100787002,,Conference Proceeding,13-18-November-2016,,,61-72,"Loops are challenging structures for program analysis, especially when loops contain multiple paths with complex interleaving executions among these paths. In this paper, we first propose a classification of multi-path loops to understand the complexity of the loop execution, which is based on the variable updates on the loop conditions and the execution order of the loop paths. Secondly, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects on the variables. The key contribution is to use a path dependency automaton (PDA) to capture the execution dependency between the paths. A DFS-based algorithm is proposed to traverse the PDA to summarize the effect for all feasible executions in the loop. The experimental results show that Proteus is effective in three applications: Proteus can 1) compute a more precise bound than the existing loop bound analysis techniques; 2) significantly outperform state-of-The-Art tools for loop verification; and 3) generate test cases for deep loops within one second, while KLEE and Pex either need much more time or fail.",Disjunctive Summary | Loop Summarization,32,1,repositoryvor,Green,NSFC,61272106,National Natural Science Foundation of China,FSE Software Engineering
2-s2.0-85076780049,,,,Push-button verification of file systems via crash refinement,cp,Conference Paper,Sigurbjarnarson H.,60015481,University of Washington,Seattle,United States,4,"Sigurbjarnarson, Helgi;Bornholt, James;Torlak, Emina;Wang, Xi",57190276853;56103636000;23089529200;56562766700,60015481;60015481;60015481;60015481,2016-01-01,2016,"Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2016",,21100962568,,Conference Proceeding,,,,1-16,"The file system is an essential operating system component for persisting data on storage devices. Writing bug-free file systems is non-trivial, as they must correctly implement and maintain complex on-disk data structures even in the presence of system crashes and reorderings of disk operations. This paper presents Yggdrasil, a toolkit for writing file systems with push-button verification: Yggdrasil requires no manual annotations or proofs about the implementation code, and it produces a counterexample if there is a bug. Yggdrasil achieves this automation through a novel definition of file system correctness called crash refinement, which requires the set of possible disk states produced by an implementation (including states produced by crashes) to be a subset of those allowed by the specification. Crash refinement is amenable to fully automated satisfiability modulo theories (SMT) reasoning, and enables developers to implement file systems in a modular way for verification. With Yggdrasil, we have implemented and verified the Yxv6 journaling file system, the Ycp file copy utility, and the Ylog persistent log. Our experience shows that the ease of proof and counterexample-based debugging support make Yggdrasil practical for building reliable storage applications.",,76,0,,,DARPA,FA8750-16-2-0032,Defense Advanced Research Projects Agency,OSDI Operating Systems
2-s2.0-84994554143,10.1145/2858036.2858243,,,RapID: A framework for fabricating low-latency interactive objects with RFID tags,cp,Conference Paper,Spielberg A.,60032776;60027950;60022195,The Walt Disney Company;Carnegie Mellon University;Massachusetts Institute of Technology,Burbank;Pittsburgh;Cambridge,United States;United States;United States,5,"Spielberg, Andrew;Sample, Alanson;Hudson, Scott E.;Mankoff, Jennifer;McCann, James",56641563200;9235634800;7201375469;57203175552;14828241900,60032776-60022195;60032776;60032776;60032776;60032776-60027950,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,5897-5908,"RFID tags can be used to add inexpensive, wireless, batteryless sensing to objects. However, quickly and accurately estimating the state of an RFID tag is difficult. In this work, we show how to achieve low-latency manipulation and movement sensing with off-the-shelf RFID tags and readers. Our approach couples a probabilistic filtering layer with a montecarlo-sampling-based interaction layer, preserving uncertainty in tag reads until they can be resolved in the context of interactions. This allows designers' code to reason about inputs at a high level. We demonstrate the effectiveness of our approach with a number of interactive objects, along with a library of components that can be combined to make new designs.",Computational fabrication | Probabilistic modeling | RFID,39,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84979201632,10.1145/2897518.2897584,,,Reed-Muller codes achieve capacity on erasure channels,cp,Conference Paper,Kudekar S.,60033010;60028186;60020547;60008724;113193397,Intel Corporation;École Polytechnique Fédérale de Lausanne;Texas A&amp;M University;Duke University;Qualcomm Research,Santa Clara;Lausanne;College Station;Durham;Bridgewater,United States;Switzerland;United States;United States;United States,6,"Kudekar, Shrinivas;Pfister, Henry D.;Kumar, Santhosh;Şaşoǧlu, Eren;Mondelli, Marco;Urbanke, Rüdiger",23492442000;7201399458;55382565400;24825445700;56022362600;55811587000,113193397;60008724;60020547;60033010;60028186;60028186,2016-06-19,19 June 2016,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,19-21-June-2016,,,658-669,"We introduce a new approach to proving that a sequence of deterministic linear codes achieves capacity on an erasure channel under maximum a posteriori decoding. Rather than relying on the precise structure of the codes, our method exploits code symmetry. In particular, the technique applies to any sequence of linear codes where the block lengths are strictly increasing, the code rates converge, and the permutation group of each code is doubly transitive. In a nutshell, we show that symmetry alone implies near-optimal performance. An important consequence of this result is that a sequence of Reed-Muller codes with increasing block length and converging rate achieves capacity. This possibility has been suggested previously in the literature, but it has only been proven for cases where the limiting code rate is 0 or 1. Moreover, these results extend naturally to affine-invariant codes and, thus, to all extended primitive narrow-sense BCH codes. This is used to resolve, in the affirmative, the existence question for capacity-achieving sequences of binary cyclic codes. The primary tools used in the proofs are the sharp threshold property for symmetric monotone boolean functions and the area theorem for extrinsic information transfer (EXIT) functions.",Affine-invariant codes | BCH codes | Capacity-achieving codes | Erasure channels | EXIT functions | Linear codes | MAP decoding | Monotone boolean functions | Reed-Muller codes,22,1,repositoryam,Green,CISE,1218398,Directorate for Computer and Information Science and Engineering,STOC Theory
2-s2.0-84995780909,10.1145/2984511.2984531,,,Rovables: Miniature on-body robots as mobile wearables,cp,Conference Paper,Dementyev A.,60141508;60022195,Stanford Engineering;Massachusetts Institute of Technology,Stanford;Cambridge,United States;United States,8,"Dementyev, Artem;Kao, Hsin Liu Cindy;Choi, Inrak;Ajilo, Deborah;Xu, Maggie;Paradiso, Joseph A.;Schmandt, Chris;Follmer, Sean",55818044900;56159604900;57191978878;56743330400;58734826500;35576415800;7003990846;26430822900,60022195;60022195;60141508;60022195;60141508;60022195;60022195;60141508,2016-10-16,16 October 2016,UIST 2016 - Proceedings of the 29th Annual Symposium on User Interface Software and Technology,,21100786308,,Conference Proceeding,,,,111-120,"We introduce Rovables, a miniature r on unmodified clothing. The robots netic wheels, and can climb vertic tethered and have an onboard batte wireless communications. They also calization system that uses wheel enc Rovables to perform limited autono body. In the technical evaluations, can operate continuously for 45 min 1.5N. We propose an interaction sp devices spanning sensing, actuation velop application scenarios in that include on-body sensing, modular d and interactive clothing and jewelry.",Mobile wearable technology | On-body robotics,54,0,repositoryvor,Green,,undefined,,UIST User Interface
2-s2.0-85076979914,,,,Ryoan: A distributed sandbox for untrusted computation on secret data,cp,Conference Paper,Hunt T.,60013372,The University of Texas at Austin,Austin,United States,5,"Hunt, Tyler;Zhu, Zhiting;Xu, Yuanzhong;Peter, Simon;Witchel, Emmett",57189458234;57193705621;56650389300;56231946100;22836994600,60013372;60013372;60013372;60013372;60013372,2016-01-01,2016,"Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2016",,21100939724,,Conference Proceeding,,,,533-549,"Users of modern data-processing services such as tax preparation or genomic screening are forced to trust them with data that the users wish to keep secret. Ryoan protects secret data while it is processed by services that the data owner does not trust. Accomplishing this goal in a distributed setting is difficult because the user has no control over the service providers or the computational platform. Confining code to prevent it from leaking secrets is notoriously difficult, but Ryoan benefits from new hardware and a request-oriented data model. Ryoan provides a distributed sandbox, leveraging hardware enclaves (e.g., Intel's software guard extensions (SGX) [15]) to protect sandbox instances from potentially malicious computing platforms. The protected sandbox instances confine untrusted data-processing modules to prevent leakage of the user's input data. Ryoan is designed for a request-oriented data model, where confined modules only process input once and do not persist state about the input. We present the design and prototype implementation of Ryoan and evaluate it on a series of challenging problems including email filtering, heath analysis, image processing and machine translation.",,135,0,,,NSF,CFC-1333594,National Science Foundation,OSDI Operating Systems
2-s2.0-85009352824,10.1109/FOCS.2016.35,,,Settling the Complexity of Computing Approximate Two-Player Nash Equilibria,cp,Conference Paper,Rubinstein A.,60025038,"University of California, Berkeley",Berkeley,United States,1,"Rubinstein, Aviad",56226073600,60025038,2016-12-14,14 December 2016,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2016-December,,7782938,258-265,"We prove that there exists a constant ϵ > 0 such that, assuming the Exponential Time Hypothesis for PPAD, computing an ϵ-approximate Nash equilibrium in a two-player (n × n) game requires quasi-polynomial time, nlog1-o(1) n. This matches (up to the o(1) term) the algorithm of Lipton, Markakis, and Mehta [54]. Our proof relies on a variety of techniques from the study of probabilistically checkable proofs (PCP), this is the first time that such ideas are used for a reduction between problems inside PPAD. En route, we also prove new hardness results for computing Nash equilibria in games with many players. In particular, we show that computing an ϵ-approximate Nash equilibrium in a game with n players requires 2Ω(n) oracle queries to the payoff tensors. This resolves an open problem posed by Hart and Nisan [43], Babichenko [13], and Chen et al. [28]. In fact, our results for n-player games are stronger: they hold with respect to the (ϵ,δ)-WeakNash relaxation recently introduced by Babichenko et al. [15].",Computational complexity,88,0,repositoryam,Green,,undefined,,FOCS Theory
2-s2.0-85015063788,10.1145/2858036.2858390,,,Smart touch: Improving touch accuracy for people with motor impairments with template matching,cp,Conference Paper,Mott M.,60015481;60000221;112590814,University of Washington;University of Colorado Boulder;Stefan Cel Mare University (USV),Seattle;Boulder;Suceava,United States;United States;Romania,4,"Mott, Martez E.;Vatavu, Radu Daniel;Kane, Shaun K.;Wobbrock, Jacob O.",36768870600;24504604700;16241496400;6603152369,60015481;112590814;60000221;60015481,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1934-1946,"We present two contributions for improving the accessibility of touch screens for people with motor impairments. First, we provide an exploration of the touch behaviors of 10 people with motor impairments, e.g., we describe how touching with the back or sides of the hand, with multiple fingers, or with the knuckles creates varied multi-point touches. Second, we introduce Smart Touch, a novel template-matching technique for touch input that maps any number of arbitrary contact-areas to a user's intended (?,?) target location. The result is that users with motor impairments can touch however their abilities allow, and Smart Touch will resolve their intended touch point. Smart Touch therefore allows users to touch targets in whichever ways are most comfortable and natural for them. In an experiment, we found that Smart Touch predicted the (?,?) coordinates of users' intended target locations over three times closer to actual intended targets than the native Landon and Lift-off techniques reported by the built-in touch sensors found in the Microsoft PixelSense interactive tabletop. This result is an important step toward improving touch accuracy for people with motor impairments and others for whom touch screen operation was previously difficult or impossible.",$P recognizer | Ability-based design | Accessibility | Motor impairment | Target acquisition | Touch input | Touch screens,53,1,publisherfree2read,Bronze,NSF,0952786,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85029421826,10.1145/2872427.2883063l,,,Social networks under stress,cp,Conference Paper,Romero D.,60025778;60007776;60007363,"University of Michigan, Ann Arbor;Cornell University;Northwestern University",Ann Arbor;Ithaca;Evanston,United States;United States;United States,3,"Romero, Daniel M.;Uzzi, Brian;Kleinberg, Jon",24345428600;6603149512;7005755823,60025778;60007363;60007776,2016-01-01,2016,"25th International World Wide Web Conference, WWW 2016",,21100846098,,Conference Proceeding,,,,9-20,"Social network research has begun to take advantage of fine-grained communications regarding coordination, decision-making, and knowledge sharing. These studies, however, have not generally analyzed how external events are asso-ciated with a social network's structure and communicative properties. Here, we study how external events are associ-ated with a network's change in structure and communica-tions. Analyzing a complete dataset of millions of instant messages among the decision-makers in a large hedge fund and their network of outside contacts, we investigate the link between price shocks, network structure, and change in the affect and cognition of decision-makers embedded in the network. When price shocks occur the communication network tends not to display structural changes associated with adaptiveness. Rather, the network \turtles up"". It displays a propensity for higher clustering, strong tie inter-action, and an intensification of insider vs. outsider commu-nication. Further, we find changes in network structure pre-dict shifts in cognitive and affective processes, execution of new transactions, and local optimality of transactions better than prices, revealing the important predictive relationship between network structure and collective behavior within a social network.",Col-lective Behavior. | Organizations | Social Networks | Temporal Dynamics,37,0,,,CISE,0910664,Directorate for Computer and Information Science and Engineering,WWW World Wide Web
2-s2.0-84971493149,10.1145/2884781.2884809,,,Termination-checking for LLVM peephole optimizations,cp,Conference Paper,Menendez D.,60120529,Department of Computer Science,Piscataway,United States,2,"Menendez, David;Nagarakatte, Santosh",55368755100;28167714800,60120529;60120529,2016-05-14,14 May 2016,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,14-22-May-2016,,,191-202,"Mainstream compilers contain a large number of peephole optimizations, which perform algebraic simplification of the input program with local rewriting of the code. These optimizations are a persistent source of bugs. Our recent research on Alive, a domainspecific language for expressing peephole optimizations in LLVM, addresses a part of the problem by automatically verifying the correctness of these optimizations and generating C++ code for use with LLVM. This paper identifies a class of non-termination bugs that arise when a suite of peephole optimizations is executed until a fixed point. An optimization can undo the effect of another optimization in the suite, which results in non-terminating compilation. This paper (1) proposes a methodology to detect non-termination bugs with a suite of peephole optimizations, (2) identifies the necessary condition to ensure termination while composing peephole optimizations, and (3) provides debugging support by generating concrete input programs that cause non-terminating compilation. We have discovered 184 optimization sequences, involving 38 optimizations, that cause non-terminating compilation in LLVM with Alive-generated C++ code.",Alive | Compiler Verification | Peephole Optimization | Termination,7,1,publisherfree2read,Bronze,NSF,1453086,National Science Foundation,ICSE Software Engineering
2-s2.0-84999090233,10.1145/2858036.2858063,,,The effect of visual appearance on the performance of continuous sliders and visual analogue scales,cp,Conference Paper,Matejka J.,60074802,Autodesk Inc.,San Francisco,United States,4,"Matejka, Justin;Glueck, Michael;Grossman, Tovi;Fitzmaurice, George",10044259500;25924965900;7003520062;7005241818,60074802;60074802;60074802;60074802,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,5421-5432,"Sliders and Visual Analogue Scales (VASs) are input mechanisms which allow users to specify a value within a predefined range. At a minimum, sliders and VASs typically consist of a line with the extreme values labeled. Additional decorations such as labels and tick marks can be added to give information about the gradations along the scale and allow for more precise and repeatable selections. There is a rich history of research about the effect of labelling in discrete scales (i.e., Likert scales), however the effect of decorations on continuous scales has not been rigorously explored. In this paper we perform a 2,000 user, 250,000 trial online experiment to study the effects of slider appearance, and find that decorations along the slider considerably bias the distribution of responses received. Using two separate experimental tasks, the trade-offs between bias, accuracy, and speed-of-use are explored and design recommendations for optimal slider implementations are proposed.",,64,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-84975828225,10.1145/2908080.2908112,,,Transactional data structure libraries,cp,Conference Paper,Spiegelman A.,60075274,Yahoo Research Labs,Sunnyvale,United States,3,"Spiegelman, Alexander;Golan-Gueta, Guy;Keidar, Idit",56940568700;54396978800;6701640442,;60075274;60075274,2016-06-02,2 June 2016,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,13-17-June-2016,,,682-696,"We introduce transactions into libraries of concurrent data structures; such transactions can be used to ensure atomicity of sequences of data structure operations. By focusing on transactional access to a well-defined set of data structure operations, we strike a balance between the ease-ofprogramming of transactions and the efficiency of customtailored data structures. We exemplify this concept by designing and implementing a library supporting transactions on any number of maps, sets (implemented as skiplists), and queues. Our library offers efficient and scalable transactions, which are an order of magnitude faster than state-of-theart transactional memory toolkits. Moreover, our approach treats stand-alone data structure operations (like put and enqueue) as first class citizens, and allows them to execute with virtually no overhead, at the speed of the original data structure library.",Concurrency | Data structures | Semantics | Transactions,32,0,,,,undefined,,PLDI Programming Languages
2-s2.0-84975841189,10.1145/2908080.2908115,,,Types from data: Making structured data first-class citizens in F,cp,Conference Paper,Petricek T.,60098463;60031101;60026532,Microsoft Research Cambridge;University of Cambridge;Microsoft Corporation,Cambridge;Cambridge;Redmond,United Kingdom;United Kingdom;United States,3,"Petricek, Tomas;Guerra, Gustavo;Syme, Don",57214983249;57189902347;7003394778,60031101;60026532;60098463,2016-06-02,2 June 2016,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,13-17-June-2016,,,477-490,"Most modern applications interact with external services and access data in structured formats such as XML, JSON and CSV. Static type systems do not understand such formats, often making data access more cumbersome. Should we give up and leave the messy world of external data to dynamic typing and runtime checks? Of course, not! We present F Data, a library that integrates external structured data into F. As most real-world data does not come with an explicit schema, we develop a shape inference algorithm that infers a shape from representative sample documents. We then integrate the inferred shape into the F type system using type providers. We formalize the process and prove a relative type soundness theorem. Our library significantly reduces the amount of data access code and it provides additional safety guarantees when contrasted with the widely used weakly typed techniques.",F | Inference | Json | Type providers | Xml,18,0,repositoryam,Green,,undefined,,PLDI Programming Languages
2-s2.0-84980351571,10.1145/2911451.2911534,,,Understanding information need: An fMRI study,cp,Conference Paper,Moshfeghi Y.,60001490,University of Glasgow,Glasgow,United Kingdom,3,"Moshfeghi, Yashar;Triantafillou, Peter;Pollick, Frank E.",27868059900;7003940986;7004147308,60001490;60001490;60001490,2016-07-07,7 July 2016,SIGIR 2016 - Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval,,21100470105,,Conference Proceeding,,,,335-344,"The raison d'etre of IR is to satisfy human information need. But, do we really understand information need? Despite advances in the past few decades in both the IR and relevant scientific communities, this question is largely unanswered. We do not really understand how an information need emerges and how it is physically manifested. Information need refers to a complex concept: at the very initial state of the phenomenon (i.e. at a visceral level), even the searcher may not be aware of its existence. This renders the measuring of this concept (using traditional behaviour studies) nearly impossible. In this paper, we investigate the connection between an information need and brain activity. Using functional Magnetic Resonance Imaging (fMRI), we measured the brain activity of twenty four participants while they performed a Question Answering (Q/A) Task, where the questions were carefully selected and developed from TREC-8 and TREC 2001 Q/A Track. The results of this experiment revealed a distributed network of brain regions commonly associated with activities related to information need and retrieval and differing brain activity in processing scenarios when participants knew the answer to a given question and when they did not and needed to search. We believe our study and conclusions constitute an important step in unravelling the nature of information need and therefore better satisfying it.",Anomalous states of knowledge | fMRI study | Information need | Information retrieval,44,1,repositoryam,Green,ESRC,ES/L011921/1,Economic and Social Research Council,SIGIR Information Retrieval
2-s2.0-85015103056,10.1145/2858036.2858378,,,Understanding and mitigating the effects of device and cloud service design decisions on the environmental footprint of digital infrastructure,cp,Conference Paper,Preist C.,60021121;60020650;60008928,Indiana University Bloomington;University of Bristol;The Hong Kong Polytechnic University,Bloomington;Bristol;Hong Kong,United States;United Kingdom;Hong Kong,3,"Preist, Chris;Schien, Dan;Blevis, Eli",57202977514;55358151900;22833683800,60020650;60020650;60021121-60008928,2016-05-07,7 May 2016,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,1324-1337,"Interactive devices and the services they support are reliant on the cloud and the digital infrastructure supporting it. The environmental impacts of this infrastructure are substantial- and for particular services the infrastructure can account for up to 85% of the total impact. In this paper, we apply the principles of Sustainable Interaction Design to cloud services use of the digital infrastructure. We perform a critical analysis of current design practice with regard to interactive services, which we identify as the cornucopian paradigm. We show how user-centered design principles induce environmental impacts in different ways, and combine with technical and business drivers to drive growth of the infrastructure through a reinforcing feedback cycle. We then create a design rubric, substantially extending that of Blevis [6], to cover impacts of the digital infrastructure. In doing so, we engage in design criticism, identifying examples (both actual and potential) of good and bad practice. We then extend this rubric beyond an ecoefficiency paradigm to consider deeper and more radical perspectives on sustainability, and finish with future directions for exploration.",Cloud computing | Green computing | Interaction Design | Sustainability | Sustainable HCI,72,0,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-84971417916,10.1145/2884781.2884866,,,VDTest: An automated framework to support testing for,cp,Conference Paper,Yu T.,60090134;60031330;60025173,"ABB Group, USA;UNL College of Engineering;Stanley and Karen Pigman College of Engineering",Cary;Lincoln;Lexington,United States;United States;United States,3,"Yu, Tingting;Qu, Xiao;Cohen, Myra B.",36987016200;36848960800;8719004300,60025173;60090134;60031330,2016-05-14,14 May 2016,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,14-22-May-2016,,,583-594,"The use of virtual devices in place of physical hardware is increasing in activities such as design, testing and debugging. Yet virtual devices are simply software applications, and like all software they are prone to faults. A full system simulator (FSS), is a class of virtual machine that includes a large set of virtual devices-enough to run the full target software stack. Defects in an FSS virtual device may have cascading effects as the incorrect behavior can be propagated forward to many different platforms as well as to guest programs. In this work we present VDTest, a novel framework for testing virtual devices within an FSS. VDTest begins by generating a test specification obtained through static analysis. It then employs a two-phase testing approach to test virtual components both individually and in combination. It leverages a differential oracle strategy, taking advantage of the existence of a physical or golden device to eliminate the need for manually generating test oracles. In an empirical study using both open source and commercial FSSs, we found 64 faults, 83% more than random testing.",Device Drivers | Test Oracles | Testing | Virtual Devices,5,1,publisherfree2read,Bronze,,undefined,,ICSE Software Engineering
2-s2.0-85019231472,,,,Value iteration networks,cp,Conference Paper,Tamar A.,60121438,Department of Electrical Engineering and Computer Sciences,Berkeley,United States,5,"Tamar, Aviv;Wu, Yi;Thomas, Garrett;Levine, Sergey;Abbeel, Pieter",52264620600;55698586300;57194216556;35731728100;8269962600,60121438;60121438;60121438;60121438;60121438,2016-01-01,2016,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,,,,2154-2162,"We introduce the value iteration network (VIN): a fully differentiable neural network with a 'planning module' embedded within. VINs can learn to plan, and are suitable for predicting outcomes that involve planning-based reasoning, such as policies for reinforcement learning. Key to our approach is a novel differentiable approximation of the value-iteration algorithm, which can be represented as a con-volutional neural network, and trained end-to-end using standard backpropagation. We evaluate VIN based policies on discrete and continuous path-planning domains, and on a natural-language based search task. We show that by learning an explicit planning computation, VIN policies generalize better to new, unseen domains.",,329,0,,,,undefined,,NeurIPS Machine Learning
2-s2.0-84996564522,10.1145/2983323.2983740,,,Vandalism detection in Wikidata,cp,Conference Paper,Heindorf S.,60028637;60020238,Bauhaus-Universität Weimar;Universität Paderborn,Weimar;Paderborn,Germany;Germany,4,"Heindorf, Stefan;Potthast, Martin;Stein, Benno;Engels, Gregor",57044833200;23012600600;23013265500;7004530938,60020238;60028637;60028637;60020238,2016-10-24,24 October 2016,"International Conference on Information and Knowledge Management, Proceedings",,55826,,Conference Proceeding,24-28-October-2016,,,327-336,"Wikidata is the new, large-scale knowledge base of the Wikimedia Foundation. Its knowledge is increasingly used within Wikipedia itself and various other kinds of information systems, imposing high demands on its integrity. Wikidata can be edited by anyone and, unfortunately, it frequently gets vandalized, exposing all information systems using it to the risk of spreading vandalized and falsified information. In this paper, we present a new machine learning-based approach to detect vandalism in Wikidata. We propose a set of 47 features that exploit both content and context information, and we report on 4 classifiers of increasing effectiveness tailored to this learning task. Our approach is evaluated on the recently published Wikidata Vandalism Corpus WDVC-2015 and it achieves an area under curve value of the receiver operating characteristic, ROCAUC, of 0.991. It significantly outperforms the state of the art represented by the rule-based Wikidata Abuse Filter (0.865 ROCAUC) and a prototypical vandalism detector recently introduced by Wikimedia within the Objective Revision Evaluation Service (0.859 ROCAUC).",Data quality | Knowledge base | Trust | Vandalism,63,0,,,,undefined,,CIKM Knowledge Management
2-s2.0-84995810282,10.1145/2984511.2984582,,,ViBand: High-fidelity bio-acoustic sensing using commodity smartwatch accelerometers,cp,Conference Paper,Laput G.,60136640,School of Computer Science,Pittsburgh,United States,3,"Laput, Gierad;Xiao, Robert;Harrison, Chris",55258463300;55480420700;35792227900,60136640;60136640;60136640,2016-10-16,16 October 2016,UIST 2016 - Proceedings of the 29th Annual Symposium on User Interface Software and Technology,,21100786308,,Conference Proceeding,,,,321-333,"Smartwatches and wearables are unique in that they reside on the body, presenting great potential for always-available input and interaction. Their position on the wrist makes them ideal for capturing bio-acoustic signals. We developed a custom smartwatch kernel that boosts the sampling rate of a smartwatch's existing accelerometer to 4 kHz. Using this new source of high-fidelity data, we uncovered a wide range of applications. For example, we can use bio-acoustic data to classify hand gestures such as flicks, claps, scratches, and taps, which combine with on-device motion tracking to create a wide range of expressive input modalities. Bioacoustic sensing can also detect the vibrations of grasped mechanical or motor-powered objects, enabling passive object recognition that can augment everyday experiences with context-aware functionality. Finally, we can generate structured vibrations using a transducer, and show that data can be transmitted through the human body. Overall, our contributions unlock user interface techniques that previously relied on special-purpose and/or cumbersome instrumentation, making such interactions considerably more feasible for inclusion in future consumer devices.",Gestures | Object detection | Vibro-tags | Wearables,194,0,,,,undefined,,UIST User Interface
2-s2.0-84979696639,10.1145/2882903.2915235,,,Wander join: Online aggregation via random walks,cp,Conference Paper,Li F.,60025488;60025084;60008592,The University of Utah;Shanghai Jiao Tong University;Hong Kong University of Science and Technology,Salt Lake City;Shanghai;Hong Kong,United States;China;Hong Kong,4,"Li, Feifei;Wu, Bin;Yi, Ke;Zhao, Zhuoyue",8918895500;55943143800;35800286800;57190389317,60025488;60008592;60008592;60025084,2016-06-26,26 June 2016,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,26-June-2016,,,615-629,"Joins are expensive, and online aggregation over joins was proposed to mitigate the cost, which offers users a nice and flexible tradeoff between query efficiency and accuracy in a continuous, online fashion. However, the state-of-the-art approach, in both internal and external memory, is based on ripple join, which is still very expensive and even needs unrealistic assumptions (e.g., tuples in a table are stored in random order). This paper proposes a new approach, the wander join algorithm, to the online aggregation problem by performing random walks over the underlying join graph. We also design an optimizer that chooses the optimal plan for conducting the random walks without having to collect any statistics a priori. Compared with ripple join, wander join is particularly efficient for equality joins involving multiple tables, but also supports θ-joins. Selection predicates and group-by clauses can be handled as well. Extensive experiments using the TPC-H benchmark have demonstrated the superior performance of wander join over ripple join. In particular, we have integrated and tested wander join in the latest version of PostgreSQL, demonstrating its practicality in a full-edged database system.",,108,1,publisherfree2read,Bronze,NSF,GRF-16200415,National Science Foundation,SIGMOD Databases
2-s2.0-84997428839,10.1145/2950290.2950305,,,Why we Refactor? Confessions of Github contributors,cp,Conference Paper,Silva D.,60033154;112544004,Concordia University;Universidade Federal de,Montreal;Alfenas,Canada;Brazil,3,"Silva, Danilo;Tsantalis, Nikolaos;Valente, Marco Tulio",56712316800;8839792600;55437198000,112544004;60033154;112544004,2016-11-01,1 November 2016,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100787002,,Conference Proceeding,13-18-November-2016,,,858-870,"Refactoring is a widespread practice that helps developers to improve the maintainability and readability of their code. However, there is a limited number of studies empirically investigating the actual motivations behind specific refac-toring operations applied by developers. To fill this gap, we monitored Java projects hosted on GitHub to detect re-cently applied refactorings, and asked the developers to ex-plain the reasons behind their decision to refactor the code. By applying thematic analysis on the collected responses, we compiled a catalogue of 44 distinct motivations for 12 well-known refactoring types. We found that refactoring ac-tivity is mainly driven by changes in the requirements and much less by code smells. Extract Method is the most versatile refactoring operation serving 11 different purposes. Finally, we found evidence that the IDE used by the devel-opers affects the adoption of automated refactoring tools.",Code smells | GitHub | Refactoring | Software evolution,191,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-84971474341,10.1145/2884781.2884826,,,Work practices and challenges in pull-based development: The contributor's perspective,cp,Conference Paper,Gousios G.,60016529;60006288;60003122,Radboud Universiteit;Delft University of Technology;University of Victoria,Nijmegen;Delft;Victoria,Netherlands;Netherlands;Canada,3,"Gousios, Georgios;Storey, Margaret Anne;Bacchelli, Alberto",14819567500;7005753655;25924697100,60016529;60003122;60006288,2016-05-14,14 May 2016,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,14-22-May-2016,,,285-296,"The pull-based development model is an emerging way of contributing to distributed software projects that is gaining enormous popularity within the open source software (OSS) world. Previous work has examined this model by focusing on projects and their owners-we complement it by examining the work practices of project contributors and the challenges they face. We conducted a survey with 645 top contributors to active OSS projects using the pull-based model on GitHub, the prevalent social coding site. We also analyzed traces extracted from corresponding GitHub repositories. Our research shows that: contributors have a strong interest in maintaining awareness of project status to get inspiration and avoid duplicating work, but they do not actively propagate information; communication within pull requests is reportedly limited to low-level concerns and contributors often use communication channels external to pull requests; challenges are mostly social in nature, with most reporting poor responsiveness from integrators; and the increased transparency of this setting is a confirmed motivation to contribute. Based on these findings, we present recommendations for practitioners to streamline the contribution process and discuss potential future research directions.",Distributed software development | GitHub | Open source contribution | Pull request | Pull-based development,206,0,repositoryvor,Green,,undefined,,ICSE Software Engineering
2-s2.0-84995794339,10.1145/2984511.2984547,,,Zooids: Building blocks for swarm user interfaces,cp,Conference Paper,Le Goc M.,60106017;60013373;60012708,Université Paris-Saclay;INRIA Institut National de Recherche en Informatique et en Automatique;Stanford University,Gif-sur-Yvette;Le Chesnay;Stanford,France;France;United States,6,"Le Goc, Mathieu;Kim, Lawrence H.;Parsaei, Ali;Fekete, Jean Daniel;Dragicevic, Pierre;Follmer, Sean",55346963200;56742755100;57191992387;7005772385;55906779900;26430822900,60013373-60106017;60012708;60012708;60013373-60106017;60013373-60106017;60012708,2016-10-16,16 October 2016,UIST 2016 - Proceedings of the 29th Annual Symposium on User Interface Software and Technology,,21100786308,,Conference Proceeding,,,,97-109,"This paper introduces swarm user interfaces, a new class of human-computer interfaces comprised of many autonomous robots that handle both display and interaction. We describe the design of Zooids, an open-source open-hardware platform for developing tabletop swarm interfaces. The platform consists of a collection of custom-designed wheeled micro robots each 2.6 cm in diameter, a radio base-station, a highspeed DLP structured light projector for optical tracking, and a software framework for application development and control. We illustrate the potential of tabletop swarm user interfaces through a set of application scenarios developed with Zooids, and discuss general design considerations unique to swarm user interfaces.",Swarm user interfaces | Tangible user interfaces,168,0,repositoryam,Green,,undefined,,UIST User Interface
2-s2.0-84995785333,10.1145/2984511.2984572,,,ProCover: Sensory augmentation of prosthetic limbs using smart textile covers,cp,Conference Paper,Leong J.,60006191;60000594,Google LLC;University of Applied Sciences Upper Austria,Mountain View;Wels,United States;Austria,9,"Leong, Joanne;Parzer, Patrick;Perteneder, Florian;Babic, Teo;Rendl, Christian;Vogl, Anita;Egger, Hubert;Olwal, Alex;Haller, Michael",57143781600;56427776600;35254182100;57191989501;35254220900;56938201000;57191993829;7801329807;7102872675,60000594;60000594;60000594;60000594;60000594;60000594;60000594;60006191;60000594,2016-10-16,16 October 2016,UIST 2016 - Proceedings of the 29th Annual Symposium on User Interface Software and Technology,,21100786308,,Conference Proceeding,,,,335-346,"Today's commercially available prosthetic limbs lack tactile sensation and feedback. Recent research in this domain focuses on sensor technologies designed to be directly embedded into future prostheses. We present a novel concept and prototype of a prosthetic-sensing wearable that offers a noninvasive, self-applicable and customizable approach for the sensory augmentation of present-day and future low to midrange priced lower-limb prosthetics. From consultation with eight lower-limb amputees, we investigated the design space for prosthetic sensing wearables and developed novel interaction methods for dynamic, user-driven creation and mapping of sensing regions on the foot to wearable haptic feedback actuators. Based on a pilot-study with amputees, we assessed the utility of our design in scenarios brought up by the amputees and we summarize our findings to establish future directions for research into using smart textiles for the sensory enhancement of prosthetic limbs.",Assistive technology | Customization | Disability | Prosthetic limbs | Smart textiles,59,0,,,,undefined,,UIST User Interface
2-s2.0-85016208784,10.1137/1.9781611974782.140,,,A (2 + ϵ)-Approximation for Maximum Weight Matching in the Semi-Streaming Model,cp,Conference Paper,Paz A.,60022403,Technion - Israel Institute of Technology,Haifa,Israel,2,"Paz, Ami;Schwartzman, Gregory",57225351023;57190954085,60022403;60022403,2017-01-01,2017,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,21100803368,,Conference Proceeding,0,,,2153-2161,"We present a simple deterministic single-pass (2 + ϵ)- Approximation algorithm for the maximum weight matching problem in the semi-streaming model. This improves upon the currently best known approximation ratio of (3:5 + ϵ). Our algorithm uses O(n log2 n) space for constant values of ϵ. It relies on a variation of the local-ratio theorem, which may be of independent interest in the semi-streaming model.",,35,1,repositoryam,Green,ISF,1696/14,Israel Science Foundation,SODA Theory
2-s2.0-85041416005,10.1145/3025453.3025522,,,A critical lens on dementia and design in HCI,cp,Conference Paper,Lazar A.,60007363;116532588,Northwestern University;MATHER LIFE WAYS,Evanston;Evanston,United States;United States,3,"Lazar, Amanda;Edasis, Caroline;Piper, Anne Marie",55660177200;57188814904;15023169400,60007363;116532588;60007363,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,2175-2188,"Designing new technologies with and for individuals with dementia is a growing topic of interest within HCI. Yet, predominant societal views contribute to the positioning of individuals with dementia as deficient and declining, and treat technology as filling a gap left by impairment. We present the perspective of critical dementia as a way of reflecting on these views in the context of recent epistemological shifts in HCI. In addition to articulating how HCI can leverage the perspective of critical dementia, we present a case analysis of technology design in art therapy involving people with dementia aimed at challenging conventional narratives. This paper calls attention to and helps solidify an agenda for how the CHI community approaches dementia, design, and technology.",Dementia | Design | Disability | Paradigm | Theory,102,1,publisherfree2read,Bronze,NSF,IIS-1551574,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85018698735,10.1109/ICSE.2017.21,,,Becoming Agile: A Grounded Theory of Agile Transitions in Practice,cp,Conference Paper,Hoda R.,60005686;60002316,The University of Auckland;Victoria University of Wellington,Auckland;Wellington,New Zealand;New Zealand,2,"Hoda, Rashina;Noble, James",26643938800;7202238195,60005686;60002316,2017-07-19,19 July 2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",,21100827404,,Conference Proceeding,,,7985657,141-151,"Agile adoption is typically understood as a oneoff organizational process involving a staged selection of agile development practices. This view of agility fails to explain the differences in the pace and effectiveness of individual teams transitioning to agile development. Based on a Grounded Theory study of 31 agile practitioners drawn from 18 teams across five countries, we present a grounded theory of becoming agile as a network of on-going transitions across five dimensions: software development practices, team practices, management approach, reflective practices, and culture. The unique position of a software team through this network, and their pace of progress along the five dimensions, explains why individual agile teams present distinct manifestations of agility and unique transition experiences. The theory expands the current understanding of agility as a holistic and complex network of on-going multidimensional transitions, and will help software teams, their managers, and organizations better navigate their individual agile journeys.",agile software development | culture | grounded theory | management | selforganizing | teams | theory | transition,89,0,,,,undefined,,ICSE Software Engineering
2-s2.0-85047010163,,,,A linear-time kernel goodness-of-fit test,cp,Conference Paper,Jitkrittum W.,60105987;60084280;106266883,Centre de Mathématiques Appliquées;Gatsby Computational Neuroscience Unit;The Institute of Statistical Mathematics,Palaiseau;London;Tokyo,France;United Kingdom;United States,5,"Jitkrittum, Wittawat;Xu, Wenkai;Szabó, Zoltán;Fukumizu, Kenji;Gretton, Arthur",23467007300;57202054932;57201605855;6602093536;6603257032,60084280;60084280;60105987;106266883;60084280,2017-01-01,2017,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,2017-December,,,262-271,"We propose a novel adaptive test of goodness-of-fit, with computational cost linear in the number of samples. We learn the test features that best indicate the differences between observed samples and a reference model, by minimizing the false negative rate. These features are constructed via Stein's method, meaning that it is not necessary to compute the normalising constant of the model. We analyse the asymptotic Bahadur efficiency of the new test, and prove that under a mean-shift alternative, our test always has greater relative efficiency than a previous linear-time kernel test, regardless of the choice of parameters for that test. In experiments, the performance of our method exceeds that of the earlier linear-time test, and matches or exceeds the power of a quadratic-time kernel test. In high dimensions and where model structure may be exploited, our goodness of fit test performs far better than a quadratic-time two-sample test based on the Maximum Mean Discrepancy, with samples drawn from the model.",,58,0,,,,25120012,Gatsby Charitable Foundation,NeurIPS Machine Learning
2-s2.0-85024385364,10.1145/3055399.3055436,,,A weighted linear matroid parity algorithm,cp,Conference Paper,Iwata S.,60025272;60014256,The University of Tokyo;University of Tsukuba,Tokyo;Tsukuba,Japan;Japan,2,"Iwata, Satoru;Kobayashi, Yusuke",7401684260;7408650171,60025272;60014256,2017-06-19,19 June 2017,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,Part F128415,,,264-276,"The matroid parity (or matroid matching) problem, introduced as a common generalization of matching and matroid intersection problems, is so general that it requires an exponential number of oracle calls. Lovász (1980) showed that this problem admits a min-max formula and a polynomial algorithm for linearly represented matroids. Since then efficient algorithms have been developed for the linear matroid parity problem. In this paper, we present a combinatorial, deterministic, polynomial-time algorithm for the weighted linear matroid parity problem. The algorithm builds on a polynomial matrix formulation using Pfaffian and adopts a primal-dual approach based on the augmenting path algorithm of Gabow and Stallmann (1986) for the unweighted problem.",Linear matroid parity | Matching | Pfaffian | Polynomial-time algorithm | Primal-dual approach,8,0,repositoryam,Green,JSPS,16K16010,Japan Society for the Promotion of Science,STOC Theory
2-s2.0-85041123792,10.1109/FOCS.2017.37,,,A dichotomy theorem for nonuniform CSPs,cp,Conference Paper,Bulatov A.A.,60018491,Simon Fraser University,Burnaby,Canada,1,"Bulatov, Andrei A.",57204255801,60018491,2017-11-10,10 November 2017,Annual Symposium on Foundations of Computer Science - Proceedings,02725428,22882,,Conference Proceeding,2017-October,,8104069,319-330,"In a non-uniform Constraint Satisfaction problem CSP(Γ), where G is a set of relations on a finite set A, the goal is to find an assignment of values to variables subject to constraints imposed on specified sets of variables using the relations from Γ. The Dichotomy Conjecture for the non-uniform CSP states that for every constraint language Γ the problem CSP(Γ) is either solvable in polynomial time or is NP-complete. It was proposed by Feder and Vardi in their seminal 1993 paper. In this paper we confirm the Dichotomy Conjecture.",Constraint Satisfaction problem | dichotomy conjecture,284,0,repositoryam,Green,,undefined,,FOCS Theory
2-s2.0-85029104981,10.1145/3097983.3098038,,,Accelerating innovation through analogy mining,cp,Conference Paper,Hope T.,60027950;60007903,Carnegie Mellon University;Hebrew University of Jerusalem,Pittsburgh;Jerusalem,United States;Israel,4,"Hope, Tom;Chan, Joel;Kittur, Aniket;Shahaf, Dafna",57191274451;46161042900;24923233700;57204201222,60007903;60027950;60027950;60027950,2017-08-13,13 August 2017,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,21100829914,,Conference Proceeding,Part F129685,,,235-243,"The availability of large idea repositories (e.g., the U.S. patent database) could significantly accelerate innovation and discovery by providing people with inspiration from solutions to analogous problems. However, finding useful analogies in these large, messy, real-world repositories remains a persistent challenge for either human or automated methods. Previous approaches include costly hand-created databases that have high relational structure (e.g., predicate calculus representations) but are very sparse. Simpler machine-learning/information-retrieval similarity metrics can scale to large, natural-language datasets, but struggle to account for structural similarity, which is central to analogy. In this paper we explore the viability and value of learning simpler structural representations, specifically, ""problem schemas"", which specify the purpose of a product and the mechanisms by which it achieves that purpose. Our approach combines crowdsourcing and recurrent neural networks to extract purpose and mechanism vector representations from product descriptions. We demonstrate that these learned vectors allow us to find analogies with higher precision and recall than traditional information-retrieval methods. In an ideation experiment, analogies retrieved by our models significantly increased people's likelihood of generating creative ideas compared to analogies retrieved by traditional methods. Our results suggest a promising approach to enabling computational analogy at scale is to learn and leverage weaker structural representations.",Computational analogy | Creativity | Innovation | Product dimensions | Text embedding | Text mining,52,0,repositoryam,Green,NSF,CHS-1526665,National Science Foundation,KDD Data Mining
2-s2.0-85021816996,10.1145/3078505.3078514,,,Accelerating performance inference over closed systems by asymptotic methods,cp,Conference Paper,Casale G.,60015150,Imperial College London,London,United Kingdom,1,"Casale, Giuliano",21742204200,60015150,2017-06-05,5 June 2017,SIGMETRICS 2017 Abstracts - Proceedings of the 2017 ACM SIGMETRICS / International Conference on Measurement and Modeling of Computer Systems,,21100821144,,Conference Proceeding,,,,64,"Recent years have seen a rapid growth of interest in exploiting monitoring data collected from enterprise applications for automated management and performance analysis. In spite of this trend, even simple performance inference problems involving queueing theoretic formulas often incur computational bottlenecks, for example upon computing likelihoods in models of batch systems. Motivated by this issue, we revisit the solution of multiclass closed queueing networks, which are popular models used to describe batch and distributed applications with parallelism constraints.We first prove that the normalizing constant of the equilibrium state probabilities of a closed model can be reformulated exactly as a multidimensional integral over the unit simplex. This gives as a by-product novel explicit expressions for the multiclass normalizing constant. We then derive a method based on cubature rules to efficiently evaluate the proposed integral form in small and medium-sized models. For large models, we propose novel asymptotic expansions and Monte Carlo sampling methods to efficiently and accurately approximate normalizing constants and likelihoods. We illustrate the resulting accuracy gains in problems involving optimization-based inference.",,3,0,repositoryam,Green,,undefined,,SIGMETRICS Performance
2-s2.0-85041408161,10.1145/3126594.3126635,,,AirCode: Unobtrusive physical tags for digital fabrication,cp,Conference Paper,Li D.,60030162,Columbia University,New York,United States,4,"Li, Dingzeyu;Nair, Avinash S.;Nayar, Shree K.;Zheng, Changxi",55367150700;57200535222;35560595700;36060955000,60030162;60030162;60030162;60030162,2017-10-20,20 October 2017,UIST 2017 - Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology,,21100850719,,Conference Proceeding,,,,449-460,"We present AirCode, a technique that allows the user to tag physically fabricated objects with given information. An Air-Code tag consists of a group of carefully designed air pockets placed beneath the object surface. These air pockets are easily produced during the fabrication process of the object, without any additional material or postprocessing. Meanwhile, the air pockets affect only the scattering light transport under the surface, and thus are hard to notice to our naked eyes. But, by using a computational imaging method, the tags become detectable. We present a tool that automates the design of air pockets for the user to encode information. AirCode system also allows the user to retrieve the information from captured images via a robust decoding algorithm. We demonstrate our tagging technique with applications for metadata embedding, robotic grasping, as well as conveying object affordances.",3D printing | Air pockets | Digital fabrication | Sensing | Unobtrusive tags,49,0,repositoryam,Green,NSF,1453101,National Science Foundation,UIST User Interface
2-s2.0-85030749258,10.1145/3106237.3106300,,,Automatically diagnosing and repairing error handling bugs in C,cp,Conference Paper,Tian Y.,60021918,University of Virginia,Charlottesville,United States,2,"Tian, Yuchi;Ray, Baishakhi",57195997273;24492560400,60021918;60021918,2017-08-21,21 August 2017,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100833006,,Conference Proceeding,Part F130154,,,752-762,"Correct error handling is essential for building reliable and secure systems. Unfortunately, low-level languages like C often do not support any error handling primitives and leave it up to the developers to create their own mechanisms for error propagation and handling. However, in practice, the developers often make mistakes while writing the repetitive and tedious error handling code and inadvertently introduce bugs. Such error handling bugs often have severe consequences undermining the security and reliability of the affected systems. Fixing these bugs is also tiring-they are repetitive and cumbersome to implement. Therefore, it is crucial to develop tool supports for automatically detecting and fixing error handling bugs. To understand the nature of error handling bugs that occur in widely used C programs, we conduct a comprehensive study of real world error handling bugs and their fixes. Leveraging the knowledge, we then design, implement, and evaluate ErrDoc, a tool that not only detects and characterizes different types of error handling bugs but also automatically fixes them. Our evaluation on five open-source projects shows that ErrDoc can detect error handling bugs with 100% to 84% precision and around 95% recall, and categorize them with 83% to 96% precision and above 90% recall. Thus, ErrDoc improves precision up to 5 percentage points, and recall up to 44 percentage points w.r.t. the state-of-the-art. We also demonstrate that ErrDoc can fix the bugs with high accuracy.",API errors | Bug detection | Bug fix | Error handling bugs,45,0,,,,CNS-16-17670,National Science Foundation,FSE Software Engineering
2-s2.0-85044866591,10.1145/3025453.3025524,,,BIGnav: Bayesian information gain for guiding multiscale navigation,cp,Conference Paper,Liu W.,60276635;60106017;60029570,Laboratoire Interdisciplinaire des Sciences du Numérique;Université Paris-Saclay;Universidade Estadual de Campinas,Orsay;Gif-sur-Yvette;Campinas,France;France;Brazil,4,"Liu, Wanyu;D'Oliveira, Rafael Lucas;Beaudouin-Lafon, Michel;Rioul, Olivier",57188823040;57201447870;6602828964;6602627732,60106017-60276635;60106017-60029570;60276635;60106017,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,5869-5880,"This paper introduces BIGnav, a new multiscale navigation technique based on Bayesian Experimental Design where the criterion is to maximize the information-theoretic concept of mutual information, also known as information gain. Rather than simply executing user navigation commands, BIGnav interprets user input to update its knowledge about the user's intended target. Then it navigates to a new view that maximizes the information gain provided by the user's expected subsequent input. We conducted a controlled experiment demonstrating that BIGnav is significantly faster than conventional pan and zoom and requires fewer commands for distant targets, especially in non-uniform information spaces. We also applied BIGnav to a realistic application and showed that users can navigate to highly probable points of interest on a map with only a few steps. We then discuss the tradeoffs of BIG-nav - including efficiency vs. increased cognitive load - and its application to other interaction tasks.",Bayesian experimental design | Guided navigation | Multiscale navigation | Mutual information,21,0,repositoryvor,Green,H2020,ANR-11-LABEX-0045-DIGICOSME,Horizon 2020 Framework Programme,CHI Human-Computer Interaction
2-s2.0-85029392005,10.1145/3077136.3080789,,,Bitfunnel: Revisiting signatures for search,cp,Conference Paper,Goodwin B.,60026532;119227341,Microsoft Corporation;Heptio,Redmond;,United States;United States,7,"Goodwin, Bob;Hopcroft, Michael;Luu, Dan;Clemmer, Alex;Curmei, Mihaela;Elnikety, Sameh;He, Yuxiong",56335741700;57195632545;57195624306;56349732200;57195632403;8366429300;21742319000,60026532;60026532;60026532;119227341;60026532;60026532;60026532,2017-08-07,7 August 2017,SIGIR 2017 - Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval,,21100830402,,Conference Proceeding,,,,605-614,"Since the mid-90s there has been a widely-held belief that signature files are inferior to inverted files for text indexing. In recent years the Bing search engine has developed and deployed an index based on bit-sliced signatures. This index, known as BitFunnel, replaced an existing production system based on an inverted index. The driving factor behind the shift away from the inverted index was operational cost savings. This paper describes algorithmic innovations and changes in the cloud computing landscape that led us to reconsider and eventually field a technology that was once considered unusable. The BitFunnel algorithm directly addresses four fundamental limitations in bit-sliced block signatures. At the same time, our mapping of the algorithm onto a cluster offers opportunities to avoid other costs associated with signatures. We show these innovations yield a significant efficiency gain versus classic bit-sliced signatures and then compare BitFunnel with Partitioned Elias-Fano Indexes, MG4J, and Lucene.",Bit-Sliced Signatures | Bitvector | Bloom Filters | Intersection | Inverted Indexes | Query Processing | Search Engines | Signature Files,33,1,publisherfree2read,Bronze,,undefined,,SIGIR Information Retrieval
2-s2.0-85025171948,10.1145/3062341.3062363,,,Bringing the web up to speed with WebAssembly,cp,Conference Paper,Haas A.,60113660;60111167;60026532;60010449;60006191,"Mozilla Corporation;Google LLC, Europe;Microsoft Corporation;Apple Computer;Google LLC",Mountain View;Dublin;Redmond;Cupertino;Mountain View,United States;Ireland;United States;United States;United States,9,"Haas, Andreas;Rossberg, Andreas;Schuff, Derek L.;Titzer, Ben L.;Holman, Michael;Gohman, Dan;Wagner, Luke;Zakai, Alon;Bastien, J. F.",57197379524;16234732500;18437924700;12141554700;57195067645;57189873002;57197299603;6507448445;57194778948,60111167;60111167;60111167-60006191;60111167;60026532;60113660;60113660;60113660;60010449,2017-06-14,14 June 2017,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,Part F128414,,,185-200,"The maturation of theWeb platform has given rise to sophisticated and demanding Web applications such as interactive 3D visualization, audio and video software, and games.With that, efficiency and security of code on the Web has become more important than ever. Yet JavaScript as the only builtin language of the Web is not well-equipped to meet these requirements, especially as a compilation target. Engineers from the four major browser vendors have risen to the challenge and collaboratively designed a portable low-level bytecode called WebAssembly. It offers compact representation, efficient validation and compilation, and safe low to no-overhead execution. Rather than committing to a specific programming model, WebAssembly is an abstraction over modern hardware, making it language-, hardware-, and platform-independent, with use cases beyond just the Web. WebAssembly has been designed with a formal semantics from the start. We describe the motivation, design and formal semantics of WebAssembly and provide some preliminary experience with implementations. Copyright is held by the owner/author(s).",Assembly languages | Just-in-time compilers | Programming languages | Type systems | Virtual machines,217,1,publisherfree2read,Bronze,,undefined,,PLDI Programming Languages
2-s2.0-85027721960,10.1109/ICSE.2017.53,,,Challenges for static analysis of Java reflection-literature review and empirical study,cp,Conference Paper,Landman D.,60032882;60011575,Technische Universiteit Eindhoven;Centrum Wiskunde &amp; Informatica,Eindhoven;Amsterdam,Netherlands;Netherlands,3,"Landman, Davy;Serebrenik, Alexander;Vinju, Jurgen J.",55987085500;8987563200;9733732800,60011575;60011575-60032882;60011575-60032882,2017-07-19,19 July 2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",,21100827404,,Conference Proceeding,,,7985689,507-518,"The behavior of software that uses the Java Reflection API is fundamentally hard to predict by analyzing code. Only recent static analysis approaches can resolve reflection under unsound yet pragmatic assumptions. We survey what approaches exist and what their limitations are. We then analyze how real-world Java code uses the Reflection API, and how many Java projects contain code challenging state-of-The-Art static analysis. Using a systematic literature review we collected and categorized all known methods of statically approximating reflective Java code. Next to this we constructed a representative corpus of Java systems and collected descriptive statistics of the usage of the Reflection API. We then applied an analysis on the abstract syntax trees of all source code to count code idioms which go beyond the limitation boundaries of static analysis approaches. The resulting data answers the research questions. The corpus, the tool and the results are openly available. We conclude that the need for unsound assumptions to resolve reflection is widely supported. In our corpus, reflection can not be ignored for 78% of the projects. Common challenges for analysis tools such as non-exceptional exceptions, programmatic filtering meta objects, semantics of collections, and dynamic proxies, widely occur in the corpus. For Java software engineers prioritizing on robustness, we list tactics to obtain more easy to analyze reflection code, and for static analysis tool builders we provide a list of opportunities to have significant impact on real Java code.",Empirical Study | Java | Reflection | Static Analysis | Systematic Literature Review,86,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-85027727722,10.1109/ICSE.2017.14,,,Clone Refactoring with Lambda Expressions,cp,Conference Paper,Tsantalis N.,60033154,Concordia University,Montreal,Canada,3,"Tsantalis, Nikolaos;Mazinanian, Davood;Rostami, Shahriar",8839792600;55308236700;57193334786,60033154;60033154;60033154,2017-07-19,19 July 2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",,21100827404,,Conference Proceeding,,,7985650,60-70,"Lambda expressions have been introduced in Java 8 to support functional programming and enable behavior parameterization by passing functions as parameters to methods. The majority of software clones (duplicated code) are known to have behavioral differences (i.e., Type-2 and Type-3 clones). However, to the best of our knowledge, there is no previous work to investigate the utility of Lambda expressions for parameterizing such behavioral differences in clones. In this paper, we propose a technique that examines the applicability of Lambda expressions for the refactoring of clones with behavioral differences. Moreover, we empirically investigate the applicability and characteristics of the Lambda expressions introduced to refactor a large dataset of clones. Our findings show that Lambda expressions enable the refactoring of a significant portion of clones that could not be refactored by any other means.",Code duplication | Lambda expressions | Refactoring,46,0,,,,undefined,,ICSE Software Engineering
2-s2.0-85026730061,10.1109/ICSE.2017.68,,,Code Defenders: Crowdsourcing Effective Tests and Subtle Mutants with a Mutation Testing Game,cp,Conference Paper,Rojas J.M.,60001881,The University of Sheffield,Sheffield,United Kingdom,4,"Rojas, Jose Miguel;White, Thomas D.;Clegg, Benjamin S.;Fraser, Gordon",35103141400;55361024800;57195287426;9247521200,60001881;60001881;60001881;60001881,2017-07-19,19 July 2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",,21100827404,,Conference Proceeding,,,7985704,677-688,"Writing good software tests is difficult and not every developer's favorite occupation. Mutation testing aims to help by seeding artificial faults (mutants) that good tests should identify, and test generation tools help by providing automatically generated tests. However, mutation tools tend to produce huge numbers of mutants, many of which are trivial, redundant, or semantically equivalent to the original program, automated test generation tools tend to produce tests that achieve good code coverage, but are otherwise weak and have no clear purpose. In this paper, we present an approach based on gamification and crowdsourcing to produce better software tests and mutants: The Code Defenders web-based game lets teams of players compete over a program, where attackers try to create subtle mutants, which the defenders try to counter by writing strong tests. Experiments in controlled and crowdsourced scenarios reveal that writing tests as part of the game is more enjoyable, and that playing Code Defenders results in stronger test suites and mutants than those produced by automated tools.",crowdsourcing | gamification | mutation testing | software testing,37,0,,,,EP/N023978/1,Engineering and Physical Sciences Research Council,ICSE Software Engineering
2-s2.0-85025122910,10.1145/3062341.3062380,,,Compiling without continuations,cp,Conference Paper,Maurer L.,60021726;60012317,Microsoft Research;University of Oregon,Redmond;Eugene,United States;United States,4,"Maurer, Luke;Downen, Paul;Ariola, Zena M.;Jones, Simon Peyton",55191062400;55152687200;6701660319;8328527700,60012317;60012317;60012317;60021726,2017-06-14,14 June 2017,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,Part F128414,,,482-494,"Many fields of study in compilers give rise to the concept of a join point-a place where different execution paths come together. Join points are often treated as functions or continuations, but we believe it is time to study them in their own right. We show that adding join points to a direct-style functional intermediate language is a simple but powerful change that allows new optimizations to be performed, including a significant improvement to list fusion. Finally, we report on recent work on adding join points to the intermediate language of the Glasgow Haskell Compiler. Copyright is held by the owner/author(s).",ANF | CPS | GHC | Haskell | Intermediate languages | Stream fusion,5,0,,,NSF,CCF-1423617,National Science Foundation,PLDI Programming Languages
2-s2.0-85133882962,10.1145/3106237.3106265,,,Cooperative kernels: GPU multitasking for blocking algorithms,cp,Conference Paper,Sorensen T.,60015150,Imperial College London,London,United Kingdom,3,"Sorensen, Tyler;Evrard, Hugues;Donaldson, Alastair F.",55786177600;55873037000;9036767800,60015150;60015150;60015150,2017-01-01,2017,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21101095930,,Conference Proceeding,2017-January,,,431-441,"There is growing interest in accelerating irregular data-parallel algorithms on GPUs. These algorithms are typically blocking, so they require fair scheduling. But GPU programming models (e.g. OpenCL) do not mandate fair scheduling, and GPU schedulers are unfair in practice. Current approaches avoid this issue by exploiting scheduling quirks of today's GPUs in a manner that does not allow the GPU to be shared with other workloads (such as graphics rendering tasks). We propose cooperative kernels, an extension to the traditional GPU programming model geared towards writing blocking algorithms. Workgroups of a cooperative kernel are fairly scheduled, and multitasking is supported via a small set of language extensions through which the kernel and scheduler cooperate. We describe a prototype implementation of a cooperative kernel framework implemented in OpenCL 2.0 and evaluate our approach by porting a set of blocking GPU applications to cooperative kernels and examining their performance under multitasking. Our prototype exploits no vendor-specific hardware, driver or compiler support, thus our results provide a lower-bound on the efficiency with which cooperative kernels can be implemented in practice.",Cooperative multitasking | GPU | Irregular parallelism,7,0,repositoryam,Green,EPSRC,EP/N026314,Intel Corporation,FSE Software Engineering
2-s2.0-85020068141,10.1145/3055399.3055409,,,Deciding parity games in quasipolynomial time?,cp,Conference Paper,Calude C.S.,60017161;60005686,National University of Singapore;The University of Auckland,Singapore City;Auckland,Singapore;New Zealand,5,"Calude, Cristian S.;Jain, Sanjay;Khoussainov, Bakhadyr;Li, Wei;Stephan, Frank",7004413501;55461303500;57191692635;57211198489;57195430876,60005686;60017161;60005686;60017161;60017161,2017-06-19,19 June 2017,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,Part F128415,,,252-263,"It is shown that the parity game can be solved in quasipolynomial time. The parameterised parity game - with n nodes and m distinct values (aka colours or priorities) - is proven to be in the class of fixed parameter tractable (FPT) problems when parameterised over m. Both results improve known bounds, from runtime no(√n) to O(nlog(m)+6) and from an XP-algorithm with runtime O(nΘ(m)) for fixed parameter m to an FPT-algorithm with runtime O(n5) + g(m), for some function g depending on m only. As an application it is proven that coloured Muller games with n nodes and m colours can be decided in time O((mm · n)5); it is also shown that this bound cannot be improved to O((2m · n)c), for any c, unless FPT = W[1].",Muller games | Parity games | Quasipolynomial time algorithm,152,0,,,,undefined,,STOC Theory
2-s2.0-85027722823,10.1109/ICSE.2017.24,,,Decoding the Representation of Code in the Brain: An fMRI Study of Code Review and Expertise,cp,Conference Paper,Floyd B.,60021918,University of Virginia,Charlottesville,United States,3,"Floyd, Benjamin;Santander, Tyler;Weimer, Westley",57195396482;56479288400;7003629741,60021918;60021918;60021918,2017-07-19,19 July 2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",,21100827404,,Conference Proceeding,,,7985660,175-186,"Subjective judgments in software engineering tasks are of critical importance but can be difficult to study with conventional means. Medical imaging techniques hold the promise of relating cognition to physical activities and brain structures. In a controlled experiment involving 29 participants, we examine code comprehension, code review and prose review using functional magnetic resonance imaging. We find that the neural representations of programming languages vs. natural languages are distinct. We can classify which task a participant is undertaking based solely on brain activity (balanced accuracy 79%.",code comprehension | medical imaging | prose review,104,0,,,NSF,CCF 1116289,National Science Foundation,ICSE Software Engineering
2-s2.0-85041685057,10.1145/3132747.3132785,,,DeepXplore: Automated Whitebox Testing of Deep Learning Systems,cp,Conference Paper,Pei K.,60030162;60000060,Columbia University;Lehigh University,New York;Bethlehem,United States;United States,4,"Pei, Kexin;Cao, Yinzhi;Yang, Junfeng;Jana, Suman",57006403300;36668327500;36676080800;26221197900,60030162;60000060;60030162;60030162,2017-10-14,14 October 2017,SOSP 2017 - Proceedings of the 26th ACM Symposium on Operating Systems Principles,,21100851209,,Conference Proceeding,,,,1-18,"Deep learning (DL) systems are increasingly deployed in safety- and security-critical domains including self-driving cars and malware detection, where the correctness and predictability of a system’s behavior for corner case inputs are of great importance. Existing DL testing depends heavily on manually labeled data and therefore often fails to expose erroneous behaviors for rare inputs. We design, implement, and evaluate DeepXplore, the first whitebox framework for systematically testing real-world DL systems. First, we introduce neuron coverage for systematically measuring the parts of a DL system exercised by test inputs. Next, we leverage multiple DL systems with similar functionality as cross-referencing oracles to avoid manual checking. Finally, we demonstrate how finding inputs for DL systems that both trigger many differential behaviors and achieve high neuron coverage can be represented as a joint optimization problem and solved efficiently using gradient-based search techniques. DeepXplore efficiently finds thousands of incorrect corner case behaviors (e.g., self-driving cars crashing into guard rails and malware masquerading as benign software) in state-of-the-art DL models with thousands of neurons trained on five popular datasets including ImageNet and Udacity self-driving challenge data. For all tested DL models, on average, DeepXplore generated one test input demonstrating incorrect behavior within one second while running only on a commodity laptop. We further show that the test inputs generated by DeepXplore can also be used to retrain the corresponding DL model to improve the model’s accuracy by up to 3%.",Deep learning testing | Differential testing | Whitebox testing,830,0,repositoryam,Green,ONR,N00014-16-1-2263,Office of Naval Research,SOSP Operating Systems
2-s2.0-85035343801,10.1109/CVPR.2017.243,,,Densely connected convolutional networks,cp,Conference Paper,Huang G.,60111190;60025278;60007776,Facebook Research;Tsinghua University;Cornell University,Menlo Park;Beijing;Ithaca,United States;China;United States,4,"Huang, Gao;Liu, Zhuang;Van Der Maaten, Laurens;Weinberger, Kilian Q.",7403425368;57201026579;23092276000;8279937900,60007776;60025278;60111190;60007776,2017-11-06,6 November 2017,"Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017",,24212,,Conference Proceeding,2017-January,,,2261-2269,"Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L2+1) direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet.",,23661,0,repositoryam,Green,NSF,20150015,National Science Foundation,CVPR Computer Vision
2-s2.0-85041451100,10.1145/3025453.3026050,,,Design and evaluation of a data-driven password meter,cp,Conference Paper,Ur B.,60029278,The University of Chicago,Chicago,United States,12,"Ur, Blase;Alfieri, Felicia;Aung, Maung;Bauer, Lujo;Christin, Nicolas;Colnago, Jessica;Cranor, Lorrie Faith;Dixon, Henry;Naeini, Pardis Emami;Habib, Hana;Johnson, Noah;Melicher, William",42962453400;57201449515;57213246695;55620608700;6602380385;57191504631;6602378856;57201450322;57209060850;57193577171;57201449922;55948169500,60029278;60029278;60029278;60029278;60029278;60029278;60029278;60029278;60029278;60029278;60029278;60029278,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,3775-3786,"Despite their ubiquity, many password meters provide inaccurate strength estimates. Furthermore, they do not explain to users what is wrong with their password or how to improve it. We describe the development and evaluation of a data-driven password meter that provides accurate strength measurement and actionable, detailed feedback to users. This meter combines neural networks and numerous carefully combined heuristics to score passwords and generate data-driven text feedback about the user's password. We describe the meter's iterative development and final design. We detail the security and usability impact of the meter's design dimensions, examined through a 4, 509-participant online study. Under the more common password-composition policy we tested, we found that the data-driven meter with detailed feedback led users to create more secure, and no less memorable, passwords than a meter with only a bar as a strength indicator.",Data-driven | Feedback | Meter | Passwords | Usable security,95,1,publisherfree2read,Bronze,NSF,CNS-1012763,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85044852706,10.1145/3025453.3025511,,,Designing gamified applications that make safe driving more engaging,cp,Conference Paper,Steinberger F.,60011019,Queensland University of Technology,Brisbane,Australia,4,"Steinberger, Fabius;Schroeter, Ronald;Foth, Marcus;Johnson, Daniel",56278586300;6701862259;14826608900;55699193800,60011019;60011019;60011019;60011019,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,2826-2839,"Low levels of engagement while driving can pose road safety risks, e.g., inattention during low traffic or routine trips. Interactive technologies that increase task engagement could therefore offer safety benefits, e.g., through performance feedback, increased challenge, and incentives. As a means to build upon these notions, we chose to explore gamification of the driving task. The research aim was to study how to design gamified applications that make safe driving more engaging. We present six design lenses which bring into focus considerations most relevant to creating engaging car applications. A user study enhanced our understanding of design requirements and revealed user personas to support the development of such applications. These lenses and personas informed two prototypes, which we evaluated in driving simulator studies. Our results indicate that the gamified conditions increased driver engagement and reduced driving speeds. As such, our work contributes towards the design of engaging applications that are both appropriate to the safety-critical driving context and compelling to users.",Gamification | Road safety | Task engagement,32,0,repositoryam,Green,ARC,DE140101542,Australian Research Council,CHI Human-Computer Interaction
2-s2.0-85021188712,10.1145/3034786.3056108,,,Dichotomies in ontology-mediated querying with the guarded fragment,cp,Conference Paper,Hernich A.,60020661;60008293,University of Liverpool;Universität Bremen,Liverpool;Bremen,United Kingdom;Germany,4,"Hernich, André;Lutz, Carsten;Papacchini, Fabio;Wolter, Frank",8850207400;7103325866;53985176100;7005739306,60020661;60008293;60020661;60020661,2017-05-09,9 May 2017,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,Part F127745,,,185-199,"We study the complexity of ontology-mediated querying when ontologies are formulated in the guarded fragment of first-order logic (GF). Our general aim is to classify the data complexity on the level of ontologies where query evaluation w.r.t. an ontology O is considered to be in PTIME if all (unions of conjunctive) queries can be evaluated in PTIME w.r.t. O and CONP-hard if at least one query is CONP-hard w.r.t. O. We identify several large and relevant fragments of GF that enjoy a dichotomy between PTIME and CONP, some of them additionally admitting a form of counting. In fact, almost all ontologies in the BioPortal repository fall into these fragments or can easily be rewritten to do so. We then establish a variation of Ladner's Theorem on the existence of NP-intermediate problems and use this result to show that for other fragments, there is provably no such dichotomy. Again for other fragments (such as full GF), establishing a dichotomy implies the Feder-Vardi conjecture on the complexity of constraint satisfaction problems. We also link these results to Datalog-rewritability and study the decidability of whether a given ontology enjoys PTIME query evaluation, presenting both positive and negative results.",Dichotomies | Ontology-Based data access | Query answering,14,0,repositoryam,Green,H2020,647289,Horizon 2020 Framework Programme,PODS Databases
2-s2.0-85030762571,10.1145/3106237.3106279,,,Discovering relational specifications,cp,Conference Paper,Smith C.,60032179,University of Wisconsin-Madison,Madison,United States,3,"Smith, Calvin;Ferns, Gabriel;Albarghouthi, Aws",57189907303;57195998114;36336887800,60032179;60032179;60032179,2017-08-21,21 August 2017,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100833006,,Conference Proceeding,Part F130154,,,616-626,"Formal specifications of library functions play a critical role in a number of program analysis and development tasks. We present Bach, a technique for discovering likely relational specifications from data describing input-output behavior of a set of functions comprising a library or a program. Relational specifications correlate different executions of different functions; for instance, commutativity, transitivity, equivalence of two functions, etc. Bach combines novel insights from program synthesis and databases to discover a rich array of specifications. We apply Bach to learn specifications from data generated for a number of standard libraries. Our experimental evaluation demonstrates Bach's ability to learn useful and deep specifications in a small amount of time.",Datalog | Hyperproperties | Specification mining,10,0,,,NSF,1566015,National Science Foundation,FSE Software Engineering
2-s2.0-85044844285,10.1145/3025453.3025996,,,Empowered participation: Exploring how citizens use technology in local governance,cp,Conference Paper,Erete S.,60026860;120485970,"DePaul University;MadX, LLC",Chicago;Alexandria,United States;United States,2,"Erete, Sheena;Burrell, Jennifer O.",55735785700;8278420400,60026860;120485970,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,2307-2319,"The partnership between local residents and city officials to inform policy and decision-making about government resources, or participatory governance, has been extensively studied. In addition to numerous ethnographic studies about how citizens engage in-person, there has been increased focus in HCI to understand the impact of technology on citizen participation in local governance. Building upon those studies, this paper provides unique insight from a 3-year longitudinal study on the use of online tools that were organically adapted by citizens to engage in local governance in three diverse Chicago neighborhoods. Though the responsiveness of government officials varied across communities, our results suggest that citizens use technology to heighten the visibility of their concerns, to support mechanisms of government accountability, and to provide various options for resident participation in local governance. We argue that while communities may be effective in their use of ICTs, technology may not increase their political power.",Civic engagement | Low income | Participatory governance,53,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85040103714,10.1145/3025453.3025635,,,Examining menstrual tracking to inform the design of personal informatics tools,cp,Conference Paper,Epstein D.A.,60015481;113161751,University of Washington;Independent Researcher,Seattle;San Francisco,United States;United States,9,"Epstein, Daniel A.;Lee, Nicole B.;Kang, Jennifer H.;Agapie, Elena;Schroeder, Jessica;Pina, Laura R.;Fogarty, James;Kientz, Julie A.;Munson, Sean A.",25645787700;56156674500;57191545877;55734639400;57193111340;36651435300;7004668263;11139289600;22835659500,60015481;113161751;60015481;60015481;60015481;60015481;60015481;60015481;60015481,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,6876-6888,"We consider why and how women track their menstrual cycles, examining their experiences to uncover design opportunities and extend the field's understanding of personal informatics tools. To understand menstrual cycle tracking practices, we collected and analyzed data from three sources: 2,000 reviews of popular menstrual tracking apps, a survey of 687 people, and follow-up interviews with 12 survey respondents. We find that women track their menstrual cycle for varied reasons that include remembering and predicting their period as well as informing conversations with healthcare providers. Participants described six methods of tracking their menstrual cycles, including use of technology, awareness of their premenstrual physiological states, and simply remembering. Although women find apps and calendars helpful, these methods are ineffective when predictions of future menstrual cycles are inaccurate. Designs can create feelings of exclusion for gender and sexual minorities. Existing apps also generally fail to consider life stages that women experience, including young adulthood, pregnancy, and menopause. Our findings encourage expanding the field's conceptions of personal informatics. Copyright is held by the owner/author(s). Publication rights licensed to ACM.",Inclusivity | Lived informatics | Menstrual cycle | Menstrual tracking | Period | Personal informatics | Women's health,185,1,repositoryam,Green,NSF,1344613,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85039061250,10.1145/3025453.3025592,,,Explaining the gap: Visualizing one's predictions improves recall and comprehension of data,cp,Conference Paper,Kim Y.S.,60015481,University of Washington,Seattle,United States,3,"Kim, Yea Seul;Reinecke, Katharina;Hullman, Jessica",56157789900;24605497700;39361803800,60015481;60015481;60015481,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,1375-1386,"Information visualizations use interactivity to enable user-driven querying of visualized data. However, users' interactions with their internal representations, including their expectations about data, are also critical for a visualization to support learning. We present multiple graphically-based techniques for eliciting and incorporating a user's prior knowledge about data into visualization interaction. We use controlled experiments to evaluate how graphically eliciting forms of prior knowledge and presenting feedback on the gap between prior knowledge and the observed data impacts a user's ability to recall and understand the data. We find that participants who are prompted to reflect on their prior knowledge by predicting and self-explaining data outperform a control group in recall and comprehension. These effects persist when participants have moderate or little prior knowledge on the datasets. We discuss how the effects differ based on text versus visual presentations of data. We characterize the design space of graphical prediction and feedback techniques and describe design recommendations.",Information visualization | Internal representations of data | Mental models | Prediction | Self-explanation,74,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85024405774,10.1145/3055399.3055408,,,"Explicit, almost optimal, epsilon-balanced codes",cp,Conference Paper,Ta-Shma A.,60005681,Tel Aviv University,Tel Aviv-Yafo,Israel,1,"Ta-Shma, Amnon",6701381914,60005681,2017-06-19,19 June 2017,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,Part F128415,,,238-251,"The question of finding an epsilon-biased set with close to optimal support size, or, equivalently, finding an explicit binary code with distance 1-ϵ/2 and rate close to the Gilbert-Varshamov bound, attracted a lot of attention in recent decades. In this paper we solve the problem almost optimally and show an explicit e-biased set over k bits with support size O(k/c2+o(1)). This improves upon all previous explicit constructions which were in the order of k2/ϵ2, k/ϵ3 or k5/4/ϵ5/2. The result is close to the Gilbert-Varshamov bound which is O(k/ϵ2) and the lower bound which is ω(k/ϵ2log 1/ϵ). The main technical tool we use is bias amplification with the s-wide replacement product. The sum of two independent samples from an ϵ-biased set is ϵ2 biased. Rozenman and Wigderson showed how to amplify the bias more economically by choosing two samples with an expander. Based on that they suggested a recursive construction that achieves sample size O(k/ϵ4). We show that amplification with a long random walk over the s-wide replacement product reduces the bias almost optimally.",Eps-bias | Wide replacement product | Zig-Zag product,53,0,,,ISF,994/14,Israel Science Foundation,STOC Theory
2-s2.0-85030786296,10.1145/3106237.3106277,,,Fairness testing: Testing software for discrimination,cp,Conference Paper,Galhotra S.,60014313,University of Massachusetts Amherst,Amherst,United States,3,"Galhotra, Sainyam;Brun, Yuriy;Meliou, Alexandra",55829468600;23003307600;16239406100,60014313;60014313;60014313,2017-08-21,21 August 2017,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100833006,,Conference Proceeding,Part F130154,,,498-510,"This paper defines software fairness and discrimination and develops a testing-based method for measuring if and howmuch software discriminates, focusing on causality in discriminatory behavior. Evidence of software discrimination has been found in modern software systems that recommend criminal sentences, grant access to financial products, and determine who is allowed to participate in promotions. Our approach, Themis, generates efficient test suites to measure discrimination. Given a schema describing valid system inputs, Themis generates discrimination tests automatically and does not require an oracle. We evaluate Themis on 20 software systems, 12 of which come from prior work with explicit focus on avoiding discrimination. We find that (1) Themis is effective at discovering software discrimination, (2) state-of-the-art techniques for removing discrimination from algorithms fail in many situations, at times discriminating against as much as 98% of an input subdomain, (3) Themis optimizations are effective at producing efficient test suites for measuring discrimination, and (4) Themis is more efficient on systems that exhibit more discrimination. We thus demonstrate that fairness testing is a critical aspect of the software development cycle in domains with possible discrimination and provide initial tools for measuring software discrimination.",Discrimination testing | Fairness testing | Software bias | Testing,216,0,repositoryam,Green,NSF,undefined,National Science Foundation,FSE Software Engineering
2-s2.0-85041530867,10.1145/3025453.3025744,,,Fingertip tactile devices for virtual object manipulation and exploration,cp,Conference Paper,Schorr S.B.,60141508,Stanford Engineering,Stanford,United States,2,"Schorr, Samuel B.;Okamura, Allison M.",55818902300;7103344370,60141508;60141508,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,3115-3119,"One of the main barriers to immersivity during object manipulation in virtual reality is the lack of realistic haptic feedback. Our goal is to convey compelling interactions with virtual objects, such as grasping, squeezing, pressing, lifting, and stroking, without requiring a bulky, world-grounded kines-thetic feedback device (traditional haptics) or the use of predetermined passive objects (haptic retargeting). To achieve this, we use a pair of finger-mounted haptic feedback devices that deform the skin on the fingertips to convey cutaneous force information from object manipulation. We show that users can perceive differences in virtual object weight and that they apply increasing grasp forces when lifting virtual objects as rendered mass is increased. Moreover, we show how naive users perceive changes of a virtual object's physical properties when we use skin deformation to render objects with varying mass, friction, and stiffness. These studies demonstrate that fingertip skin deformation devices can provide a compelling haptic experience appropriate for virtual reality scenarios involving object manipulation.",Haptics | Mass perception | Virtual reality,116,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85041524862,10.1145/3025453.3025811,,,Flash organizations: Crowdsourcing complex work by structuring crowds as organizations,cp,Conference Paper,Valentine M.A.,60027950;60012708,Carnegie Mellon University;Stanford University,Pittsburgh;Stanford,United States;United States,6,"Valentine, Melissa A.;Retelny, Daniela;To, Alexandra;Rahmati, Negar;Doshi, Tulsee;Bernstein, Michael S.",24765781400;36182232500;57188762857;56414763900;55890972200;57193014048,60012708;60012708;60012708-60027950;60012708;60012708;60012708,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,3523-3537,"This paper introduces flash organizations: Crowds structured like organizations to achieve complex and open-ended goals. Microtask workflows, the dominant crowdsourcing structures today, only enable goals that are so simple and modular that their path can be entirely pre-defined. We present a system that organizes crowd workers into computationally-represented structures inspired by those used in organizations - roles, teams, and hierarchies - which support emergent and adaptive coordination toward open-ended goals. Our system introduces two technical contributions: 1) encoding the crowd's division of labor into de-individualized roles, much as movie crews or disaster response teams use roles to support coordination between on-demand workers who have not worked together before; and 2) reconfiguring these structures through a model inspired by version control, enabling continuous adaptation of the work and the division of labor. We report a deployment in which flash organizations successfully carried out open-ended and complex goals previously out of reach for crowdsourcing, including product design, software development, and game production. This research demonstrates digitally networked organizations that flexibly assemble and reassemble themselves from a globally distributed online workforce to accomplish complex work.",Crowdsourcing | Expert crowd work | Flash organizations,114,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85031895580,10.24963/ijcai.2017/156,,,Foundations of declarative data analysis using limit Datalog programs,cp,Conference Paper,Kaminski M.,60026851,University of Oxford,Oxford,United Kingdom,5,"Kaminski, Mark;Grau, Bernardo Cuenca;Kostylev, Egor V.;Motik, Boris;Horrocks, Ian",36147567400;22834310900;26433628600;23101071600;20734105100,60026851;60026851;60026851;60026851;60026851,2017-01-01,2017,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,0,,,1123-1130,"Motivated by applications in declarative data analysis, we study Datalogℤ-an extension of positive Datalog with arithmetic functions over integers. This language is known to be undecidable, so we propose two fragments. In limit Datalogℤ predicates are axiomatised to keep minimal/maximal numeric values, allowing us to show that fact entailment is CONEXPTIME-complete in combined, and CONP-complete in data complexity. Moreover, an additional stability requirement causes the complexity to drop to EXPTIME and PTIME, respectively. Finally, we show that stable Datalogℤ can express many useful data analysis tasks, and so our results provide a sound foundation for the development of advanced information systems.",,11,1,repositoryam,Green,EPSRC,ED3,Engineering and Physical Sciences Research Council,IJCAI Artificial Intelligence
2-s2.0-85041522326,10.1145/3126594.3126599,,,Grabity: A wearable haptic interface for simulating weight and grasping in virtual reality,cp,Conference Paper,Choi I.,60012708;60006191,Stanford University;Google LLC,Stanford;Mountain View,United States;United States,5,"Choi, Inrak;Culbertson, Heather;Miller, Mark R.;Olwal, Alex;Follmer, Sean",57191978878;16642007100;57200524331;7801329807;26430822900,60012708;60012708;60012708;60006191;60012708,2017-10-20,20 October 2017,UIST 2017 - Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology,,21100850719,,Conference Proceeding,,,,119-130,"Ungrounded haptic devices for virtual reality (VR) applications lack the ability to convincingly render the sensations of a grasped virtual object's rigidity and weight. We present Grabity, a wearable haptic device designed to simulate kinesthetic pad opposition grip forces and weight for grasping virtual objects in VR. The device is mounted on the index finger and thumb and enables precision grasps with a wide range of motion. A unidirectional brake creates rigid grasping force feedback. Two voice coil actuators create virtual force tangential to each finger pad through asymmetric skin deformation. These forces can be perceived as gravitational and inertial forces of virtual objects. The rotational orientation of the voice coil actuators is passively aligned with the real direction of gravity through a revolute joint, causing the virtual forces to always point downward. This paper evaluates the performance of Grabity through two user studies, finding promising ability to simulate different levels of weight with convincing object rigidity. The first user study shows that Grabity can conveyvarious magnitudes of weight and force sensations to users by manipulating the amplitude of the asymmetric vibration. The second user study shows that users can differentiate different weights in a virtual environment using Grabity.",Graspt | Haptics | Mass perception | Virtual reality | Weight force,172,1,publisherfree2read,Bronze,,undefined,,UIST User Interface
2-s2.0-85037376304,10.1145/3132847.3132912,,,Hike: A hybrid human-machine method for entity alignment in large-scale knowledge bases,cp,Conference Paper,Zhuang Y.,60025278,Tsinghua University,Beijing,China,4,"Zhuang, Yan;Li, Guoliang;Zhong, Zhuojian;Feng, Jianhua",57200274467;55800543300;57188709495;7403884576,60025278;60025278;60025278;60025278,2017-11-06,6 November 2017,"International Conference on Information and Knowledge Management, Proceedings",,55826,,Conference Proceeding,Part F131841,,,1917-1926,"With the vigorous development of the World Wide Web, many large-scale knowledge bases (KBs) have been generated. To improve the coverage of KBs, an important task is to integrate the heterogeneous KBs. Several automatic alignment methods have been proposed which achieve considerable success. However, due to the inconsistency and uncertainty of large-scale KBs, automatic techniques for KBs alignment achieve low quality (especially recall). Thanks to the open crowdsourcing platforms, we can harness the crowd to improve the alignment quality. To achieve this goal, in this paper we propose a novel hybrid human-machine framework for large-scale KB integration. We first partition the entities of different KBs into many smaller blocks based on their relations. We then construct a partial order on these partitions and develop an inference model which crowdsources a set of tasks to the crowd and infers the answers of other tasks based on the crowdsourced tasks. Next we formulate the question selection problem, which, given a monetary budget B, selects B crowdsourced tasks to maximize the number of inferred tasks. We prove that this problem is NP-hard and propose greedy algorithms to address this problem with an approximation ratio of 1 - 1/e. Our experiments on realworld datasets indicate that our method improves the quality and outperforms state-of-the-art approaches.",Crowdsourcing | Entity alignment | Knowledge base,43,0,,,NSF,BHJ14L010,National Science Foundation,CIKM Knowledge Management
2-s2.0-85044853429,10.1145/3025453.3025466,,,Illumination aesthetics: Light as a creative material within computational design,cp,Conference Paper,Torres C.,60025038,"University of California, Berkeley",Berkeley,United States,4,"Torres, Cesar;O'Leary, Jasper;Nicholas, Molly;Paulos, Eric",57197189270;57190251622;57201450019;6603491550,60025038;60025038;60025038;60025038,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,6111-6122,"Recent digital fabrication tools have enabled new form-giving using a wide range of physical materials. However, light as a first class creative material has been largely ignored within the design of our electronic objects. Our work expands the illumination design space by treating light as a physical material. We introduce a digital design tool that simulates and visualizes physical light interactions with a variety of materials for creating custom luminaires. We further develop a computational design and fabrication process for creating custom secondary optics elements (SOEs), which provides additional handles for users to physically shape and redirect light to compose, fill, and evenly diffuse planar and volumetric geometries. Through a workshop study with novice electronic designers, we show how incorporating physical techniques to shape light alters how users view the role and function of LEDs and electronics. We produce example pieces that showcase how our approach expands the electronics aesthetic and discuss how viewing light as material can engender novel, expressive artifacts. Copyright is held by the owner/author(s).",Digital fabrication | Displays | Lighting | Luminaire | New media,22,1,repositoryam,Green,,undefined,Adobe Systems,CHI Human-Computer Interaction
2-s2.0-85020173618,10.1145/3025453.3025729,,,Kinecting with orangutans: Zoo visitors' empathetic responses to animals' use of interactive technology,cp,Conference Paper,Webber S.,60026553;60011114,University of Melbourne;Zoos Victoria,Melbourne;Melbourne,Australia;Australia,6,"Webber, Sarah;Carter, Marcus;Sherwen, Sally;Smith, Wally;Joukhadar, Zaher;Vetere, Frank",56023289800;55316053700;56059590300;34880686900;57201296945;10039716000,60026553;60026553;60011114;60026553;60026553;60026553,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,6075-6088,"Animal conservation organisations occasionally harness depictions of animals using digital technology to inspire interest in, and concern for animals. To better understand the forms of empathy experienced by people observing animal-computer interaction, we designed and studied an interactive installation for orangutans at a zoo. Through collaborative design we established an understanding of zoos' objectives and strategies related to empathy in the zoo context. We deployed a prototype installation, and observed and interviewed visitors who watched orangutans use the installation. Analysis of observations and interviews revealed that visitors responded with cognitive, affective and motor empathy for the animals. We propose that these empathetic responses are prompted by the visibility of orangutans' bodily movements, by the 'anthropic frame' provided by digital technology, and by prompting reflection on animals' cognitive processes and affective states. This paper contributes new evidence and understanding of people's empathetic responses to observing animal-computer interaction and confirms the value of designing for empathy in its various forms.",Animal-computer interaction | Conservation | Empathy | Primates | Zoos,63,0,,,,undefined,Microsoft Research,CHI Human-Computer Interaction
2-s2.0-85030467939,,,,Label-free supervision of neural networks with physics and domain knowledge,cp,Conference Paper,Stewart R.,60141508,Stanford Engineering,Stanford,United States,2,"Stewart, Russell;Ermon, Stefano",57191078763;35791579200,60141508;60141508,2017-01-01,2017,"31st AAAI Conference on Artificial Intelligence, AAAI 2017",,21100832747,,Conference Proceeding,,,,2576-2582,"In many machine learning applications, labeled data is scarce and obtaining more labels is expensive. We introduce a new approach to supervising neural networks by specifying constraints that should hold over the output space, rather than direct examples of input-output pairs. These constraints are derived from prior domain knowledge, e.g., from known laws of physics. We demonstrate the effectiveness of this approach on real world and simulated computer vision tasks. We are able to train a convolutional neural network to detect and track objects without any labeled examples. Our approach can significantly reduce the need for labeled training data, but introduces new challenges for encoding prior knowledge into appropriate loss functions.",,179,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-85029441157,10.1145/3098822.3098829,,,Language-directed hardware design for network performance monitoring,cp,Conference Paper,Narayana S.,60010126;60006320;119223230;114059328,Indian Institute of Technology Guwahati;MIT Computer Science &amp; Artificial Intelligence Laboratory;Cisco Tetration Analytics;Barefoot Networks,Guwahati;Cambridge;Cisco;Palo Alto,India;United States;United States;United States,8,"Narayana, Srinivas;Sivaraman, Anirudh;Nathan, Vikram;Goyal, Prateesh;Arun, Venkat;Alizadeh, Mohammad;Jeyakumar, Vimalkumar;Kim, Changhoon",55329476700;55549279000;57192235882;57195635268;57195640570;55658057154;57196780799;55697753700,60006320;60006320;60006320;60006320;60010126;60006320;119223230;114059328,2017-08-07,7 August 2017,SIGCOMM 2017 - Proceedings of the 2017 Conference of the ACM Special Interest Group on Data Communication,,21100830485,,Conference Proceeding,,,,85-98,"Network performance monitoring today is restricted by existing switch support for measurement, forcing operators to rely heavily on endpoints with poor visibility into the network core. Switch vendors have added progressively more monitoring features to switches, but the current trajectory of adding specific features is unsustainable given the ever-changing demands of network operators. Instead, we ask what switch hardware primitives are required to support an expressive language of network performance questions. We believe that the resulting switch hardware design could address a wide variety of current and future performance monitoring needs. We present a performance query language, Marple, modeled on familiar functional constructs like map, filter, groupby, and zip. Marple is backed by a new programmable key-value store primitive on switch hardware. The key-value store performs flexible aggregations at line rate (e.g., a moving average of queueing latencies per flow), and scales to millions of keys. We present a Marple compiler that targets a P4-programmable software switch and a simulator for highspeed programmable switches. Marple can express switch queries that could previously run only on end hosts, while Marple queries only occupy a modest fraction of a switch's hardware resources.",Network hardware | Network measurement | Network programming,217,1,repositoryvor,Green,NSF,undefined,National Science Foundation,SIGCOMM Networking
2-s2.0-85041912723,10.1109/CVPR.2017.241,,,Learning from simulated and unsupervised images through adversarial training,cp,Conference Paper,Shrivastava A.,60010449,Apple Computer,Cupertino,United States,6,"Shrivastava, Ashish;Pfister, Tomas;Tuzel, Oncel;Susskind, Josh;Wang, Wenda;Webb, Russ",57197090723;36598926300;8619883500;15077025900;57201317548;57201314933,60010449;60010449;60010449;60010449;60010449;60010449,2017-11-06,6 November 2017,"Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017",,24212,,Conference Proceeding,2017-January,,,2242-2251,"With recent progress in graphics, it has become more tractable to train models on synthetic images, potentially avoiding the need for expensive annotations. However, learning from synthetic images may not achieve the desired performance due to a gap between synthetic and real image distributions. To reduce this gap, we propose Simulated+Unsupervised (S+U) learning, where the task is to learn a model to improve the realism of a simulator's output using unlabeled real data, while preserving the annotation information from the simulator. We develop a method for S+U learning that uses an adversarial network similar to Generative Adversarial Networks (GANs), but with synthetic images as inputs instead of random vectors. We make several key modifications to the standard GAN algorithm to preserve annotations, avoid artifacts, and stabilize training: (i) a 'self-regularization' term, (ii) a local adversarial loss, and (iii) updating the discriminator using a history of refined images. We show that this enables generation of highly realistic images, which we demonstrate both qualitatively and with a user study. We quantitatively evaluate the generated images by training models for gaze estimation and hand pose estimation. We show a significant improvement over using synthetic images, and achieve state-of-the-art results on the MPIIGaze dataset without any labeled real data.",,1080,0,repositoryam,Green,,undefined,,CVPR Computer Vision
2-s2.0-85018731450,10.1145/3062341.3062371,,,Low overhead dynamic binary translation on ARM,cp,Conference Paper,D'Antras A.,60003771,The University of Manchester,Manchester,United Kingdom,4,"D'Antras, Amanieu;Gorgovan, Cosmin;Garside, Jim;Luján, Mikel",57188993297;57188990996;7006197275;57205867906,60003771;60003771;60003771;60003771,2017-06-14,14 June 2017,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,Part F128414,,,333-346,"The ARMv8 architecture introduced AArch64, a 64-bit execution mode with a new instruction set, while retaining binary compatibility with previous versions of the ARM architecture through AArch32, a 32-bit execution mode. Most hardware implementations of ARMv8 processors support both AArch32 and AArch64, which comes at a cost in hardware complexity. We present MAMBO-X64, a dynamic binary translator for Linux which executes 32-bit ARM binaries using only the AArch64 instruction set. We have evaluated the performance of MAMBO-X64 on three existing ARMv8 processors which support both AArch32 and AArch64 instruction sets. The performance was measured by comparing the running time of 32-bit benchmarks running under MAMBO-X64 with the same benchmark running natively. On SPEC CPU2006, we achieve a geometric mean overhead of less than 7.5% on in-order Cortex-A53 processors and a performance improvement of 1% on out-of-order X-Gene 1 processors. MAMBO-X64 achieves such low overhead by novel optimizations to map AArch32 floating-point registers to AArch64 registers dynamically, handle overflowing address calculations efficiently, generate traces that harness hardware return address prediction, and handle operating system signals accurately. Copyright is held by the owner/author(s).",ARM | Binary translation,15,0,repositoryam,Green,,undefined,,PLDI Programming Languages
2-s2.0-85040313738,10.1109/ICCV.2017.322,,,Mask R-CNN,cp,Conference Paper,He K.,60111190,Facebook Research,Menlo Park,United States,4,"He, Kaiming;Gkioxari, Georgia;Dollar, Piotr;Girshick, Ross",57209052101;55922650600;15622876800;35179333300,60111190;60111190;60111190;60111190,2017-12-22,22 December 2017,Proceedings of the IEEE International Conference on Computer Vision,15505499,110561,,Conference Proceeding,2017-October,,8237584,2980-2988,"We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without tricks, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code will be made available.",,16419,0,,,,undefined,,ICCV Computer Vision
2-s2.0-85044130161,10.1145/3025453.3025580,,,Modelling learning of new keyboard layouts,cp,Conference Paper,Jokinen J.P.P.,60103653;60007399,Aalto University;Kochi University of Technology,Espoo;Kami,Finland;Japan,6,"Jokinen, Jussi P.P.;Sarcar, Sayan;Oulasvirta, Antti;Silpasuwanchai, Chaklam;Wang, Zhenxin;Ren, Xiangshi",55841434500;36139109600;13006124600;56157659200;56740240600;7401875870,60103653;60007399;60103653;60007399;60007399;60007399,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,4203-4215,"Predicting how users learn new or changed interfaces is a longstanding objective in HCI research. This paper contributes to understanding of visual search and learning in text entry. With a goal of explaining variance in novices' typing performance that is attributable to visual search, a model was designed to predict how users learn to locate keys on a keyboard: initially relying on visual short-term memory but then transitioning to recall-based search. This allows predicting search times and visual search patterns for completely and partially new layouts. The model complements models of motor performance and learning in text entry by predicting change in visual search patterns over time. Practitioners can use it for estimating how long it takes to reach the desired level of performance with a given layout.",Keyboard layouts | Models of learning | Visual search,44,1,repositoryvor,Green,H2020,291556,Horizon 2020 Framework Programme,CHI Human-Computer Interaction
2-s2.0-85034111806,10.1109/INFOCOM.2017.8057136,,,One step at a time: Optimizing SDN upgrades in ISP networks,cp,Conference Paper,Poularakis K.,60157832;60011604;60011149,Yale School of Engineering &amp; Applied Science;Technische Universität Berlin;Trinity College Dublin,New Haven;Berlin;Dublin,United States;Germany;Ireland,4,"Poularakis, Konstantinos;Iosifidis, George;Smaragdakis, Georgios;Tassiulas, Leandros",55454010800;24821181700;8361129000;36562504600,60157832;60157832-60011149;60011604;60157832,2017-10-02,2 October 2017,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,,,8057136,,"Nowadays, there is a fast-paced shift from legacy telecommunication systems to novel Software Defined Network (SDN) architectures that can support on-the-fly network reconfiguration, therefore, empowering advanced traffic engineering mechanisms. Despite this momentum, migration to SDN cannot be realized at once especially in high-end cost networks of Internet Service Providers (ISPs). It is expected that ISPs will gradually upgrade their networks to SDN over a period that spans several years. In this paper, we study the SDN upgrading problem in an ISP network: which nodes to upgrade and when. We consider a general model that captures different migration costs and network topologies, and two plausible ISP objectives; first, the maximization of the traffic that traverses at least one SDN node, and second, the maximization of the number of dynamically selectable routing paths enabled by SDN nodes. We leverage the theory of submodular and supermodular functions to devise algorithms with provable approximation ratios for each objective. Using real-world network topologies and traffic matrices, we evaluate the performance of our algorithms and show up to 54% gains over state-of-the-art methods. Moreover, we describe the interplay between the two objectives; maximizing one may cause a factor of 2 loss to the other.",,74,0,,,NSF,CNS 1527090,National Science Foundation,INFOCOM Networking
2-s2.0-85027674841,10.1109/ICSE.2017.69,,,Optimizing Test Placement for Module-Level Regression Testing,cp,Conference Paper,Shi A.,60026532;60021726;60000745,Microsoft Corporation;Microsoft Research;University of Illinois Urbana-Champaign,Redmond;Redmond;Urbana,United States;United States;United States,5,"Shi, August;Thummalapenta, Suresh;Lahiri, Shuvendu K.;Bjorner, Nikolaj;Czerwonka, Jacek",56453975300;24072113500;8938407600;23396128200;35742607100,60000745;60026532;60021726;60000745;60000745,2017-07-19,19 July 2017,"Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering, ICSE 2017",,21100827404,,Conference Proceeding,,,7985705,689-699,"Modern build systems help increase developer productivityby performing incremental building and testing. Thesebuild systems view a software project as a group of interdependentmodules and perform regression test selection at themodule level. However, many large software projects have imprecisedependency graphs that lead to wasteful test executions. Ifa test belongs to a module that has more dependencies than theactual dependencies of the test, then it is executed unnecessarilywhenever a code change impacts those additional dependencies. In this paper, we formulate the problem of wasteful testexecutions due to suboptimal placement of tests in modules. We propose a greedy algorithm to reduce the number oftest executions by suggesting test movements while consideringhistorical build information and actual dependencies of tests. Wehave implemented our technique, called TestOptimizer, on topof CloudBuild, the build system developed within Microsoft overthe last few years. We have evaluated the technique on five largeproprietary projects. Our results show that the suggested testmovements can lead to a reduction of 21.66 million test executions(17.09%) across all our subject projects. We received encouragingfeedback from the developers of these projects, they accepted andintend to implement ≈80% of our reported suggestions.",build system | module-level regression testing | regression test selection,26,0,,,,CCF-1409423,National Stroke Foundation,ICSE Software Engineering
2-s2.0-85044846788,10.1145/3025453.3025952,,,"Organic primitives: Synthesis and design of pH-reactive materials using molecular I/O for sensing, actuation, and interaction",cp,Conference Paper,Kan V.,60025997;60002243,Keio University;MIT Media Lab,Tokyo;Cambridge,Japan;United States,7,"Kan, Viirj;Vargo, Emma;Machover, Noa;Ishii, Hiroshi;Pan, Serena;Chen, Weixuan;Kakehi, Yasuaki",56536337900;57195982127;58390829100;26660877000;57201451378;57037183400;8316381200,60002243;60002243;60002243;60002243;60002243;60002243;60002243-60025997,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,989-1000,"In this paper we present Organic Primitives, an enabling toolbox that expands upon the library of input-output devices in HCI and facilitates the design of interactions with organic, fluid-based systems. We formulated color, odor and shape changing material primitives which act as sensor-actuators that convert pH signals into human-readable outputs. Food-grade organic molecules anthocyanin, vanillin, and chitosan were employed as dopants to synthesize materials which output a spectrum of colors, degrees of shape deformation, and switch between odorous and non-odorous states. We evaluated the individual output properties of our sensor-actuators to assess the rate, range, and reversibility of the changes as a function of pH 2-10. We present a design space with techniques for enhancing the functionality of the material primitives, and offer passive and computational methods for controlling the material interfaces. Finally, we explore applications enabled by Organic Primitives under four contexts: environmental, cosmetic, edible, and interspecies.",Chemical sensing | Color | Droplets | Edible materials | Microfluidics | Molecular design interactions | Multi-modal output | Odor | pH-reactive | Programmable food | Shape change,47,1,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85044846788,10.1145/3025453.3025952,,,"Organic primitives: Synthesis and design of pH-reactive materials using molecular I/O for sensing, actuation, and interaction",cp,Conference Paper,Kan V.,60025997;60002243,Keio University;MIT Media Lab,Tokyo;Cambridge,Japan;United States,7,"Kan, Viirj;Vargo, Emma;Machover, Noa;Ishii, Hiroshi;Pan, Serena;Chen, Weixuan;Kakehi, Yasuaki",56536337900;57195982127;58390829100;26660877000;57201451378;57037183400;8316381200,60002243;60002243;60002243;60002243;60002243;60002243;60002243-60025997,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,989-1000,"In this paper we present Organic Primitives, an enabling toolbox that expands upon the library of input-output devices in HCI and facilitates the design of interactions with organic, fluid-based systems. We formulated color, odor and shape changing material primitives which act as sensor-actuators that convert pH signals into human-readable outputs. Food-grade organic molecules anthocyanin, vanillin, and chitosan were employed as dopants to synthesize materials which output a spectrum of colors, degrees of shape deformation, and switch between odorous and non-odorous states. We evaluated the individual output properties of our sensor-actuators to assess the rate, range, and reversibility of the changes as a function of pH 2-10. We present a design space with techniques for enhancing the functionality of the material primitives, and offer passive and computational methods for controlling the material interfaces. Finally, we explore applications enabled by Organic Primitives under four contexts: environmental, cosmetic, edible, and interspecies.",Chemical sensing | Color | Droplets | Edible materials | Microfluidics | Molecular design interactions | Multi-modal output | Odor | pH-reactive | Programmable food | Shape change,47,1,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85036619107,10.14778/3137765.3137801,,,GRAPE: Parallelizing sequential graph computations,cp,Conference Paper,Fan W.,60027272;60018208;60014347;60013789,The University of Edinburgh;Washington State University Pullman;Hong Kong Baptist University;Beihang University,Edinburgh;Pullman;Hong Kong;Beijing,United Kingdom;United States;Hong Kong;China,5,"Fan, Wenfei;Xu, Jingbo;Wu, Yinghui;Yu, Wenyuan;Jiang, Jiaxin",7401635408;57044925200;36167747600;42263090700;57192075389,60027272-60013789;60027272-60013789;60018208;60013789;60014347,2017-08-01,1 August 2017,Proceedings of the VLDB Endowment,,21100199855,21508097,Journal,10,12,,1889-1892,"We demonstrate GRAPE, a parallel GRAPh query Engine. GRAPE advocates a parallel model based on a simultaneous fixed point computation in terms of partial and incremental evaluation. It differs from prior systems in its ability to parallelize existing sequential graph algorithms as a whole, without the need for recasting the entire algorithms into a new model. One of its unique features is that under a monotonic condition, GRAPE parallelization guarantees to terminate with correct answers as long as the sequential algorithms ""plugged in"" are correct. We demonstrate its parallel computations, ease-of-use and performance compared with the start-of-the-art graph systems. We also demonstrate a use case of GRAPE in social media marketing.",,24,0,,,GRF,652976,Glaucoma Research Foundation,SIGMOD Databases
2-s2.0-85040903381,10.18653/v1/P17-1109,,,Probabilistic typology: Deep generative models of vowel inventories,cp,Conference Paper,Cotterell R.,60005248,Johns Hopkins University,Baltimore,United States,2,"Cotterell, Ryan;Eisner, Jason",56350054200;57206503633,60005248;60005248,2017-01-01,2017,"ACL 2017 - 55th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)",,21100846917,,Conference Proceeding,1,,,1182-1192,"Linguistic typology studies the range of structures present in human language. The main goal of the field is to discover which sets of possible phenomena are universal, and which are merely frequent. For example, all languages have vowels, while most-but not all-languages have an [u] sound. In this paper we present the first probabilistic treatment of a basic question in phonological typology: What makes a natural vowel inventory? We introduce a series of deep stochastic point processes, and contrast them with previous computational, simulation-based approaches. We provide a comprehensive suite of experiments on over 200 distinct languages.",,18,1,repositoryam,Green,CISE,1423276,Directorate for Computer and Information Science and Engineering,ACL Natural Language Processing
2-s2.0-85020417159,10.14778/3055540.3055550,,,Provenance for natural language queries,cp,Conference Paper,Deutch D.,60005681,Tel Aviv University,Tel Aviv-Yafo,Israel,3,"Deutch, Daniel;Frost, Nave;Gilad, Amir",23472515200;57194513669;56818807700,60005681;60005681;60005681,2016-01-01,2016,Proceedings of the VLDB Endowment,,21100199855,21508097,Conference Proceeding,10,5,,577-588,"Multiple lines of research have developed Natural Language (NL) interfaces for formulating database queries. We build upon this work, but focus on presenting a highly detailed form of the answers in NL. The answers that we present are importantly based on the provenance of tuples in the query result, detailing not only the results but also their explanations. We develop a novel method for transforming provenance information to NL, by leveraging the original NL query structure. Furthermore, since provenance information is typically large and complex, we present two solutions for its effective presentation as NL text: One that is based on provenance factorization, with novel desiderata relevant to the NL case, and one that is based on summarization. We have implemented our solution in an end-to-end system supporting questions, answers and provenance, all expressed in NL. Our experiments, including a user study, indicate the quality of our solution and its scalability.",,20,0,,,,undefined,,VLDB Databases
2-s2.0-85029415541,10.1145/3098822.3098825,,,Re-architecting datacenter networks and stacks for low latency and high performance,cp,Conference Paper,Handley M.,60031101;60022148;60003161,University of Cambridge;University College London;University Politehnica of Bucharest,Cambridge;London;Bucharest,United Kingdom;United Kingdom;Romania,7,"Handley, Mark;Raiciu, Costin;Agache, Alexandru;Voinescu, Andrei;Moore, Andrew W.;Antichi, Gianni;Wojcik, Marcin",7006454610;16307632000;57194114875;36018573100;57202346326;25924766600;39962787100,60022148;60003161;60003161;60003161;60031101;60031101;60031101,2017-08-07,7 August 2017,SIGCOMM 2017 - Proceedings of the 2017 Conference of the ACM Special Interest Group on Data Communication,,21100830485,,Conference Proceeding,,,,29-42,"Modern datacenter networks provide very high capacity via redundant Clos topologies and low switch latency, but transport protocols rarely deliver matching performance. We present NDP, a novel datacenter transport architecture that achieves near-optimal completion times for short transfers and high flow throughput in a wide range of scenarios, including incast. NDP switch buffers are very shallow and when they fill the switches trim packets to headers and priority forward the headers. This gives receivers a full view of instantaneous demand from all senders, and is the basis for our novel, high-performance, multipath-aware transport protocol that can deal gracefully with massive incast events and prioritize traffic from different senders on RTT timescales. We implemented NDP in Linux hosts with DPDK, in a software switch, in a NetFPGA-based hardware switch, and in P4. We evaluate NDP's performance in our implementations and in large-scale simulations, simultaneously demonstrating support for very low-latency and high throughput.",Datacenters | Network Stacks | Transport Protocols,248,0,repositoryam,Green,H2020,644866,Horizon 2020 Framework Programme,SIGCOMM Networking
2-s2.0-85044853440,10.1145/3025453.3025516,,,Reflective practicum: A framework of sensitising concepts to design for transformative reflection,cp,Conference Paper,Slovak P.,60018163,Technische Universität Wien,Vienna,Austria,3,"Slovak, Petr;Frauenberger, Chris;Fitzpatrick, Geraldine",24777208600;56450924400;8403702300,60018163;60018163;60018163,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,2696-2707,"Designing for reflection is becoming an increasingly important part of many HCI systems in a wide range of application domains. However, there is a gap in our understanding of how the process of reflection can be supported through technology. In fact, an implicit assumption in the majority of existing work is that, just by providing access to well-selected data, in-depth reflection can and will occur. To counter this view, we draw on Schön's notion of reflective practicum and apply it as a sensitising concept to identify the complex interplay of factors that support transformative reflection in the context of two social-emotional learning (SEL) studies. The results highlight the need to carefully scaffold the process of reflection, rather than simply assume that the capability to reflect is a broadly available trait to be 'triggered' through data. Building on this analysis, we develop a conceptual framework that extends the concept of the reflective practicum towards identifying appropriate roles of technology to support transformative reflection. While our case is within the context of SEL, we argue that a deeper understanding of these opportunities can also benefit designing for reflection in other areas.",Personal informatics | Reflection | Reflective informatics | SEL | Social-emotional skills,81,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85025169678,10.1145/3062341.3062352,,,Repairing sequential consistency in C/C++11,cp,Conference Paper,Lahav O.,60013682;60002485,Seoul National University;Max Planck Institute for Software Systems,Seoul;Saarbrucken,South Korea;Germany,5,"Lahav, Ori;Vafeiadis, Viktor;Kang, Jeehoon;Hur, Chung Kil;Dreyer, Derek",36460156400;14018754100;57013793100;56184835000;7004212179,60002485;60002485;60013682;60013682;60002485,2017-06-14,14 June 2017,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,Part F128414,,,618-632,"The C/C++11 memory model defines the semantics of concurrent memory accesses in C/C++, and in particular supports racy ""atomic"" accesses at a range of different consistency levels, from very weak consistency (""relaxed"") to strong, sequential consistency (""SC""). Unfortunately, as we observe in this paper, the semantics of SC atomic accesses in C/C++11, as well as in all proposed strengthenings of the semantics, is flawed, in that (contrary to previously published results) both suggested compilation schemes to the Power architecture are unsound. We propose a model, called RC11 (for Repaired C11), with a better semantics for SC accesses that restores the soundness of the compilation schemes to Power, maintains the DRF-SC guarantee, and provides stronger, more useful, guarantees to SC fences. In addition, we formally prove, for the first time, the correctness of the proposed stronger compilation schemes to Power that preserve load-to-store ordering and avoid ""out-of-thin-air"" reads.",C++11 | Declarative semantics | Sequential consistency | Weak memory models,69,0,repositoryam,Green,,undefined,,PLDI Programming Languages
2-s2.0-85047014251,,,,Safe and nested subgame solving for imperfect-information games,cp,Conference Paper,Brown N.,60136640,School of Computer Science,Pittsburgh,United States,2,"Brown, Noam;Sandholm, Tuomas",56393665600;57203083791,60136640;60136640,2017-01-01,2017,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,2017-December,,,690-700,"In imperfect-information games, the optimal strategy in a subgame may depend on the strategy in other, unreached subgames. Thus a subgame cannot be solved in isolation and must instead consider the strategy for the entire game as a whole, unlike perfect-information games. Nevertheless, it is possible to first approximate a solution for the whole game and then improve it in individual subgames. This is referred to as subgame solving. We introduce subgame-solving techniques that outperform prior methods both in theory and practice. We also show how to adapt them, and past subgame-solving techniques, to respond to opponent actions that are outside the original action abstraction; this significantly outperforms the prior state-of-the-art approach, action translation. Finally, we show that subgame solving can be repeated as the game progresses down the game tree, leading to far lower exploitability. These techniques were a key component of Libratus, the first AI to defeat top humans in heads-up no-limit Texas hold'em poker.",,86,0,,,,CCF-1733556,National Science Foundation,NeurIPS Machine Learning
2-s2.0-85019634994,10.1145/3025453.3025683,,,ShareVR: Enabling co-located experiences for virtual reality between HMD and Non-HMD users,cp,Conference Paper,Gugenheimer J.,60010586,Universität Ulm,Ulm,Germany,4,"Gugenheimer, Jan;Stemasov, Evgeny;Frommel, Julian;Rukzio, Enrico",55876769400;57194287893;56422369000;18233783900,60010586;60010586;60010586;60010586,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,4021-4033,"Virtual reality (VR) head-mounted displays (HMD) allow for a highly immersive experience and are currently becoming part of the living room entertainment. Current VR systems focus mainly on increasing the immersion and enjoyment for the user wearing the HMD (HMD user), resulting in all the bystanders (Non-HMD users) being excluded from the experience. We propose ShareVR, a proof-of-concept prototype using floor projection and mobile displays in combination with positional tracking to visualize the virtual world for the Non-HMD user, enabling them to interact with the HMD user and become part of the VR experience. We designed and implemented ShareVR based on the insights of an initial online survey (n=48) with early adopters of VR HMDs. We ran a user study (n=16) comparing ShareVR to a baseline condition showing how the interaction using ShareVR led to an increase of enjoyment, presence and social interaction. In a last step we implemented several experiences for ShareVR, exploring its design space and giving insights for designers of co-located asymmetric VR experiences.",Asymmetric virtual reality | Co-located virtual reality | Consumer virtual reality | Multi-user virtual reality | ShareVR,215,0,,,DFG,undefined,Deutsche Forschungsgemeinschaft,CHI Human-Computer Interaction
2-s2.0-85031668869,10.1145/3025453.3025875,,,Stories from survivors: Privacy &amp; security practices when coping with intimate partner abuse,cp,Conference Paper,Matthews T.,60006191;120258126,Google LLC;CORA (COMMUNITY OVERCOMING RELATIONSHIP ABUSE),Mountain View;San Mateo,United States;United States,9,"Matthews, Tara;O'Leary, Kathleen;Turner, Anna;Sleeper, Manya;Woelfer, Jill Palzkill;Shelton, Martin;Manthorne, Cori;Churchill, Elizabeth F.;Consolvo, Sunny",56212800500;57220422893;57193577958;50362140300;34978008800;57196074000;57196073726;7003488324;10140027800,60006191;60006191;60006191;60006191;60006191;60006191;120258126;60006191;60006191,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,2189-2201,"We present a qualitative study of the digital privacy and security motivations, practices, and challenges of survivors of intimate partner abuse (IPA). This paper provides a framework for organizing survivors' technology practices and challenges into three phases: physical control, escape, and life apart. This three-phase framework combines technology practices with three phases of abuse to provide an empirically sound method for technology creators to consider how survivors of IPA can leverage new and existing technologies. Overall, our results suggest that the usability of and control over privacy and security functions should be or continue to be high priorities for technology creators seeking ways to better support survivors of IPA. Copyright is held by the owner/author(s).",Domestic violence | Intimate partner abuse | Privacy | Security | User study,140,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85016226269,10.1137/1.9781611974782.139,,,Subquadratic algorithms for the diameter and the sum of pairwise distances in planar graphs,cp,Conference Paper,Cabello S.,60031106,Univerza v Ljubljani,Ljubljana,Slovenia,1,"Cabello, Sergio",55971985200,60031106,2017-01-01,2017,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,21100803368,,Conference Proceeding,0,,,2143-2152,We show how to compute in O(n11/6 polylog(n)) expected time the diameter and the sum of the pairwise distances in an undirected planar graph with n vertices and positive edge weights. These are the first algorithms for these problems using time O(nc) for some constant c < 2.,,22,1,repositoryam,Green,,undefined,,SODA Theory
2-s2.0-85041645850,10.1145/3132747.3132760,,,"The Efficient Server Audit Problem, Deduplicated Re-execution, and the Web",cp,Conference Paper,Tan C.,60003261;106019929,Courant Institute of Mathematical Sciences;Two Sigma Investments,New York;New York,United States;United States,4,"Tan, Cheng;Yu, Lingfan;Leners, Joshua B.;Walfish, Michael",57200563451;57200558018;36662574000;8623622200,60003261;60003261;106019929;60003261,2017-10-14,14 October 2017,SOSP 2017 - Proceedings of the 26th ACM Symposium on Operating Systems Principles,,21100851209,,Conference Proceeding,,,,546-564,"You put a program on a concurrent server, but you don’t trust the server; later, you get a trace of the actual requests that the server received from its clients and the responses that it delivered. You separately get logs from the server; these are untrusted. How can you use the logs to efficiently verify that the responses were derived from running the program on the requests? This is the Efficient Server Audit Problem, which abstracts real-world scenarios, including running a web application on an untrusted provider. We give a solution based on several new techniques, including simultaneous replay and efficient verification of concurrent executions. We implement the solution for PHP web applications. For several applications, our verifier achieves 5.6–10.9× speedup versus simply re-executing, with <10% overhead for the server.",,16,0,repositoryam,Green,,undefined,,SOSP Operating Systems
2-s2.0-85041099312,10.1109/FOCS.2017.70,,,The matching problem in general graphs is in quasi-NC,cp,Conference Paper,Svensson O.,60028186,École Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,2,"Svensson, Ola;Tarnawski, Jakub",23393910000;56743254500,60028186;60028186,2017-11-10,10 November 2017,Annual Symposium on Foundations of Computer Science - Proceedings,02725428,22882,,Conference Proceeding,2017-October,,8104102,696-707,"We show that the perfect matching problem in general graphs is in Quasi-NC. That is, we give a deterministic parallel algorithm which runs in O(\log^3 n) time on n^{O(\log^2 n)} processors. The result is obtained by a derandomization of the Isolation Lemma for perfect matchings, which was introduced in the classic paper by Mulmuley, Vazirani and Vazirani [1987] to obtain a Randomized NC algorithm.Our proof extends the framework of Fenner, Gurjar and Thierauf [2016], who proved the analogous result in the special case of bipartite graphs. Compared to that setting, several new ingredients are needed due to the significantly more complex structure of perfect matchings in general graphs. In particular, our proof heavily relies on the laminar structure of the faces of the perfect matching polytope.",derandomization | Isolation Lemma | parallel complexity | perfect matching,44,0,repositoryam,Green,FP7,335288,Seventh Framework Programme,FOCS Theory
2-s2.0-85028995068,10.1145/3106237.3106272,,,"The power of ""why"" and ""why not"": Enriching scenario exploration with provenance",cp,Conference Paper,Nelson T.,60011460;60011410,Brown University;Worcester Polytechnic Institute,Providence;Worcester,United States;United States,4,"Nelson, Tim;Danas, Natasha;Dougherty, Daniel J.;Krishnamurthi, Shriram",55316112900;57195585132;7101912622;7006567277,60011460;60011460;60011410;60011460,2017-08-21,21 August 2017,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100833006,,Conference Proceeding,Part F130154,,,106-116,"Scenario-finding tools like the Alloy Analyzer are widely used in numerous concrete domains like security, network analysis, UML analysis, and so on. They can help to verify properties and, more generally, aid in exploring a system's behavior. While scenario finders are valuable for their ability to produce concrete examples, individual scenarios only give insight into what is possible, leaving the user to make their own conclusions about what might be necessary. This paper enriches scenario finding by allowing users to ask ""why?"" and ""why not?"" questions about the examples they are given. We show how to distinguish parts of an example that cannot be consistently removed (or changed) from those that merely reflect underconstraint in the specification. In the former case we show how to determine which elements of the specification and which other components of the example together explain the presence of such facts. This paper formalizes the act of computing provenance in scenariofinding. We present Amalgam, an extension of the popular Alloy scenario-finder, which implements these foundations and provides interactive exploration of examples. We also evaluate Amalgam's algorithmics on a variety of both textbook and real-world examples.",Alloy analyzer | Formal methods | Model finding | Provenance,23,0,,,NSF,1714431,National Science Foundation,FSE Software Engineering
2-s2.0-85040080057,10.1109/FOCS.2017.38,,,A proof of CSP dichotomy conjecture,cp,Conference Paper,Zhuk D.,60007457,Lomonosov Moscow State University,Moscow,Russian Federation,1,"Zhuk, Dmitriy",36176713600,60007457,2017-11-10,10 November 2017,Annual Symposium on Foundations of Computer Science - Proceedings,02725428,22882,,Conference Proceeding,2017-October,,8104070,331-342,"Many natural combinatorial problems can be expressed as constraint satisfaction problems. This class of problems is known to be NP-complete in general, but certain restrictions on the form of the constraints can ensure tractability. The standard way to parametrize interesting subclasses of the constraint satisfaction problem is via finite constraint languages. The main problem is to classify those subclasses that are solvable in polynomial time and those that are NP-complete. It was conjectured that if a core of a constraint language has a weak near unanimity polymorphism then the corresponding constraint satisfaction problem is tractable, otherwise it is NP-complete.In the paper we present an algorithm that solves Constraint Satisfaction Problem in polynomial time for constraint languages having a weak near unanimity polymorphism, which proves the remaining part of the conjecture.",computational complexity | Constraint satisfaction problem | CSP dichotomy,202,0,repositoryam,Green,,undefined,,FOCS Theory
2-s2.0-85030774508,10.1145/3106237.3106270,,,"Trade-offs in continuous integration: Assurance, security, and flexibility",cp,Conference Paper,Hilton M.,60013402;60000745,Oregon State University;University of Illinois Urbana-Champaign,Corvallis;Urbana,United States;United States,5,"Hilton, Michael;Nelson, Nicholas;Tunnell, Timothy;Marinov, Darko;Dig, Danny",56754178400;57189508480;57215878864;8730036800;13404654100,60013402;60013402;60000745;60000745;60013402,2017-08-21,21 August 2017,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100974093,,Conference Proceeding,Part F130154,,,197-207,"Continuous integration (CI) systems automate the compilation, building, and testing of software. Despite CI being a widely used activity in software engineering, we do not know what motivates developers to use CI, and what barriers and unmet needs they face. Without such knowledge, developers make easily avoidable errors, tool builders invest in the wrong direction, and researchers miss opportunities for improving the practice of CI. We present a qualitative study of the barriers and needs developers face when using CI. We conduct semi-structured interviews with developers from different industries and development scales. We triangulate our findings by running two surveys. We find that developers face trade-offs between speed and certainty (Assurance), between better access and information security (Security), and between more configuration options and greater ease of use (Flexibility). We present implications of these trade-offs for developers, tool builders, and researchers.",Automated testing | Continuous integration,136,0,,,NSF,CCF-1421503,National Science Foundation,FSE Software Engineering
2-s2.0-85041492710,10.1145/3126594.3126596,,,Triggering artwork swaps for live animation,cp,Conference Paper,Willett N.,60076047;60003269,Adobe Inc.;Princeton University,San Jose;Princeton,United States;United States,4,"Willett, Nora S.;Li, Wilmot;Popović, Jovan;Finkelstein, Adam",57200523753;7501790814;13007429600;7101962340,60003269;60076047;60076047;60003269,2017-10-20,20 October 2017,UIST 2017 - Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology,,21100850719,,Conference Proceeding,,,,85-95,"Live animation of 2D characters is a new form of storytelling that has started to appear on streaming platforms and broadcast TV. Unlike traditional animation, human performers control characters in real time so that they can respond and improvise to live events. Current live animation systems provide a range of animation controls, such as camera input to drive head movements, audio for lip sync, and keyboard shortcuts to trigger discrete pose changes via artwork swaps. However, managing all of these controls during a live performance is challenging. In this work, we present a new interactive system that specifically addresses the problem of triggering artwork swaps in live settings. Our key contributions are the design of a multi-touch triggering interface that overlays visual triggers around a live preview of the character, and a predictive triggering model that leverages practice performances to suggest pose transitions during live performances. We evaluate our system with quantitative experiments, a user study with novice participants, and interviews with professional animators.",2D animation | Live performance,11,0,,,,undefined,,UIST User Interface
2-s2.0-85048455773,,,,Understanding black-box predictions via influence functions,cp,Conference Paper,Koh P.W.,60012708,Stanford University,Stanford,United States,2,"Koh, Pang Wei;Liang, Percy",52263787100;56646712700,60012708;60012708,2017-01-01,2017,"34th International Conference on Machine Learning, ICML 2017",,21100864010,,Conference Proceeding,4,,,2976-2987,"How can we explain the predictions of a black-box model? In this paper, we use influence functions - a classic technique from robust statistics - to trace a model's prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.",,375,0,,,,undefined,,ICML Machine Learning
2-s2.0-85030755893,10.1145/3106237.3106264,,,Understanding misunderstandings in source code,cp,Conference Paper,Gopstein D.,60021784;60010265;60001439,New York University;University of Colorado at Colorado Springs;Pennsylvania State University,New York;Colorado Springs;University Park,United States;United States;United States,7,"Gopstein, Dan;Iannacone, Jake;Yan, Yu;DeLong, Lois;Zhuang, Yanyan;Yeh, Martin K.C.;Cappos, Justin",57191997003;57196001119;57188738867;57195995263;16314597200;24492385100;13006019000,60021784;60021784;60001439;60021784;60010265;60001439;60021784,2017-08-21,21 August 2017,Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering,,21100833006,,Conference Proceeding,Part F130154,,,129-139,"Humans often mistake the meaning of source code, and so misjudge a program's true behavior. These mistakes can be caused by extremely small, isolated patterns in code, which can lead to signiicant runtime errors. These patterns are used in large, popular software projects and even recommended in style guides. To identify code patterns that may confuse programmers we extracted a preliminary set of atoms of confusion' from known confusing code. We show empirically in an experiment with 73 participants that these code patterns can lead to a signiicantly increased rate of misunderstanding versus equivalent code without the patterns. We then go on to take larger confusing programs and measure (in an experiment with 43 participants) the impact, in terms of programmer confusion, of removing these confusing patterns. All of our instruments, analysis code, and data are publicly available online for replication, experimentation, and feedback.",Program understanding | Programming languages,35,0,,,CISE,1513055,National Science Foundation,FSE Software Engineering
2-s2.0-85044856396,10.1145/3025453.3025598,,,Understanding public evaluation: Quantifying experimenter intervention,cp,Conference Paper,Williamson J.R.,60001490,University of Glasgow,Glasgow,United Kingdom,2,"Williamson, Julie R.;Williamson, John",39062233100;8678439600,60001490;60001490,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,3414-3425,"Public evaluations are popular because some research questions can only be answered by turning ""to the wild."" Different approaches place experimenters in different roles during deployment, which has implications for the kinds of data that can be collected and the potential bias introduced by the experimenter. This paper expands our understanding of how experimenter roles impact public evaluations and provides an empirical basis to consider different evaluation approaches. We completed an evaluation of a playful gesture-controlled display - not to understand interaction at the display but to compare different evaluation approaches. The conditions placed the experimenter in three roles, steward observer, overt observer, and covert observer, to measure the effect of experimenter presence and analyse the strengths and weaknesses of each approach.",In the wild methods | Public displays | Public evaluation,14,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85047002810,,,,Variance-based regularization with convex objectives,cp,Conference Paper,Namkoong H.,60012708,Stanford University,Stanford,United States,2,"Namkoong, Hongseok;Duchi, John C.",57194213292;26221757400,60012708;60012708,2017-01-01,2017,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,2017-December,,,2972-2981,"We develop an approach to risk minimization and stochastic optimization that provides a convex surrogate for variance, allowing near-optimal and computationally efficient trading between approximation and estimation error. Our approach builds off of techniques for distributionally robust optimization and Owen's empirical likelihood, and we provide a number of finite-sample and asymptotic results characterizing the theoretical performance of the estimator. In particular, we show that our procedure comes with certificates of optimality, achieving (in some scenarios) faster rates of convergence than empirical risk minimization by virtue of automatically balancing bias and variance. We give corroborating empirical evidence showing that in practice, the estimator indeed trades between variance and absolute performance on a training sample, improving out-of-sample (test) performance over standard empirical risk minimization for a number of classification problems.",,96,0,,,,AI Research,National Science Foundation,NeurIPS Machine Learning
2-s2.0-85024490593,10.1109/SP.2017.26,,,Verified Models and Reference Implementations for the TLS 1.3 Standard Candidate,cp,Conference Paper,Bhargavan K.,60013373,INRIA Institut National de Recherche en Informatique et en Automatique,Le Chesnay,France,3,"Bhargavan, Karthikeyan;Blanchet, Bruno;Kobeissi, Nadim",6602428438;7004335722;57192164938,60013373;60013373;60013373,2017-06-23,23 June 2017,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,,,7958594,483-502,"TLS 1.3 is the next version of the Transport Layer Security (TLS) protocol. Its clean-slate design is a reaction both to the increasing demand for low-latency HTTPS connections and to a series of recent high-profile attacks on TLS. The hope is that a fresh protocol with modern cryptography will prevent legacy problems, the danger is that it will expose new kinds of attacks, or reintroduce old flaws that were fixed in previous versions of TLS. After 18 drafts, the protocol is nearing completion, and the working group has appealed to researchers to analyze the protocol before publication. This paper responds by presenting a comprehensive analysis of the TLS 1.3 Draft-18 protocol. We seek to answer three questions that have not been fully addressed in previous work on TLS 1.3: (1) Does TLS 1.3 prevent well-known attacks on TLS 1.2, such as Logjam or the Triple Handshake, even if it is run in parallel with TLS 1.2? (2) Can we mechanically verify the computational security of TLS 1.3 under standard (strong) assumptions on its cryptographic primitives? (3) How can we extend the guarantees of the TLS 1.3 protocol to the details of its implementations?To answer these questions, we propose a methodology for developing verified symbolic and computational models of TLS 1.3 hand-in-hand with a high-assurance reference implementation of the protocol. We present symbolic ProVerif models for various intermediate versions of TLS 1.3 and evaluate them against a rich class of attacks to reconstruct both known and previously unpublished vulnerabilities that influenced the current design of the protocol. We present a computational CryptoVerif model for TLS 1.3 Draft-18 and prove its security. We present RefTLS, an interoperable implementation of TLS 1.0-1.3 and automatically analyze its protocol core by extracting a ProVerif model from its typed JavaScript code.",,146,0,repositoryam,Green,H2020,683032,Horizon 2020 Framework Programme,S&P Security and Privacy
2-s2.0-85034097461,10.1145/3117811.3117816,,,WEBee: Physical-layer cross-technology communication via emulation,cp,Conference Paper,Li Z.,60029445,University of Minnesota Twin Cities,Minneapolis,United States,2,"Li, Zhijun;He, Tian",57197720979;14019293900,60029445;60029445,2017-10-04,4 October 2017,"Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM",,21100837971,,Conference Proceeding,Part F131210,,,2-14,"Recent advances in Cross-Technology Communication (CTC) have improved efficient coexistence and cooperation among heterogeneous wireless devices (e.g., WiFi, ZigBee, and Bluetooth) operating in the same ISM band. However, until now the effectiveness of existing CTCs, which rely on packet-level modulation, is limited due to their low throughput (e.g., tens of bps). Our work, named WEBee, opens a promising direction for high-throughput CTC via physical-level emulation. WEBee uses a high-speed wireless radio (e.g., WiFi OFDM) to emulate the desired signals of a low-speed radio (e.g., ZigBee). Our unique emulation technique manipulates only the payload of WiFi packets, requiring neither hardware nor firmware changes in commodity technologies - a feature allowing zero-cost fast deployment on existing WiFi infrastructure. We de-signedand implemented WEBee with commodity devices (Atheros AR2425 WiFi card and MicaZ CC2420) and the USRP-N210 platform (for PHY layer evaluation). Our comprehensive evaluation reveals that WEBee can achieve a more than 99% reliable parallel CTC between WiFi and ZigBee with 126 Kbps in noisy environments, a throughput about 16, 000x faster than current state-of-the-art CTCs.",Cross technology communication | DSSS | Signal emulation | WiFi OFDM | ZigBee OQPSK,186,0,,,NSF,61672196,National Science Foundation,MOBICOM Mobile
2-s2.0-85041138136,10.1145/3025453.3025929,,,What can be predicted from six seconds of driver glances?,cp,Conference Paper,Fridman L.,60022195;117160712;112747670,Massachusetts Institute of Technology;Toyota Collaborative Safety Research Center;Touchstone Evaluations,Cambridge;;Detroit,United States;Japan;United States,8,"Fridman, Lex;Toyoda, Heishiro;Seaman, Sean;Seppelt, Bobbie;Angell, Linda;Lee, Joonbum;Mehler, Bruce;Reimer, Bryan",57185179400;57190621577;57194965731;15766218300;36907040600;57189577286;26423894400;7003475727,60022195;117160712;112747670;112747670;112747670;60022195;60022195;60022195,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,2805-2813,"We consider a large dataset of real-world, on-road driving from a 100-car naturalistic study to explore the predictive power of driver glances and, specifically, to answer the following question: what can be predicted about the state of the driver and the state of the driving environment from a 6-second sequence of macro-glances? The context-based nature of such glances allows for application of supervised learning to the problem of vision-based gaze estimation, making it robust, accurate, and reliable in messy, real-world conditions. So, it's valuable to ask whether such macro-glances can be used to infer behavioral, environmental, and demographic variables? We analyze 27 binary classification problems based on these variables. The takeaway is that glance can be used as part of a multi-sensor real-time system to predict radio-tuning, fatigue state, failure to signal, talking, and several environment variables.",Driver state prediction | Gaze patterns | Hidden Markov models | Naturalistic on-road study,33,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85039459766,10.1145/3025453.3025765,,,What is interaction?,cp,Conference Paper,Hornbæk K.,60103653;60030840,Aalto University;Københavns Universitet,Espoo;Copenhagen,Finland;Denmark,2,"Hornbæk, Kasper;Oulasvirta, Antti",6602385484;13006124600,60030840;60103653,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,5040-5052,"The term interaction is field-defining, yet surprisingly confused. This essay discusses what interaction is. We first argue that only few attempts to directly define interaction exist. Nevertheless, we extract from the literature distinct and highly developed concepts, for instance viewing interaction as dialogue, transmission, optimal behavior, embodiment, and tool use. Importantly, these concepts are associated with different scopes and ways of construing the causal relationships between the human and the computer. This affects their ability to inform empirical studies and design. Based on this discussion, we list desiderata for future work on interaction, emphasizing the need to improve scope and specificity, to better account for the effects and agency that computers have in interaction, and to generate strong propositions about interaction.",Concepts | Human-computer interaction | Interaction | Models | Scientific progress | Theories,102,1,repositoryvor,Green,H2020,637991,Horizon 2020 Framework Programme,CHI Human-Computer Interaction
2-s2.0-85040653093,10.1145/3025453.3026011,,,You want me to work with who? Stakeholder perceptions of automated team formation in project-based courses,cp,Conference Paper,Jahanbakhsh F.,60000745,University of Illinois Urbana-Champaign,Urbana,United States,5,"Jahanbakhsh, Farnaz;Fu, Wai Tat;Karahalios, Karrie;Marinov, Darko;Bailey, Brian",57201449589;7202947384;23397392600;8730036800;7201607207,60000745;60000745;60000745;60000745;60000745,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,3201-3212,"Instructors are increasingly using algorithmic tools for team formation, yet little is known about how these tools are applied or how students and instructors perceive their use. We studied a representative team formation tool (CATME) in eight project-based courses. An instructor uses the tool to form teams by surveying students' working styles, skills, and demographics-then configuring the criteria as input into an algorithm that assigns teams. We surveyed students (N=277) in the courses to gauge their perceptions of the strengths and weaknesses of the tool and ideas for improving it. We also interviewed instructors (N=13) different from those who taught the eight courses to learn about their criteria selections and perceptions of the tool. Students valued the rational basis for forming teams but desired a stronger voice in criteria selection and explanations as to why they were assigned to a particular team. Instructors appreciated the efficiency of team formation but wanted to view exemplars of criteria used in similar courses. This work contributes recommendations for deploying team formation tools in educational settings and for better satisfying the goals of all stakeholders.",Algorithms | CATME | Education | Team formation,46,0,,,NSF,CCF-1439957,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85044856420,10.1145/3025453.3025918,,,mHealth for maternal mental health: Everyday wisdom in ethical design,cp,Conference Paper,Barry M.,60098463;60015150;60011149,Microsoft Research Cambridge;Imperial College London;Trinity College Dublin,Cambridge;London;Dublin,United Kingdom;United Kingdom;Ireland,6,"Barry, Marguerite;Doherty, Kevin;Bellisario, Jose Marcano;Car, Josip;Morrison, Cecily;Doherty, Gavin",57192905067;57192910271;57201449987;6701783618;57211159610;13006308800,60011149;60011149;60015150;60015150;60015150-60098463;60011149,2017-05-02,2 May 2017,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2017-May,,,2708-2720,"Health and wellbeing applications increasingly raise ethical issues for design. User-centred and participatory design approaches, while grounded in everyday wisdom, cannot be expected to address ethical reflection consistently, as multiple value systems come into play. We explore the potential of phronesis, a concept from Aristotelian virtue ethics, for mHealth design. Phronesis describes wisdom and judgment garnered from practical experience of specific situations in context. Applied phronesis contributes everyday wisdom to challenging issues for vulnerable target users. Drawing on research into mHealth technologies for psychological wellbeing, we explore how phronesis can inform ethical design. Using a case study on an app for self-reporting symptoms of depression during pregnancy, we present a framework for incorporating a phronetic approach into design, involving: (a) a wide feedback net to capture phronetic input early in design; (b) observing the order of feedback, which directly affects value priorities in design; (c) ethical pluralism recognising different coexisting value systems; (d) acknowledging subjectivity in the disclosure and recognition of individual researcher and participant values. We offer insights into how a phronetic approach can contribute everyday wisdom to designing mHealth technologies to help designers foster the values that promote human flourishing.",Ethical design | Human flourishing | Maternal mental health | MHealth | Phronesis | Psychological wellbeing | Virtue ethics,42,1,repositoryam,Green,NIHR,12/CE/I2267,National Institute for Health Research,CHI Human-Computer Interaction
2-s2.0-85076890916,,,,MOS: A reusable networking stack for flow monitoring middleboxes,cp,Conference Paper,Jamshed M.,60032144,Korea Advanced Institute of Science and Technology,Daejeon,South Korea,5,"Jamshed, Muhammad;Moon, Young Gyoun;Kim, Donghwi;Han, Dongsu;Park, Kyoung Soo",57214228934;55208909800;57203012468;36709887100;16040551900,60032144;60032144;60032144;60032144;60032144,2017-01-01,2017,"Proceedings of the 14th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2017",,21100939702,,Conference Proceeding,,,,113-129,"Stateful middleboxes, such as intrusion detection systems and application-level firewalls, have provided key functionalities in operating modern IP networks. However, designing an efficient middlebox is challenging due to the lack of networking stack abstraction for TCP flow processing. Thus, middlebox developers often write the complex flow management logic from scratch, which is not only prone to errors, but also wastes efforts for similar functionalities across applications. This paper presents the design and implementation of mOS, a reusable networking stack for stateful flow processing in middlebox applications. Our API allows developers to focus on the core application logic instead of dealing with low-level packet/flow processing themselves. Under the hood, it implements an efficient event system that scales to monitoring millions of concurrent flow events. Our evaluation demonstrates that mOS enables modular development of stateful middleboxes, often significantly reducing development efforts represented by the source lines of code, while introducing little performance overhead in multi-10Gbps network environments.",,57,0,,,MSIP,2016-0-00563,"Ministry of Science, ICT and Future Planning",NSDI Networking
2-s2.0-85046954121,10.1145/3173574.3174241,,,"""A stalker's paradise"": How intimate partner abusers exploit technology",cp,Conference Paper,Freed D.,60104837;60028458;60007776;60002896,Cornell Tech;City College of New York;Cornell University;Hunter College,New York;New York;Ithaca;New York,United States;United States;United States;United States,6,"Freed, Diana;Palmer, Jackeline;Minchala, Diana;Levy, Karen;Ristenpart, Thomas;Dell, Nicola",57210687213;57202050595;57202048164;57202613926;23393983800;45560910100,60104837;60002896;60028458;60007776;60104837;60104837,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"This paper describes a qualitative study with 89 participants that details how abusers in intimate partner violence (IPV) contexts exploit technologies to intimidate, threaten, monitor, impersonate, harass, or otherwise harm their victims. We show that, at their core, many of the attacks in IPV contexts are technologically unsophisticated from the perspective of a security practitioner or researcher. For example, they are often carried out by a UI-bound adversary-an adversarial but authenticated user that interacts with a victim's device or account via standard user interfaces- or by downloading and installing a ready-made application that enables spying on a victim. Nevertheless, we show how the sociotechnical and relational factors that characterize IPV make such attacks both extremely damaging to victims and challenging to counteract, in part because they undermine the predominant threat models under which systems have been designed. We discuss the nature of these new IPV threat models and outline opportunities for HCI research and design to mitigate these attacks.",Domestic abuse | Domestic violence | Intimate partner violence | IPV | Privacy | Safety | Security | Violence against women,186,0,,,NSF,CNS-1330308,Norsk Sykepleierforbund,CHI Human-Computer Interaction
2-s2.0-85049915468,10.1145/3188745.3188824,,,A constant-Factor approximation algorithm for the asymmetric traveling salesman problem,cp,Conference Paper,Svensson O.,60028186;60003059,École Polytechnique Fédérale de Lausanne;London School of Economics and Political Science,Lausanne;London,Switzerland;United Kingdom,3,"Svensson, Ola;Tarnawski, Jakub;Végh, László A.",23393910000;56743254500;36163631300,60028186;60028186;60003059,2018-06-20,20 June 2018,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,587-597,"We give a constant-factor approximation algorithm for the asymmetric traveling salesman problem. Our approximation guarantee is analyzed with respect to the standard LP relaxation, and thus our result confirms the conjectured constant integrality gap of that relaxation. Our techniques build upon the constant-factor approximation algorithm for the special case of node-weighted metrics. Specifically, we give a generic reduction to structured instances that resemble, but are more general than, those arising from node-weighted metrics. For those instances, we then solve Local-Connectivity ATSP, a problem known to be equivalent (in terms of constant-factor approximation) to the asymmetric traveling salesman problem.",Approximation algorithms | Asymmetric traveling salesman problem | Combinatorial optimization | Linear programming,21,1,repositoryam,Green,H2020,335288,Horizon 2020 Framework Programme,STOC Theory
2-s2.0-85055692525,10.24963/ijcai.2018/360,,,A degeneracy framework for graph similarity,cp,Conference Paper,Nikolentzos G.,60019507;60013425,Athens University of Economics and Business;École polytechnique,Athens;Palaiseau,Greece;France,4,"Nikolentzos, Giannis;Meladianos, Polykarpos;Limnios, Stratis;Vazirgiannis, Michalis",57173279500;57008238900;57204470494;7004248278,60013425;60019507;60013425;60013425,2018-01-01,2018,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2018-July,,,2595-2601,"The problem of accurately measuring the similarity between graphs is at the core of many applications in a variety of disciplines. Most existing methods for graph similarity focus either on local or on global properties of graphs. However, even if graphs seem very similar from a local or a global perspective, they may exhibit different structure at different scales. In this paper, we present a general framework for graph similarity which takes into account structure at multiple different scales. The proposed framework capitalizes on the well-known k-core decomposition of graphs in order to build a hierarchy of nested subgraphs. We apply the framework to derive variants of four graph kernels, namely graphlet kernel, shortest-path kernel, Weisfeiler-Lehman subtree kernel, and pyramid match graph kernel. The framework is not limited to graph kernels, but can be applied to any graph comparison algorithm. The proposed framework is evaluated on several benchmark datasets for graph classification. In most cases, the core-based kernels achieve significant improvements in terms of classification accuracy over the base kernels, while their time complexity remains very attractive.",,45,1,publisherfree2read,Bronze,,ANR-17-CE40-0028,Project Management,IJCAI Artificial Intelligence
2-s2.0-85050379397,10.1145/3219617.3219663,,,A refined mean field approximation,cp,Conference Paper,Gast N.,60013373;60012937,INRIA Institut National de Recherche en Informatique et en Automatique;Universiteit Antwerpen,Le Chesnay;Antwerpen,France;Belgium,2,"Gast, Nicolas;Van Houdt, Benny",35322318000;6602838973,60013373;60012937,2018-06-12,12 June 2018,SIGMETRICS 2018 - Abstracts of the 2018 ACM International Conference on Measurement and Modeling of Computer Systems,,21100869499,,Conference Proceeding,,,,113,"Stochastic models have been used to assess the performance of computer (and other) systems for many decades. As a direct analysis of large and complex stochastic models is often prohibitive, approximations methods to study their behavior have been devised. One very popular approximation method relies on mean field theory. Its widespread use can be explained by the relative ease involved to define and solve a mean field model in combination with its high accuracy for large systems.",,8,0,repositoryvor,Green,FP7,600708,Seventh Framework Programme,SIGMETRICS Performance
2-s2.0-85049604501,10.1145/3192366.3192416,,,A data-driven CHC solver,cp,Conference Paper,Zhu H.,60009254;105940720,"Purdue University;Galois, Inc",West Lafayette;Beaverton,United States;United States,3,"Zhu, He;Magill, Stephen;Jagannathan, Suresh",56031394100;55496765600;57202888433,105940720;105940720;60009254,2018-06-11,11 June 2018,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,707-721,"We present a data-driven technique to solve Constrained Horn Clauses (CHCs) that encode verification conditions of programs containing unconstrained loops and recursions. Our CHC solver neither constrains the search space from which a predicate's components are inferred (e.g., by constraining the number of variables or the values of coefficients used to specify an invariant), nor fixes the shape of the predicate itself (e.g., by bounding the number and kind of logical connectives). Instead, our approach is based on a novel machine learning-inspired tool chain that synthesizes CHC solutions in terms of arbitrary Boolean combinations of unrestricted atomic predicates. A CEGAR-based verification loop inside the solver progressively samples representative positive and negative data from recursive CHCs, which is fed to the machine learning tool chain. Our solver is implemented as an LLVM pass in the SeaHorn verification framework and has been used to successfully verify a large number of nontrivial and challenging C programs from the literature and well-known benchmark suites (e.g., SV-COMP).",Constrained horn clauses (CHCs) | Data-driven analysis | Invariant inference | Program verification,34,0,,,NSF,CCF-SHF 1717741,National Science Foundation,PLDI Programming Languages
2-s2.0-85046977477,10.1145/3173574.3173986,,,Addressing age-related bias in sentiment analysis,cp,Conference Paper,Díaz M.,60020304;60007363,"University of Maryland, College Park;Northwestern University",College Park;Evanston,United States;United States,5,"Díaz, Mark;Johnson, Isaac;Lazar, Amanda;Piper, Anne Marie;Gergle, Darren",36678677500;57002435200;55660177200;15023169400;6505994142,60007363;60007363;60020304;60007363;60007363,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"Computational approaches to text analysis are useful in understanding aspects of online interaction, such as opinions and subjectivity in text. Yet, recent studies have identified various forms of bias in language-based models, raising concerns about the risk of propagating social biases against certain groups based on sociodemographic factors (e.g., gender, race, geography). In this study, we contribute a systematic examination of the application of language models to study discourse on aging. We analyze the treatment of age-related terms across 15 sentiment analysis models and 10 widely-used GloVe word embeddings and attempt to alleviate bias through a method of processing model training data. Our results demonstrate that significant age bias is encoded in the outputs of many sentiment analysis algorithms and word embeddings. We discuss the models' characteristics in relation to output bias and how these models might be best incorporated into research.","Aging | Older adults, algorithmic bias | Sentiment analysis",98,1,publisherfree2read,Bronze,,IIS-1551574,,CHI Human-Computer Interaction
2-s2.0-85051494482,10.1145/3219819.3220078,,,Adversarial attacks on neural networks for graph data,cp,Conference Paper,Zügner D.,60019722,Technische Universität München,Munich,Germany,3,"Zügner, Daniel;Akbarnejad, Amir;Günnemann, Stephan",57188995298;57203390828;35242528700,60019722;60019722;60019722,2018-07-19,19 July 2018,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,21100872702,,Conference Proceeding,,,,2847-2856,"Deep learning models for graphs have achieved strong performance for the task of node classification. Despite their proliferation, currently there is no study of their robustness to adversarial attacks. Yet, in domains where they are likely to be used, e.g. the web, adversaries are common. Can deep learning models for graphs be easily fooled? In this work, we introduce the first study of adversarial attacks on attributed graphs, specifically focusing on models exploiting ideas of graph convolutions. In addition to attacks at test time, we tackle the more challenging class of poisoning/causative attacks, which focus on the training phase of a machine learning model. We generate adversarial perturbations targeting the node's features and the graph structure, thus, taking the dependencies between instances in account. Moreover, we ensure that the perturbations remain unnoticeable by preserving important data characteristics. To cope with the underlying discrete domain we propose an efficient algorithm Nettack exploiting incremental computations. Our experimental study shows that accuracy of node classification significantly drops even when performing only few perturbations. Even more, our attacks are transferable: the learned attacks generalize to other state-of-the-art node classification models and unsupervised approaches, and likewise are successful even when only limited knowledge about the graph is given.",Adversarial machine learning | Graph convolutional networks | Graph mining | Network mining | Semi-supervised learning,552,0,repositoryam,Green,FP7,291763,Seventh Framework Programme,KDD Data Mining
2-s2.0-85056530498,10.1145/3236024.3236028,,,Adversarial symbolic execution for detecting concurrency-related cache timing leaks,cp,Conference Paper,Guo S.,60029311;60027090,University of Southern California;Virginia Polytechnic Institute and State University,Los Angeles;Blacksburg,United States;United States,3,"Guo, Shengjian;Wu, Meng;Wang, Chao",56709114700;57190030064;55647141100,60027090;60027090;60029311,2018-10-26,26 October 2018,ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21100890553,,Conference Proceeding,,,,377-388,"The timing characteristics of cache, a high-speed storage between the fast CPU and the slowmemory, may reveal sensitive information of a program, thus allowing an adversary to conduct side-channel attacks. Existing methods for detecting timing leaks either ignore cache all together or focus only on passive leaks generated by the program itself, without considering leaks that are made possible by concurrently running some other threads. In this work, we show that timing-leak-freedom is not a compositional property: A program that is not leaky when running alone may become leaky when interleaved with other threads. Thus, we develop a new method, named adversarial symbolic execution, to detect such leaks. It systematically explores both the feasible program paths and their interleavings while modeling the cache, and leverages an SMT solver to decide if there are timing leaks. We have implemented our method in LLVM and evaluated it on a set of real-world ciphers with 14,455 lines of C code in total. Our experiments demonstrate both the efficiency of our method and its effectiveness in detecting side-channel leaks.",cache | concurrency | Side-channel attack | symbolic execution | timing,29,0,repositoryam,Green,NSF,1702824,National Science Foundation,FSE Software Engineering
2-s2.0-85046960585,10.1145/3173574.3173812,,,Agile 3D sketching with air scaffolding,cp,Conference Paper,Kim Y.,60032144,Korea Advanced Institute of Science and Technology,Daejeon,South Korea,4,"Kim, Yongkwan;An, Sang Gyun;Lee, Joon Hyub;Bae, Seok Hyung",57188756191;57198859355;55482201900;7202714518,60032144;60032144;60032144;60032144,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"Hand motion and pen drawing can be intuitive and expressive inputs for professional digital 3D authoring. However, their inherent limitations have hampered wider adoption. 3D sketching using hand motion is rapid but rough, and 3D sketching using pen drawing is delicate but tedious. Our new 3D sketching workflow combines these two in a complementary manner. The user makes quick hand motions in the air to generate approximate 3D shapes, and uses them as scaffolds on which to add details via pen-based 3D sketching on a tablet device. Our air scaffolding technique and corresponding algorithm extract only the intended shapes from unconstrained hand motions. Then, the user sketches 3D ideas by defining sketching planes on these scaffolds while appending new scaffolds, as needed. A user study shows that our progressive and iterative workflow enables more agile 3D sketching compared to ones using either hand motion or pen drawing alone.",3D sketching | Hand motion | Product design | Scaffolding,34,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85058340884,10.1145/3236024.3236030,,,An empirical study on crash recovery bugs in large-scale distributed systems,cp,Conference Paper,Gao Y.,60149838;60118460;60027363,College of Engineering;Alibaba Group Holding Limited;University of Chinese Academy of Sciences,Columbus;Yu Hang;Beijing,United States;China;China,9,"Gao, Yu;Dou, Wensheng;Qin, Feng;Gao, Chushu;Wang, Dong;Wei, Jun;Huang, Ruirui;Zhou, Li;Wu, Yongming",57200512721;57189041402;57203239221;51663446200;57205027591;34772294900;57205029545;57205025164;57205031217,60027363;60027363;60149838;60027363;60027363;60027363;60118460;60118460;60118460,2018-10-26,26 October 2018,ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21100890553,,Conference Proceeding,,,,539-550,"In large-scale distributed systems, node crashes are inevitable, and can happen at any time. As such, distributed systems are usually designed to be resilient to these node crashes via various crash recovery mechanisms, such as write-ahead logging in HBase and hinted handoffs in Cassandra. However, faults in crash recovery mechanisms and their implementations can introduce intricate crash recovery bugs, and lead to severe consequences. In this paper, we present CREB, the most comprehensive study on 103 Crash REcovery Bugs from four popular open-source dis-tributed systems, including ZooKeeper, Hadoop MapReduce, Cas-sandra and HBase. For all the studied bugs, we analyze their root causes, triggering conditions, bug impacts and fixing. Through this study, we obtain many interesting findings that can open up new research directions for combating crash recovery bugs.",crash recovery bugs | Distributed systems | empirical study,36,0,,,,undefined,,FSE Software Engineering
2-s2.0-85045539513,10.1137/1.9781611975031.121,,,Approaching 3/2 for the s-t-path TSP,cp,Conference Paper,Traub V.,60007493,Universität Bonn,Bonn,Germany,2,"Traub, Vera;Vygen, Jens",57188973294;55999901700,60007493;60007493,2018-01-01,2018,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,,,,1854-1864,"We show that there is a polynomial-time algorithm with approximation guarantee 3/2 + ϵ for the s-t-path TSP, for any fixed ϵ > 0. It is well known that Wolsey's analysis of Christofides' algorithm also works for the s-t-path TSP with its natural LP relaxation except for the narrow cuts (in which the LP solution has value less than two). A fixed optimum tour has either a single edge in a narrow cut (then call the edge and the cut lonely) or at least three (then call the cut busy). Our algorithm ""guesses"" (by dynamic programming) lonely cuts and edges. Then we partition the instance into smaller instances and strengthen the LP, requiring value at least three for busy cuts. By setting up a k-stage recursive dynamic program, we can compute a spanning tree (V; S) and an LP solution y such that (1/2+O(2-k))y is in the T-join polyhedron, where T is the set of vertices whose degree in S has the wrong parity.",,11,1,publisherfree2read,Bronze,,undefined,,SODA Theory
2-s2.0-85059809812,10.1109/FOCS.2018.00096,,,Approximating edit distance within constant factor in truly sub-quadratic time,cp,Conference Paper,Chakraborty D.,60119141;60093490;60016605,Rutgers University–New Brunswick;Academic College of Tel-Aviv - Yaffo;Charles University,New Brunswick;Tel Aviv-Yafo;Prague,United States;Israel;Czech Republic,5,"Chakraborty, Diptarka;Das, Debarati;Goldenberg, Elazar;Koucký, Michal;Saks, Michael",56489696200;56042168300;25927900700;23397402000;7005891412,60016605;60016605;60093490;60016605;60119141,2018-11-30,30 November 2018,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2018-October,,8555174,979-990,"Edit distance is a measure of similarity of two strings based on the minimum number of character insertions, deletions, and substitutions required to transform one string into the other. The edit distance can be computed exactly using a dynamic programming algorithm that runs in quadratic time. Andoni, Krauthgamer and Onak (2010) gave a nearly linear time algorithm that approximates edit distance within approximation factor poly(logn). In this paper, we provide an algorithm with running time Õ(n 2-2/7 ) that approximates the edit distance within a constant factor.",Approximation algorithm | Edit distance | Randomized algorithm | Sub-quadratic time algorithm,51,0,repositoryam,Green,SF,332622,Simons Foundation,FOCS Theory
2-s2.0-85056829358,10.1145/3242587.3242634,,,Authoring and verifying human-robot interactions,cp,Conference Paper,Porfirio D.,60032179;60021023,University of Wisconsin-Madison;University of Wisconsin-La Crosse,Madison;La Crosse,United States;United States,4,"Porfirio, David;Sauppé, Allison;Albarghouthi, Aws;Mutlu, Bilge",56600670600;56084504000;36336887800;15060220700,60032179;60021023;60032179;60032179,2018-10-11,11 October 2018,UIST 2018 - Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology,,21100886509,,Conference Proceeding,,,,75-86,"As social agents, robots designed for human interaction must adhere to human social norms. How can we enable designers, engineers, and roboticists to design robot behaviors that adhere to human social norms and do not result in interaction breakdowns? In this paper, we use automated formal-verification methods to facilitate the encoding of appropriate social norms into the interaction design of social robots and the detection of breakdowns and norm violations in order to prevent them. We have developed an authoring environment that utilizes these methods to provide developers of social-robot applications with feedback at design time and evaluated the benefits of their use in reducing such breakdowns and violations in human-robot interactions. Our evaluation with application developers (N = 9) shows that the use of formal-verification methods increases designers' ability to identify and contextualize social-norm violations. We discuss the implications of our approach for the future development of tools for effective design of social-robot applications.",Authoring | Human-robot interaction | Interaction design | Program analysis | Verification | Visual programming,46,1,publisherfree2read,Bronze,NSF,1651129,National Science Foundation,UIST User Interface
2-s2.0-85062284084,10.1145/3180155.3180224,,,Automated Localization for Unreproducible Builds,cp,Conference Paper,Ren Z.,60279414;60029306;60004538,Western Michigan University’s College of Engineering and Applied Sciences;Wuhan University;Dalian University of Technology,Kalamazoo;Wuhan;Dalian,United States;China;China,4,"Ren, Zhilei;Jiang, He;Xuan, Jifeng;Yang, Zijiang",25640088200;57205479128;25640418400;55716575100,60004538;60004538;60029306;60279414,2018-01-01,2018,ACM International Conference Proceeding Series,,11600154611,,Conference Proceeding,,,,71-81,"Reproducibility is the ability of recreating identical binaries under pre-defined build environments. Due to the need of quality assurance and the benefit of better detecting attacks against build environments, the practice of reproducible builds has gained popularity in many open-source software repositories such as Debian and Bitcoin. However, identifying the unreproducible issues remains a labour intensive and time consuming challenge, because of the lacking of information to guide the search and the diversity of the causes that may lead to the unreproducible binaries. In this paper we propose an automated framework called RepLoc to localize the problematic files for unreproducible builds. RepLoc features a query augmentation component that utilizes the information extracted from the build logs, and a heuristic rule-based filtering component that narrows the search scope. By integrating the two components with a weighted file ranking module, RepLoc is able to automatically produce a ranked list of files that are helpful in locating the problematic files for the unreproducible builds. We have implemented a prototype and conducted extensive experiments over 671 real-world unreproducible Debian packages in four different categories. By considering the topmost ranked file only, RepLoc achieves an accuracy rate of 47.09%. If we expand our examination to the top ten ranked files in the list produced by RepLoc, the accuracy rate becomes 79.28%. Considering that there are hundreds of source code, scripts, Makefiles, etc., in a package, RepLoc significantly reduces the scope of localizing problematic files. Moreover, with the help of RepLoc, we successfully identified and fixed six new unreproducible packages from Debian and Guix.",Localization | Software Maintenance | Unreproducible Build,23,0,repositoryam,Green,NSFC,61403057,National Natural Science Foundation of China,ICSE Software Engineering
2-s2.0-85059803224,10.1109/FOCS.2018.00033,,,Classical verification of quantum computations,cp,Conference Paper,Mahadev U.,60025038,"University of California, Berkeley",Berkeley,United States,1,"Mahadev, Urmila",56414906600,60025038,2018-11-30,30 November 2018,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2018-October,,8555111,259-267,"We present the first protocol allowing a classical computer to interactively verify the result of an efficient quantum computation. We achieve this by constructing a measurement protocol, which enables a classical verifier to use a quantum prover as a trusted measurement device. The protocol forces the prover to behave as follows: the prover must construct an n qubit state of his choice, measure each qubit in the Hadamard or standard basis as directed by the verifier, and report the measurement results to the verifier. The soundness of this protocol is enforced based on the assumption that the learning with errors problem is computationally intractable for efficient quantum machines.",,99,0,repositoryam,Green,NSF,52536,National Science Foundation,FOCS Theory
2-s2.0-85055701005,10.24963/ijcai.2018/643,,,Commonsense knowledge aware conversation generation with graph attention,cp,Conference Paper,Zhou H.,60159618;60104026;60016835,"Sogou, Inc.;Beijing National Research Center for Information Science and Technology;Beijing Institute of Technology",Beijing;Beijing;Beijing,China;China;China,6,"Zhou, Hao;Young, Tom;Huang, Minlie;Zhao, Haizhou;Xu, Jingfang;Zhu, Xiaoyan",56898234800;57203267719;7404260571;57204475096;57198896401;7406185137,60104026;60016835;;60159618;60159618;60104026,2018-01-01,2018,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2018-July,,,4623-4629,"Commonsense knowledge is vital to many natural language processing tasks. In this paper, we present a novel open-domain conversation generation model to demonstrate how large-scale commonsense knowledge can facilitate language understanding and generation. Given a user post, the model retrieves relevant knowledge graphs from a knowledge base and then encodes the graphs with a static graph attention mechanism, which augments the semantic information of the post and thus supports better understanding of the post. Then, during word generation, the model attentively reads the retrieved knowledge graphs and the knowledge triples within each graph to facilitate better generation through a dynamic graph attention mechanism. This is the first attempt that uses large-scale commonsense knowledge in conversation generation. Furthermore, unlike existing models that use knowledge triples (entities) separately and independently, our model treats each knowledge graph as a whole, which encodes more structured, connected semantic information in the graphs. Experiments show that the proposed model can generate more appropriate and informative responses than state-of-the-art baselines.",,402,1,publisherfree2read,Bronze,NSFC,61272227/61332007,Gulf Research Program,IJCAI Artificial Intelligence
2-s2.0-85049780764,10.1109/SP.2018.00033,,,DEEPSEC: Deciding Equivalence Properties in Security Protocols Theory and Practice,cp,Conference Paper,Cheval V.,60013373,INRIA Institut National de Recherche en Informatique et en Automatique,Le Chesnay,France,3,"Cheval, Vincent;Kremer, Steve;Rakotonirina, Itsaka",36436757300;57203194613;57203243002,60013373;60013373;60013373,2018-07-23,23 July 2018,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2018-May,,8418623,529-546,"Automated verification has become an essential part in the security evaluation of cryptographic protocols. Recently, there has been a considerable effort to lift the theory and tool support that existed for reachability properties to the more complex case of equivalence properties. In this paper we contribute both to the theory and practice of this verification problem. We establish new complexity results for static equivalence, trace equivalence and labelled bisimilarity and provide a decision procedure for these equivalences in the case of a bounded number of sessions. Our procedure is the first to decide trace equivalence and labelled bisimilarity exactly for a large variety of cryptographic primitives-those that can be represented by a subterm convergent destructor rewrite system. We implemented the procedure in a new tool, DEEPSEC. We showed through extensive experiments that it is significantly more efficient than other similar tools, while at the same time raises the scope of the protocols that can be analysed.",Automated verification | Equivalence properties | Security protocols,45,1,repositoryam,Green,H2020,645865-SPOOC,Horizon 2020 Framework Programme,S&P Security and Privacy
2-s2.0-85046937882,10.1145/3173574.3173697,,,Data illustrator: Augmenting vector design tools with lazy data binding for expressive visualization authoring,cp,Conference Paper,Liu Z.,60076047;60019647,Adobe Inc.;Georgia Institute of Technology,San Jose;Atlanta,United States;United States,8,"Liu, Zhicheng;Thompson, John;Wilson, Alan;Dontcheva, Mira;Delorey, James;Grigg, Sam;Kerr, Bernard;Stasko, John",55714445500;57202616180;57214103255;9038568300;57202049786;57202047361;57226338769;7006755495,60076047;60019647;60076047;60076047;60076047;60076047;60076047;60019647,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"Building graphical user interfaces for visualization authoring is challenging as one must reconcile the tension between flexible graphics manipulation and procedural visualization generation based on a graphical grammar or declarative languages. To better support designers' workflows and practices, we propose Data Illustrator, a novel visualization framework. In our approach, all visualizations are initially vector graphics; data binding is applied when necessary and only constrains interactive manipulation to that data bound property. The framework augments graphic design tools with new concepts and operators, and describes the structure and generation of a variety of visualizations. Based on the framework, we design and implement a visualization authoring system. The system extends interaction techniques in modern vector design tools for direct manipulation of visualization configurations and parameters. We demonstrate the expressive power of our approach through a variety of examples. A qualitative study shows that designers can use our framework to compose visualizations.",Authoring | Data visualization | Framework | Graphic design | Interaction techniques | Systems,96,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85058284381,10.1145/3236024.3236025,,,Data race detection on compressed traces,cp,Conference Paper,Kini D.,60000745;120399513,University of Illinois Urbana-Champaign;Akuna Capital LLC,Urbana;Chicago,United States;United States,3,"Kini, Dileep;Mathur, Umang;Viswanathan, Mahesh",51763848100;57223123224;7102067916,120399513;60000745;60000745,2018-10-26,26 October 2018,ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21100890553,,Conference Proceeding,,,,26-37,"We consider the problem of detecting data races in program traces that have been compressed using straight line programs (SLP), which are special context-free grammars that generate exactly one string, namely the trace that they represent. We consider two classical approaches to race detection D using the happens-before relation and the lockset discipline. We present algorithms for both these methods that run in time that is linear in the size of the compressed, SLP representation. Typical program executions almost always exhibit patterns that lead to significant compression. Thus, our algorithms are expected to result in large speedups when compared with analyzing the uncompressed trace. Our experimental evaluation of these new algorithms on standard benchmarks confirms this observation.",Compression | Dynamic Program Analysis | Race Detection,11,1,repositoryam,Green,CISE,1329991,Directorate for Computer and Information Science and Engineering,FSE Software Engineering
2-s2.0-85057286276,,,,Delayed impact of fair machine learning,cp,Conference Paper,Liu L.T.,60025038,"University of California, Berkeley",Berkeley,United States,5,"Liu, Lydia T.;Dean, Sarah;Rolf, Esther;Simchowitz, Max;Hardt, Moritz",57204783015;57203320013;56592944500;57192165585;24512337400,60025038;60025038;60025038;60025038;60025038,2018-01-01,2018,"35th International Conference on Machine Learning, ICML 2018",,21100887646,,Conference Proceeding,7,,,4929-4958,"Fairness in machine learning has predominantly been studied in static classification settings without concern for how decisions change the underlying population over time. Conventional wisdom suggests that fairness criteria promote the long- Term well-being of those groups they aim to protect. We study how static fairness criteria interact with temporal indicators of well-being, such as long-term improvement, stagnation, and decline in a variable of interest. We demonstrate that even in a one-step feedback model, common fairness criteria in general do not promote improvement over time, and may in fact cause harm in cases where an unconstrained objective would not. We completely characterize the delayed impact of three standard criteria, contrasting the regimes in which these exhibit qualitatively different behavior. In addition, we find that a natural form of measurement error broadens the regime in which fairness criteria perform favorably. Our results highlight the importance of measurement and temporal modeling in the evaluation of fairness criteria, suggesting a range of new challenges and trade-offs.",,107,0,,,,undefined,,ICML Machine Learning
2-s2.0-85046957941,10.1145/3173574.3174110,,,Design within a patriarchal society: Opportunities and challenges in designing for rural women in Bangladesh,cp,Conference Paper,Sultana S.,60104837;60028072,Cornell Tech;Cornell University Department of Information Science,New York;Ithaca,United States;United States,4,"Sultana, Sharifa;Guimbretière, François;Sengers, Phoebe;Dell, Nicola",57213062810;6508204254;22836146000;45560910100,60028072;60028072;60028072;60104837,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"This paper examines the opportunities and issues that arise in designing technologies to support low-income rural women in Bangladesh. Through a qualitative, empirical study with 90 participants, we reveal systemic everyday challenges that women face that form the backdrop against which technology design could potentially happen. We discuss how technology is already impacting women's lives, sometimes by reinforcing their subservient role in society and sometimes used tactically by women to gain a measure of agency. The issues raised by our participants concerning technology's place in their lives provide HCI researchers with valuable guidance about what might (or might not) be appropriate to design for them. We also show how prevalent HCI research and design strategies may fit more poorly than expected into rural women's lives, and we discuss possible alternative design directions, and the ethical and pragmatic trade-offs that they entail. Our contribution is not to ""solve"" the problem of designing for low-income rural women, but to expand the HCI community's understanding of technology design within deeply patriarchal societies.",Bangladesh | Feminism | Gender | HCI4D | ICTD | Rural | Women,111,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85046977934,10.1145/3173574.3173614,,,Design for collaborative survival: An inquiry into human-fungi relationships,cp,Conference Paper,Liu J.,60027950;60000221,Carnegie Mellon University;University of Colorado Boulder,Pittsburgh;Boulder,United States;United States,3,"Liu, Jen;Byrne, Daragh;Devendorf, Laura",57202049558;57105888300;55734892700,60000221;60027950;60000221,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"In response to recent calls for HCI to address ongoing environmental crises and existential threats, this paper introduces the concept of collaborative survival and examines how it shapes the design of interactive artifacts. Collaborative survival describes how our (human) ability to persist as a species is deeply entangled with and dependent upon the health of a multitude of other species. We explore collaborative survival within the context of designing tools for mushroom foraging and reflect on how interactive products can open new pathways for noticing and joiningwith these entanglements towards preferable futures. In addition to highlighting three tactics-engagement, attunement and expansion-that can guide designs towards multispecies flourishing, our prototypes illustrate the potential for wearable technology to extend the body into the environment.",Collaborative survival | Fungi | Postanthropocentric design | Sensing | Wearable technology,114,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85058302437,10.1145/3236024.3236029,,,Do android taint analysis tools keep their promises?,cp,Conference Paper,Pauck F.,60020238,Universität Paderborn,Paderborn,Germany,3,"Pauck, Felix;Bodden, Eric;Wehrheim, Heike",57195994711;14041233500;6603094619,60020238;60020238;60020238,2018-10-26,26 October 2018,ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21100890553,,Conference Proceeding,,,,331-341,"In recent years, researchers have developed a number of tools to conduct taint analysis of Android applications. While all the respective papers aim at providing a thorough empirical evaluation, comparability is hindered by varying or unclear evaluation targets. Sometimes, the apps used for evaluation are not precisely described. In other cases, authors use an established benchmark but cover it only partially. In yet other cases, the evaluations differ in terms of the data leaks searched for, or lack a ground truth to compare against. All those limitations make it impossible to truly compare the tools based on those published evaluations. We thus present ReproDroid, a framework allowing the accurate comparison of Android taint analysis tools. ReproDroid supports researchers in inferring the ground truth for data leaks in apps, in automatically applying tools to benchmarks, and in evaluating the obtained results.We use ReproDroid to comparatively evaluate on equal grounds the six prominent taint analysis tools Amandroid, DIALDroid, DidFail, DroidSafe, FlowDroid and IccTA. The results are largely positive although four tools violate some promises concerning features and accuracy. Finally, we contribute to the area of unbiased benchmarking with a new and improved version of the open test suite DroidBench.",Android Taint Analysis | Benchmarks | Empirical Studies | Reproducibility | Tools,70,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-85047991607,10.1145/3196959.3196984,,,Entity matching with active monotone classification,cp,Conference Paper,Tao Y.,60002798,Chinese University of Hong Kong,Hong Kong,Hong Kong,2,"Tao, Yufei;Kong, Hong",7402420191;57202347486,60002798;60002798,2018-05-27,27 May 2018,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,49-62,"Given two sets of entities X and Y, entity matching aims to decide whether x and y represent the same entity for each pair (x,y) ∈ X × Y . As the last resort, human experts can be called upon to inspect every (x,y), but this is expensive because the correct verdict could not be determined without investigation efforts dedicated specifically to the two entities x and y involved. It is therefore important to design an algorithm that asks humans to look at only some pairs, and renders the verdicts on the other pairs automatically with good accuracy. At the core of most (if not all) existing approaches is the following classification problem. The input is a set P of points in Rd , each of which carries a binary label: 0 or 1. A classifier F is a function from Rd to (0, 1). The objective is to find a classifier that captures the labels of a large number of points in P. In this paper, we cast the problem as an instance of active learning where the goal is to learn a monotone classifier F, namely, F (p) ≥ F (q) holds whenever the coordinate of p is at least that of q on all dimensions. In our formulation, the labels of all points in P are hidden at the beginning. An algorithm A can invoke an oracle, which discloses the label of a point p ∈ P chosen by A. The algorithm may do so repetitively, until it has garnered enough information to produce F . The cost of A is the number of times that the oracle is called. The challenge is to strike a good balance between the cost and the accuracy of the classifier produced. We describe algorithms with non-trivial guarantees on the cost and accuracy simultaneously. We also prove lower bounds that establish the asymptotic optimality of our solutions for a wide range of parameters.",Active Learning | Entity Matching | Monotone Classification,8,0,,,CUHK,undefined,Google,PODS Databases
2-s2.0-85046977536,10.1145/3173574.3174140,,,Examining Wikipedia with a broader lens: Quantifying the value of Wikipedia's relationships with other large-scale online communities,cp,Conference Paper,Vincent N.,60007363,Northwestern University,Evanston,United States,3,"Vincent, Nicholas;Johnson, Isaac;Hecht, Brent",57202044868;57002435200;24824723600,60007363;60007363;60007363,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"The extensive Wikipedia literature has largely considered Wikipedia in isolation, outside of the context of its broader Internet ecosystem. Very recent research has demonstrated the significance of this limitation, identifying critical relationships between Google and Wikipedia that are highly relevant to many areas of Wikipedia-based research and practice. This paper extends this recent research beyond search engines to examine Wikipedia's relationships with large-scale online communities, Stack Overflow and Reddit in particular. We find evidence of consequential, albeit unidirectional relationships. Wikipedia provides substantial value to both communities, with Wikipedia content increasing visitation, engagement, and revenue, but we find little evidence that these websites contribute to Wikipedia in return. Overall, these findings highlight important connections between Wikipedia and its broader ecosystem that should be considered by researchers studying Wikipedia. Critically, our results also emphasize the key role that volunteer-created Wikipedia content plays in improving other websites, even contributing to revenue generation.",Online communities | Peer production | Reddit | Stack Overflow | Wikipedia,28,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85046977003,10.1145/3173574.3173784,,,Experiencing the body as play,cp,Conference Paper,Mueller F.,60011362,RMIT University,Melbourne,Australia,4,"Mueller, Florian;Byrne, Richard;Andres, Josh;Patibanda, Rakesh",22835390000;56492320700;57146736100;57197768198,60011362;60011362;60011362;60011362,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"Games research in HCI is continually interested in the human body. However, recent work suggests that the field has only begun to understand how to design bodily games. We propose that the games research field is advancing from playing with digital content using a keyboard, to using bodies to play with digital content, towards a future where we experience our bodies as digital play. To guide designers interested in supporting players to experience their bodies as play, we present two phenomenological perspectives on the human body (Körper and Leib) and articulate a suite of design tactics using our own and other people's work. We hope with this paper, we are able to help designers embrace the point that we both ""have"" a body and ""are"" a body, thereby aiding the facilitation of the many benefits of engaging the human body through games and play, and ultimately contributing to a more humanized technological future.",Exergame | Exertion games | Play | Whole-body interaction,97,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85046971408,10.1145/3173574.3173962,,,Expressive time series querying with hand-drawn scale-free sketches,cp,Conference Paper,Mannino M.,60104576,NYU Abu Dhabi,Abu Dhabi,United Arab Emirates,2,"Mannino, Miro;Abouzied, Azza",57202048776;14832214000,60104576;60104576,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"We present Qetch, a tool where users freely sketch patterns on a scale-less canvas to query time series data without specifying query length or amplitude. We study how humans sketch time series patterns - humans preserve visually salient perceptual features but often non-uniformly scale and locally distort a pattern - and we develop a novel matching algorithm that accounts for human sketching errors. Qetch enables the easy construction of complex and expressive queries with two key features: regular expressions over sketches and relative positioning of sketches to query multiple time-aligned series. Through user studies, we demonstrate the effectiveness of Qetch's different interaction features. We also demonstrate the effectiveness of Qetch's matching algorithm compared to popular algorithms on targeted, and exploratory query-bysketch search tasks on a variety of data sets.",Regular expressions | Scale-less sketches | Time series querying by sketching,29,0,,,CISE,1420941,Directorate for Computer and Information Science and Engineering,CHI Human-Computer Interaction
2-s2.0-85046950061,10.1145/3173574.3174164,,,Extending manual drawing practices with artist-centric programming tools,cp,Conference Paper,Jacobs J.,60076047;60002243,Adobe Inc.;MIT Media Lab,San Jose;Cambridge,United States;United States,4,"Jacobs, Jennifer;Brandt, Joel;Měch, Radomír;Resnick, Mitchel",25624887300;22833423700;24169244200;7201681944,60002243;60076047;60076047;60002243,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"Procedural art, or art made with programming, suggests opportunities to extend traditional arts like painting and drawing; however, this potential is limited by tools that conflict with manual practices. Programming languages present learning barriers and manual drawing input is not a first class primitive in common programming models. We hypothesize that by developing programming languages and environments that align with how manual artists work, we can build procedural systems that enhance, rather than displace, manual art. To explore this, we developed Dynamic Brushes, a programming and drawing environment motivated by interviews with artists. Dynamic Brushes enables the creation of ad-hoc drawing tools that transform stylus inputs to procedural patterns. Applications range from transforming individual strokes to behaviors that draw multiple strokes simultaneously, respond to temporal events, and leverage external data. Results from an extended evaluation with artists provide guidelines for learnable, expressive systems that blend manual and procedural creation.",Generative art | Procedural art | Programming,34,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85060074618,10.18653/v1/p18-1254,,,Finding syntax in human encephalography with beam search,cp,Conference Paper,Hale J.,60111161;60026851;60025778;60007776,"DeepMind Technologies Limited;University of Oxford;University of Michigan, Ann Arbor;Cornell University",London;Oxford;Ann Arbor;Ithaca,United Kingdom;United Kingdom;United States;United States,4,"Hale, John;Dyer, Chris;Kuncoro, Adhiguna;Brennan, Jonathan R.",14015526600;51664869700;57191846356;55426863500,60111161-60007776;60111161;60111161-60026851;60025778,2018-01-01,2018,"ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)",,21100901653,,Conference Proceeding,1,,,2727-2736,"Recurrent neural network grammars (RNNGs) are generative models of (tree, string) pairs that rely on neural networks to evaluate derivational choices. Parsing with them using beam search yields a variety of incremental complexity metrics such as word surprisal and parser action count. When used as regressors against human electrophys-iological responses to naturalistic text, they derive two amplitude effects: an early peak and a P600-like later peak. By contrast, a non-syntactic neural language model yields no reliable effects. Model comparisons attribute the early peak to syntactic composition within the RNNG. This pattern of results recommends the RNNG+beam search combination as a mechanistic model of the syntactic processing that occurs during normal human language comprehension.",,68,1,repositoryam,Green,NSF,1607251,National Science Foundation,ACL Natural Language Processing
2-s2.0-85055696498,10.24963/ijcai.2018/250,,,From conjunctive queries to instance queries in ontology-mediated querying,cp,Conference Paper,Feier C.,60020661;60008293,University of Liverpool;Universität Bremen,Liverpool;Bremen,United Kingdom;Germany,3,"Feier, Cristina;Lutz, Carsten;Wolter, Frank",14041503900;7103325866;7005739306,60008293;60008293;60020661,2018-01-01,2018,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2018-July,,,1810-1816,"We consider ontology-mediated queries (OMQs) based on expressive description logics of the ALC family and (unions) of conjunctive queries, studying the rewritability into OMQs based on instance queries (IQs). Our results include exact characterizations of when such a rewriting is possible and tight complexity bounds for deciding rewritability. We also give a tight complexity bound for the related problem of deciding whether a given MMSNP sentence is equivalent to a CSP.",,4,1,repositoryam,Green,H2020,647289,Consolidated Edison,IJCAI Artificial Intelligence
2-s2.0-85046949760,10.1145/3173574.3173931,,,"From her story, to our story: Digital storytelling as public engagement around abortion rights advocacy in Ireland",cp,Conference Paper,Michie L.,60025160;60006222;60002014,University College Cork;Newcastle University;The Royal Institute of Technology (KTH),Cork;Newcastle;Stockholm,Ireland;United Kingdom;Sweden,5,"Michie, Lydia;Balaam, Madeline;McCarthy, John;Osadchiy, Timur;Morrissey, Kellie",57202044926;36095639700;7402958639;57201451516;55802585500,60006222;60002014;60025160;60006222;60006222,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"Despite the divisive nature of abortion within the Republic of Ireland and Northern Ireland, where access to safe, legal abortion is severely restricted, effecting legislative reform demands widespread public support. In light of a building pro-choice counter-voice, this work contributes to a growing body of HCI research that takes an activist approach to design. We report findings from four design workshops with 31 pro-choice stakeholders across Ireland in which we positioned an exploratory protosite, HerStoryTold, to engender critical conversations around the use of sensitive abortion narratives as a tool for engagement. Our analysis shows how digital storytelling can help reject false narratives and raise awareness of the realities of abortion laws. It suggests design directions to curate narratives that provoke empathy, foster polyvocality, and ultimately expand the engaged community. Furthermore, this research calls for designers to actively support community mobilization through providing 'stepping stones' to activism.",Activism | Feminist HCI | Reproductive rights | Social movements | Storytelling,44,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85049398609,10.1145/3180155.3180211,,,Generalized data structure synthesis,cp,Conference Paper,Loncaric C.,60028661,UW College of Engineering,Seattle,United States,3,"Loncaric, Calvin;Ernst, Michael D.;Torlak, Emina",57136760000;36916423000;23089529200,60028661;60028661;60028661,2018-05-27,27 May 2018,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,958-968,"Data structure synthesis is the task of generating data structure implementations from high-level specifications. Recent work in this area has shown potential to save programmer time and reduce the risk of defects. Existing techniques focus on data structures for manipulating subsets of a single collection, but real-world programs often track multiple related collections and aggregate properties such as sums, counts, minimums, and maximums. This paper shows how to synthesize data structures that track subsets and aggregations of multiple related collections. Our technique decomposes the synthesis task into alternating steps of query synthesis and incrementalization. The query synthesis step implements pure operations over the data structure state by leveraging existing enumerative synthesis techniques, specialized to the data structures domain. The incrementalization step implements imperative state modifications by re-framing them as fresh queries that determine what to change, coupled with a small amount of code to apply the change. As an added benefit of this approach over previous work, the synthesized data structure is optimized for not only the queries in the specification but also the required update operations. We have evaluated our approach in four large case studies, demonstrating that these extensions are broadly applicable.",Automatic programming | Data structures | Program synthesis,21,0,,,NSF,1651225,National Science Foundation,ICSE Software Engineering
2-s2.0-85046938033,10.1145/3173574.3173715,,,HARK no more: On the preregistration of chi experiments,cp,Conference Paper,Cockburn A.,60020585;60019702;60015186,University of Canterbury;University of Birmingham;University of Saskatchewan,Christchurch;Birmingham;Saskatoon,New Zealand;United Kingdom;Canada,3,"Cockburn, Andy;Gutwin, Carl;Dix, Alan",7004557137;35587413900;7005324365,60020585;60015186;60019702,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"Experimental preregistration is required for publication in many scientific disciplines and venues. When experimental intentions are preregistered, reviewers and readers can be confident that experimental evidence in support of reported hypotheses is not the result of HARKing, which stands for Hypothesising After the Results are Known. We review the motivation and outcomes of experimental preregistration across a variety of disciplines, as well as previous work commenting on the role of evaluation in HCI research. We then discuss how experimental preregistration could be adapted to the distinctive characteristics of Human-Computer Interaction empirical research, to the betterment of the discipline.","Experimental preregistration | File drawer effect | Harking, p-fishing | Nhst controversy | Replication",62,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85058034427,10.1145/3178876.3186000,,,HighLife: Higher-arity fact harvesting,cp,Conference Paper,Ernst P.,60000256,Max Planck Institute for Informatics,Saarbrucken,Germany,3,"Ernst, Patrick;Siu, Amy;Weikum, Gerhard",36657058800;55634668400;56270327600,60000256;60000256;60000256,2018-04-10,10 April 2018,"The Web Conference 2018 - Proceedings of the World Wide Web Conference, WWW 2018",,21100983204,,Conference Proceeding,,,,1013-1022,"Text-based knowledge extraction methods for populating knowledge bases have focused on binary facts: relationships between two entities. However, in advanced domains such as health, it is often crucial to consider ternary and higher-arity relations. An example is to capture which drug is used for which disease at which dosage (e.g. 2.5 mg/day) for which kinds of patients (e.g., children vs. adults). In this work, we present an approach to harvest higher-arity facts from textual sources. Our method is distantly supervised by seed facts, and uses the fact-pattern duality principle to gather fact candidates with high recall. For high precision, we devise a constraint-based reasoning method to eliminate false candidates. A major novelty is in coping with the difficulty that higher-arity facts are often expressed only partially in texts and strewn across multiple sources. For example, one sentence may refer to a drug, a disease and a group of patients, whereas another sentence talks about the drug, its dosage and the target group without mentioning the disease. Our methods cope well with such partially observed facts, at both pattern-learning and constraint-reasoning stages. Experiments with health-related documents and with news articles demonstrate the viability of our method.",Distant supervision | Health | Higher-arity relation extraction | Knowledge base construction | Knowledge graphs | Partial facts | Text-based knowledge harvesting | Tree pattern learning,24,1,publisherfree2read,Bronze,,undefined,,WWW World Wide Web
2-s2.0-85046966277,10.1145/3173574.3174161,,,Hoarding and minimalism: Tendencies in digital data preservation,cp,Conference Paper,Vitale F.,60010365,The University of British Columbia,Vancouver,Canada,3,"Vitale, Francesco;Janzen, Izabelle;McGrenere, Joanna",57201448836;57193574195;6505966811,60010365;60010365;60010365,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"Digital data, from texts to files and mobile applications, has become a pervasive component of our society. With seemingly unlimited storage in the cloud at their disposal, how do people approach data preservation, deciding what to keep and discard? We interviewed 23 participants with diverse backgrounds, asking them about their perceived digital data: what ""stuff"" they kept through the years, why, how they used it, and what they considered important. In an iterative analysis process, we uncovered a spectrum of tendencies that drive preservation strategies, with two extremes: hoarding (where participants accumulated large amounts of data, even if considered of little value) and minimalism (where they kept as little as possible, regularly cleaning their data). We contrast and compare the two extremes of the spectrum, characterize their nuanced nature, and discuss how our categorization compares to previously reported behaviors such as filing and piling, email cleaners and keepers. We conclude with broad implications for shaping technology.",Data management | Data preservation | Individual differences,36,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85046941722,10.1145/3173574.3173588,,,How relevant are incidental power poses for HCI?,cp,Conference Paper,Jansen Y.,60069769;60030840,Institut des Systèmes Intelligents et de Robotique;Københavns Universitet,Paris;Copenhagen,France;Denmark,2,"Jansen, Yvonne;Hornbæk, Kasper",34880075700;6602385484,60069769;60030840,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"The concept of power pose originates from a Psychology study from 2010 which suggested that holding an expansive pose can change hormone levels and increase risk-taking behavior. Follow-up experiments suggested that expansive poses incidentally imposed by the design of an environment lead to more dishonest behaviors. While multiple replication attempts of the 2010 study failed, the follow-up experiments on incidental postures have so far not been replicated. As UI design in HCI can incidentally lead to expansive body postures, we attempted two conceptual replications: we first asked 44 participants to tap areas on a wall-sized display and measured their self-reported sense of power; we then asked 80 participants to play a game on a large touch-screen and measured risk-taking. Based on Bayesian analyses we find that incidental power poses had little to no effect on our measures but could cause physical discomfort. We conclude by discussing our findings in the context of theory-driven research in HCI.",Bayesian analysis | Incidental postures | Power pose,7,0,repositoryam,Green,H2020,648785,Horizon 2020 Framework Programme,CHI Human-Computer Interaction
2-s2.0-85049399305,10.1145/3180155.3180239,,,Identifying design problems in the source code: A grounded theory,cp,Conference Paper,Sousa L.,60032361;60023643;60005405,Pontifícia Universidade Católica do Rio de Janeiro;Lancaster University;Universidade Federal de Alagoas,Rio de Janeiro;Lancaster;Maceio,Brazil;United Kingdom;Brazil,12,"Sousa, Leonardo;Oliveira, Anderson;Oizumi, Willian;Barbosa, Simone;Garcia, Alessandro;Lee, Jaejoon;Kalinowski, Marcos;De Mello, Rafael;Fonseca, Baldoino;Oliveira, Roberto;Lucena, Carlos;Paes, Rodrigo",57194212913;56851872700;55515918200;7005050704;7404608626;56949401000;8288075800;37025865700;36175426900;57188679629;26643099500;23392951200,60032361;60032361;60032361;60032361;60032361;60023643;60032361;60032361;60005405;60032361;60032361;60032361,2018-05-27,27 May 2018,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,921-931,"The prevalence of design problems may cause re-engineering or even discontinuation of the system. Due to missing, informal or outdated design documentation, developers often have to rely on the source code to identify design problems. Therefore, developers have to analyze different symptoms that manifest in several code elements, which may quickly turn into a complex task. Although researchers have been investigating techniques to help developers in identifying design problems, there is little knowledge on how developers actually proceed to identify design problems. In order to tackle this problem, we conducted a multi-trial industrial experiment with professionals from 5 software companies to build a grounded theory. The resulting theory offers explanations on how developers identify design problems in practice. For instance, it reveals the characteristics of symptoms that developers consider helpful. Moreover, developers often combine different types of symptoms to identify a single design problem. This knowledge serves as a basis to further understand the phenomena and advance towards more effective identification techniques.",Design problem | Grounded theory | Software design | Symptoms,44,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-85056430247,10.1145/3230543.3230549,,,Inferring persistent interdomain congestion,cp,Conference Paper,Dhamdhere A.,60030612;60022195;60019722;60004424,"University of California, San Diego;Massachusetts Institute of Technology;Technische Universität München;The University of Waikato",La Jolla;Cambridge;Munich;Hamilton,United States;United States;Germany;New Zealand,9,"Dhamdhere, Amogh;Clark, David D.;Matthew Luckie, Alexander Gamero Garrido;Mok, Ricky K.P.;Akiwate, Gautam;Gogia, Kabir;Bajpai, Vaibhav;Snoeren, Alex C.;Claffy, Kc",8938019400;55613235535;57204619047;50262503700;55318683200;57204618058;55246491500;10142863200;57204872056,;60022195;60004424;60030612;60030612;60030612;60019722;60030612;60030612,2018-08-07,7 August 2018,SIGCOMM 2018 - Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication,,21100885290,,Conference Proceeding,,,,1-15,"There is significant interest in the technical and policy communities regarding the extent, scope, and consumer harm of persistent interdomain congestion. We provide empirical grounding for discussions of interdomain congestion by developing a system and method to measure congestion on thousands of interdomain links without direct access to them. We implement a system based on the Time Series Latency Probes (TSLP) technique that identifies links with evidence of recurring congestion suggestive of an under-provisioned link. We deploy our system at 86 vantage points worldwide and show that congestion inferred using our lightweight TSLP method correlates with other metrics of interconnection performance impairment. We use our method to study interdomain links of eight large U.S. broadband access providers from March 2016 to December 2017, and validate our inferences against ground-truth traffic statistics from two of the providers. For the period of time over which we gathered measurements, we did not find evidence of widespread endemic congestion on interdomain links between access ISPs and directly connected transit and content providers, although some such links exhibited recurring congestion patterns. We describe limitations, open challenges, and a path toward the use of this method for large-scale third-party monitoring of the Internet interconnection ecosystem.",Internet congestion | Internet topology | Performance,66,1,repositoryam,Green,NSF,1414177,National Science Foundation,SIGCOMM Networking
2-s2.0-85046954171,10.1145/3173574.3173688,,,"Keeping a low profile? Technology, risk and privacy among undocumented immigrants",cp,Conference Paper,Guberek T.,60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,6,"Guberek, Tamy;McDonald, Allison;Simioni, Sylvia;Mhaidli, Abraham H.;Toyama, Kentaro;Schaub, Florian",57193224012;57202043663;57202044661;57192103688;56902256500;35190916400,60025778;60025778;60025778;60025778;60025778;60025778,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"Undocumented immigrants in the United States face risks of discrimination, surveillance, and deportation. We investigate their technology use, risk perceptions, and protective strategies relating to their vulnerability. Through semi-structured interviews with Latinx undocumented immigrants, we find that while participants act to address offline threats, this vigilance does not translate to their online activities. Their technology use is shaped by needs and benefits rather than risk perceptions. While our participants are concerned about identity theft and privacy generally, and some raise concerns about online harassment, their understanding of government surveillance risks is vague and met with resignation. We identify tensions among self-expression, group privacy, and self-censorship related to their immigration status, as well as strong trust in service providers. Our findings have implications for digital literacy education, privacy and security interfaces, and technology design in general. Even minor design decisions can substantially affect exposure risks and well-being for such vulnerable communities.",Immigration | Integration | Online risk | Privacy | Surveillance | Technology use | Undocumented immigrants,68,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85128871403,10.1109/TSE.2020.3013438,,,Why My App Crashes? Understanding and Benchmarking Framework-Specific Exceptions of Android Apps,ar,Article,Su T.,60107184;60078616;60025858;60019533;60018038;60005510,NYU Shanghai;School of Computer Science and Engineering;ETH Zürich;Tianjin University;Nankai University;Nanyang Technological University,Shanghai;Singapore City;Zurich;Tianjin;Tianjin;Singapore City,China;Singapore;Switzerland;China;China;Singapore,7,"Su, Ting;Fan, Lingling;Chen, Sen;Liu, Yang;Xu, Lihua;Pu, Geguang;Su, Zhendong",55749546700;57197024797;57190395316;56911879800;55846204400;9534351100;7402248744,60025858;60018038-60005510;60005510-60019533;60078616;60107184;;60025858,2022-04-01,1 April 2022,IEEE Transactions on Software Engineering,00985589,18711,19393520,Journal,48,4,,1115-1137,"Mobile apps have become ubiquitous. Ensuring their correctness and reliability is important. However, many apps still suffer from occasional to frequent crashes, weakening their competitive edge. Large-scale, deep analyses of the characteristics of real-world app crashes can provide useful insights to both developers and researchers. However, such studies are difficult and yet to be carried out - this work fills this gap. We collected 16,245 and 8,760 unique exceptions from 2,486 open-source and 3,230 commercial Android apps, respectively, and observed that the exceptions thrown from Android framework (termed 'framework-specific exceptions') account for the majority. With one-year effort, we (1) extensively investigated these framework-specific exceptions, and (2) further conducted an online survey of 135 professional app developers about how they analyze, test, reproduce and fix these exceptions. Specifically, we aim to understand the framework-specific exceptions from several perspectives: (i) their characteristics (e.g., manifestation locations, fault taxonomy), (ii) the developers' testing practices, (iii) existing bug detection techniques' effectiveness, (iv) their reproducibility and (v) bug fixes. To enable follow-up research (e.g., bug understanding, detection, localization and repairing), we further systematically constructed, DroidDefects, the first comprehensive and largest benchmark of Android app exception bugs. This benchmark contains 33 reproducible exceptions (with test cases, stack traces, faulty and fixed app versions, bug types, etc.), and 3,696 ground-truth exceptions (real faults manifested by automated testing tools), which cover the apps with different complexities and diverse exception types. Based on our findings, we also built two prototype tools: Stoat+, an optimized dynamic testing tool, which quickly uncovered three previously-unknown, fixed crashes in Gmail and Google+; ExLocator, an exception localization tool, which can locate the root causes of specific exception types. Our dataset, benchmark and tools are publicly available on https://github.com/tingsu/droiddefects.",android applications | bug reproducibility | empirical study | exception analysis | Mobile applications | software testing,18,0,,,NRF,NRF2018NCR-NCR005-0001,National Research Foundation Singapore,ICSE Software Engineering
2-s2.0-85063101843,10.18653/v1/p18-1255,,,Learning to ask good questions: Ranking clarification questions using neural expected value of perfect information,cp,Conference Paper,Rao S.,60021726;60020304,"Microsoft Research;University of Maryland, College Park",Redmond;College Park,United States;United States,2,"Rao, Sudha;Daumé, Hal",57158096800;57210198346,60020304;60021726,2018-01-01,2018,"ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)",,21100901653,,Conference Proceeding,1,,,2737-2746,"Inquiry is fundamental to communication, and machines cannot effectively collaborate with humans unless they can ask questions. In this work, we build a neural network model for the task of ranking clarification questions. Our model is inspired by the idea of expected value of perfect information: a good question is one whose expected answer will be useful. We study this problem using data from StackExchange, a plentiful online resource in which people routinely ask clarifying questions to posts so that they can better offer assistance to the original poster. We create a dataset of clarification questions consisting of ∼77K posts paired with a clarification question (and answer) from three domains of StackExchange: askubuntu, unix and superuser. We evaluate our model on 500 samples of this dataset against expert human judgments and demonstrate significant improvements over controlled baselines.",,87,1,repositoryam,Green,NSF,IIS-1618193,National Science Foundation,ACL Natural Language Processing
2-s2.0-85076699985,,,,"Legoos: A disseminated, distributed OS for hardware resource disaggregation",cp,Conference Paper,Shan Y.,60009254,Purdue University,West Lafayette,United States,4,"Shan, Yizhou;Huang, Yutong;Chen, Yilun;Zhang, Yiying",57196256886;57196260647;57196260219;57196198658,60009254;60009254;60009254;60009254,2007-01-01,2007,"Proceedings of the 13th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2018",,21100958403,,Conference Proceeding,,,,69-87,"The monolithic server model where a server is the unit of deployment, operation, and failure is meeting its limits in the face of several recent hardware and application trends. To improve resource utilization, elasticity, heterogeneity, and failure handling in datacenters, we believe that datacenters should break monolithic servers into disaggregated, network-attached hardware components. Despite the promising benefits of hardware resource disaggregation, no existing OSes or software systems can properly manage it. We propose a new OS model called the splitkernel to manage disaggregated systems. Splitkernel disseminates traditional OS functionalities into loosely-coupled monitors, each of which runs on and manages a hardware component. A splitkernel also performs resource allocation and failure handling of a distributed set of hardware components. Using the splitkernel model, we built LegoOS, a new OS designed for hardware resource disaggregation. LegoOS appears to users as a set of distributed servers. Internally, a user application can span multiple processor, memory, and storage hardware components. We implemented LegoOS on x86-64 and evaluated it by emulating hardware components using commodity servers. Our evaluation results show that LegoOS' performance is comparable to monolithic Linux servers, while largely improving resource packing and reducing failure rate over monolithic clusters.",,187,0,,,NSF,NSF 1719215,National Science Foundation,OSDI Operating Systems
2-s2.0-85046964184,10.1145/3173574.3173889,,,"Let's talk about race: Identity, chatbots, and AI",cp,Conference Paper,Schlesinger A.,60098463;60097290;60025704,"Microsoft Research Cambridge;College of Computing;City, University of London",Cambridge;Atlanta;London,United Kingdom;United States;United Kingdom,3,"Schlesinger, Ari;O'Hara, Kenton P.;Taylor, Alex S.",57201447035;7101930949;35581562900,60097290;60098463;60025704,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"Why is it so hard for chatbots to talk about race? This work explores how the biased contents of databases, the syntactic focus of natural language processing, and the opaque nature of deep learning algorithms cause chatbots difficulty in handling race-talk. In each of these areas, the tensions between race and chatbots create new opportunities for people and machines. By making the abstract and disparate qualities of this problem space tangible, we can develop chatbots that are more capable of handling race-talk in its many forms. Our goal is to provide the HCI community with ways to begin addressing the question, how can chatbots handle race-talk in new and improved ways?",Artificial intelligence | Chatbots | Race,96,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85063102957,10.18653/v1/p18-1256,,,Let's do it “Again”: A first computational approach to detecting adverbial presupposition triggers,cp,Conference Paper,Cianflone A.,60113142;60002494,Montreal Institute for Learning Algorithms;Université McGill,Montreal;Montreal,Canada;Canada,4,"Cianflone, Andre;Feng, Yulan;Kabbara, Jad;Cheung, Jackie Chi Kit",57205398430;57204215679;56303697100;51664627900,60002494;60002494;60002494;60113142,2018-01-01,2018,"ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)",,21100901653,,Conference Proceeding,1,,,2747-2755,"We introduce the task of predicting adverbial presupposition triggers such as also and again. Solving such a task requires detecting recurring or similar events in the discourse context, and has applications in natural language generation tasks such as summarization and dialogue systems. We create two new datasets for the task, derived from the Penn Treebank and the Annotated English Gigaword corpora, as well as a novel attention mechanism tailored to this task. Our attention mechanism augments a baseline recurrent neural network without the need for additional trainable parameters, minimizing the added computational cost of our mechanism. We demonstrate that our model statistically outperforms a number of baselines, including an LSTM-based language model.",,8,1,repositoryam,Green,NSERC,undefined,Natural Sciences and Engineering Research Council of Canada,ACL Natural Language Processing
2-s2.0-85046947745,10.1145/3173574.3174105,,,Making Core Memory: Design inquiry into gendered legacies of engineering and craftwork,cp,Conference Paper,Rosner D.K.,60015481,University of Washington,Seattle,United States,4,"Rosner, Daniela K.;Shorey, Samantha;Craft, Brock R.;Remick, Helen",23009944700;57196417189;57202475124;57202048757,60015481;60015481;60015481;,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"This paper describes the Making Core Memory project, a design inquiry into the invisible work that went into assem-bling core memory, an early form of computer information storage initially woven by hand. Drawing on feminist tradi-tions of situated knowing, we designed an electronic quilt and a series of participatory workshops that materialize the work of the core memory weavers. With this case we not only broaden dominant stories of design, but we also reflect on the entanglement of predominantly male, high status labor with the ostensibly low-status work of women's hands. By integrating design and archival research as a means of cultural analysis, we further expand conversations on design research methods within human-computer inter-action (HCI), using design to reveal legacies of practice elided by contemporary technology cultures. In doing so, this paper highlights for HCI scholars that worlds of hand-work and computing, or weaving and space travel, are not as separate as we might imagine them to be.",Compu-ting history | Craft | Gendered labor | Handwork | Participatory workshops | Woven memory,66,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85046962988,10.1145/3173574.3173925,,,Making as expression: Informing design with people with complex communication needs through art therapy,cp,Conference Paper,Lazar A.,60020304;60007363;116532588,"University of Maryland, College Park;Northwestern University;MATHER LIFE WAYS",College Park;Evanston;Evanston,United States;United States;United States,4,"Lazar, Amanda;Feuston, Jessica L.;Edasis, Caroline;Piper, Anne Marie",55660177200;56426609200;57188814904;15023169400,60020304-60007363;60007363;116532588;60007363,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"There is a growing emphasis on designing with people with diverse health experiences rather than designing for them. Yet, collaborative design becomes difficult when working with individuals with health conditions (e.g., stroke, cancer, abuse, depression) that affect their ability or willingness to engage alongside researchers and verbally express themselves. The present paper analyzes how the clinical practice of art therapy engages these individuals in cocreative, visual expression of ideas, thoughts, and experiences. Drawing on interviews with 22 art therapists and over two years of field work in a clinical setting, we detail how art therapists view making as expression for people with complex communication needs. Under this view, we argue that art therapy practice can inspire collaborative design engagements by understanding materials as language, creating space for expression, and sustaining expressions in a broader context. We discuss practical and ethical implications for design work involving individuals with complex communication needs.",Art therapy | Collaborative design | Communication | Health,58,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85060461233,,,,Memory-augmented Monte Carlo tree search,cp,Conference Paper,Xiao C.,60030835,University of Alberta,Edmonton,Canada,3,"Xiao, Chenjun;Mei, Jincheng;Müller, Martin",55365453800;56393854100;57208122193,60030835;60030835;60030835,2018-01-01,2018,"32nd AAAI Conference on Artificial Intelligence, AAAI 2018",,21100896173,,Conference Proceeding,,,,1455-1461,"This paper proposes and evaluates Memory-Augmented Monte Carlo Tree Search (M-MCTS), which provides a new approach to exploit generalization in online real-time search. The key idea of M-MCTS is to incorporate MCTS with a memory structure, where each entry contains information of a particular state. This memory is used to generate an approximate value estimation by combining the estimations of similar states. We show that the memory based value approximation is better than the vanilla Monte Carlo estimation with high probability under mild conditions. We evaluate M-MCTS in the game of Go. Experimental results show that M-MCTS outperforms the original MCTS with the same number of simulations.",,15,0,,,NSERC,undefined,Natural Sciences and Engineering Research Council of Canada,AAAI Artificial Intelligence
2-s2.0-85064804469,,,,Nearly tight sample complexity bounds for learning mixtures of Gaussians via sample compression schemes,cp,Conference Paper,Ashtiani H.,60031828;60014171;60010365;60002494,McMaster University;University of Waterloo;The University of British Columbia;Université McGill,Hamilton;Waterloo;Vancouver;Montreal,Canada;Canada;Canada;Canada,6,"Ashtiani, Hassan;Ben-David, Shai;Harvey, Nicholas J.A.;Liaw, Christopher;Mehrabian, Abbas;Plan, Yaniv",57190794712;7004280914;8626283300;57193425155;35799753100;33368178000,60031828;60014171;60010365;60010365;60002494;60010365,2018-01-01,2018,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,2018-December,,,3412-3421,"We prove that Θ(e kd2/ε2) samples are necessary and sufficient for learning a mixture of k Gaussians in Rd, up to error ε in total variation distance. This improves both the known upper bounds and lower bounds for this problem. For mixtures of axis-aligned Gaussians, we show that Oe(kd/ε2) samples suffice, matching a known lower bound. The upper bound is based on a novel technique for distribution learning based on a notion of sample compression. Any class of distributions that allows such a sample compression scheme can also be learned with few samples. Moreover, if a class of distributions has such a compression scheme, then so do the classes of products and mixtures of those distributions. The core of our main result is showing that the class of Gaussians in Rd has a small-sized sample compression.",,35,0,,,NSERC,22R23068,Natural Sciences and Engineering Research Council of Canada,NeurIPS Machine Learning
2-s2.0-85076724141,,,,NetChain: Scale-free sub-RTT coordination,cp,Conference Paper,Jin X.,60025038;60007776;60006824;60005248;60003269;114059328,"University of California, Berkeley;Cornell University;Università della Svizzera italiana;Johns Hopkins University;Princeton University;Barefoot Networks",Berkeley;Ithaca;Lugano;Baltimore;Princeton;Palo Alto,United States;United States;Switzerland;United States;United States;United States,8,"Jin, Xin;Li, Xiaozhou;Zhang, Haoyu;Foster, Nate;Lee, Jeongkeun;Soulé, Robert;Kim, Changhoon;Stoica, Ion",57189270771;35213400300;57207485096;37006482600;7601458039;35868197700;55697753700;7007009125,60005248;114059328;60003269;114059328-60007776;114059328;114059328-60006824;114059328;60025038,2018-01-01,2018,"Proceedings of the 15th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2018",,21101017661,,Conference Proceeding,,,,35-49,"Coordination services are a fundamental building block of modern cloud systems, providing critical functionalities like configuration management and distributed locking. The major challenge is to achieve low latency and high throughput while providing strong consistency and fault-tolerance. Traditional server-based solutions require multiple round-trip times (RTTs) to process a query. This paper presents NetChain, a new approach that provides scale-free sub-RTT coordination in datacenters. NetChain exploits recent advances in programmable switches to store data and process queries entirely in the network data plane. This eliminates the query processing at coordination servers and cuts the end-to-end latency to as little as half of an RTT-clients only experience processing delay from their own software stack plus network delay, which in a datacenter setting is typically much smaller. We design new protocols and algorithms based on chain replication to guarantee strong consistency and to efficiently handle switch failures. We implement a prototype with four Barefoot Tofino switches and four commodity servers. Evaluation results show that compared to traditional server-based solutions like ZooKeeper, our prototype provides orders of magnitude higher throughput and lower latency, and handles failures gracefully.",,186,0,,,NSF,CCF-1139158,National Science Foundation,NSDI Networking
2-s2.0-85064831041,,,,Neural ordinary differential equations,cp,Conference Paper,Chen R.T.Q.,60016849,University of Toronto,Toronto,Canada,4,"Chen, Ricky T.Q.;Rubanova, Yulia;Bettencourt, Jesse;Duvenaud, David",57208443833;57211450858;57189976603;47762020000,60016849;60016849;60016849;60016849,2018-01-01,2018,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,2018-December,,,6571-6583,"We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.",,1756,0,,,,undefined,,NeurIPS Machine Learning
2-s2.0-85064848455,,,,Non-delusional Q-learning and value iteration,cp,Conference Paper,Lu T.,60006191,Google LLC,Mountain View,United States,3,"Lu, Tyler;Schuurmans, Dale;Boutilier, Craig",36175939500;57204335408;7003804813,60006191;60006191;60006191,2018-01-01,2018,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,2018-December,,,9949-9959,"We identify a fundamental source of error in Q-learning and other forms of dynamic programming with function approximation. Delusional bias arises when the approximation architecture limits the class of expressible greedy policies. Since standard Q-updates make globally uncoordinated action choices with respect to the expressible policy class, inconsistent or even conflicting Q-value estimates can result, leading to pathological behaviour such as over/under-estimation, instability and even divergence. To solve this problem, we introduce a new notion of policy consistency and define a local backup process that ensures global consistency through the use of information sets-sets that record constraints on policies consistent with backed-up Q-values. We prove that both the model-based and model-free algorithms using this backup remove delusional bias, yielding the first known algorithms that guarantee optimal results under general conditions. These algorithms furthermore only require polynomially many information sets (from a potentially exponential support). Finally, we suggest other practical heuristics for value-iteration and Q-learning that attempt to reduce delusional bias.",,17,0,,,,undefined,,NeurIPS Machine Learning
2-s2.0-85053904058,,,,Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples,cp,Conference Paper,Athalye A.,60025038;60022195,"University of California, Berkeley;Massachusetts Institute of Technology",Berkeley;Cambridge,United States;United States,3,"Athalye, Anish;Carlini, Nicholas;Wagner, David",57204807086;57194977162;7401982903,60022195;60025038;60025038,2018-01-01,2018,"35th International Conference on Machine Learning, ICML 2018",,21100887644,,Conference Proceeding,1,,,436-448,"We identify obfuscated gradients, a kind of gradient masking, as a phenomenon that leads to a false sense of security in defenses against adversarial examples. While defenses that causc obfuscated gradients appear to defeat iterative optimization- based attacks, wc find defenses relying on this effect can be circumvented. We describe characteristic behaviors of defenses exhibiting the effect, and for each of the three types Qf obfuscated gradients we discover, wc develop attack techniques to overcome it. In a case study, examining non- certified white-box-secure defenses at ICLR 2018. we find obfuscated gradients arc a common occurrence, with 7 of 9 defenses relying on obfuscated gradients. Our new attacks successfully circumvent 6 completely, and 1 partially, in the original threat model each paper considers.",,773,0,,,NSF,CNS-1514457,National Science Foundation,ICML Machine Learning
2-s2.0-85051037592,10.1109/SP.2018.00019,,,On Enforcing the Digital Immunity of a Large Humanitarian Organization,cp,Conference Paper,Le Blond S.,60028186,École Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,6,"Le Blond, Stevens;Cuevas, Alejandro;Troncoso-Pastoriza, Juan Ramon;Jovanovic, Philipp;Ford, Bryan;Hubaux, Jean Pierre",6505566392;58325026600;15060614500;55104237200;36791913700;55944389200,60028186;60028186;60028186;60028186;60028186;60028186,2018-07-23,23 July 2018,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2018-May,,8418617,424-440,"Humanitarian action, the process of aiding individuals in situations of crises, poses unique information-security challenges due to natural or manmade disasters, the adverse environments in which it takes place, and the scale and multi-disciplinary nature of the problems. Despite these challenges, humanitarian organizations are transitioning towards a strong reliance on the digitization of collected data and digital tools, which improves their effectiveness but also exposes them to computer security threats. In this paper, we conduct a qualitative analysis of the computer-security challenges of the International Committee of the Red Cross (ICRC), a large humanitarian organization with over sixteen thousand employees, an international legal personality, which involves privileges and immunities, and over 150 years of experience with armed conflicts and other situations of violence worldwide. To investigate the computer security needs and practices of the ICRC from an operational, technical, legal, and managerial standpoint by considering individual, organizational, and governmental levels, we interviewed 27 field workers, IT staff, lawyers, and managers. Our results provide a first look at the unique security and privacy challenges that humanitarian organizations face when collecting, processing, transferring, and sharing data to enable humanitarian action for a multitude of sensitive activities. These results highlight, among other challenges, the trade offs between operational security and requirements stemming from all stakeholders, the legal barriers for data sharing among jurisdictions; especially, the need to complement privileges and immunities with robust technological safeguards in order to avoid any leakages that might hinder access and potentially compromise the neutrality, impartiality, and independence of humanitarian action.",Anonymity networks | Block chains | Coercion resistance | Data protection | Operational security | Privacy enhancing technologies | Privileges and Immunities,9,1,repositoryam,Green,,undefined,,S&P Security and Privacy
2-s2.0-85064839890,,,,Optimal algorithms for non-smooth distributed optimization in networks,cp,Conference Paper,Scaman K.,60119391;60108665;60021726;60015481;113734158,Huawei Noah's Ark Lab;Université PSL;Microsoft Research;University of Washington;MSR-INRIA Joint Centre,Hong Kong;Paris;Redmond;Seattle;,Hong Kong;France;United States;United States;France,5,"Scaman, Kevin;Bach, Francis;Bubeck, Sébastien;Lee, Yin Tat;Massoulié, Laurent",56737183700;7202286449;26431237900;55785529000;6603753137,60119391;60108665;60021726;60021726-60015481;60108665-113734158,2018-01-01,2018,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,2018-December,,,2740-2749,"In this work, we consider the distributed optimization of non-smooth convex functions using a network of computing units. We investigate this problem under two regularity assumptions: (1) the Lipschitz continuity of the global objective function, and (2) the Lipschitz continuity of local individual functions. Under the local regularity assumption, we provide the first optimal first-order decentralized algorithm called multi-step primal-dual (MSPD) and its corresponding optimal convergence rate. A notable aspect of this result is that, for non-smooth functions, while the dominant term of the error is in O(1/t), the structure of the communication network only impacts a second-order term in O(1/t), where t is time. In other words, the error due to limits in communication resources decreases at a fast rate even in the case of non-strongly-convex objective functions. Under the global regularity assumption, we provide a simple yet efficient algorithm called distributed randomized smoothing (DRS) based on a local smoothing of the objective function, and show that DRS is within a d1/4 multiplicative factor of the optimal convergence rate, where d is the underlying dimension.",,89,0,,,,undefined,,NeurIPS Machine Learning
2-s2.0-85053479341,10.1109/INFOCOM.2018.8486307,,,Optimizing Age of Information in Wireless Networks with Throughput Constraints,cp,Conference Paper,Kadota I.,60022195,Massachusetts Institute of Technology,Cambridge,United States,3,"Kadota, Igor;Sinha, Abhishek;Modiano, Eytan",57189371740;57209528590;7006138684,60022195;60022195;60022195,2018-10-08,8 October 2018,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2018-April,,8486307,1844-1852,"Age of Information (AoI) is a performance metric that captures the freshness of the information from the perspective of the destination. The AoI measures the time that elapsed since the generation of the packet that was most recently delivered to the destination. In this paper, we consider a single-hop wireless network with a number of nodes transmitting time-sensitive information to a Base Station and address the problem of minimizing the Expected Weighted Sum AoI of the network while simultaneously satisfying timely-throughput constraints from the nodes. We develop three low-complexity transmission scheduling policies that attempt to minimize AoI subject to minimum throughput requirements and evaluate their performance against the optimal policy. In particular, we develop a randomized policy, a Max-Weight policy and a Whittle's Index policy, and show that they are guaranteed to be within a factor of two, four and eight, respectively, away from the minimum AoI possible. In contrast, simulation results show that Max-Weight outperforms the other policies, both in terms of AoI and throughput, in every network configuration simulated, and achieves near optimal performance.",,185,0,,,NSF,AST-1547331,National Science Foundation,INFOCOM Networking
2-s2.0-85063874467,,,,OrcA: Differential bug localization in large-scale services,cp,Conference Paper,Bhagwan R.,60098465,Microsoft Research India,Bengaluru,India,4,"Bhagwan, Ranjita;Kumar, Rahul;Maddila, Chandra Sekhar;Philip, Adithya Abraham",6506809871;58285930900;57200337950;57155982100,60098465;60098465;60098465;60098465,2007-01-01,2007,"Proceedings of the 13th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2018",,21100955671,,Conference Proceeding,,,,493-509,"Today, we depend on numerous large-scale services for basic operations such as email. These services are complex and extremely dynamic as developers continuously commit code and introduce new features, fixes and, consequently, new bugs. Hundreds of commits may enter deployment simultaneously. Therefore one of the most time-critical, yet complex tasks towards mitigating service disruption is to localize the bug to the right commit. This paper presents the concept of differential bug localization that uses a combination of differential code analysis and software provenance tracking to effectively pin-point buggy commits. We have built Orca, a customized code search-engine that implements differential bug localization. On-Call Engineers (OCEs) of Orion, a large enterprise email and collaboration service, use Orca to localize bugs to the appropriate buggy commits. Our evaluation shows that Orca correctly localizes 77% of bugs for which it has been used. We also show that it causes a 3x reduction in the work done by the OCE.",,15,0,,,,undefined,,OSDI Operating Systems
2-s2.0-85058270262,10.1145/3236024.3236026,,,Oreo: Detection of clones in the twilight zone,cp,Conference Paper,Saini V.,60007278,"University of California, Irvine",Irvine,United States,5,"Saini, Vaibhav;Farmahinifarahani, Farima;Lu, Yadong;Baldi, Pierre;Lopes, Cristina V.",56553828400;57205023722;57205030426;7101759672;7103222266,60007278;60007278;60007278;60007278;60007278,2018-10-26,26 October 2018,ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21100890553,,Conference Proceeding,,,,354-365,"Source code clones are categorized into four types of increasing difficulty of detection, ranging from purely textual (Type-1) to purely semantic (Type-4). Most clone detectors reported in the literature work well up to Type-3, which accounts for syntactic differences. In between Type-3 and Type-4, however, there lies a spectrum of clones that, although still exhibiting some syntactic similarities, are extremely hard to detect s the Twilight Zone. Most clone detectors reported in the literature fail to operate in this zone. We present Oreo, a novel approach to source code clone detection that not only detects Type-1 to Type-3 clones accurately, but is also capable of detecting harder-to-detect clones in the Twilight Zone. Oreo is built using a combination of machine learning, information retrieval, and software metrics. We evaluate the recall of Oreo on BigCloneBench, and perform manual evaluation for precision. Oreo has both high recall and precision. More importantly, it pushes the boundary in detection of clones with moderate to weak syntactic similarity in a scalable manner.",Clone detection | Machine Learning | Software Metrics,114,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-85046953545,10.1145/3173574.3173655,,,Pinpointing: Precise head- and eye-based target selection for augmented reality,cp,Conference Paper,Kytö M.,60103653;60031846,Aalto University;University of South Australia,Espoo;Adelaide,Finland;Australia,5,"Kytö, Mikko;Ens, Barrett;Piumsomboon, Thammathip;Lee, Gun A.;Billinghurst, Mark",36975727300;53867874600;54885265000;15021122000;7006142663,60103653;60031846;60031846;60031846;60031846,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"Head and eye movement can be leveraged to improve the user's interaction repertoire for wearable displays. Head movements are deliberate and accurate, and provide the current state-of-the-art pointing technique. Eye gaze can potentially be faster and more ergonomic, but suffers from low accuracy due to calibration errors and drift of wearable eye-tracking sensors. This work investigates precise, multimodal selection techniques using head motion and eye gaze. A comparison of speed and pointing accuracy reveals the relative merits of each method, including the achievable target size for robust selection. We demonstrate and discuss example applications for augmented reality, including compact menus with deep structure, and a proof-of-concept method for on-line correction of calibration drift.",Augmented reality | Eye tracking | Gaze interaction | Head-worn display | Refinement techniques | Target selection,190,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85056865276,10.1145/3242587.3242633,,,Porta: Profiling software tutorials using operating-system-wide activity tracing,cp,Conference Paper,Mysore A.,60030612,"University of California, San Diego",La Jolla,United States,2,"Mysore, Alok;Guo, Philip J.",57188755028;16238467300,60030612;60030612,2018-10-11,11 October 2018,UIST 2018 - Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology,,21100886509,,Conference Proceeding,,,,201-212,"It can be hard for tutorial creators to get fine-grained feedback about how learners are actually stepping through their tutorials and which parts lead to the most struggle. To provide such feedback for technical software tutorials, we introduce the idea of tutorial profiling, which is inspired by software code profiling. We prototyped this idea in a system called Porta that automatically tracks how users navigate through a tutorial webpage and what actions they take on their computer such as running shell commands, invoking compilers, and logging into remote servers. Porta surfaces this trace data in the form of profiling visualizations that augment the tutorial with heatmaps of activity hotspots and markers that expand to show event details, error messages, and embedded screencast videos of user actions. We found through a user study of 3 tutorial creators and 12 students who followed their tutorials that Porta enabled both the tutorial creators and the students to provide more specific, targeted, and actionable feedback about how to improve these tutorials. Porta opens up possibilities for performing user testing of technical documentation in a more systematic and scalable way.",Activity tracing | Software tutorials | Tutorial profiling,11,0,,,,undefined,,UIST User Interface
2-s2.0-85049561751,10.1145/3192366.3192382,,,Program synthesis using conflict-driven learning,cp,Conference Paper,Feng Y.,60027950;60022195;60013372,Carnegie Mellon University;Massachusetts Institute of Technology;The University of Texas at Austin,Pittsburgh;Cambridge;Austin,United States;United States;United States,4,"Feng, Yu;Martins, Ruben;Bastani, Osbert;Dillig, Isil",57026668300;36188587200;56786340300;22936636100,60013372;60027950;60022195;60013372,2018-06-11,11 June 2018,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,420-435,"We propose a new conflict-driven program synthesis technique that is capable of learning from past mistakes. Given a spurious program that violates the desired specification, our synthesis algorithm identifies the root cause of the conflict and learns new lemmas that can prevent similar mistakes in the future. Specifically, we introduce the notion of equivalence modulo conflict and show how this idea can be used to learn useful lemmas that allow the synthesizer to prune large parts of the search space. We have implemented a generalpurpose CDCL-style program synthesizer called Neo and evaluate it in two different application domains, namely data wrangling in R and functional programming over lists. Our experiments demonstrate the substantial benefits of conflict-driven learning and show that Neo outperforms two state-of-the-art synthesis tools, Morpheus and DeepCoder, that target these respective domains.",Automated reasoning | Conflict-driven learning | Program synthesis,60,1,repositoryam,Green,NSF,#1162076,National Science Foundation,PLDI Programming Languages
2-s2.0-85046945732,10.1145/3173574.3174089,,,Project Zanzibar: A portable and flexible tangible interaction platform,cp,Conference Paper,Villar N.,60021726,Microsoft Research,Redmond,United States,10,"Villar, Nicolas;Cletheroe, Daniel;Saul, Greg;Holz, Christian;Regan, Tim;Salandin, Oscar;Sra, Misha;Yeo, Hui Shyong;Field, William;Zhang, Haiyan",8419646300;57202050117;35792297200;56070704000;36091690800;57202050376;55479732200;55662129900;57202044463;57202047762,60021726;60021726;60021726;60021726;60021726;60021726;60021726;60021726;60021726;60021726,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"We present Project Zanzibar, a flexible mat that locates, uniquely identifies, and communicates with tangible objects placed on its surface, as well as senses a user's touch and hover gestures. We describe the underlying technical contributions: efficient and localised Near Field Communication (NFC) over a large surface area; object tracking combining NFC signal strength and capacitive footprint detection, and manufacturing techniques for a rollable device form-factor that enables portability, while providing a sizable interaction area when unrolled. In addition, we detail design patterns for tangibles of varying complexity and interactive capabilities, including the ability to sense orientation on the mat, harvest power, provide additional input and output, stack, or extend sensing outside the bounds of the mat. Capabilities and interaction modalities are illustrated with self-generated applications. Finally, we report on the experience of professional game developers building novel physical/digital experiences using the platform.",Capacitive sensing | Education | Flexible devices | Games | Near Field Communication | Play | Tangible user interfaces,55,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85059820563,10.1109/FOCS.2018.00062,,,Pseudorandom sets in Grassmann graph have near-perfect expansion,cp,Conference Paper,Khot S.,60005681;60003261,Tel Aviv University;Courant Institute of Mathematical Sciences,Tel Aviv-Yafo;New York,Israel;United States,3,"Khot, Subhash;Minzer, Dor;Safra, Muli",6701814147;57163731900;24462461200,60003261;60005681;60005681,2018-11-30,30 November 2018,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2018-October,,8555140,592-601,"We prove that pseudorandom sets in the Grassmann graph have near-perfect expansion. This completes the last missing piece of the proof of the 2-to-2-Games Conjecture (albeit with imperfect completeness). The Grassmann graph has induced subgraphs that are themselves isomorphic to Grassmann graphs of lower orders. A set of vertices is called pseudorandom if its density within all such subgraphs (of constant order) is at most slightly higher than its density in the entire graph. We prove that pseudorandom sets have almost no edges within them. Namely, their edge-expansion is very close to 1.",2-to-2 games | Grassmann graph | PCP | Unique games conjecture,65,0,,,NSF,CCF-1422159,National Science Foundation,FOCS Theory
2-s2.0-85055712271,10.24963/ijcai.2018/334,,,R-SVM+: Robust learning with privileged information,cp,Conference Paper,Li X.,60029306;60025709,Wuhan University;The University of Sydney,Wuhan;Sydney,China;Australia,6,"Li, Xue;Du, Bo;Xu, Chang;Zhang, Yipeng;Zhang, Lefei;Tao, Dacheng",58663674000;57217375214;55725662000;57204294758;48663190100;7102600334,60029306;60029306;60025709;60029306;60029306;60025709,2018-01-01,2018,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2018-July,,,2411-2417,"In practice, the circumstance that training and test data are clean is not always satisfied. The performance of existing methods in the learning using privileged information (LUPI) paradigm may be seriously challenged, due to the lack of clear strategies to address potential noises in the data. This paper proposes a novel Robust SVM+ (R-SVM+) algorithm based on a rigorous theoretical analysis. Under the SVM+ framework in the LUPI paradigm, we study the lower bound of perturbations of both example feature data and privileged feature data, which will mislead the model to make wrong decisions. By maximizing the lower bound, tolerance of the learned model over perturbations will be increased. Accordingly, a novel regularization function is introduced to upgrade a variant form of SVM+. The objective function of R-SVM+ is transformed into a quadratic programming problem, which can be efficiently optimized using off-the-shelf solvers. Experiments on real-world datasets demonstrate the necessity of studying robust SVM+ and the effectiveness of the proposed algorithm.",,14,1,publisherfree2read,Bronze,ARC,DE-180101438,Australian Research Council,IJCAI Artificial Intelligence
2-s2.0-85066881748,,,,REPT: Reverse debugging of failures in deployed software,cp,Conference Paper,Cui W.,60025778;60021726;60019647;60003892,"University of Michigan, Ann Arbor;Microsoft Research;Georgia Institute of Technology;Arizona State University",Ann Arbor;Redmond;Atlanta;Tempe,United States;United States;United States;United States,7,"Cui, Weidong;Ge, Xinyang;Kasikci, Baris;Niu, Ben;Sharma, Upamanyu;Wang, Ruoyu;Yun, Insu",56212216600;56278527900;57200611230;58423948600;57217224809;57191163591;58308940100,60021726;60021726;60025778;60021726;60025778;60003892;60019647,2007-01-01,2007,"Proceedings of the 13th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2018",,21100939569,,Conference Proceeding,,,,17-32,"Debugging software failures in deployed systems is important because they impact real users and customers. However, debugging such failures is notoriously hard in practice because developers have to rely on limited information such as memory dumps. The execution history is usually unavailable because high-fidelity program tracing is not affordable in deployed systems. In this paper, we present REPT, a practical system that enables reverse debugging of software failures in deployed systems. REPT reconstructs the execution history with high fidelity by combining online lightweight hardware tracing of a program's control flow with offline binary analysis that recovers its data flow. It is seemingly impossible to recover data values thousands of instructions before the failure due to information loss and concurrent execution. REPT tackles these challenges by constructing a partial execution order based on timestamps logged by hardware and iteratively performing forward and backward execution with error correction. We design and implement REPT, deploy it on Microsoft Windows, and integrate it into WinDbg. We evaluate REPT on 16 real-world bugs and show that it can recover data values accurately (92% on average) and efficiently (in less than 20 seconds) for these bugs. We also show that it enables effective reverse debugging for 14 bugs.",,52,0,,,,undefined,Intel Corporation,OSDI Operating Systems
2-s2.0-85056844033,10.1145/3242587.3242664,,,"Resi: A highly flexible, pressure-sensitive, imperceptible textile interface based on resistive yarns",cp,Conference Paper,Parzer P.,60021931;60000594,Johannes Kepler University Linz;University of Applied Sciences Upper Austria,Linz;Wels,Austria;Austria,11,"Parzer, Patrick;Perteneder, Florian;Probst, Kathrin;Rendl, Christian;Leong, Joanne;Schütz, Sarah;Vogl, Anita;Schwödiauer, Reinhard;Kaltenbrunner, Martin;Bauer, Siegfried;Haller, Michael",56427776600;35254182100;56096797600;35254220900;57143781600;57204730758;56938201000;6601919634;13106193000;13409302000;7102872675,60000594;60000594;60000594;60000594;60000594;60000594;60000594;60021931;60021931;60021931;60000594,2018-10-11,11 October 2018,UIST 2018 - Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology,,21100886509,,Conference Proceeding,,,,745-756,"We present RESi (Resistive tExtile Sensor Interfaces), a novel sensing approach enabling a new kind of yarn-based, resistive pressure sensing. The core of RESi builds on a newly designed yarn, which features conductive and resistive properties. We run a technical study to characterize the behaviour of the yarn and to determine the sensing principle. We demonstrate how the yarn can be used as a pressure sensor and discuss how specific issues, such as connecting the soft textile sensor with the rigid electronics can be solved. In addition, we present a platform-independent API that allows rapid prototyping. To show its versatility, we present applications developed with different textile manufacturing techniques, including hand sewing, machine sewing, and weaving. RESi is a novel technology, enabling textile pressure sensing to augment everyday objects with interactive capabilities.",Conductive Yarns | Interactive Textiles | Manufacturing | Textile Sensor | Wearable Computing,62,0,,,,undefined,,UIST User Interface
2-s2.0-85055717939,10.24963/ijcai.2018/7,,,Reasoning about consensus when opinions diffuse through majority dynamics,cp,Conference Paper,Auletta V.,60020261;60007061,Università della Calabria;Università degli Studi di Salerno,Rende;Salerno,Italy;Italy,3,"Auletta, Vincenzo;Ferraioli, Diodato;Greco, Gianluigi",6603957729;36650560300;7101640146,60007061;60007061;60020261,2018-01-01,2018,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2018-July,,,49-55,"Opinion diffusion is studied on social graphs where agents hold binary opinions and where social pressure leads them to conform to the opinion manifested by the majority of their neighbors. Within this setting, questions related to whether a minority/majority can spread the opinion it supports to all the other agents are considered. It is shown that, no matter of the underlying graph, there is always a group formed by a half of the agents that can annihilate the opposite opinion. Instead, the influence power of minorities depends on certain features of the given graph, which are NP-hard to be identified. Deciding whether the two opinions can coexist in some stable configuration is NP-hard, too.",,44,1,publisherfree2read,Bronze,INdAM,undefined,"Istituto Nazionale di Alta Matematica ""Francesco Severi""",IJCAI Artificial Intelligence
2-s2.0-85058030113,10.1145/3269206.3271673,,,Relevance estimation with multiple information sources on search engine result pages,cp,Conference Paper,Zhang J.,60143652;60104026,Department of Computer Science;Beijing National Research Center for Information Science and Technology,San Antonio;Beijing,United States;China,4,"Zhang, Junqi;Liu, Yiqun;Ma, Shaoping;Tian, Qi",57204947068;35327597400;7403725163;7102891959,60104026;60104026;60104026;60143652,2018-10-17,17 October 2018,"International Conference on Information and Knowledge Management, Proceedings",,55826,,Conference Proceeding,,,,627-636,"Relevance estimation is among the most important tasks in the ranking of search results. Current relevance estimation methodologies mainly concentrate on text matching between the query and Web documents, link analysis and user behavior models. However, users judge the relevance of search results directly from Search Engine Result Pages (SERPs), which provide valuable signals for reranking. Morden search engines aggregate heterogeneous information items (such as images, news, and hyperlinks) to a single ranking list on SERPs. The aggregated search results have different visual patterns, textual semantics and presentation structures, and a better strategy should rely on all these information sources to improve ranking performance. In this paper, we propose a novel framework named Joint Relevance Estimation model (JRE), which learns the visual patterns from screenshots of search results, explores the presentation structures from HTML source codes and also adopts the semantic information of textual contents. To evaluate the performance of the proposed model, we construct a large scale practical Search Result Relevance (SRR) dataset which consists of multiple information sources and 4-grade relevance scores of over 60, 000 search results. Experimental results show that the proposed JRE model achieves better performance than state-of-the-art ranking solutions as well as the original ranking of commercial search engines.",Information Retrieval | Multimodal | Ranking | Relevance,13,0,,,NSFC,2015CB358700,Gulf Research Program,CIKM Knowledge Management
2-s2.0-85046948268,10.1145/3173574.3173922,,,Semi-automated coding for Qualitative research: A user-centered inquiry and initial prototypes,cp,Conference Paper,Marathe M.,60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,2,"Marathe, Megh;Toyama, Kentaro",56469061800;56902256500,60025778;60025778,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"Qualitative researchers perform an important and painstaking data annotation process known as coding. However, much of the process can be tedious and repetitive, becoming prohibitive for large datasets. Could coding be partially automated, and should it be? To answer this question, we interviewed researchers and observed them code interview transcripts. We found that across disciplines, researchers follow several coding practices well-suited to automation. Further, researchers desire automation after having developed a codebook and coded a subset of data, particularly in extending their coding to unseen data. Researchers also require any assistive tool to be transparent about its recommendations. Based on our findings, we built prototypes to partially automate coding using simple natural language processing techniques. Our top-performing system generates coding that matches human coders on inter-rater reliability measures. We discuss implications for interface and algorithm design, meta-issues around automating qualitative research, and suggestions for future work.",Natural language processing | Qualitative coding | Qualitative data analysis | Qualitative research | User-centered design,32,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85055689610,10.24963/ijcai.2018/618,,,Sentigan: Generating sentimental texts via mixture adversarial networks,cp,Conference Paper,Wang K.,60124576,"Key Laboratory of Computational Linguistics, Ministry of Education, Peking University",Beijing,China,2,"Wang, Ke;Wan, Xiaojun",57203393028;7202533498,60124576;60124576,2018-01-01,2018,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2018-July,,,4446-4452,"Generating texts of different sentiment labels is getting more and more attention in the area of natural language generation. Recently, Generative Adversarial Net (GAN) has shown promising results in text generation. However, the texts generated by GAN usually suffer from the problems of poor quality, lack of diversity and mode collapse. In this paper, we propose a novel framework - SentiGAN, which has multiple generators and one multi-class discriminator, to address the above problems. In our framework, multiple generators are trained simultaneously, aiming at generating texts of different sentiment labels without supervision. We propose a penalty based objective in the generators to force each of them to generate diversified examples of a specific sentiment label. Moreover, the use of multiple generators and one multi-class discriminator can make each generator focus on generating its own examples of a specific sentiment label accurately. Experimental results on four datasets demonstrate that our model consistently outperforms several state-of-the-art text generation methods in the sentiment accuracy and quality of generated texts.",,121,1,publisherfree2read,Bronze,NSFC,61331011,National Natural Science Foundation of China,IJCAI Artificial Intelligence
2-s2.0-85051540077,10.1145/3209978.3210014,,,Should i follow the crowd?: A probabilistic analysis of the effectiveness of popularity in recommender systems,cp,Conference Paper,Cãamares R.,60026796,Universidad Autónoma de Madrid,Madrid,Spain,2,"Cãamares, Rocío;Castells, Pablo",56415041800;8928406700,60026796;60026796,2018-06-27,27 June 2018,"41st International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2018",,21100872704,,Conference Proceeding,,,,415-424,"The use of IR methodology in the evaluation of recommender systems has become common practice in recent years. IR metrics have been found however to be strongly biased towards rewarding algorithms that recommend popular items ""the same bias that state of the art recommendation algorithms display. Recent research has confirmed and measured such biases, and proposed methods to avoid them. The fundamental question remains open though whether popularity is really a bias we should avoid or not; whether it could be a useful and reliable signal in recommendation, or it may be unfairly rewarded by the experimental biases. We address this question at a formal level by identifying and modeling the conditions that can determine the answer, in terms of dependencies between key random variables, involving item rating, discovery and relevance. We find conditions that guarantee popularity to be effective or quite the opposite, and for the measured metric values to reflect a true effectiveness, or qualitatively deviate from it. We exemplify and confirm the theoretical findings with empirical results. We build a crowdsourced dataset devoid of the usual biases displayed by common publicly available data, in which we illustrate contradictions between the accuracy that would be measured in a common biased offline experimental setting, and the actual accuracy that can be measured with unbiased observations.",Accuracy | Bias | Collaborative filtering | Evaluation | Non-random missing data | Popularity | Recommender systems,92,0,,,,undefined,,SIGIR Information Retrieval
2-s2.0-85056854412,10.1145/3241539.3241549,,,SkyCore: Moving core to the edge for untethered and reliable UAV-based LTE networks,cp,Conference Paper,Moradi M.,60025778;60018008,"University of Michigan, Ann Arbor;NEC Laboratories America, Inc.",Ann Arbor;Princeton,United States;United States,5,"Moradi, Mehrdad;Sundaresan, Karthikeyan;Chai, Eugene;Rangarajan, Sampath;Mao, Z. Morley",56354816500;57204371204;24280556300;7005139319;15623490000,60025778;60018008;60018008;60018008;60025778,2018-10-15,15 October 2018,"Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM",,21100886505,,Conference Proceeding,,,,35-49,"The advances in unmanned aerial vehicle (UAV) technology have empowered mobile operators to deploy LTE base stations (BSs) on UAVs, and provide on-demand, adaptive connectivity to hotspot venues as well as emergency scenarios. However, today's evolved packet core (EPC) that orchestrates the LTE RAN faces fundamental limitations in catering to such a challenging, wireless and mobile UAV environment, particularly in the presence of multiple BSs (UAVs). In this work, we argue for and propose an alternate, radical edge EPC design, called SkyCore that pushes the EPC functionality to the extreme edge of the core network - collapses the EPC into a single, light-weight, self-contained entity that is co-located with each of the UAV BS. SkyCore incorporates elements that are designed to address the unique challenges facing such a distributed design in the UAV environment, namely the resource-constraints of UAV platforms, and the distributed management of pronounced UAV and UE mobility. We build and deploy a fully functional version of SkyCore on a two-UAV LTE network and showcase its (i) ability to interoperate with commercial LTE BSs as well as smartphones, (ii) support for both hotspot and standalone multi-UAV deployments, and (iii) superior control and data plane performance compared to other EPC variants in this environment.",5G | Drone | Edge EPC | EPC | LTE | Mobility Management | Resource-Challenged | SDN | UAV | UAV-based LTE networks,57,0,,,,undefined,,MOBICOM Mobile
2-s2.0-85133628257,10.1145/3180155.3180178,,,Spatio-Temporal Context Reduction: A Pointer-Analysis-Based Static Approach for Detecting Use-After-Free Vulnerabilities,cp,Conference Paper,Yan H.,60029470;60028333;60023932,Commonwealth Scientific and Industrial Research Organisation;UNSW Sydney;University of Technology Sydney,Canberra;Sydney;Sydney,Australia;Australia;Australia,4,"Yan, Hua;Sui, Yulei;Chen, Shiping;Xue, Jingling",57189906695;54788439800;35241832100;7202881461,60028333;60023932;60029470;60028333,2018-01-01,2018,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2018-January,,,327-337,"Zero-day Use-After-Free (UAF) vulnerabilities are increasingly popular and highly dangerous, but few mitigations exist. We introduce a new pointer-analysis-based static analysis, CRed, for finding UAF bugs in multi-MLOC C source code efficiently and effectively. CRed achieves this by making three advances: (i) a spatio-temporal context reduction technique for scaling down soundly and precisely the exponential number of contexts that would otherwise be considered at a pair of free and use sites, (ii) a multi-stage analysis for filtering out false alarms efficiently, and (iii) a path-sensitive demand-driven approach for finding the points-to information required. We have implemented CRed in LLVM-3.8.0 and compared it with four different state-of-the-art static tools: CBMC (model checking), Clang (abstract interpretation), Coccinelle (pattern matching), and Supa (pointer analysis) using all the C test cases in Juliet Test Suite (JTS) and 10 open-source C applications. For the ground-truth validated with JTS, CRed detects all the 138 known UAF bugs as CBMC and Supa do while Clang and Coccinelle miss some bugs, with no false alarms from any tool. For practicality validated with the 10 applications (totaling 3+ MLOC), CRed reports 132 warnings including 85 bugs in 7.6 hours while the existing tools are either unscalable by terminating within 3 days only for one application (CBMC) or impractical by finding virtually no bugs (Clang and Coccinelle) or issuing an excessive number of false alarms (Supa).",bug detection | program analysis | Use-after-free,58,0,,,ARC,DE170101081,Australian Research Council,ICSE Software Engineering
2-s2.0-85061076090,10.1145/3180155.3180250,,,Static Automated Program Repair for Heap Properties,cp,Conference Paper,Van Tonder R.,60136640,School of Computer Science,Pittsburgh,United States,2,"Van Tonder, Rijnard;Le Goues, Claire",57190401014;35113323900,60136640;60136640,2018-01-01,2018,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2018-January,,,151-162,"Static analysis tools have demonstrated effectiveness at finding bugs in real world code. Such tools are increasingly widely adopted to improve software quality in practice. Automated Program Repair (APR) has the potential to further cut down on the cost of improving software quality. However, there is a disconnect between these effective bug-finding tools and APR. Recent advances in APR rely on test cases, making them inapplicable to newly discovered bugs or bugs difficult to test for deterministically (like memory leaks). Additionally, the quality of patches generated to satisfy a test suite is a key challenge. We address these challenges by adapting advances in practical static analysis and verification techniques to enable a new technique that finds and then accurately fixes real bugs without test cases. We present a new automated program repair technique using Separation Logic. At a high-level, our technique reasons over semantic effects of existing program fragments to fix faults related to general pointer safety properties: resource leaks, memory leaks, and null dereferences. The procedure automatically translates identified fragments into source-level patches, and verifies patch correctness with respect to reported faults. In this work we conduct the largest study of automatically fixing undiscovered bugs in realworld code to date. We demonstrate our approach by correctly fixing 55 bugs, including 11 previously undiscovered bugs, in 11 real-world projects.",Automated Program Repair | Separation Logic,56,0,,,NSF,CCF-1563797,National Science Foundation,ICSE Software Engineering
2-s2.0-85046969099,10.1145/3173574.3173901,,,Streets for people: Engaging children In placemaking through a socio-technical process,cp,Conference Paper,Peacock S.,60006222,Newcastle University,Newcastle,United Kingdom,3,"Peacock, Sean;Anderson, Robert;Crivellaro, Clara",57202047209;56175439500;56156809500,60006222;60006222;60006222,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"In this paper, we present a socio-technical process designed to engage children in an ongoing urban design project-Streets for People-in Newcastle, UK. We translated urban design proposals developed by residents and the local authority to enable children to contribute ideas to the project. Our process comprised three stages: situated explorations and evidence gathering through digitally supported neighbourhood walks; issue mapping and peer-to-peer discussions using an online engagement platform; and faceto-face dialogue between children, residents, and the local authority through a 'Town Hall' event. We report insights gained through our engagement and show how our activities facilitated issue advocacy and the development of children's capacities, but also surfaced tensions around the agency of children in political processes. We reflect on the challenges of working in this space, and discuss wider implications for technology design and ethical questions that 'scaling up' such work might pose.",Children | Community engagement | Digital civics | Urban design | Urban planning,26,1,publisherfree2read,Bronze,EPSRC,EP/M023001/1,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-85048801333,10.1145/3183713.3196931,,,SuRF: Practical range query filtering with fast succinct tries,cp,Conference Paper,Zhang H.,60107956;60033010;60027950;60019722,Hewlett Packard Enterprise;Intel Corporation;Carnegie Mellon University;Technische Universität München,Palo Alto;Santa Clara;Pittsburgh;Munich,United States;United States;United States;Germany,7,"Zhang, Huanchen;Lim, Hyeontaek;Leis, Viktor;Andersen, David G.;Kaminsky, Michael;Keeton, Kimberly;Pavlo, Andrew",57190390737;36639824000;55319976000;57210522272;35233511800;7003460025;35190948800,60027950;60027950;60019722;60027950;60033010;60107956;60027950,2018-05-27,27 May 2018,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,323-336,"We present the Succinct Range Filter (SuRF), a fast and compact data structure for approximate membership tests. Unlike traditional Bloom filters, SuRF supports both single-key lookups and common range queries: open-range queries, closed-range queries, and range counts. SuRF is based on a newdata structure called the Fast Succinct Trie (FST) that matches the point and range query performance of state-of-the-art order-preserving indexes, while consuming only 10 bits per trie node. The false positive rates in SuRF for both point and range queries are tunable to satisfy different application needs. We evaluate SuRF in RocksDB as a replacement for its Bloom filters to reduce I/O by filtering requests before they access on-disk data structures. Our experiments on a 100 GB dataset showthat replacing RocksDB's Bloom filters with SuRFs speeds up open-seek (without upper-bound) and closed-seek (with upper-bound) queries by up to 1.5× and 5× with a modest cost on the worst-case (all-missing) point query throughput due to slightly higher false positive rate.",,101,1,publisherfree2read,Bronze,,undefined,,SIGMOD Databases
2-s2.0-85062829745,10.1109/CVPR.2018.00391,,,Taskonomy: Disentangling Task Transfer Learning,cp,Conference Paper,Zamir A.R.,60025038;60012708,"University of California, Berkeley;Stanford University",Berkeley;Stanford,United States;United States,6,"Zamir, Amir R.;Sax, Alexander;Shen, William;Guibas, Leonidas;Malik, Jitendra;Savarese, Silvio",56496616900;57207763413;57208007751;35451872900;7101991704;6603319910,60012708-60025038;60012708;60012708;60012708;60025038;60012708,2018-12-14,14 December 2018,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,,,8578489,3712-3722,"Do visual tasks have a relationship, or are they unrelated? For instance, could having surface normals simplify estimating the depth of an image? Intuition answers these questions positively, implying existence of a structure among visual tasks. Knowing this structure has notable values; it is the concept underlying transfer learning and provides a principled way for identifying redundancies across tasks, e.g., to seamlessly reuse supervision among related tasks or solve many tasks in one system without piling up the complexity. We proposes a fully computational approach for modeling the structure of space of visual tasks. This is done via finding (first and higher-order) transfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D, and semantic tasks in a latent space. The product is a computational taxonomic map for task transfer learning. We study the consequences of this structure, e.g. nontrivial emerged relationships, and exploit them to reduce the demand for labeled data. We provide a set of tools for computing and probing this taxonomical structure including a solver users can employ to find supervision policies for their use cases.",,678,0,repositoryam,Green,NSF,1521608,National Science Foundation,CVPR Computer Vision
2-s2.0-85058321067,10.1145/3236024.3236027,,,The impact of Regular Expression Denial of Service (ReDoS) in practice: An empirical study at the ecosystem scale,cp,Conference Paper,Davis J.C.,60027090,Virginia Polytechnic Institute and State University,Blacksburg,United States,4,"Davis, James C.;Coghlan, Christy A.;Servant, Francisco;Lee, Dongyoon",57194212372;57205350546;36461842200;55697057900,60027090;60027090;60027090;60027090,2018-10-26,26 October 2018,ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21100890553,,Conference Proceeding,,,,246-256,"Regular expressions (regexes) are a popular and powerful means of automatically manipulating text. Regexes are also an understudied denial of service vector (ReDoS). If a regex has super-linear worst-case complexity, an attacker may be able to trigger this complexity, exhausting the victim's CPU resources and causing denial of service. Existing research has shown how to detect these superlinear regexes, and practitioners have identified super-linear regex anti-pattern heuristics that may lead to such complexity. In this paper, we empirically study three major aspects of ReDoS that have hitherto been unexplored: The incidence of super-linear regexes in practice, how they can be prevented, and how they can be repaired. In the ecosystems of two of the most popular programming languages D JavaScript and Python S we detected thousands of super-linear regexes affecting over 10,000 modules across diverse application domains. We also found that the conventional wisdom for super-linear regex anti-patterns has few false negatives but many false positives; these anti-patterns appear to be necessary, but not sufficient, signals of super-linear behavior. Finally, we found that when faced with a super-linear regex, developers favor revising it over truncating input or developing a custom parser, regardless of whether they had been shown examples of all three fix strategies. These findings motivate further research into ReDoS, since many modules are vulnerable to it and existing mechanisms to avoid it are insufficient. We believe that ReDoS vulnerabilities are a larger threat in practice than might have been guessed.",catastrophic backtracking | empirical software engineering | mining software repositories | ReDoS | Regular expressions,67,1,publisherfree2read,Bronze,NSF,1814430,National Science Foundation,FSE Software Engineering
2-s2.0-85049589523,10.1145/3192366.3192373,,,"The semantics of transactions and weak memory in x86, power, ARM, and C++",cp,Conference Paper,Chong N.,60099299;60015150,Arm Limited;Imperial College London,Cambridge;London,United Kingdom;United Kingdom,3,"Chong, Nathan;Sorensen, Tyler;Wickerson, John",55498335400;55786177600;36022891600,60099299;60015150;60015150,2018-06-11,11 June 2018,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,211-225,"Weak memory models provide a complex, system-centric semantics for concurrent programs, while transactional memory (TM) provides a simpler, programmer-centric semantics. Both have been studied in detail, but their combined semantics is not well understood. This is problematic because such widely-used architectures and languages as x86, Power, and C++ all support TM, and all have weak memory models. Our work aims to clarify the interplay between weak memory and TM by extending existing axiomatic weak memory models (x86, Power, ARMv8, and C++) with new rules for TM. Our formal models are backed by automated tooling that enables (1) the synthesis of tests for validating our models against existing implementations and (2) the model-checking of TM-related transformations, such as lock elision and compiling C++ transactions to hardware. A key finding is that a proposed TM extension to ARMv8 currently being considered within ARM Research is incompatible with lock elision without sacrificing portability or performance.",Program synthesis | Shared memory concurrency | Transactional memory | Weak memory,16,1,repositoryam,Green,EPSRC,EP/K034448/1,Engineering and Physical Sciences Research Council,PLDI Programming Languages
2-s2.0-85068323900,10.1007/s00778-019-00548-x,,,The ubiquity of large graphs and surprising challenges of graph processing: extended survey,cp,Conference Paper,Sahu S.,60014171,University of Waterloo,Waterloo,Canada,5,"Sahu, Siddhartha;Mhedhbi, Amine;Salihoglu, Semih;Lin, Jimmy;Özsu, M. Tamer",57194608786;57209637249;24345289400;56824507200;57220402181,60014171;60014171;60014171;60014171;60014171,2020-05-01,1 May 2020,VLDB Journal,10668888,13646,0949877X,Journal,29,2-3,,595-618,"Graph processing is becoming increasingly prevalent across many application domains. In spite of this prevalence, there is little research about how graphs are actually used in practice. We performed an extensive study that consisted of an online survey of 89 users, a review of the mailing lists, source repositories, and white papers of a large suite of graph software products, and in-person interviews with 6 users and 2 developers of these products. Our online survey aimed at understanding: (i) the types of graphs users have; (ii) the graph computations users run; (iii) the types of graph software users use; and (iv) the major challenges users face when processing their graphs. We describe the participants’ responses to our questions highlighting common patterns and challenges. Based on our interviews and survey of the rest of our sources, we were able to answer some new questions that were raised by participants’ responses to our online survey and understand the specific applications that use graph data and software. Our study revealed surprising facts about graph processing in practice. In particular, real-world graphs represent a very diverse range of entities and are often very large, scalability and visualization are undeniably the most pressing challenges faced by participants, and data integration, recommendations, and fraud detection are very popular applications supported by existing graph software. We hope these findings can guide future research.",Graph databases | Graph processing | RDF systems | User survey,56,0,repositoryam,Green,,undefined,Luonnontieteiden ja Tekniikan Tutkimuksen Toimikunta,VLDB Databases
2-s2.0-85056528879,10.1145/3180155.3180177,,,Towards Optimal Concolic Testing,cp,Conference Paper,Wang X.,60017161;60003970;114698766;106773056,National University of Singapore;Zhejiang University;Univ of National Defense Technology;Singapore University of Techniology and Design Singapore,Singapore City;Hangzhou;;Singapore City,Singapore;China;China;Singapore,6,"Wang, Xinyu;Sun, Jun;Chen, Zhenbang;Zhang, Peixin;Wang, Jingyi;Lin, Yun",7501858663;56153273100;8367155000;57211025760;57191964922;56683209800,60003970;106773056;114698766;60003970;106773056;60017161,2018-01-01,2018,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,291-302,"Concolic testing integrates concrete execution (e.g., random testing) and symbolic execution for test case generation. It is shown to be more cost-effective than random testing or symbolic execution sometimes. A concolic testing strategy is a function which decides when to apply random testing or symbolic execution, and if it is the latter case, which program path to symbolically execute. Many heuristics-based strategies have been proposed. It is still an open problem what is the optimal concolic testing strategy. In this work, we make two contributions towards solving this problem. First, we show the optimal strategy can be defined based on the probability of program paths and the cost of constraint solving. The problem of identifying the optimal strategy is then reduced to a model checking problem of Markov Decision Processes with Costs. Secondly, in view of the complexity in identifying the optimal strategy, we design a greedy algorithm for approximating the optimal strategy. We conduct two sets of experiments. One is based on randomly generated models and the other is based on a set of C programs. The results show that existing heuristics have much room to improve and our greedy algorithm often outperforms existing heuristics.",,54,0,repositoryam,Green,MOE,61472440,Ministry of Education - Singapore,ICSE Software Engineering
2-s2.0-85049401953,10.1145/3180155.3180207,,,Traceability in the wild: Automatically augmenting incomplete trace links,cp,Conference Paper,Rath M.,60030040;60021508;60002494,Technischen Universität Ilmenau;University of Notre Dame;Université McGill,Ilmenau;Notre Dame;Montreal,Germany;United States;Canada,5,"Rath, Michael;Rendall, Jacob;Guo, Jin L.C.;Cleland-Huang, Jane;Mäder, Patrick",57193736812;57195486803;57203289380;6506741859;35586964300,60030040;60021508;60002494;60021508;60030040,2018-05-27,27 May 2018,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,834-845,"Software and systems traceability is widely accepted as an essential element for supporting many software development tasks. Today's version control systems provide inbuilt features that allow developers to tag each commit with one or more issue ID, thereby providing the building blocks from which project-wide traceability can be established between feature requests, bug fixes, commits, source code, and specific developers. However, our analysis of six open source projects showed that on average only 60% of the commits were linked to specific issues. Without these fundamental links the entire set of project-wide links will be incomplete, and therefore not trustworthy. In this paper we address the fundamental problem of missing links between commits and issues. Our approach leverages a combination of process and text-related features characterizing issues and code changes to train a classifier to identify missing issue tags in commit messages, thereby generating the missing links. We conducted a series of experiments to evaluate our approach against six open source projects and showed that it was able to effectively recommend links for tagging issues at an average of 96% recall and 33% precision. In a related task for augmenting a set of existing trace links, the classifier returned precision at levels greater than 89% in all projects and recall of 50%.",Link recovery | Machine learning | Open source | Traceability,76,0,,,CISE,1319680,Directorate for Computer and Information Science and Engineering,ICSE Software Engineering
2-s2.0-85056168392,10.1109/INFOCOM.2018.8486401,,,Understanding Ethereum via Graph Analysis,cp,Conference Paper,Chen T.,60008928;60007155;60005465;60000521,The Hong Kong Polytechnic University;Guangdong University of Technology;University of Electronic Science and Technology of China;Wilfrid Laurier University,Hong Kong;Guangzhou;Chengdu;Waterloo,Hong Kong;China;China;Canada,8,"Chen, Ting;Zhu, Yuxiao;Li, Zihao;Chen, Jiachi;Li, Xiaoqi;Luo, Xiapu;Lin, Xiaodong;Zhange, Xiaosong",56159439700;22982527700;57199508044;57184505400;57194043648;23005241300;17435253300;57204557550,60005465;60007155;60005465;60008928;60008928;60008928;60000521;60007155,2018-10-08,8 October 2018,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2018-April,,8486401,1484-1492,"Being the largest blockchain with the capability of running smart contracts, Ethereum has attracted wide attention and its market capitalization has reached 20 billion USD. Ethereum not only supports its cryptocurrency named Ether but also provides a decentralized platform to execute smart contracts in the Ethereum virtual machine. Although Ether's price is approaching 200 USD and nearly 600K smart contracts have been deployed to Ethereum, little is known about the characteristics of its users, smart contracts, and the relationships among them. To fill in the gap, in this paper, we conduct the first systematic study on Ethereum by leveraging graph analysis to characterize three major activities on Ethereum, namely money transfer, smart contract creation, and smart contract invocation. We design a new approach to collect all transaction data, construct three graphs from the data to characterize major activities, and discover new observations and insights from these graphs. Moreover, we propose new approaches based on cross-graph analysis to address two security issues in Ethereum. The evaluation through real cases demonstrates the effectiveness of our new approaches.",,159,0,,,,undefined,,INFOCOM Networking
2-s2.0-85046968214,10.1145/3173574.3174214,,,Voice interfaces in everyday life,cp,Conference Paper,Porcheron M.,60015138,University of Nottingham,Nottingham,United Kingdom,4,"Porcheron, Martin;Fischer, Joel E.;Reeves, Stuart;Sharples, Sarah",56157070100;36095705300;7102635630;10140073200,60015138;60015138;60015138;60015138,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"Voice User Interfaces (VUIs) are becoming ubiquitously available, being embedded both into everyday mobility via smartphones, and into the life of the home via 'assistant' devices. Yet, exactly how users of such devices practically thread that use into their everyday social interactions remains underexplored. By collecting and studying audio data from month-long deployments of the Amazon Echo in participants' homes-informed by ethnomethodology and conversation analysis-our study documents the methodical practices of VUI users, and how that use is accomplished in the complex social life of the home. Data we present shows how the device is made accountable to and embedded into conversational settings like family dinners where various simultaneous activities are being achieved. We discuss how the VUI is finely coordinated with the sequential organisation of talk. Finally, we locate implications for the accountability of VUI interaction, request and response design, and raise conceptual challenges to the notion of designing 'conversational' interfaces.",Amazon Echo | Collocated interaction | Conversation analysis | Conversational agent | Conversational user interface | Ethnomethodology | Intelligent personal assistants,426,0,repositoryam,Green,EPSRC,EP/G037574/1,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-85046952448,10.1145/3173574.3173847,,,Wall++: Room-scale interactive and context-aware sensing,cp,Conference Paper,Zhang Y.,60032776;60027950,The Walt Disney Company;Carnegie Mellon University,Burbank;Pittsburgh,United States;United States,5,"Zhang, Yang;Yang, Chouchang;Hudson, Scott E.;Harrison, Chris;Sample, Alanson",57144720100;58737479700;7201375469;35792227900;9235634800,60032776-60027950;60032776;60032776-60027950;60032776-60027950;60032776,2018-04-20,20 April 2018,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,2018-April,,,,"Human environments are typified by walls - homes, offices, schools, museums, hospitals and pretty much every indoor context one can imagine has walls. In many cases, they make up a majority of readily accessible indoor surface area, and yet they are static - their primary function is to be a wall, separating spaces and hiding infrastructure. We present Wall++, a low-cost sensing approach that allows walls to become a smart infrastructure. Instead of merely separating spaces, walls can now enhance rooms with sensing and interactivity. Our wall treatment and sensing hardware can track users' touch and gestures, as well as estimate body pose if they are close. By capturing airborne electromagnetic noise, we can also detect what appliances are active and where they are located. Through a series of evaluations, we demonstrate Wall++ can enable robust room-scale interactive and context-aware applications.","Em sensing, context aware | Gestures | Indoor localization | Internet of things | Pose estimation | Smart environments | Touch sensing | User identification",73,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85055687577,10.24963/ijcai.2018/55,,,What game are we playing? End-to-end learning in normal and extensive form games,cp,Conference Paper,Ling C.K.,60136640,School of Computer Science,Pittsburgh,United States,3,"Ling, Chun Kai;Fang, Fei;Zico Kolter, J.",57192668941;55335042200;36873773800,60136640;60136640;60136640,2018-01-01,2018,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2018-July,,,396-402,"Although recent work in AI has made great progress in solving large, zero-sum, extensive-form games, the underlying assumption in most past work is that the parameters of the game itself are known to the agents. This paper deals with the relatively under-explored but equally important “inverse” setting, where the parameters of the underlying game are not known to all agents, but must be learned through observations. We propose a differentiable, end-to-end learning framework for addressing this task. In particular, we consider a regularized version of the game, equivalent to a particular form of quantal response equilibrium, and develop 1) a primal-dual Newton method for finding such equilibrium points in both normal and extensive form games; and 2) a backpropagation method that lets us analytically compute gradients of all relevant game parameters through the solution itself. This ultimately lets us learn the game by training in an end-to-end fashion, effectively by integrating a “differentiable game solver” into the loop of larger deep network architectures. We demonstrate the effectiveness of the learning method in several settings including poker and security game tasks.",,41,1,repositoryam,Green,,undefined,,IJCAI Artificial Intelligence
2-s2.0-85056191203,10.1109/INFOCOM.2018.8486207,,,WiFED: WiFi Friendly Energy Delivery with Distributed Beamforming,cp,Conference Paper,Mohanti S.,60204070;60141202;60022002,Milli Savunma Üniversitesi;College of Engineering;İstanbul Teknik Üniversitesi,Istanbul;Boston;Istanbul,Turkey;United States;Turkey,5,"Mohanti, Subhramoy;Bozkaya, Elif;Yousof Naderi, M.;Canberk, Berk;Chowdhury, Kaushik",57192655129;56439927500;57192654145;35084950600;15019097300,60141202;60022002-60204070;60141202;60022002;60141202,2018-10-08,8 October 2018,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2018-April,,8486207,926-934,"Wireless RF energy transfer for indoor sensors is an emerging paradigm that ensures continuous operation without battery limitations. However, high power radiation within the ISM band interferes with the packet reception for existing WiFi devices. The paper proposes the first effort in merging the RF energy transfer functions within a standards compliant 802.11 protocol to realize practical and WiFi-friendly Energy Delivery (WiFED). The WiFED architecture is composed of a centralized controller that coordinates the actions of multiple distributed energy transmitters (ETs), and a number of deployed sensors that periodically request energy from the ETs. The paper first describes the specific 802.11 supported protocol features that can be exploited by sensors to request energy and for the ETs to participate in the energy delivery process. Second, it devises a controller-driven bipartite matching-based algorithmic solution that assigns the appropriate number of ETs to energy requesting sensors for an efficient energy transfer process. The proposed in-band and protocol supported coexistence in WiFED is validated via simulations and partly in a software defined radio testbed, showing 15% improvement in network lifetime and 31% reduction in the charging delay compared to the classical nearest distance-based charging schemes that do not anticipate future energy needs of the sensors and are not designed to co-exist with wifi systems.",,5,0,,,,IIP-1701041,,INFOCOM Networking
2-s2.0-85067626409,10.1145/3290605.3300459,,,“I feel it is my responsibility to stream” Streaming and Engaging with Intangible Cultural Heritage through Livestreaming,cp,Conference Paper,Lu Z.,60016849;121213241,University of Toronto;MishMashMakers,Toronto;Toronto,Canada;Canada,4,"Lu, Zhicong;Annett, Michelle;Fan, Mingming;Wigdor, Daniel",57194274057;24337421400;26424940800;6507569914,60016849;121213241;60016849;60016849,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"Globalization has led to the destruction of many cultural practices, expressions, and knowledge found within local communities. These practices, defined by UNESCO as Intangible Cultural Heritage (ICH), have been identified, promoted, and safeguarded by nations, academia, organizations and local communities to varying degrees. Despite such efforts, many practices are still in danger of being lost or forgotten forever. With the increased popularity of livestreaming in China, some streamers have begun to use livestreaming to showcase and promote ICH activities. To better understand the practices, opportunities, and challenges inherent in sharing and safeguarding ICH through livestreaming, we interviewed 10 streamers and 8 viewers from China. Through our qualitative investigation, we found that ICH streamers had altruistic motivations and engaged with viewers using multiple modalities beyond livestreams. We also found that livestreaming encouraged real-time interaction and sociality, while non-live curated videos attracted attention from a broader audience and assisted in the archiving of knowledge.",Cultural preservation | Intangible cultural heritage | Livestreaming | Social media | User engagement,86,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85067621729,10.1145/3290605.3300232,,,“They don’t leave us alone anywhere we go”: Gender and digital abuse in South Asia,cp,Conference Paper,Sambasivan N.,60105219;60028220;60024551;60015941;60006191,Information Technology University;North South University;Universidad de Colima;University of Kentucky;Google LLC,Lahore;Dhaka;Colima;Lexington;Mountain View,Pakistan;Bangladesh;Mexico;United States;United States,10,"Sambasivan, Nithya;Matthews, Tara;Batool, Amna;Thomas, Kurt;Ahmed, Nova;Gaytán-Lugo, Laura Sanely;Nemer, David;Bursztein, Elie;Churchill, Elizabeth;Consolvo, Sunny",22836402400;56212800500;57188877561;36245642500;9735336000;55568852800;57202369001;23466423300;7003488324;10140027800,60006191;;60105219;60006191;60028220;60024551;60015941;60006191;60006191;60006191,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"South Asia faces one of the largest gender gaps online globally, and online safety is one of the main barriers to gender-equitable Internet access [GSMA, 2015]. To better understand the gendered risks and coping practices online in South Asia, we present a qualitative study of the online abuse experiences and coping practices of 199 people who identified as women and 6 NGO staff from India, Pakistan, and Bangladesh, using a feminist analysis. We found that a majority of our participants regularly contended with online abuse, experiencing three major abuse types: cyberstalking, impersonation, and personal content leakages. Consequences of abuse included emotional harm, reputation damage, and physical and sexual violence. Participants coped through informal channels rather than through technological protections or law enforcement. Altogether, our findings point to opportunities for designs, policies, and algorithms to improve women’s safety online in South Asia.",Bangladesh | Coping | Impacts | Impersonation | India | Leakages | Online abuse | Pakistan | Privacy | Stalking | Women,73,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85067594436,10.1145/3290605.3300519,,,“Think secure from the beginning”: A survey with software developers,cp,Conference Paper,Assal H.,60017592,Carleton University,Ottawa,Canada,2,"Assal, Hala;Chiasson, Sonia",57144303600;9039336600,60017592;60017592,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"Vulnerabilities persist despite existing software security initiatives and best practices. This paper focuses on the human factors of software security, including human behaviour and motivation. We conducted an online survey to explore the interplay between developers and software security processes, e.g., we looked into how developers influence and are influenced by these processes. Our data included responses from 123 software developers currently employed in North America who work on various types of software applications. Whereas developers are often held responsible for security vulnerabilities, our analysis shows that the real issues frequently stem from a lack of organizational or process support to handle security throughout development tasks. Our participants are self-motivated towards software security, and the majority did not dismiss it but identified obstacles to achieving secure code. Our work highlights the need to look beyond the individual, and take a holistic approach to investigate organizational issues influencing software security.",HCI for development | Secure programming | Security | Survey,85,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85071955221,10.1145/3338906.3338965,,,A framework for writing trigger-action todo comments in executable format,cp,Conference Paper,Nie P.,60013372,The University of Texas at Austin,Austin,United States,6,"Nie, Pengyu;Rai, Rishabh;Li, Junyi Jessy;Khurshid, Sarfraz;Mooney, Raymond J.;Gligoric, Milos",57210932883;57210935460;56350081100;56231912700;7102791999;26221765900,60013372;60013372;60013372;60013372;60013372;60013372,2019-08-12,12 August 2019,ESEC/FSE 2019 - Proceedings of the 2019 27th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21100927970,,Conference Proceeding,,,,385-396,"Natural language elements, e.g., todo comments, are frequently used to communicate among developers and to describe tasks that need to be performed (actions) when specific conditions hold on artifacts related to the code repository (triggers), e.g., from the Apache Struts project: remove expectedJDK15 and if() after switching to Java 1.6. As projects evolve, development processes change, and development teams reorganize, these comments, because of their informal nature, frequently become irrelevant or forgotten. We present the first framework, dubbed TrigIt, to specify trigger-action todo comments in executable format. Thus, actions are executed automatically when triggers evaluate to true. TrigIt specifications are written in the host language (e.g., Java) and are evaluated as part of the build process. The triggers are specified as query statements over abstract syntax trees, abstract representation of build configuration scripts, issue tracking systems, and system clock time. The actions are either notifications to developers or code transformation steps. We implemented TrigIt for the Java programming language and migrated 44 existing trigger-action comments from several popular open-source projects. Evaluation of TrigIt, via a user study, showed that users find TrigIt easy to learn and use. TrigIt has the potential to enforce more discipline in writing and maintaining comments in large code repositories.",Domain specific languages | Todo comments | Trigger-action,15,1,publisherfree2read,Bronze,NSF,1652517,National Science Foundation,FSE Software Engineering
2-s2.0-85067599423,10.1145/3290605.3300455,,,A framework for the experience of meaning in human-computer interaction,cp,Conference Paper,Mekler E.,60030840;60023588,Københavns Universitet;Universität Basel,Copenhagen;Basel,Denmark;Switzerland,2,"Mekler, Elisa D.;Hornbæk, Kasper",55516458900;6602385484,60023588;60030840,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"The view of quality in human-computer interaction continuously develops, having in past decades included consistency, transparency, usability, and positive emotions. Recently, meaning is receiving increased interest in the user experience literature and in industry, referring to the end, purpose or significance of interaction with computers. However, the notion of meaning remains elusive and a bewildering number of senses are in use. We present a framework of meaning in interaction, based on a synthesis of psychological meaning research. The framework outlines five distinct senses of the experience of meaning: connectedness, purpose, coherence, resonance, and significance. We illustrate the usefulness of the framework by analyzing a selection of recent papers at the CHI conference and by raising a series of open research questions about the interplay of meaning, user experience, reflection, and well-being.",Meaning | Meaning-making | Meaningful interaction | Meaningfulness | User experience,57,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85071901921,10.1145/3338906.3338912,,,A statistics-based performance testing methodology for cloud applications,cp,Conference Paper,He S.,60023004;60021918;60003212,University of Delaware;University of Virginia;The University of Texas at San Antonio,Newark;Charlottesville;San Antonio,United States;United States;United States,6,"He, Sen;Manns, Glenna;Saunders, John;Wang, Wei;Pollock, Lori;Soffa, Mary Lou",57202453564;57210926189;57210928600;56948511500;7005623618;7003864328,60003212;60021918;60021918;60003212;60023004;60021918,2019-08-12,12 August 2019,ESEC/FSE 2019 - Proceedings of the 2019 27th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21100927970,,Conference Proceeding,,,,188-199,"The low cost of resource ownership and flexibility have led users to increasingly port their applications to the clouds. To fully realize the cost benefits of cloud services, users usually need to reliably know the execution performance of their applications. However, due to the random performance fluctuations experienced by cloud applications, the black box nature of public clouds and the cloud usage costs, testing on clouds to acquire accurate performance results is extremely difficult. In this paper, we present a novel cloud performance testing methodology called PT4Cloud. By employing non-parametric statistical approaches of likelihood theory and the bootstrap method, PT4Cloud provides reliable stop conditions to obtain highly accurate performance distributions with confidence bands. These statistical approaches also allow users to specify intuitive accuracy goals and easily trade between accuracy and testing cost. We evaluated PT4Cloud with 33 benchmark configurations on Amazon Web Service and Chameleon clouds. When compared with performance data obtained from extensive performance tests, PT4Cloud provides testing results with 95.4% accuracy on average while reducing the number of test runs by 62%. We also propose two test execution reduction techniques for PT4Cloud, which can reduce the number of test runs by 90.1% while retaining an average accuracy of 91%. We compared our technique to three other techniques and found that our results are much more accurate.",Cloud computing | Non- parametric statistics | Performance testing | Resource contention,32,0,,,,undefined,,FSE Software Engineering
2-s2.0-85067609498,10.1145/3290605.3300624,,,A tale of two perspectives: A conceptual framework of user expectations and experiences of instructional fitness apps,cp,Conference Paper,Aladwan A.,60118847,School of Computing and Information Systems,Melbourne,Australia,4,"Aladwan, Ahed;Kelly, Ryan M.;Baker, Steven;Velloso, Eduardo",57209394467;23488976000;56255744000;53364337000,60118847;60118847;60118847;60118847,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"We present a conceptual framework grounded in both users’ reviews and HCI theories, residing between practices and theories as a form of intermediate-level knowledge in interaction design. Previous research has examined diferent forms of intermediary knowledge such as conceptual structures, strong concepts, and bridging concepts. Within HCI, these forms are generic and rise either from theories or particular instances. In this work, we created and evaluated a conceptual framework for a specifc domain (instructional ftness apps). We frst extracted the particular instances using users’ online reviews and conceptualised them as an expectations and experiences framework. Second, within the framework, we evaluated the artefact related constructs using Norman’s design principles. Third, we evaluated beyond the artefact related constructs using distributed cognition theory. We present an analysis of such intermediate-level knowledge with the aim of informing future designs.",Conceptual framework | Expectations | Experience | Fitness | Intermediate-level knowledge | Online reviews | Smartphone,6,0,repositoryvor,Green,ARC,DE180100315,Australian Research Council,CHI Human-Computer Interaction
2-s2.0-85070240721,10.1109/CVPR.2019.00696,,,A theory of fermat paths for non-line-of-sight shape reconstruction,cp,Conference Paper,Xin S.,60027950;60022148;60016849,Carnegie Mellon University;University College London;University of Toronto,Pittsburgh;London;Toronto,United States;United Kingdom;Canada,6,"Xin, Shumian;Nousias, Sotiris;Kutulakos, Kiriakos N.;Sankaranarayanan, Aswin C.;Narasimhan, Srinivasa G.;Gkioulekas, Ioannis",57214471277;57200613390;6701920248;14523223000;7103035733;36738892600,60027950;60016849-60022148;60016849;60027950;60027950;60027950,2019-06-01,June 2019,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,2019-June,,8954312,6793-6802,"We present a novel theory of Fermat paths of light between a known visible scene and an unknown object not in the line of sight of a transient camera. These light paths either obey specular reflection or are reflected by the object's boundary, and hence encode the shape of the hidden object. We prove that Fermat paths correspond to discontinuities in the transient measurements. We then derive a novel constraint that relates the spatial derivatives of the path lengths at these discontinuities to the surface normal. Based on this theory, we present an algorithm, called Fermat Flow, to estimate the shape of the non-line-of-sight object. Our method allows, for the first time, accurate shape recovery of complex objects, ranging from diffuse to specular, that are hidden around the corner as well as hidden behind a diffuser. Finally, our approach is agnostic to the particular technology used for transient imaging. As such, we demonstrate mm-scale shape recovery from pico-second scale transients using a SPAD and ultrafast laser, as well as micron-scale reconstruction from femto-second scale transients using interferometry. We believe our work is a significant advance over the state-of-the-art in non-line-of-sight imaging.",Computational Photography | Physics-based Vision and Shape-from-X,116,0,,,NSF,1730147,National Science Foundation,CVPR Computer Vision
2-s2.0-85067611086,10.1145/3290605.3300231,,,A translational science model for HCI,cp,Conference Paper,Colusso L.,60015481,University of Washington,Seattle,United States,4,"Colusso, Lucas;Munson, Sean A.;Jones, Ridley;Hsieh, Gary",57188823223;22835659500;55568530779;23397317600,60015481;60015481;60015481;60015481,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"Using scientific discoveries to inform design practice is an important, but difficult, objective in HCI. In this paper, we provide an overview of Translational Science in HCI by triangulating literature related to the research-practice gap with interview data from many parties engaged (or not) in translating HCI knowledge. We propose a model for Translational Science in HCI based on the concept of a continuum to describe how knowledge progresses (or stalls) through multiple steps and translations until it can influence design practice. The model offers a conceptual framework that can be used by researchers and practitioners to visualize and describe the progression of HCI knowledge through a sequence of translations. Additionally, the model may facilitate a precise identification of translational barriers, which allows devising more effective strategies to increase the use of scientific findings in design practice.",Research-practice gap | Translational research | Translational science,39,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85067689579,10.1145/3314221.3314625,,,"A typed, algebraic approach to parsing",cp,Conference Paper,Krishnaswami N.,60031101,University of Cambridge,Cambridge,United Kingdom,2,"Krishnaswami, Neelakantan R.;Yallop, Jeremy",57203668800;23487525000,60031101;60031101,2019-06-08,8 June 2019,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,379-393,"In this paper, we recall the definition of the context-free expressions (or µ-regular expressions), an algebraic presentation of the context-free languages. Then, we define a core type system for the context-free expressions which gives a compositional criterion for identifying those context-free expressions which can be parsed unambiguously by predictive algorithms in the style of recursive descent or LL(1). Next, we show how these typed grammar expressions can be used to derive a parser combinator library which both guarantees linear-time parsing with no backtracking and single-token lookahead, and which respects the natural denotational semantics of context-free expressions. Finally, we show how to exploit the type information to write a staged version of this library, which produces dramatic increases in performance, even outperforming code generated by the standard parser generator tool ocamlyacc.",Context-free languages | Kleene algebra | Parsing | Type theory,13,0,repositoryvor,Green,,undefined,,PLDI Programming Languages
2-s2.0-85067678231,10.1145/3314221.3314638,,,An inductive synthesis framework for verifiable reinforcement learning,cp,Conference Paper,Zhu H.,60009254;121067125,"Purdue University;Galois, Inc.",West Lafayette;Arlington,United States;United States,4,"Zhu, He;Magill, Stephen;Xiong, Zikang;Jagannathan, Suresh",56031394100;55496765600;57209408676;57202888433,121067125;121067125;60009254;60009254,2019-06-08,8 June 2019,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,686-701,"Despite the tremendous advances that have been made in the last decade on developing useful machine-learning applications, their wider adoption has been hindered by the lack of strong assurance guarantees that can be made about their behavior. In this paper, we consider how formal verification techniques developed for traditional software systems can be repurposed for verification of reinforcement learning-enabled ones, a particularly important class of machine learning systems. Rather than enforcing safety by examining and altering the structure of a complex neural network implementation, our technique uses blackbox methods to synthesizes deterministic programs, simpler, more interpretable, approximations of the network that can nonetheless guarantee desired safety properties are preserved, even when the network is deployed in unanticipated or previously unobserved environments. Our methodology frames the problem of neural network verification in terms of a counterexample and syntax-guided inductive synthesis procedure over these programs. The synthesis procedure searches for both a deterministic program and an inductive invariant over an infinite state transition system that represents a specification of an application's control logic. Additional specifications defining environment-based constraints can also be provided to further refine the search space. Synthesized programs deployed in conjunction with a neural network implementation dynamically enforce safety conditions by monitoring and preventing potentially unsafe actions proposed by neural policies. Experimental results over a wide range of cyber-physical applications demonstrate that software-inspired formal verification techniques can be used to realize trustworthy reinforcement learning systems with low overhead.",Invariant Inference | Program Synthesis | Program Verification | Reinforcement Learning | Runtime Shielding,57,1,repositoryam,Green,RCSA,undefined,Research Corporation for Science Advancement,PLDI Programming Languages
2-s2.0-85067616478,10.1145/3290605.3300238,,,Anchored audio sampling a seamless method for exploring children’s thoughts during deployment studies,cp,Conference Paper,Hiniker A.,60015481,University of Washington,Seattle,United States,4,"Hiniker, Alexis;Froehlich, Jon E.;Zhang, Mingrui;Beneteau, Erin",55800655000;7101665384;57209400842;57209395479,60015481;60015481;60015481;60015481,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"Many traditional HCI methods, such as surveys and interviews, are of limited value when working with preschoolers. In this paper, we present anchored audio sampling (AAS), a remote data collection technique for extracting qualitative audio samples during feld deployments with young children. AAS ofers a developmentally sensitive way of understanding how children make sense of technology and situates their use in the larger context of daily life. AAS is defned by an anchor event, around which audio is collected. A sliding window surrounding this anchor captures both antecedent and ensuing recording, providing the researcher insight into the activities that led up to the event of interest as well as those that followed. We present themes from three deployments that leverage this technique. Based on our experiences using AAS, we have also developed a reusable open-source library for embedding AAS into any Android application.",CCI | Context-aware ESM | Deployments | Methods,6,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85071920488,10.1145/3338906.3338947,,,Assessing the quality of the steps to reproduce in bug reports,cp,Conference Paper,Chaparro O.,60016114;60009415;60004300,William &amp; Mary;The University of Texas at Dallas;Università degli Studi del Sannio,Williamsburg;Richardson;Benevento,United States;United States;Italy,8,"Chaparro, Oscar;Bernal-Cárdenas, Carlos;Lu, Jing;Moran, Kevin;Marcus, Andrian;Di Penta, Massimiliano;Poshyvanyk, Denys;Ng, Vincent",25631575400;55848479200;57199238558;57095532500;9239576200;6602794138;13613571900;55432380800,60016114;60016114;60009415;60016114;60009415;60004300;60016114;60009415,2019-08-12,12 August 2019,ESEC/FSE 2019 - Proceedings of the 2019 27th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21100927970,,Conference Proceeding,,,,86-96,"A major problem with user-written bug reports, indicated by developers and documented by researchers, is the (lack of high) quality of the reported steps to reproduce the bugs. Low-quality steps to reproduce lead to excessive manual effort spent on bug triage and resolution. This paper proposes Euler, an approach that automatically identifies and assesses the quality of the steps to reproduce in a bug report, providing feedback to the reporters, which they can use to improve the bug report. The feedback provided by Euler was assessed by external evaluators and the results indicate that Euler correctly identified 98% of the existing steps to reproduce and 58% of the missing ones, while 73% of its quality annotations are correct.",Bug Report Quality | Dynamic Software Analysis | Textual Analysis,43,0,repositoryam,Green,NSF,1525902,National Science Foundation,FSE Software Engineering
2-s2.0-85075484191,10.1145/3357384.3357896,,,AutoGRD: Model recommendation through graphical dataset representation,cp,Conference Paper,Cohen-Shapira N.,60027161,Ben-Gurion University of the Negev,Beer-Sheva,Israel,5,"Cohen-Shapira, Noy;Rokach, Lior;Shapira, Bracha;Katz, Gilad;Vainshtein, Roman",57211939999;9276243500;7004315829;7102880002;57204941044,60027161;60027161;60027161;60027161;60027161,2019-11-03,3 November 2019,"International Conference on Information and Knowledge Management, Proceedings",,55826,,Conference Proceeding,,,,821-830,"The widespread use of machine learning algorithms and the high level of expertise required to utilize them have fuelled the demand for solutions that can be used by non-experts. One of the main challenges non-experts face in applying machine learning to new problems is algorithm selection - the identification of the algorithm(s) that will deliver top performance for a given dataset, task, and evaluation measure. We present AutoGRD, a novel meta-learning approach for algorithm recommendation. AutoGRD first represents datasets as graphs and then extracts their latent representation that is used to train a ranking meta-model capable of accurately recommending top-performing algorithms for previously unseen datasets. We evaluate our approach on 250 datasets and demonstrate its effectiveness both for classification and regression tasks. AutoGRD outperforms state-of-the-art meta-learning and Bayesian methods.",Algorithm selection | AutoML | Classification | Dataset representation | Graph embedding | Meta-learning | Regression,32,0,,,DARPA,D3M,Defense Advanced Research Projects Agency,CIKM Knowledge Management
2-s2.0-85078427294,10.1109/FOCS.2019.00038,,,Automating resolution is NP-hard,cp,Conference Paper,Atserias A.,60007592,Universitat Politécnica de Catalunya,Barcelona,Spain,2,"Atserias, Albert;Muller, Moritz",55885344800;24338941500,60007592;60007592,2019-11-01,November 2019,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2019-November,,8948665,498-509,"We show that the problem of finding a Resolution refutation that is at most polynomially longer than a shortest one is NP-hard. In the parlance of proof complexity, Resolution is not automatizable unless P = NP. Indeed, we show that it is NP-hard to distinguish between formulas that have Resolution refutations of polynomial length and those that do not have subexponential length refutations. This also implies that Resolution is not automatizable in subexponential time or quasi-polynomial time unless~NP is included in SUBEXP or QP, respectively.",Hardness of approximation | NP hard | Proof search | Resolution | Satisfiability,10,0,repositoryam,Green,H2020,648276,Horizon 2020 Framework Programme,FOCS Theory
2-s2.0-85074915996,10.24963/ijcai.2019/255,,,Boosting for comparison-based learning,cp,Conference Paper,Perrot M.,60030569;60017246,Max Planck Institute for Intelligent Systems;Eberhard Karls Universität Tübingen,Tubingen;Tubingen,Germany;Germany,2,"Perrot, Michaël;Von Luxburg, Ulrike",56335949200;17436496700,60030569;60030569-60017246,2019-01-01,2019,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2019-August,,,1844-1850,"We consider the problem of classification in a comparison-based setting: given a set of objects, we only have access to triplet comparisons of the form “object A is closer to object B than to object C.” In this paper we introduce TripletBoost, a new method that can learn a classifier just from such triplet comparisons. The main idea is to aggregate the triplets information into weak classifiers, which can subsequently be boosted to a strong classifier. Our method has two main advantages: (i) it is applicable to data from any metric space, and (ii) it can deal with large scale problems using only passively obtained and noisy triplets. We derive theoretical generalization guarantees and a lower bound on the number of necessary triplets, and we empirically show that our method is both competitive with state of the art approaches and resistant to noise.",,4,1,repositoryam,Green,DFG,390727645,Deutsche Forschungsgemeinschaft,IJCAI Artificial Intelligence
2-s2.0-85074723032,,,,Bridging the gap between training and inference for neural machine translation,cp,Conference Paper,Zhang W.,60119391;60114181;60019499;60011410,Huawei Noah's Ark Lab;Tencent;Chinese Academy of Sciences;Worcester Polytechnic Institute,Hong Kong;Shenzhen;Beijing;Worcester,Hong Kong;China;China;United States,5,"Zhang, Wen;Feng, Yang;Meng, Fandong;You, Di;Liu, Qun",57212063917;55747582000;55847567500;57211943867;56181387900,60019499;60019499;60114181;60011410;60119391,2020-01-01,2020,"ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference",,21100981076,,Conference Proceeding,,,,4334-4343,"Neural Machine Translation (NMT) generates target words sequentially in the way of predicting the next word conditioned on the context words. At training time, it predicts with the ground truth words as context while at inference it has to generate the entire sequence from scratch. This discrepancy of the fed context leads to error accumulation among the way. Furthermore, word-level training requires strict matching between the generated sequence and the ground truth sequence which leads to overcorrection over different but reasonable translations. In this paper, we address these issues by sampling context words not only from the ground truth sequence but also from the predicted sequence by the model during training, where the predicted sequence is selected with a sentence-level optimum. Experiment results on Chinese?English and WMT'14 English?German translation tasks demonstrate that our approach can achieve significant improvements on multiple datasets.",,134,0,,,NSFC,61662077,National Natural Science Foundation of China,ACL Natural Language Processing
2-s2.0-85083952445,,,,Challenging common assumptions in the unsupervised learning of disentangled representations,cp,Conference Paper,Locatello F.,60030569;60025858;60006191,Max Planck Institute for Intelligent Systems;ETH Zürich;Google LLC,Tubingen;Zurich;Mountain View,Germany;Switzerland;United States,7,"Locatello, Francesco;Bauer, Stefan;Lucic, Mario;Rätsch, Gunnar;Gelly, Sylvain;Schölkopf, Bernhard;Bachem, Olivier",57202057108;56410381900;48161478700;6603370159;55038126700;7004460308;55916070200,60025858-60030569;60030569;60006191;60025858;60006191;60030569;60006191,2019-01-01,2019,RML@ICLR 2019 Workshop - Reproducibility in Machine Learning,,21100962067,,Conference Proceeding,,,,,"The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms. In this paper, we provide a sober look on recent progress in the field and challenge some common assumptions. We train more than 12 000 models covering most prominent methods and evaluation metrics in a reproducible large-scale experimental study on seven different data sets. We observe that while the different methods successfully enforce properties ""encouraged"" by the corresponding losses, well-disentangled models seemingly cannot be identified without supervision. Furthermore, increased disentanglement does not seem to lead to a decreased sample complexity of learning for downstream tasks. Our results suggest that future work on disentanglement learning should be explicit about the role of inductive biases and (implicit) supervision, investigate concrete benefits of enforcing disentanglement of the learned representations, and consider a reproducible experimental setup covering several data sets.",,455,0,,,ETH,undefined,Eidgenössische Technische Hochschule Zürich,ICML Machine Learning
2-s2.0-85068219744,10.1109/INFOCOM.2019.8737461,,,Combinatorial Sleeping Bandits with Fairness Constraints,cp,Conference Paper,Li F.,60149322;60145790,Department of Computer and Information Sciences;Department of Computer Science,Philadelphia;Ames,United States;United States,3,"Li, Fengjiao;Liu, Jia;Ji, Bo",57209608275;52763624900;43661562600,60149322;60145790;60149322,2019-04-01,April 2019,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2019-April,,8737461,1702-1710,"The multi-armed bandit (MAB) model has been widely adopted for studying many practical optimization problems (network resource allocation, ad placement, crowdsourcing, etc.) with unknown parameters. The goal of the player i.e., the decision maker) here is to maximize the cumulative reward in the face of uncertainty. However, the basic MAB model neglects several important factors of the system in many real-world applications, where multiple arms (i.e., actions) can be simultaneously played and an arm could sometimes be 'sleeping' (i.e., unavailable). Besides reward maximization, ensuring fairness is also a key design concern in practice. To that end, we propose a new Combinatorial Sleeping MAB model with Fairness constraints, called CSMAB-F, aiming to address the aforementioned crucial modeling issues. The objective is now to maximize the reward while satisfying the fairness requirement of a minimum selection fraction for each individual arm. To tackle this new problem, we extend an online learning algorithm, called Upper Confidence Bound (UCB), to deal with a critical tradeoff between exploitation and exploration and employ the virtual queue technique to properly handle the fairness constraints. By carefully integrating these two techniques, we develop a new algorithm, called Learning with Fairness Guarantee (LFG), for the CSMAB-F problem. Further, we rigorously prove that not only LFG is feasibility-optimal but it also has a time-average regret upper bounded by N2η}+β1√ mNT\log T}+β2NT, where N is the total number of arms, m is the maximum number of arms that can be simultaneously played, T is the time horizon, β1 and β2 are constants, and η is a design parameter that we can tune. Finally, we perform extensive simulations to corroborate the effectiveness of the proposed algorithm. Interestingly, the simulation results reveal an important tradeoff between the regret and the speed of convergence to a point satisfying the fairness constraints.",,65,0,repositoryam,Green,NSF,1446582,National Science Foundation,INFOCOM Networking
2-s2.0-85069175639,10.1145/3309697.3331486,,,Computationally efficient estimation of the spectral gap of a Markov chain,cp,Conference Paper,Combes R.,60104081;60007136,Orange Labs;Laboratoire des Signaux et Systèmes,Issy-les-Moulineaux;Gif-sur-Yvette,France;France,2,"Combes, Richard;Touati, Mikael",36439300400;56971080000,60007136;60104081,2019-06-20,20 June 2019,SIGMETRICS Performance 2019 - Abstracts of the 2019 SIGMETRICS/Performance Joint International Conference on Measurement and Modeling of Computer Systems,,21100918279,,Conference Proceeding,,,,99-100,"We consider the problem of estimating from sample paths the absolute spectral gap 1 - λ∗ of a reversible, irreducible and aperiodic Markov chain (χt) tϵN over a finite state space Ω. We propose the UCPI (Upper Confidence Power Iteration) algorithm for this problem, a low-complexity algorithm which estimates the spectral gap in time O(n) and memory space O((lnn)2) given n samples. This is in stark contrast with most known methods which require at least memory space O(|Ω|), so that they cannot be applied to large state spaces. Furthermore, UCPI is amenable to parallel implementation.",,0,0,repositoryam,Green,,undefined,,SIGMETRICS Performance
2-s2.0-85067647598,10.1145/3314221.3314616,,,Continuously reasoning about programs using differential Bayesian inference,cp,Conference Paper,Heo K.,60006297,University of Pennsylvania,Philadelphia,United States,4,"Heo, Kihong;Si, Xujie;Raghothaman, Mukund;Naik, Mayur",58306194500;57191053690;55796324700;12140829000,60006297;60006297;60006297;60006297,2019-06-08,8 June 2019,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,561-575,"Programs often evolve by continuously integrating changes from multiple programmers. The effective adoption of program analysis tools in this continuous integration setting is hindered by the need to only report alarms relevant to a particular program change. We present a probabilistic framework, Drake, to apply program analyses to continuously evolving programs. Drake is applicable to a broad range of analyses that are based on deductive reasoning. The key insight underlying Drake is to compute a graph that concisely and precisely captures differences between the derivations of alarms produced by the given analysis on the program before and after the change. Performing Bayesian inference on the graph thereby enables to rank alarms by likelihood of relevance to the change. We evaluate Drake using SparrowÐa static analyzer that targets buffer-overrun, format-string, and integer-overflow errorsÐon a suite of ten widely-used C programs each comprising 13k-112k lines of code. Drake enables to discover all true bugs by inspecting only 30 alarms per benchmark on average, compared to 85 (3× more) alarms by the same ranking approach in batch mode, and 118 (4× more) alarms by a differential approach based on syntactic masking of alarms which also misses 4 of the 26 bugs overall.",Alarm prioritization | Alarm relevance | Continuous integration | Software evolution | Static analysis,16,1,publisherfree2read,Bronze,NSF,#1253867,National Science Foundation,PLDI Programming Languages
2-s2.0-85068214593,10.1109/INFOCOM.2019.8737363,,,Counterintuitive Characteristics of Optimal Distributed LRU Caching over Unreliable Channels,cp,Conference Paper,Quan G.,60118459;60003500,"Alibaba Group, USA;The Ohio State University",San Mateo;Columbus,United States;United States,3,"Quan, Guocong;Tan, Jian;Eryilmaz, Atilla",57203513899;36141478500;57207522864,60003500;60003500-60118459;60003500,2019-04-01,April 2019,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2019-April,,8737363,694-702,"Least-recently-used (LRU) caching and its variants have conventionally been used as a fundamental and critical method to ensure fast and efficient data access in computer and communication systems. Emerging data-intensive applications over unreliable channels, e.g., mobile edge computing and wireless content delivery networks, have imposed new challenges in optimizing LRU caching systems in environments prone to failures. Most existing studies focus on reliable channels, e.g., on wired Web servers and within data centers, which have already yielded good insights with successful algorithms on how to reduce cache miss ratios. Surprisingly, we show that these widely held insights do not necessarily hold true for unreliable channels.We consider a single-hop multi-cache distributed system with data items being dispatched by random hashing. The objective is to achieve efficient cache organization and data placement. The former allocates the total memory space to each of the involved caches. The latter decides data routing strategies and data replication schemes. Analytically we characterize the unreliable LRU caches by explicitly deriving their asymptotic miss probabilities. Based on these results, we optimize the system design.Remarkably, these results sometimes are counterintuitive, differing from the ones obtained for reliable caches. We discover an interesting phenomenon: asymmetric cache organization is optimal even for symmetric channels. Specifically, even when channel unreliability probabilities are equal, allocating the cache spaces unequally can achieve a better performance. We also propose an explicit unequal allocation policy that outperforms the equal allocation. In addition, we prove that splitting the total cache space into separate LRU caches can achieve a lower asymptotic miss probability than resource pooling that organizes the total space in a single LRU cache.These results provide new and even counterintuitive insights that motivate novel designs for caching systems over unreliable channels. They can potentially be exploited to further improve the system performance in real practice.",,6,0,,,NSF,1562065,National Science Foundation,INFOCOM Networking
2-s2.0-85067617338,10.1145/3290605.3300474,,,Data is personal: Attitudes and perceptions of data visualization in rural Pennsylvania,cp,Conference Paper,Peck E.M.,60020426,Bucknell University,Lewisburg,United States,3,"Peck, Evan M.;Ayuso, Sofia E.;El-Etr, Omar",36170923500;57209398429;57209400339,60020426;60020426;60020426,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"Many of the guidelines that inform how designers create data visualizations originate in studies that unintentionally exclude populations that are most likely to be among the “data poor”. In this paper, we explore which factors may drive attention and trust in rural populations with diverse economic and educational backgrounds - a segment that is largely underrepresented in the data visualization literature. In 42 semi-structured interviews in rural Pennsylvania (USA), we find that a complex set of factors intermix to inform attitudes and perceptions about data visualization - including educational background, political affiliation, and personal experience. The data and materials for this research can be found at https://osf.io/uxwts/.",Data | Information literacy | Information visualization | Rural,80,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85066881893,,,,Datacenter RPCs can be general and fast,cp,Conference Paper,Kalia A.,60033010;60027950,Intel Corporation;Carnegie Mellon University,Santa Clara;Pittsburgh,United States;United States,3,"Kalia, Anuj;Kaminsky, Michael;Andersen, David G.",56367885300;35233511800;57210522272,60027950;60033010;60027950,2019-01-01,2019,"Proceedings of the 16th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2019",,21100962613,,Conference Proceeding,,,,1-16,"It is commonly believed that datacenter networking software must sacrifice generality to attain high performance. The popularity of specialized distributed systems designed specifically for niche technologies such as RDMA, lossless networks, FPGAs, and programmable switches testifies to this belief. In this paper, we show that such specialization is not necessary. eRPC is a new general-purpose remote procedure call (RPC) library that offers performance comparable to specialized systems, while running on commodity CPUs in traditional datacenter networks based on either lossy Ethernet or lossless fabrics. eRPC performs well in three key metrics: message rate for small messages; bandwidth for large messages; and scalability to a large number of nodes and CPU cores. It handles packet loss, congestion, and background request execution. In microbenchmarks, one CPU core can handle up to 10 million small RPCs per second, or send large messages at 75 Gbps. We port a production-grade implementation of Raft state machine replication to eRPC without modifying the core Raft source code. We achieve 5.5 µs of replication latency on lossy Ethernet, which is faster than or comparable to specialized replication systems that use programmable switches, FPGAs, or RDMA.",,183,0,,,NSF,CCF-1535821,National Science Foundation,NSDI Networking
2-s2.0-85067593663,10.1145/3290605.3300451,,,Detecting personality traits using eye-tracking data,cp,Conference Paper,Berkovsky S.,60032179;60029470;60025709;60019544,University of Wisconsin-Madison;Commonwealth Scientific and Industrial Research Organisation;The University of Sydney;Macquarie University,Madison;Canberra;Sydney;Sydney,United States;Australia;Australia;Australia,7,"Berkovsky, Shlomo;Taib, Ronnie;Koprinska, Irena;Wang, Eileen;Zeng, Yucheng;Li, Jingjie;Kleitman, Sabina",8945336100;17347338100;6506616260;57209399486;57209396959;57205694120;7801633089,60019544;60029470;60025709;60025709;60025709;60032179;60025709,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"Personality is an established domain of research in psychology, and individual differences in various traits are linked to a variety of real-life outcomes and behaviours. Personality detection is an intricate task that typically requires humans to fill out lengthy questionnaires assessing specific personality traits. The outcomes of this, however, may be unreliable or biased if the respondents do not fully understand or are not willing to honestly answer the questions. To this end, we propose a framework for objective personality detection that leverages humans’ physiological responses to external stimuli. We exemplify and evaluate the framework in a case study, where we expose subjects to affective image and video stimuli, and capture their physiological responses using a commercial-grade eye-tracking sensor. These responses are then processed and fed into a classifier capable of accurately predicting a range of personality traits. Our work yields notably high predictive accuracy, suggesting the applicability of the proposed framework for robust personality detection.",Eye tracking | Field study | Framework | Personality detection,64,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85072298048,10.1109/ICSE.2019.00125,,,Detecting Incorrect Build Rules,cp,Conference Paper,Licker N.,60031101,University of Cambridge,Cambridge,United Kingdom,2,"Licker, Nandor;Rice, Andrew",57211018397;14036315700,60031101;60031101,2019-05-01,May 2019,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2019-May,,8812082,1234-1244,"Automated build systems are routinely used by software engineers to minimize the number of objects that need to be recompiled after incremental changes to the source files of a project. In order to achieve efficient and correct builds, developers must provide the build tools with dependency information between the files and modules of a project, usually expressed in a macro language specific to each build tool. In order to guarantee correctness, the authors of these tools are responsible for enumerating all the files whose contents an output depends on. Unfortunately, this is a tedious process and not all dependencies are captured in practice, which leads to incorrect builds. We automatically uncover such missing dependencies through a novel method that we call build fuzzing. The correctness of build definitions is verified by modifying files in a project, triggering incremental builds and comparing the set of changed files to the set of expected changes. These sets are determined using a dependency graph inferred by tracing the system calls executed during a clean build. We evaluate our method by exhaustively testing build rules of open-source projects, uncovering issues leading to race conditions and faulty builds in 31 of them. We provide a discussion of the bugs we detect, identifying anti-patterns in the use of the macro languages. We fix some of the issues in projects where the features of build systems allow a clean solution.",build tools | exhaustive testing | verification,9,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-85072286167,10.1109/ICSE.2019.00053,,,Distilling Neural Representations of Data Structure Manipulation using fMRI and fNIRS,cp,Conference Paper,Huang Y.,60029241;60025778,"University of California, Santa Barbara;University of Michigan, Ann Arbor",Santa Barbara;Ann Arbor,United States;United States,7,"Huang, Yu;Liu, Xinyu;Krueger, Ryan;Santander, Tyler;Hu, Xiaosu;Leach, Kevin;Weimer, Westley",57188585234;57211024321;57211024897;56479288400;55496218100;55843963300;7003629741,60025778;60025778;60025778;60029241;60025778;60025778;60025778,2019-05-01,May 2019,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2019-May,,8812086,396-407,"Data structures permeate many aspects of software engineering, but their associated human cognitive processes are not thoroughly understood. We leverage medical imaging and insights from the psychological notion of spatial ability to decode the neural representations of several fundamental data structures and their manipulations. In a human study involving 76 participants, we examine list, array, tree, and mental rotation tasks using both functional near-infrared spectroscopy (fNIRS) and functional magnetic resonance imaging (fMRI). We find a nuanced relationship: data structure and spatial operations use the same focal regions of the brain but to different degrees. They are related but distinct neural tasks. In addition, more difficult computer science problems induce higher cognitive load than do problems of pure spatial reasoning. Finally, while fNIRS is less expensive and more permissive, there are some computing-relevant brain regions that only fMRI can reach.",data structures | medical imaging | spatial ability,23,0,,,,undefined,,ICSE Software Engineering
2-s2.0-85090173876,,,,Distribution-independent PAC learning of halfspaces with massart noise,cp,Conference Paper,Diakonikolas I.,60032179;60000256,University of Wisconsin-Madison;Max Planck Institute for Informatics,Madison;Saarbrucken,United States;Germany,3,"Diakonikolas, Ilias;Gouleakis, Themis;Tzamos, Christos",23388448100;55795219900;36722865500,60032179;60000256;60032179,2019-01-01,2019,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,32,,,,"We study the problem of distribution-independent PAC learning of halfspaces in the presence of Massart noise. Specifically, we are given a set of labeled examples (x, y) drawn from a distribution D on Rd+1 such that the marginal distribution on the unlabeled points x is arbitrary and the labels y are generated by an unknown halfspace corrupted with Massart noise at noise rate ? < 1/2. The goal is to find a hypothesis h that minimizes the misclassification error Pr(x,y)~D [h(x) 6= y]. We give a poly (d, 1/e) time algorithm for this problem with misclassification error ? + e. We also provide evidence that improving on the error guarantee of our algorithm might be computationally hard. Prior to our work, no efficient weak (distribution-independent) learner was known in this model, even for the class of disjunctions. The existence of such an algorithm for halfspaces (or even disjunctions) has been posed as an open question in various works, starting with Sloan (1988), Cohen (1997), and was most recently highlighted in Avrim Blum's FOCS 2003 tutorial.",,42,0,,,NSF,CCF-1652862,National Science Foundation,NeurIPS Machine Learning
2-s2.0-85072269421,10.1109/ICSE.2019.00059,,,Do Developers Discover New Tools on the Toilet?,cp,Conference Paper,Murphy-Hill E.,60006191,Google LLC,Mountain View,United States,9,"Murphy-Hill, Emerson;Smith, Edward K.;Sadowski, Caitlin;Jaspan, Ciera;Winter, Collin;Jorde, Matthew;Knight, Andrea;Trenk, Andrew;Gross, Steve",16307910100;39262634600;34977439000;24070973300;57020912800;21742361700;22834883100;57211018568;57211024809,60006191;;60006191;60006191;;60006191;60006191;60006191;60006191,2019-05-01,May 2019,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2019-May,,8812046,465-475,"Maintaining awareness of useful tools is a substantial challenge for developers. Physical newsletters are a simple technique to inform developers about tools. In this paper, we evaluate such a technique, called Testing on the Toilet, by performing a mixed-methods case study. We first quantitatively evaluate how effective this technique is by applying statistical causal inference over six years of data about tools used by thousands of developers. We then qualitatively contextualize these results by interviewing and surveying 382 developers, from authors to editors to readers. We found that the technique was generally effective at increasing software development tool use, although the increase varied depending on factors such as the breadth of applicability of the tool, the extent to which the tool has reached saturation, and the memorability of the tool name.",diffusion of innovations | software engineering,6,0,,,,undefined,,ICSE Software Engineering
2-s2.0-85076762182,10.1145/3341301.3359638,,,Efficient scalable thread-safety-violation detection finding thousands of concurrency bugs during testing,cp,Conference Paper,Li G.,60029278;60025038;60021726,"The University of Chicago;University of California, Berkeley;Microsoft Research",Chicago;Berkeley;Redmond,United States;United States;United States,5,"Li, Guangpu;Lu, Shan;Musuvathi, Madanlal;Nath, Suman;Padhye, Rohan",57194780198;35199803400;11141222500;22835570000;37020629700,60029278;60029278;60021726;60021726;60025038,2019-10-27,27 October 2019,SOSP 2019 - Proceedings of the 27th ACM Symposium on Operating Systems Principles,,21100955176,,Conference Proceeding,,,,162-180,"Concurrency bugs are hard to find, reproduce, and debug. They often escape rigorous in-house testing, but result in large-scale outages in production. Existing concurrency-bug detection techniques unfortunately cannot be part of industry’s integrated build and test environment due to some open challenges: how to handle code developed by thousands of engineering teams that uses a wide variety of synchronization mechanisms, how to report little/no false positives, and how to avoid excessive testing resource consumption. This paper presents TSVD, a thread-safety violation detector that addresses these challenges through a new design point in the domain of active testing. Unlike previous techniques that inject delays randomly or employ expensive synchronization analysis, TSVD uses lightweight monitoring of the calling behaviors of thread-unsafe methods, not any synchronization operations, to dynamically identify bug suspects. It then injects corresponding delays to drive the program towards thread-unsafe behaviors, actively learns from its ability or inability to do so, and persists its learning from one test run to the next. TSVD is deployed and regularly used in Microsoft and it has already found over 1000 thread-safety violations from thousands of projects. It detects more bugs than state-of-the-art techniques, mostly with just one test run.",Concurrency bugs | Debugging | Reliability | Scalability | Thread-safety violation,44,0,,,NSF,CNS-1514256,National Science Foundation,SOSP Operating Systems
2-s2.0-85066914973,10.1145/3308558.3313600,,,Emoji-powered representation learning for cross-lingual sentiment classification,cp,Conference Paper,Chen Z.,60027550;60025778;60025038;60014966,"University of California, Los Angeles;University of Michigan, Ann Arbor;University of California, Berkeley;Peking University",Los Angeles;Ann Arbor;Berkeley;Beijing,United States;United States;United States;China,6,"Chen, Zhenpeng;Lu, Xuan;Shen, Sheng;Mei, Qiaozhu;Hu, Ziniu;Liu, Xuanzhe",57209222899;55840609300;57196278219;12241600600;57195286594;22035687800,60014966;60014966;60014966-60025038;60025778;60014966-60027550;60014966,2019-05-13,13 May 2019,"The Web Conference 2019 - Proceedings of the World Wide Web Conference, WWW 2019",,21100910900,,Conference Proceeding,,,,251-262,"Sentiment classification typically relies on a large amount of labeled data. In practice, the availability of labels is highly imbalanced among different languages, e.g., more English texts are labeled than texts in any other languages, which creates a considerable inequality in the quality of related information services received by users speaking different languages. To tackle this problem, cross-lingual sentiment classification approaches aim to transfer knowledge learned from one language that has abundant labeled examples (i.e., the source language, usually English) to another language with fewer labels (i.e., the target language). The source and the target languages are usually bridged through off-the-shelf machine translation tools. Through such a channel, cross-language sentiment patterns can be successfully learned from English and transferred into the target languages. This approach, however, often fails to capture sentiment knowledge specific to the target language, and thus compromises the accuracy of the downstream classification task. In this paper, we employ emojis, which are widely available in many languages, as a new channel to learn both the cross-language and the language-specific sentiment patterns. We propose a novel representation learning method that uses emoji prediction as an instrument to learn respective sentiment-aware representations for each language. The learned representations are then integrated to facilitate cross-lingual sentiment classification. The proposed method demonstrates state-of-the-art performance on benchmark datasets, which is sustained even when sentiment labels are scarce.",Cross-lingual analysis | Emoji | Sentiment classification,46,0,repositoryam,Green,NSF,1131500,National Science Foundation,WWW World Wide Web
2-s2.0-85071934264,10.1145/3338906.3338911,,,"Empirical review of Java program repair tools: A large-scale experiment on 2,141 bugs and 23,551 repair attempts",cp,Conference Paper,Durieux T.,60106051;60027663;115043473,Universidade de Lisboa;Université Polytechnique Hauts-de-France;Federal University of Uberl�ndia,Lisbon;Valenciennes;,Portugal;France;Brazil,4,"Durieux, Thomas;Madeiral, Fernanda;Martinez, Matias;Abreu, Rui",57189692747;57203243249;55938368500;16479696600,60106051;115043473;60027663;60106051,2019-08-12,12 August 2019,ESEC/FSE 2019 - Proceedings of the 2019 27th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21100927970,,Conference Proceeding,,,,302-313,"In the past decade, research on test-suite-based automatic program repair has grown significantly. Each year, new approaches and implementations are featured in major software engineering venues. However, most of those approaches are evaluated on a single benchmark of bugs, which are also rarely reproduced by other researchers. In this paper, we present a large-scale experiment using 11 Java test-suite-based repair tools and 2,141 bugs from 5 benchmarks. Our goal is to have a better understanding of the current state of automatic program repair tools on a large diversity of benchmarks. Our investigation is guided by the hypothesis that the repairability of repair tools might not be generalized across different benchmarks. We found that the 11 tools 1) are able to generate patches for 21% of the bugs from the 5 benchmarks, and 2) have better performance on Defects4J compared to other benchmarks, by generating patches for 47% of the bugs from Defects4J compared to 10-30% of bugs from the other benchmarks. Our experiment comprises 23,551 repair attempts, which we used to find causes of non-patch generation. These causes are reported in this paper, which can help repair tool designers to improve their approaches and tools.",Automatic program repair | Benchmark overfitting | Patch generation,81,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-85131934742,10.1145/3290605.3300416,,,Engagement with Mental Health Screening on Mobile Devices: Results from an Antenatal Feasibility Study,cp,Conference Paper,Doherty K.,60098463;60015150;60011149,Microsoft Research Cambridge;Imperial College London;Trinity College Dublin,Cambridge;London;Dublin,United Kingdom;United Kingdom;Ireland,6,"Doherty, Kevin;Cohn, Martin;Mastellos, Nikolaos;Morrison, Cecily;Car, Josip;Doherty, Gavin",57192910271;57218288498;55834611400;57211159610;6701783618;13006308800,60011149;60015150;60015150;60098463;60015150;60011149,2019-01-01,2019,Conference on Human Factors in Computing Systems - Proceedings,,21101091993,,Conference Proceeding,2019-January,,,,"Perinatal depression (PND) affects up to 15% of women within the United Kingdom and has a lasting impact on a woman's quality of life, birth outcomes and her child's development. Suicide is the leading cause of maternal mortality. However, it is estimated that at least 50% of PND cases go undiagnosed. This paper presents the results of the first feasibility study to examine the potential of mobile devices to engage women in antenatal mental health screening. Using a mobile application, 254 women attending 14 National Health Service midwifery clinics provided 2,280 momentary and retrospective reports of their wellbeing over a 9-month period. Women spoke positively of the experience, installing and engaging with this technology regardless of age, education, wellbeing, number of children, marital or employment status, or past diagnosis of depression. 39 women reported a risk of depression, self-harm or suicide; two-Thirds of whom were not identified by screening in-clinic.",EMA | Mental Health | Mobile Devices | Pregnancy | Psychological Wellbeing | Public Health Screening | Self-Report,30,1,repositoryvor,Green,NIHR,15IC2687,National Institute for Health and Care Research,CHI Human-Computer Interaction
2-s2.0-85082167172,10.1145/3300061.3345443,,,FLUID: Flexible User Interface Distribution for Ubiquitous Multi-device Interaction,cp,Conference Paper,Oh S.,60032144;60032083,"Korea Advanced Institute of Science and Technology;University at Buffalo, The State University of New York",Daejeon;Buffalo,South Korea;United States,7,"Oh, Sangeun;Kim, Ahyeon;Lee, Sunjae;Lee, Kilho;Jeong, Dae R.;Ko, Steven Y.;Shi, Insik",56043026700;57741699300;57740906600;55923454800;57195200658;8988690800;7103409230,60032144;60032144;60032144;60032144;60032144;60032083;60032144,2019-01-01,2019,"Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM",,21101091991,,Conference Proceeding,2019-January,,,,"The growing trend of multi-device ownerships creates a need and an opportunity to use applications across multiple devices. However, in general, the current app development and usage still remain within the single-device paradigm, falling far short of user expectations. For example, it is currently not possible for a user to dynamically partition an existing live streaming app with chatting capabilities across different devices, such that she watches her favorite broadcast on her smart TV while real-time chatting on her smartphone. In this paper, we present FLUID, a new Android-based multi-device platform that enables innovative ways of using multiple devices. FLUID aims to i) allow users to migrate or replicate individual user interfaces (UIs) of a single app on multiple devices (high flexibility), ii) require no additional development effort to support unmodified, legacy applications (ease of development), and iii) support a wide range of apps that follow the trend of using custom-made UIs (wide applicability). Previous approaches, such as screen mirroring, app migration, and customized apps utilizing multiple devices, do not satisfy those goals altogether. FLUID, on the other hand, meets the goals by carefully analyzing which UI states are necessary to correctly render UI objects, deploying only those states on different devices, supporting cross-device function calls transparently, and synchronizing the UI states of replicated UI objects across multiple devices. Our evaluation with 20 unmodified, real-world Android apps shows that FLUID can transparently support a wide range of apps and is fast enough for interactive use.",Multi-device Mobile Platform | Multi-surface Computing | User Interface Distribution,16,1,publisherfree2read,Bronze,NSF,CNS-1350883,National Science Foundation,MOBICOM Mobile
2-s2.0-85074000994,10.14778/3329772.3329775,,,"Fine grained, secure and efficient data provenance on blockchain systems",cp,Conference Paper,Ruan P.,60017161;60016835;60003970,National University of Singapore;Beijing Institute of Technology;Zhejiang University,Singapore City;Beijing;Hangzhou,Singapore;China;China,6,"Ruan, Pingcheng;Chen, Gang;Dinh, Tien Tuan Anh;Lin, Qian;Ooi, Beng Chin;Zhang, Meihui",57208146225;57114035800;57188754045;35759480300;55665418900;55800437300,60017161;60003970;60017161;60017161;60017161;60016835,2018-01-01,2018,Proceedings of the VLDB Endowment,,21100199855,21508097,Conference Proceeding,12,9,,975-988,"The success of Bitcoin and other cryptocurrencies bring enormous interest to blockchains. A blockchain system implements a tamper-evident ledger for recording transactions that modify some global states. The system captures entire evolution history of the states. The management of that history, also known as data provenance or lineage, has been studied extensively in database systems. However, querying data history in existing blockchains can only be done by replaying all transactions. This approach is applicable to large-scale, offline analysis, but is not suitable for online transaction processing. We present LineageChain, a fine-grained, secure and efficient provenance system for blockchains. LineageChain exposes provenance information to smart contracts via simple and elegant interfaces, thereby enabling a new class of blockchain applications whose execution logics depend on provenance information at runtime. LineageChain captures provenance during contract execution, and efficiently stores it in a Merkle tree. LineageChain provides a novel skip list index designed for supporting efficient provenance query processing. We have implemented LineageChain on top of Hyperledger and a blockchain-optimized storage system called ForkBase. Our extensive evaluation of LineageChain demonstrates its benefits to the new class of blockchain applications, its efficient query, and its small storage overhead.",,103,0,,,,undefined,,VLDB Databases
2-s2.0-85071946902,10.1145/3338906.3338920,,,Generating automated and online test oracles for Simulink models with continuous and uncertain behaviors,cp,Conference Paper,Menghi C.,60072562,University of Luxembourg,Esch-sur-Alzette,Luxembourg,4,"Menghi, Claudio;Nejati, Shiva;Gaaloul, Khouloud;Briand, Lionel C.",55532052400;18038340600;57217902396;7006613079,60072562;60072562;60072562;60072562,2019-08-12,12 August 2019,ESEC/FSE 2019 - Proceedings of the 2019 27th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21100927970,,Conference Proceeding,,,,27-38,"Test automation requires automated oracles to assess test outputs. For cyber physical systems (CPS), oracles, in addition to be automated, should ensure some key objectives: (i) they should check test outputs in an online manner to stop expensive test executions as soon as a failure is detected; (ii) they should handle time- and magnitude-continuous CPS behaviors; (iii) they should provide a quantitative degree of satisfaction or failure measure instead of binary pass/fail outputs; and (iv) they should be able to handle uncertainties due to CPS interactions with the environment. We propose an automated approach to translate CPS requirements specified in a logic-based language into test oracles specified in Simulink - a widely-used development and simulation language for CPS. Our approach achieves the objectives noted above through the identification of a fragment of Signal First Order logic (SFOL) to specify requirements, the definition of a quantitative semantics for this fragment and a sound translation of the fragment into Simulink. The results from applying our approach on 11 industrial case studies show that: (i) our requirements language can express all the 98 requirements of our case studies; (ii) the time and effort required by our approach are acceptable, showing potentials for the adoption of our work in practice, and (iii) for large models, our approach can dramatically reduce the test execution time compared to when test outputs are checked in an offline manner.",Cyber Physical Systems | Monitoring | Signal Logic | Test Oracle,38,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-85069000810,10.1109/ICSE.2019.00078,,,Going Farther Together: The Impact of Social Capital on Sustained Participation in Open Source,cp,Conference Paper,Qiu H.S.,60068856;60032882;60027950;60016747,Tartu Ülikool;Technische Universiteit Eindhoven;Carnegie Mellon University;Bryn Mawr College,Tartu;Eindhoven;Pittsburgh;Bryn Mawr,Estonia;Netherlands;United States;United States,5,"Qiu, Huilian Sophie;Nolte, Alexander;Brown, Anita;Serebrenik, Alexander;Vasilescu, Bogdan",57211019535;36608840400;57212395973;8987563200;42062536300,60027950;60068856;60016747;60032882;60027950,2019-05-01,May 2019,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2019-May,,8812044,688-699,"Sustained participation by contributors in opensource software is critical to the survival of open-source projects and can provide career advancement benefits to individual contributors. However, not all contributors reap the benefits of open-source participation fully, with prior work showing that women are particularly underrepresented and at higher risk of disengagement. While many barriers to participation in open-source have been documented in the literature, relatively little is known about how the social networks that open-source contributors form impact their chances of long-term engagement. In this paper we report on a mixed-methods empirical study of the role of social capital (i.e., the resources people can gain from their social connections) for sustained participation by women and men in open-source GitHub projects. After combining survival analysis on a large, longitudinal data set with insights derived from a user survey, we confirm that while social capital is beneficial for prolonged engagement for both genders, women are at disadvantage in teams lacking diversity in expertise.",gender | open source software | social capital,79,0,repositoryam,Green,,undefined,Alfred P. Sloan Foundation,ICSE Software Engineering
2-s2.0-85067623743,10.1145/3290605.3300810,,,Guerilla warfare and the use of new (and some old) technology: Lessons from FARC-EP’s armed struggle in Colombia,cp,Conference Paper,De Castro Leal D.,60024260;100428319,Universität Siegen;International Institute for Socio-Informatics,Siegen;Bonn,Germany;Germany,5,"De Castro Leal, Débora;Krueger, Max;Misaki, Kaoru;Randall, David;Wulf, Volker",57207776098;57209399859;55620528100;7202208815;55072850600,60024260;60024260;100428319;60024260;60024260,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"Studying armed political struggles from a CSCW perspective can throw the complex interactions between culture, technology, materiality and political conflict into sharp relief. Such studies highlight interrelations that otherwise remain under-remarked upon, despite their severe consequences. The present paper provides an account of the armed struggle of one of the Colombian guerrillas, FARC-EP, with the Colombian army. We document how radio-based communication became a crucial, but ambiguous infrastructure of war. The sudden introduction of localization technologies by the Colombian army presented a lethal threat to the guerrilla group. Our interviewees report a severe learning process to diminish this new risk, relying on a combination of informed beliefs and significant technical understanding. We end with a discussion of the role of HCI in considerations of ICT use in armed conflicts and introduce the concept of counter-appropriation as process of adapting one's practices to other's appropriation of technology in conflict.",Appropriation | Infrastructure | Political conflict | War,12,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85090804544,,,,How to combine tree-search methods in reinforcement learning,cp,Conference Paper,Efroni Y.,60022403;60017576,Technion - Israel Institute of Technology;INRIA Nancy,Haifa;Villers-les-Nancy,Israel;France,4,"Efroni, Yonathan;Dalal, Gal;Scherrer, Bruno;Mannor, Shie",57195997846;57016742800;55903675600;8218747000,60022403;60022403;60017576;60022403,2019-01-01,2019,"33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019",,21101021490,,Conference Proceeding,,,,3494-3501,"Finite-horizon lookahead policies are abundantly used in Reinforcement Learning and demonstrate impressive empirical success. Usually, the lookahead policies are implemented with specific planning methods such as Monte Carlo Tree Search (e.g. in AlphaZero (Silver et al. 2017b)). Referring to the planning problem as tree search, a reasonable practice in these implementations is to back up the value only at the leaves while the information obtained at the root is not leveraged other than for updating the policy. Here, we question the potency of this approach. Namely, the latter procedure is non-contractive in general, and its convergence is not guaranteed. Our proposed enhancement is straightforward and simple: use the return from the optimal tree path to back up the values at the descendants of the root. This leads to a ?h-contracting procedure, where ? is the discount factor and h is the tree depth. To establish our results, we first introduce a notion called multiple-step greedy consistency. We then provide convergence rates for two algorithmic instantiations of the above enhancement in the presence of noise injected to both the tree search stage and value estimation stage.",,9,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-85067626167,10.1145/3290605.3300295,,,Increasing the transparency of research papers with explorable multiverse analyses,cp,Conference Paper,Dragicevic P.,60025778;60016849;60013373;60001422,"University of Michigan, Ann Arbor;University of Toronto;INRIA Institut National de Recherche en Informatique et en Automatique;Sorbonne Université",Ann Arbor;Toronto;Le Chesnay;Paris,United States;Canada;France;France,5,"Dragicevic, Pierre;Jansen, Yvonne;Sarma, Abhraneel;Kay, Matthew;Chevalier, Fanny",55906779900;34880075700;57194278146;55389474000;18834382100,60013373;60001422;60025778;60025778;60016849,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"We present explorable multiverse analysis reports, a new approach to statistical reporting where readers of research papers can explore alternative analysis options by interacting with the paper itself. This approach draws from two recent ideas: i) multiverse analysis, a philosophy of statistical reporting where paper authors report the outcomes of many different statistical analyses in order to show how fragile or robust their findings are; and ii) explorable explanations, narratives that can be read as normal explanations but where the reader can also become active by dynamically changing some elements of the explanation. Based on five examples and a design space analysis, we show how combining those two ideas can complement existing reporting approaches and constitute a step towards more transparent research papers.",Explorable explanation | Interactive documents | Multiverse analysis | Statistics | Transparent reporting,63,0,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85069541967,10.1145/3299869.3319901,,,Interventional fairness: Causal database repair for algorithmic fairness,cp,Conference Paper,Salimi B.,60015481,University of Washington,Seattle,United States,4,"Salimi, Babak;Rodriguez, Luke;Howe, Bill;Suciu, Dan",56382337200;57205683649;57203255530;7006812452,60015481;60015481;60015481;60015481,2019-06-25,25 June 2019,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,793-810,"Fairness is increasingly recognized as a critical component of machine learning systems. However, it is the underlying data on which these systems are trained that often reflect discrimination, suggesting a database repair problem. Existing treatments of fairness rely on statistical correlations that can be fooled by statistical anomalies, such as Simpson's paradox. Proposals for causality-based definitions of fairness can correctly model some of these situations, but they require specification of the underlying causal models. In this paper, we formalize the situation as a database repair problem, proving sufficient conditions for fair classifiers in terms of admissible variables as opposed to a complete causal model. We show that these conditions correctly capture subtle fairness violations. We then use these conditions as the basis for database repair algorithms that provide provable fairness guarantees about classifiers trained on their training labels. We evaluate our algorithms on real data, demonstrating improvement over the state of the art on multiple fairness metrics proposed in the literature while retaining high utility.",,101,1,publisherfree2read,Bronze,NSF,AITF 1535565,National Science Foundation,PODS Databases
2-s2.0-85067617165,10.1145/3290605.3300264,,,Investigating slowness as a frame to design longer-term experiences with personal data: A field study of olly,cp,Conference Paper,Odom W.,60032882;60018491,Technische Universiteit Eindhoven;Simon Fraser University,Eindhoven;Burnaby,Netherlands;Canada,7,"Odom, William;Wakkary, Ron;Hol, Jeroen;Naus, Bram;Verburg, Pepijn;Amram, Tal;Yo Sue Chen, Amy",6701770018;9633977700;57202051329;57202050578;57202047530;57209394357;57209310043,60018491;60018491-60032882;60032882;60032882;60032882;60018491;60018491,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"We describe the design and deployment of Olly, a domestic music player that enables people to re-experience digital music they listened to in the past. Olly uses its owner’s Last.FM listening history metadata archive to occasionally select a song from their past, but offers no user control over what is selected or when. We deployed Olly in 3 homes for 15 months to explore how its slow pace might support experiences of reflection and reminiscence. Findings revealed that Olly became highly integrated in participants lives with sustained engagement over time. They drew on Olly to reflect on past life experiences and reactions indicated an increase in perceived value of their Last.FM archive. Olly also provoked reflections on the temporalities of personal data and technology. Findings are interpreted to present opportunities for future HCI research and practice.",Digital music | Home | Personal data | Research through design | Slow technology | Temporality,49,0,,,NSERC,undefined,Natural Sciences and Engineering Research Council of Canada,CHI Human-Computer Interaction
2-s2.0-85067684275,10.1145/3314221.3314598,,,Low-latency graph streaming using compressed purely-functional trees,cp,Conference Paper,Dhulipala L.,60027950;60006320,Carnegie Mellon University;MIT Computer Science &amp; Artificial Intelligence Laboratory,Pittsburgh;Cambridge,United States;United States,3,"Dhulipala, Laxman;Blelloch, Guy E.;Shun, Julian",56278340900;7004515491;36816733200,60027950;60027950;60006320,2019-06-08,8 June 2019,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,918-934,"There has been a growing interest in the graph-streaming setting where a continuous stream of graph updates is mixed with graph queries. In principle, purely-functional trees are an ideal fit for this setting as they enable safe parallelism, lightweight snapshots, and strict serializability for queries. However, directly using them for graph processing leads to significant space overhead and poor cache locality. This paper presents C -trees, a compressed purely-functional search tree data structure that significantly improves on the space usage and locality of purely-functional trees. We design theoretically-efficient and practical algorithms for performing batch updates to C -trees, and also show that we can store massive dynamic real-world graphs using only a few bytes per edge, thereby achieving space usage close to that of the best static graph processing frameworks. To study the applicability of our data structure, we designed Aspen, a graph-streaming framework that extends the interface of Ligra with operations for updating graphs. We show that Aspen is faster than two state-of-the-art graph-streaming systems, Stinger and LLAMA, while requiring less memory, and is competitive in performance with the state-of-the-art static graph frameworks, Galois, GAP, and Ligra+. With Aspen, we are able to efficiently process the largest publicly-available graph with over two hundred billion edges in the graph-streaming setting using a single commodity multicore server with 1TB of memory.",Parallel graph algorithms | Purely-functional data structures | Streaming graph processing,73,1,repositoryam,Green,NSF,1408940,National Science Foundation,PLDI Programming Languages
2-s2.0-85078476851,10.1109/FOCS.2019.00037,,,Lower Bounds for Maximal Matchings and Maximal Independent Sets,cp,Conference Paper,Balliu A.,60103653;60025858;60001422,Aalto University;ETH Zürich;Sorbonne Université,Espoo;Zurich;Paris,Finland;Switzerland;France,6,"Balliu, Alkida;Brandt, Sebastian;Hirvonen, Juho;Olivetti, Dennis;Rabie, Mikael;Suomela, Jukka",56511987000;57023104900;55317405300;56512196900;57217656705;56186283100,60103653;60025858;60103653;60103653;60103653-60001422;60103653,2019-11-01,November 2019,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2019-November,,8948588,481-497,"There are distributed graph algorithms for finding maximal matchings and maximal independent sets in O(Δ + log∗ n) communication rounds; here n is the number of nodes and Δ is the maximum degree. The lower bound by Linial (1987, 1992) shows that the dependency on n is optimal: These problems cannot be solved in o(log∗ n) rounds even if Δ = 2. However, the dependency on Δ is a long-standing open question, and there is currently an exponential gap between the upper and lower bounds. We prove that the upper bounds are tight. We show that maximal matchings and maximal independent sets cannot be found in o(Δ + log log n / log log log n) rounds with any randomized algorithm in the LOCAL model of distributed computing. As a corollary, it follows that there is no deterministic algorithm for maximal matchings or maximal independent sets that runs in o(Δ + log n / log log n) rounds; this is an improvement over prior lower bounds also as a function of n.",distributed graph algorithms | lower bounds | maximal independent set | Maximal matching,48,0,repositoryam,Green,,undefined,,FOCS Theory
2-s2.0-85067620679,10.1145/3290605.3300723,,,Managerial visions stories of upgrading and maintaining the public restroom with IoT,cp,Conference Paper,Fox S.E.,60030612;60015481,"University of California, San Diego;University of Washington",La Jolla;Seattle,United States;United States,3,"Fox, Sarah E.;Sobel, Kiley;Rosner, Daniela K.",56277993800;57014925700;23009944700,60030612;60015481;60015481,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"This paper examines the entangled development of governance strategies and networked technologies in the pervasive but under-examined domain of public restrooms. Drawing on a mix of archival materials, participant observation, and interviews within and beyond the city of Seattle, Washington, we look at the motivations of public restroom facilities managers as they introduce (or consider introducing) networked technology in the spaces they administer. Over the course of the research, we found internet of things technologies—or, connected devices imbued with computational capacity—became increasingly tied up with cost-reducing efficiencies and exploitative regulatory techniques. Drawing from this case study, we develop the concept of managerial visions: ways of seeing that structure labor, enforce compliance, and define access to resources. We argue that these ways of seeing prove increasingly critical to HCI research as it attends to computer-mediated collaboration beyond white-collar settings.",Governance | Internet of things | Restrooms,21,1,publisherfree2read,Bronze,NSF,#1423074,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85067595391,10.1145/3290605.3300500,,,Managing messes in computational notebooks,cp,Conference Paper,Head A.,60026532;60025038;60021726;60019647,"Microsoft Corporation;University of California, Berkeley;Microsoft Research;Georgia Institute of Technology",Redmond;Berkeley;Redmond;Atlanta,United States;United States;United States;United States,5,"Head, Andrew;Hohman, Fred;Barik, Titus;Drucker, Steven M.;DeLine, Robert",57156107000;57194277192;55772354200;35902233200;6602118069,60025038;60019647;60026532;60021726;60021726,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"Data analysts use computational notebooks to write code for analyzing and visualizing data. Notebooks help analysts iteratively write analysis code by letting them interleave code with output, and selectively execute cells. However, as analysis progresses, analysts leave behind old code and outputs, and overwrite important code, producing cluttered and inconsistent notebooks. This paper introduces code gathering tools, extensions to computational notebooks that help analysts fnd, clean, recover, and compare versions of code in cluttered, inconsistent notebooks. The tools archive all versions of code outputs, allowing analysts to review these versions and recover the subsets of code that produced them. These subsets can serve as succinct summaries of analysis activity or starting points for new analyses. In a qualitative usability study, 12 professional analysts found the tools useful for cleaning notebooks and writing analysis code, and discovered new ways to use them, like generating personal documentation and lightweight versioning.",Clutter | Code history | Computational notebooks | Exploratory programming | Inconsistency | Messes | Program slicing,87,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85078449591,10.1109/FOCS.2019.00039,,,NEEXP is Contained in MIP,cp,Conference Paper,Natarajan A.,60031581,California Institute of Technology,Pasadena,United States,2,"Natarajan, Anand;Wright, John",57189601263;57206755699,60031581;60031581,2019-11-01,November 2019,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2019-November,,8948641,510-518,"We study multiprover interactive proof systems. The power of classical multiprover interactive proof systems, in which the provers do not share entanglement, was characterized in a famous work by Babai, Fortnow, and Lund (Computational Complexity 1991), whose main result was the equality MIP = NEXP. The power of quantum multiprover interactive proof systems, in which the provers are allowed to share entanglement, has proven to be much more difficult to characterize. The best known lower-bound on MIP∗ is NEXP, due to Ito and Vidick (FOCS 2012). As for upper bounds, MIP∗ could be as large as RE, the class of recursively enumerable languages. The main result of this work is the inclusion of NEEXP (nondeterministic doubly exponential time) in MIP∗. This is an exponential improvement over the prior lower bound and shows that proof systems with entangled provers are at least exponentially more powerful than classical provers. In our protocol the verifier delegates a classical, exponentially large MIP protocol for NEEXP to two entangled provers: The provers obtain their exponentially large questions by measuring their shared state, and use a classical PCP to certify the correctness of their exponentially-long answers. For the soundness of our protocol, it is crucial that each player should not only sample its own question correctly but also avoid performing measurements that would reveal the other player's sampled question. We ensure this by commanding the players to perform a complementary measurement, relying on the Heisenberg uncertainty principle to prevent the forbidden measurements from being performed.",complexity theory | multiprover interactive proof systems | Nonlocal games | pcp theorem | quantum computing,16,0,repositoryam,Green,NSF,CCF-1452616,National Science Foundation,FOCS Theory
2-s2.0-85066898170,10.1145/3308558.3313665,,,Outguard: Detecting in-browser covert cryptocurrency mining in the wild,cp,Conference Paper,Kharraz A.,60019647;60000745,Georgia Institute of Technology;University of Illinois Urbana-Champaign,Atlanta;Urbana,United States;United States,9,"Kharraz, Amin;Lever, Charles;Borisov, Nikita;Ma, Zane;Mason, Joshua;Antonakakis, Manos;Murley, Paul;Miller, Andrew;Bailey, Michael",56429420600;57062562400;24175615000;57194208426;57194212279;34972742700;57209223587;56026126700;8442510000,60000745;60019647;60000745;60000745;60000745;60019647;60000745;60000745;60000745,2019-05-13,13 May 2019,"The Web Conference 2019 - Proceedings of the World Wide Web Conference, WWW 2019",,21100910900,,Conference Proceeding,,,,840-852,"In-browser cryptojacking is a form of resource abuse that leverages end-users' machines to mine cryptocurrency without obtaining the users' consent. In this paper, we design, implement, and evaluate Outguard, an automated cryptojacking detection system. We construct a large ground-truth dataset, extract several features using an instrumented web browser, and ultimately select seven distinctive features that are used to build an SVM classification model. Outguardachieves a 97.9% TPR and 1.1% FPR and is reasonably tolerant to adversarial evasions. We utilized Outguardin the wild by deploying it across the Alexa Top 1M websites and found 6,302 cryptojacking sites, of which 3,600 are new detections that were absent from the training data. These cryptojacking sites paint a broad picture of the cryptojacking ecosystem, with particular emphasis on the prevalence of cryptojacking websites and the shared infrastructure that provides clues to the operators behind the cryptojacking phenomenon.",Browser Security | Cryptojacking | Web Security,57,0,,,NSF,CNS-1518741,National Science Foundation,WWW World Wide Web
2-s2.0-85067616328,10.1145/3290605.3300879,,,Online grocery delivery services: An Opportunity to Address Food Disparities in Transportation-scarce Areas,cp,Conference Paper,Dillahunt T.R.,60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,3,"Dillahunt, Tawanna R.;Simioni, Sylvia;Xu, Xuecong",34881486000;57202044661;57195428144,60025778;60025778;60025778,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"Online grocery delivery services present new opportunities to address food disparities, especially in underserved areas. However, such services have not been systematically evaluated. This study evaluates such services’ potential to provide healthy-food access and infuence healthy-food purchases among individuals living in transportation-scarce and low-resource areas. We conducted a pilot experiment with 20 participants consisting of a randomly assigned group’s 1-month use of an online grocery delivery service, and a control group’s 1-month collection of grocery receipts, and a set of semi-structured interviews. We found that online grocery delivery services (a) serve as a feasible model to healthy-food access if they are afordable and amenable to multiple payment forms and (b) could lead to healthier selections. We contribute policy recommendations to bolster afordability of healthy-food access and design opportunities to promote healthy foods to support the adoption and use of these services among low-resource and transportation-scarce groups.",Food disparities | Health | Online grocery delivery,23,1,publisherfree2read,Bronze,NSF,CMMI 1636876,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85067695736,10.1145/3314221.3314614,,,Optimization and abstraction: A synergistic approach for analyzing neural network robustness,cp,Conference Paper,Anderson G.,60013372;60005286,The University of Texas at Austin;Rice University,Austin;Houston,United States;United States,4,"Anderson, Greg;Dillig, Isil;Pailoor, Shankara;Chaudhuri, Swarat",57203282495;22936636100;57209417506;8727948900,60013372;60013372;60013372;60005286,2019-06-08,8 June 2019,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,731-744,"In recent years, the notion of local robustness (or robustness for short) has emerged as a desirable property of deep neural networks. Intuitively, robustness means that small perturbations to an input do not cause the network to perform misclas-sifications. In this paper, we present a novel algorithm for verifying robustness properties of neural networks. Our method synergistically combines gradient-based optimization methods for counterexample search with abstraction-based proof search to obtain a sound and (δ-)complete decision procedure. Our method also employs a data-driven approach to learn a verification policy that guides abstract interpretation during proof search. We have implemented the proposed approach in a tool called Charon and experimentally evaluated it on hundreds of benchmarks. Our experiments show that the proposed approach significantly outperforms three state-of-the-art tools, namely AI2, Reluplex, and Reluval.",Abstract Interpretation | Machine learning | Optimization | Robustness,68,0,repositoryam,Green,NSF,CCF-1162076,National Science Foundation,PLDI Programming Languages
2-s2.0-85071172375,10.1145/3292500.3330829,,,Optimizing impression counts for outdoor advertising,cp,Conference Paper,Zhang Y.,60029306;60018933;60011362;123045391,Wuhan University;Singapore Management University;RMIT University;Huawei,Wuhan;Singapore City;Melbourne;,China;Singapore;Australia;,5,"Zhang, Yipeng;Li, Yuchen;Bao, Zhifeng;Mo, Songsong;Zhang, Ping",57202339454;56819149900;23388282400;57203201829;57196218034,60011362;60018933;60011362;60029306;123045391,2019-07-25,25 July 2019,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,21100925601,,Conference Proceeding,,,,1205-1215,"In this paper we propose and study the problem of optimizing the influence of outdoor advertising (ad) when impression counts are taken into consideration. Given a database U of billboards, each of which has a location and a non-uniform cost, a trajectory database T and a budget B, it aims to find a set of billboards that has the maximum influence under the budget. In line with the advertising consumer behavior studies, we adopt the logistic function to take into account the impression counts of an ad (placed at different billboards) to a user trajectory when defining the influence measurement. However, this poses two challenges: (1) our problem is NP-hard to approximate within a factor of O(|T |1-e) for any e > 0 in polynomial time; (2) the influence measurement is non-submodular, which means a straightforward greedy approach is not applicable. Therefore, we propose a tangent line based algorithm to compute a submodular function to estimate the upper bound of influence. Henceforth, we introduce a branch-and-bound framework with a ?-termination condition, achieving ?2 (1 - 1/e) approximation ratio. However, this framework is time-consuming when |U| is huge. Thus, we further optimize it with a progressive pruning upper bound estimation approach which achieves ?2 (1 - 1/e - ?) approximation ratio and significantly decreases the running-time. We conduct the experiments on real-world billboard and trajectory datasets, and show that the proposed approaches outperform the baselines by 95% in effectiveness. Moreover, the optimized approach is around two orders of magnitude faster than the original framework.",Influence Maximization | Logistic Function | Moving Trajectory | Non-submodularity | Outdoor Advertising,19,0,repositoryvor,Green,ARC,DP170102726,Google,KDD Data Mining
2-s2.0-85067615054,10.1145/3290605.3300625,,,PICME: Interactive visual guidance for taking requested photo composition,cp,Conference Paper,Kim M.,60032144;112698644,"Korea Advanced Institute of Science and Technology;KAI, Inc.",Daejeon;Austin,South Korea;United States,2,"Kim, Minju;Lee, Jungjin",56918768900;55697060800,60032144;112698644,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"PicMe is a mobile application that provides interactive onscreen guidance that helps the user take pictures of a composition that another person requires. Once the requester captures a picture of the desired composition and delivers it to the user (photographer), a 2.5D guidance system, called the virtual frame, guides the user in real-time by showing a three-dimensional composition of the target image (i.e., size and shape). In addition, according to the matching accuracy rate, we provide a small-sized target image in an inset window as feedback and edge visualization for further alignment of the detail elements. We implemented PicMe to work fully in mobile environments. We then conducted a preliminary user study to evaluate the effectiveness of PicMe compared to traditional 2D guidance methods. The results show that PicMe helps users reach their target images more accurately and quickly by giving participants more confidence in their tasks.",Interactive visual guidance | Mobile application | Photo composition | Photography assistance,8,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85067601249,10.1145/3290605.3300292,,,Project Sidewalk: A Web-based Crowdsourcing Tool for Collecting Sidewalk Accessibility Data at Scale,cp,Conference Paper,Saha M.,60025778;60020304;60018933;60015481;100802385,"University of Michigan, Ann Arbor;University of Maryland, College Park;Singapore Management University;University of Washington;Montgomery Blair High School",Ann Arbor;College Park;Singapore City;Seattle;Silver Spring,United States;United States;Singapore;United States;United States,11,"Saha, Manaswi;Saugstad, Michael;Maddali, Hanuma Teja;Zeng, Aileen;Holland, Ryan;Bower, Steven;Dash, Aditya;Chen, Sage;Li, Anthony;Hara, Kotaro;Froehlich, Jon",57200500825;57200496064;57200498178;57209397514;57209393870;57209395049;57209395645;57200504876;57200498825;55498092800;7101665384,60015481;60015481;60015481-60020304;60015481;100802385;60020304;60020304;60025778;60020304;60018933;60015481,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"We introduce Project Sidewalk, a new web-based tool that enables online crowdworkers to remotely label pedestrian-related accessibility problems by virtually walking through city streets in Google Street View. To train, engage, and sustain users, we apply basic game design principles such as interactive onboarding, mission-based tasks, and progress dashboards. In an 18-month deployment study, 797 online users contributed 205,385 labels and audited 2,941 miles of Washington DC streets. We compare behavioral and labeling quality differences between paid crowdworkers and volunteers, investigate the effects of label type, label severity, and majority vote on accuracy, and analyze common labeling errors. To complement these findings, we report on an interview study with three key stakeholder groups (N=14) soliciting reactions to our tool and methods. Our findings demonstrate the potential of virtually auditing urban accessibility and highlight tradeoffs between scalability and quality compared to traditional approaches.",Accessibility | Crowdsourcing | GIS | Mobility impairments,80,0,repositoryvor,Green,NSF,IIS-1302338,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85067603081,10.1145/3290605.3300875,,,"Protection, productivity and pleasure in the smart home emerging expectations and gendered insights from Australian early adopters",cp,Conference Paper,Strengers Y.,60033010;60019578;60011362,Intel Corporation;Monash University;RMIT University,Santa Clara;Clayton;Melbourne,United States;Australia;Australia,5,"Strengers, Yolande;Kennedy, Jenny;Arcari, Paula;Nicholls, Larissa;Gregg, Melissa",6506783906;56660196300;22956874600;55932888200;16021588200,60019578;60011362;60011362;60011362;60033010,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"Interest and uptake of smart home technologies has been lower than anticipated, particularly among women. Reporting on an academic-industry partnership, we present findings from an ethnographic study with 31 Australian smart home early adopters. The paper analyses these households’ experiences in relation to three concepts central to Intel’s ambient computing vision for the home: protection, productivity and pleasure, or ‘the 3Ps’. We find that protection is a form of caregiving; productivity provides ‘small conveniences’, energy savings and multitasking possibilities; and pleasure is derived from ambient and aesthetic features, and the joy of ‘playing around’ with tech. Our analysis identifies three design challenges and opportunities for the smart home: internal threats to household protection; feminine desires for the smart home; and increased ‘digital housekeeping’. We conclude by suggesting how HCI designers can and should respond to these gendered challenges.",Ethnography | Gender/Identity | Home | Smart environments/Connected home,81,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85068228094,10.1109/INFOCOM.2019.8737419,,,RF-Mehndi: A Fingertip Profiled RF Identifier,cp,Conference Paper,Zhao C.,60117751;60018308;60013983;60003970;122780386;122779994,"College of Computer Science and Technology, Zhejiang University;Xi'an Jiaotong University;City University of Hong Kong;Zhejiang University;Ministry of Education Key Lab for Intelligent Netwroks and Network Security;Shaanxi Provincial Key Laboratory of Computer Network",Hangzhou;Xi'an;Hong Kong;Hangzhou;;,China;China;Hong Kong;China;China;China,7,"Zhao, Cui;Li, Zhenjiang;Liu, Ting;Ding, Han;Han, Jinsong;Xi, Wei;Gui, Ruowei",57204183726;55707061900;55835301800;57208503757;8869746900;36505197000;57204825447,60018308-122780386-122779994;60013983;60018308-122780386;60018308;60117751-60003970;60018308;60018308-122779994,2019-04-01,April 2019,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2019-April,,8737419,1513-1521,"This paper presents RF-Mehndi, a passive commercial RFID tag array formed identifier. The key RF-Mehndi novelty is that when the user's fingertip touching on the tag array surface during the communication, the backscattered signals by the tag array become user-dependent and unique. Hence, if we enhance the communication modality of many personal cards nowadays by RF-Mehndi, in case that a card gets lost or stolen, it cannot be used illegally by the adversaries. To harvest such a benefit, we have two key observations in designing RF-Mehndi. The first observation is when tags are nearby, their interrogated currents can change each other's circuit characteristics, based on which unique phase features can be obtained from backscattered signals. The second observation is that when the user's fingertip touches the tag array surface during communication, the phase feature can be further profiled by this user. Based on these observations, the card and its holder can be potentially authenticated at the same time. To transfer the RF-Mehndi idea to a practical system, we further address technical challenges. We implement a prototype system. Extensive evaluations show the effectiveness of RF-Mehndi, achieving excellent authentication performance.",,65,0,,,NSFC,CityU 11217817,National Natural Science Foundation of China,INFOCOM Networking
2-s2.0-85077652933,,,,Rates of convergence for sparse variational Gaussian process regression,cp,Conference Paper,Burt D.R.,60118653;60031101,Secondmind Limited;University of Cambridge,Cambridge;Cambridge,United Kingdom;United Kingdom,3,"Burt, David R.;Rasmussen, Carl Edward;van der Wilk, Mark",57213689604;7103365199;56737079800,60031101;60031101-60118653;60118653,2019-01-01,2019,"36th International Conference on Machine Learning, ICML 2019",,21100942228,,Conference Proceeding,2019-June,,,1390-1404,"Excellent variational approximations to Gaussian process posteriors have been developed which avoid the O (N3) scaling with dataset size N. They reduce the computational cost to O(NM2), with M ≪ N the number of inducing variables, which summarise the process. While the computational cost seems to be linear in N, the true complexity of the algorithm depends on how M must increase to ensure a certain quality of approximation. We show that with high probability the KL divergence can be made arbitrarily small by growing M more slowly than N. A particular case is that for regression with normally distributed inputs in D-dimensions with the Squared Exponential kernel, M = O(logD N) suffices. Our results show that as datasets grow, Gaussian process posteriors can be approximated cheaply, and provide a concrete rule for how to increase M in continual learning scenarios.",,35,0,,,SPP,undefined,Sociedade Portuguesa de Pediatria,ICML Machine Learning
2-s2.0-85067606902,10.1145/3290605.3300433,,,Retype: Quick text editing with keyboard and gaze,cp,Conference Paper,Sindhwani S.,60030480;60005686,University of Bath;The University of Auckland,Bath;Auckland,United Kingdom;New Zealand,3,"Sindhwani, Shyamli;Lutteroth, Christof;Weber, Gerald",57209394759;55928632000;57191104534,60005686;60030480;60005686,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"When a user needs to reposition the cursor during text editing, this is often done using the mouse. For experienced typists especially, the switch between keyboard and mouse can slow down the keyboard editing workflow considerably. To address this we propose ReType, a new gaze-assisted positioning technique combining keyboard with gaze input based on a new ‘patching’ metaphor. ReType allows users to perform some common editing operations while keeping their hands on the keyboard. We present the result of two studies. A free-use study indicated that ReType enhances the user experience of text editing. ReType was liked by many participants, regardless of their typing skills. A comparative user study showed that ReType is able to match or even beat the speed of mouse-based interaction for small text edits. We conclude that the gaze-augmented user interface can make common interactions more fluent, especially for professional keyboard users.",Eye gaze tracking | Keyboard | Natural user interfaces | Patching metaphor | Positioning | Text editor | Typographical error,17,0,repositoryvor,Green,EPSRC,EP/M023281/1,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-85071903950,10.1109/ICSE.2019.00103,,,Redundant Loads: A Software Inefficiency Indicator,cp,Conference Paper,Su P.,60016114;60013789;120005284,William &amp; Mary;Beihang University;Scalable Machines Research,Williamsburg;Beijing;Cupertino,United States;China;United States,5,"Su, Pengfei;Wen, Shasha;Yang, Hailong;Chabbi, Milind;Liu, Xu",57208238856;56242440800;37762426600;42860940900;56743755500,60016114;60016114;60013789;120005284;60016114,2019-05-01,May 2019,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2019-May,,8811970,982-993,"Modern software packages have become increasingly complex with millions of lines of code and references to many external libraries. Redundant operations are a common performance limiter in these code bases. Missed compiler optimization opportunities, inappropriate data structure and algorithm choices, and developers' inattention to performance are some common reasons for the existence of redundant operations. Developers mainly depend on compilers to eliminate redundant operations. However, compilers' static analysis often misses optimization opportunities due to ambiguities and limited analysis scope; automatic optimizations to algorithmic and data structural problems are out of scope. We develop LoadSpy, a whole-program profiler to pinpoint redundant memory load operations, which are often a symptom of many redundant operations. The strength of LoadSpy exists in identifying and quantifying redundant load operations in programs and associating the redundancies with program execution contexts and scopes to focus developers' attention on problematic code. LoadSpy works on fully optimized binaries, adopts various optimization techniques to reduce its overhead, and provides a rich graphic user interface, which make it a complete developer tool. Applying LoadSpy showed that a large fraction of redundant loads is common in modern software packages despite highest levels of automatic compiler optimizations. Guided by LoadSpy, we optimize several well-known benchmarks and real-world applications, yielding significant speedups.",Performance measurement | Software optimization | Tools | Whole-program profiling,25,0,repositoryam,Green,NSFC,61502019,National Natural Science Foundation of China,ICSE Software Engineering
2-s2.0-85072276957,10.1109/ICSE.2019.00027,,,Resource-Aware Program Analysis Via Online Abstraction Coarsening,cp,Conference Paper,Heo K.,60032144;60006297;60005273,Korea Advanced Institute of Science and Technology;University of Pennsylvania;Korea University,Daejeon;Philadelphia;Seoul,South Korea;United States;South Korea,3,"Heo, Kihong;Oh, Hakjoo;Yang, Hongseok",58306194500;35275738100;55153940300,60006297;60005273;60032144,2019-05-01,May 2019,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2019-May,,8812143,94-104,"We present a new technique for developing a resource-aware program analysis. Such an analysis is aware of constraints on available physical resources, such as memory size, tracks its resource use, and adjusts its behaviors during fixpoint computation in order to meet the constraint and achieve high precision. Our resource-aware analysis adjusts behaviors by coarsening program abstraction, which usually makes the analysis consume less memory and time until completion. It does so multiple times during the analysis, under the direction of what we call a controller. The controller constantly intervenes in the fixpoint computation of the analysis and decides how much the analysis should coarsen the abstraction. We present an algorithm for learning a good controller automatically from benchmark programs. We applied our technique to a static analysis for C programs, where we control the degree of flow-sensitivity to meet a constraint on peak memory consumption. The experimental results with 18 real-world programs show that our algorithm can learn a good controller and the analysis with this controller meets the constraint and utilizes available memory effectively.",learning | resource constraint | static analysis,16,0,,,MSIP,SRFC-IT1701-09,Samsung,ICSE Software Engineering
2-s2.0-85067610081,10.1145/3290605.3300497A,,,Risk vs. Restriction: The tension between providing a sense of normalcy and keeping foster teens safe online,cp,Conference Paper,Badillo-Urquiola K.,60154598;60103124,College of Engineering and Computer Science;Bentley University,Orlando;Waltham,United States;United States,3,"Badillo-Urquiola, Karla;Page, Xinru;Wisniewski, Pamela J.",56938945600;35190963300;57293685900,60154598;60103124;60154598,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"Foster youth are particularly vulnerable to offline risks; yet, little is known about their online risk experiences or how foster parents mediate technology use in the home. We conducted 29 interviews with foster parents of 42 teens (ages 13-17) who were part of the child welfare system. Foster parents faced significant challenges relating to technology mediation in the home. Based on parental accounts, over half of the foster teens encountered high-risk situations that involved interacting with unsafe people online, resulting in rape, sex trafficking, and/or psychological harm. Overall, foster parents were at a loss for how to balance online safety with technology access in a way that engendered positive relationships with their foster teens. Instead, parents often resorted to outright restriction. Our research highlights the importance of considering the unique needs of foster families and designing technologies to address the challenges faced by this vulnerable population of teens and parents.",Adolescent online safety | Foster care system | Foster parents | Parental mediation strategies,27,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85070649706,10.1109/ICSE.2019.00025,,,SMOKE: Scalable Path-Sensitive Memory Leak Detection for Millions of Lines of Code,cp,Conference Paper,Fan G.,60008592;120948372,Hong Kong University of Science and Technology;Sourcebrella Inc.,Hong Kong;,Hong Kong;China,6,"Fan, Gang;Wu, Rongxin;Shi, Qingkai;Xiao, Xiao;Zhou, Jinguo;Zhang, Charles",57202858475;55469414900;56242157100;57197586466;42162478100;7405494017,60008592;60008592;60008592;120948372;120948372;60008592,2019-05-01,May 2019,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2019-May,,8812075,72-82,"Detecting memory leak at industrial scale is still not well addressed, in spite of the tremendous effort from both industry and academia in the past decades. Existing work suffers from an unresolved paradox - a highly precise analysis limits its scalability and an imprecise one seriously hurts its precision or recall. In this work, we present SMOKE, a staged approach to resolve this paradox. In the ?rst stage, instead of using a uniform precise analysis for all paths, we use a scalable but imprecise analysis to compute a succinct set of candidate memory leak paths. In the second stage, we leverage a more precise analysis to verify the feasibility of those candidates. The ?rst stage is scalable, due to the design of a new sparse program representation, the use-?ow graph (UFG), that models the problem as a polynomial-time state analysis. The second stage analysis is both precise and ef?cient, due to the smaller number of candidates and the design of a dedicated constraint solver. Experimental results show that SMOKE can ?nish checking industrial-sized projects, up to 8MLoC, in forty minutes with an average false positive rate of 24.4%. Besides, SMOKE is signi?cantly faster than the state-of-the-art research techniques as well as the industrial tools, with the speedup ranging from 5.2X to 22.8X. In the twenty-nine mature and extensively checked benchmark projects, SMOKE has discovered thirty previously unknown memory leaks which were con?rmed by developers, and one even assigned a CVE ID.",memory leak | static bug finding | use-flow graph | value-flow graph,48,0,,,,undefined,,ICSE Software Engineering
2-s2.0-85072294337,10.1109/ICSE.2019.00055,,,Scalable Approaches for Test Suite Reduction,cp,Conference Paper,Cruciani E.,60136210;60031482;60021199;60008734,Gran Sasso Science Institute;Universidade Federal de Pernambuco;Consiglio Nazionale delle Ricerche;Vrije Universiteit Amsterdam,L'Aquila;Recife;Rome;Amsterdam,Italy;Brazil;Italy;Netherlands,4,"Cruciani, Emilio;Miranda, Breno;Verdecchia, Roberto;Bertolino, Antonia",57204144904;56405278100;57200754960;7006797074,60136210;60031482;60008734;60021199,2019-05-01,May 2019,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2019-May,,8812048,419-429,"Test suite reduction approaches aim at decreasing software regression testing costs by selecting a representative subset from large-size test suites. Most existing techniques are too expensive for handling modern massive systems and moreover depend on artifacts, such as code coverage metrics or specification models, that are not commonly available at large scale. We present a family of novel very efficient approaches for similaritybased test suite reduction that apply algorithms borrowed from the big data domain together with smart heuristics for finding an evenly spread subset of test cases. The approaches are very general since they only use as input the test cases themselves (test source code or command line input).We evaluate four approaches in a version that selects a fixed budget B of test cases, and also in an adequate version that does the reduction guaranteeing some fixed coverage. The results show that the approaches yield a fault detection loss comparable to state-of-the-art techniques, while providing huge gains in terms of efficiency. When applied to a suite of more than 500K real world test cases, the most efficient of the four approaches could select B test cases (for varying B values) in less than 10 seconds.",Clustering | Random projection | Similarity-based testing | Software testing | Test suite reduction,36,0,repositoryam,Green,H2020,731535,Horizon 2020 Framework Programme,ICSE Software Engineering
2-s2.0-85076763895,10.1145/3341301.3359641,,,Scaling symbolic evaluation for automated verification of systems code with serval,cp,Conference Paper,Nelson L.,60030162;60021726;60015481,Columbia University;Microsoft Research;University of Washington,New York;Redmond;Seattle,United States;United States;United States,6,"Nelson, Luke;Bornholt, James;Gu, Ronghui;Baumann, Andrew;Torlak, Emina;Wang, Xi",57200557267;56103636000;56785252200;26025576700;23089529200;56562766700,60015481;60015481;60030162;60021726;60015481;60015481,2019-10-27,27 October 2019,SOSP 2019 - Proceedings of the 27th ACM Symposium on Operating Systems Principles,,21100939593,,Conference Proceeding,,,,225-242,"This paper presents Serval, a framework for developing automated verifiers for systems software. Serval provides an extensible infrastructure for creating verifiers by lifting interpreters under symbolic evaluation, and a systematic approach to identifying and repairing verification performance bottlenecks using symbolic profiling and optimizations. Using Serval, we build automated verifiers for the RISC-V, x86-32, LLVM, and BPF instruction sets. We report our experience of retrofitting CertiKOS and Komodo, two systems previously verified using Coq and Dafny, respectively, for automated verification using Serval, and discuss trade-offs of different verification methodologies. In addition, we apply Serval to the Keystone security monitor and the BPF compilers in the Linux kernel, and uncover 18 new bugs through verification, all confirmed and fixed by developers.",,64,1,publisherfree2read,Bronze,NSF,1651225,National Science Foundation,SOSP Operating Systems
2-s2.0-85081905989,10.1109/ICCV.2019.00467,,,SinGAN: Learning a generative model from a single natural image,cp,Conference Paper,Shaham T.R.,60022403;60006191,Technion - Israel Institute of Technology;Google LLC,Haifa;Mountain View,Israel;United States,3,"Shaham, Tamar Rott;Dekel, Tali;Michaeli, Tomer",57191429022;56119329800;18042574300,60022403;60006191;60022403,2019-10-01,October 2019,Proceedings of the IEEE International Conference on Computer Vision,15505499,110561,,Conference Proceeding,2019-October,,9008787,4569-4579,"We introduce SinGAN, an unconditional generative model that can be learned from a single natural image. Our model is trained to capture the internal distribution of patches within the image, and is then able to generate high quality, diverse samples that carry the same visual content as the image. SinGAN contains a pyramid of fully convolutional GANs, each responsible for learning the patch distribution at a different scale of the image. This allows generating new samples of arbitrary size and aspect ratio, that have significant variability, yet maintain both the global structure and the fine textures of the training image. In contrast to previous single image GAN schemes, our approach is not limited to texture images, and is not conditional (i.e. it generates samples from noise). User studies confirm that the generated samples are commonly confused to be real images. We illustrate the utility of SinGAN in a wide range of image manipulation tasks.",,563,0,repositoryam,Green,ISF,852/17,Israel Science Foundation,ICCV Computer Vision
2-s2.0-85067626915,10.1145/3290605.3300660,,,Social play in an exergame: How the need to belong predicts adherence,cp,Conference Paper,Kaos M.D.,60103653;60016005;60003122,Aalto University;Queen’s University;University of Victoria,Espoo;Kingston;Victoria,Finland;Canada;Canada,4,"Kaos, Maximus D.;Rhodes, Ryan E.;Hämäläinen, Perttu;Nicholas Graham, T. C.",57203869371;7202777576;10040911400;6507324776,60016005-60103653;60003122;60103653;60016005,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"The general trend in exercise interventions, including those based on exergames, is to see high initial enthusiasm but signifcantly declining adherence. Social play is considered a core tenet of the design of exercise interventions help foster motivation to play. To determine whether social play aids in adherence to exergames, we analyzed data from a study involving fve waves of six-week exergame trials between a single-player and multiplayer group. In this paper, we examine the multiplayer group to determine who might beneft from social play and why. We found that people who primarily engage in group play have superior adherence to people who primarily play alone. People who play alone in a multiplayer exergame have worse adherence than playing a single-player version, which can undo any potential beneft of social play. The primary construct distinguishing group versus alone players is their sense of program belonging. Program belonging is, thus, crucial to multiplayer exergame design.",Exergames | Program belonging | Social play,23,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85061282485,10.1109/SP.2019.00002,,,Spectre attacks: Exploiting speculative execution,cp,Conference Paper,Kocher P.,60019663;60009512;60006297;60006191;123259425;123259124,Technische Universitat Graz;The University of Adelaide;University of Pennsylvania;Google LLC;Cyberus Technology;Cryptography Research Division,Graz;Adelaide;Philadelphia;Mountain View;;,Austria;Australia;United States;United States;;,12,"Kocher, Paul;Horn, Jann;Fogh, Anders;Genkin, Daniel;Gruss, Daniel;Haas, Werner;Hamburg, Mike;Lipp, Moritz;Mangard, Stefan;Prescher, Thomas;Schwarz, Michael;Yarom, Yuval",56918124700;57211187677;57191967781;36135431800;55787524900;57197447601;24461679900;57191964089;8840189200;57217193426;57189495839;25825786400,;60006191;;60006297;60019663;123259425;123259124;60019663;60019663;123259425;60019663;60009512,2019-05-01,May 2019,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2019-May,,8835233,1-19,"Modern processors use branch prediction and speculative execution to maximize performance. For example, if the destination of a branch depends on a memory value that is in the process of being read, CPUs will try to guess the destination and attempt to execute ahead. When the memory value finally arrives, the CPU either discards or commits the speculative computation. Speculative logic is unfaithful in how it executes, can access the victim's memory and registers, and can perform operations with measurable side effects. Spectre attacks involve inducing a victim to speculatively perform operations that would not occur during correct program execution and which leak the victim's confidential information via a side channel to the adversary. This paper describes practical attacks that combine methodology from side channel attacks, fault attacks, and return-oriented programming that can read arbitrary memory from the victim's process. More broadly, the paper shows that speculative execution implementations violate the security assumptions underpinning numerous software security mechanisms, including operating system process separation, containerization, just-in-time (JIT) compilation, and countermeasures to cache timing and side-channel attacks. These attacks represent a serious threat to actual systems since vulnerable speculative execution capabilities are found in microprocessors from Intel, AMD, and ARM that are used in billions of devices. While makeshift processor-specific countermeasures are possible in some cases, sound solutions will require fixes to processor designs as well as updates to instruction set architectures (ISAs) to give hardware architects and software developers a common understanding as to what computation state CPU implementations are (and are not) permitted to leak.",Microarchitectural-attack | Microarchitecture-security | Spectre | Speculative-execution,938,1,repositoryam,Green,NIST,8650-16-C-7622,National Institute of Standards and Technology,S&P Security and Privacy
2-s2.0-85067597575,10.1145/3290605.3300760,,,Street–level algorithms: A theory at the gaps between policy and decisions,cp,Conference Paper,Alkhatib A.,60012708,Stanford University,Stanford,United States,2,"Alkhatib, Ali;Bernstein, Michael",57014941700;57193014048,60012708;60012708,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"Errors and biases are earning algorithms increasingly malignant reputations in society. A central challenge is that algorithms must bridge the gap between high–level policy and on–the–ground decisions, making inferences in novel situations where the policy or training data do not readily apply. In this paper, we draw on the theory of street–level bureaucracies, how human bureaucrats such as police and judges interpret policy to make on–the–ground decisions. We present by analogy a theory of street–level algorithms, the algorithms that bridge the gaps between policy and decisions about people in a socio-technical system. We argue that unlike street–level bureaucrats, who reflexively refine their decision criteria as they reason through a novel situation, street–level algorithms at best refine their criteria only after the decision is made. This loop–and–a–half delay results in illogical decisions when handling new or extenuating circumstances. This theory suggests designs for street–level algorithms that draw on historical design patterns for street–level bureaucracies, including mechanisms for self–policing and recourse in the case of error.",Artificial intelligence | Street–level algorithms | Street–level bureaucracies,88,1,publisherfree2read,Bronze,NSF,IIS-1351131,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85066921335,,,,Sublinear algorithms for (∆ + 1) vertex coloring,cp,Conference Paper,Assadi S.,60006297,University of Pennsylvania,Philadelphia,United States,3,"Assadi, Sepehr;Chen, Yu;Khanna, Sanjeev",55536783800;57209239512;7401552504,60006297;60006297;60006297,2019-01-01,2019,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,,,,767-786,"Any graph with maximum degree ∆ admits a proper vertex coloring with ∆+1 colors that can be found via a simple sequential greedy algorithm in linear time and space. But can one find such a coloring via a sublinear algorithm? We answer this fundamental question in the affirmative for several canonical classes of sublinear algorithms including graph streaming, sublinear time, and massively parallel computation (MPC) algorithms. In particular, we design: • A single-pass semi-streaming algorithm in dynamic streams using Oe(n) space. The only known semi-streaming algorithm prior to our work was a folklore O(log n)-pass algorithm obtained by simulating classical distributed algorithms in the streaming model. • A sublinear-time algorithm in the standard query model that allows neighbor queries and pair queries using Oe(nn) time. We further show that any algorithm that outputs a valid coloring with sufficiently large constant probability requires Ω(nn) time. No non-trivial sublinear time algorithms were known prior to our work. • A parallel algorithm in the massively parallel computation (MPC) model using Oe(n) memory per machine and O(1) MPC rounds. Our number of rounds significantly improves upon the recent O(log log ∆ • log∗ (n))-round algorithm of Parter [ICALP 2018]. At the core of our results is a remarkably simple meta-algorithm for the (∆ + 1) coloring problem: Sample O(log n) colors for each vertex independently and uniformly at random from the ∆ + 1 colors; find a proper coloring of the graph using only the sampled colors of each vertex. As our main result, we prove that the sampled set of colors with high probability contains a proper coloring of the input graph. The sublinear algorithms are then obtained by designing efficient algorithms for finding a proper coloring of the graph from the sampled colors in each model. We note that all our upper bound results for (∆ + 1) coloring are either optimal or close to best possible in each model studied. We also establish new lower bounds that rule out the possibility of achieving similar results in these models for the closely related problems of maximal independent set and maximal matching. Collectively, our results highlight a sharp contrast between the complexity of (∆+1) coloring vs maximal independent set and maximal matching in various models of sublinear computation even though all three problems are solvable by a simple greedy algorithm in the classical setting.",,66,0,,,NSF,CCF-1617851,National Science Foundation,SODA Theory
2-s2.0-85071933945,10.1145/3338906.3338941,,,The importance of accounting for real-world labelling when predicting software vulnerabilities,cp,Conference Paper,Jimenez M.,60072562;60022148,University of Luxembourg;University College London,Esch-sur-Alzette;London,Luxembourg;United Kingdom,6,"Jimenez, Matthieu;Rwemalika, Renaud;Papadakis, Mike;Sarro, Federica;Le Traon, Yves;Harman, Mark",57191959513;57208769382;57197295611;36631133800;55884641800;7006379048,60072562;60072562;60072562;60022148;60072562;60022148,2019-08-12,12 August 2019,ESEC/FSE 2019 - Proceedings of the 2019 27th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21100927970,,Conference Proceeding,,,,695-705,"Previous work on vulnerability prediction assume that predictive models are trained with respect to perfect labelling information (includes labels from future, as yet undiscovered vulnerabilities). In this paper we present results from a comprehensive empirical study of 1,898 real-world vulnerabilities reported in 74 releases of three security-critical open source systems (Linux Kernel, OpenSSL and Wiresark). Our study investigates the effectiveness of three previously proposed vulnerability prediction approaches, in two settings: with and without the unrealistic labelling assumption. The results reveal that the unrealistic labelling assumption can profoundly mis- lead the scientific conclusions drawn; suggesting highly effective and deployable prediction results vanish when we fully account for realistically available labelling in the experimental methodology. More precisely, MCC mean values of predictive effectiveness drop from 0.77, 0.65 and 0.43 to 0.08, 0.22, 0.10 for Linux Kernel, OpenSSL and Wiresark, respectively. Similar results are also obtained for precision, recall and other assessments of predictive efficacy. The community therefore needs to upgrade experimental and empirical methodology for vulnerability prediction evaluation and development to ensure robust and actionable scientific findings.",Machine Learning | Prediction Modelling | Software Vulnerabilities,60,1,repositoryvor,Green,H2020,741278,Horizon 2020 Framework Programme,FSE Software Engineering
2-s2.0-85068804572,10.1145/3313276.3316369,,,The reachability problem for petri nets is not elementary,cp,Conference Paper,Czerwiński W.,60102125;60022020;60013756,Université de Bordeaux;University of Warwick;University of Warsaw,Bordeaux;Coventry;Warsaw,France;United Kingdom;Poland,5,"Czerwiński, Wojciech;Lasota, Sławomir;Lazić, Ranko;Leroux, Jérôme;Mazowiecki, Filip",55608486500;8987815500;8382451800;23397064800;55795950700,60013756;60013756;60022020;60102125;60102125,2019-06-23,23 June 2019,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,24-33,"Petri nets, also known as vector addition systems, are a long established model of concurrency with extensive applications in modelling and analysis of hardware, software and database systems, as well as chemical, biological and business processes. The central algorithmic problem for Petri nets is reachability: whether from the given initial configuration there exists a sequence of valid execution steps that reaches the given final configuration. The complexity of the problem has remained unsettled since the 1960s, and it is one of the most prominent open questions in the theory of verification. Decidability was proved by Mayr in his seminal STOC 1981 work, and the currently best published upper bound is non-primitive recursive Ackermannian of Leroux and Schmitz from LICS 2019. We establish a non-elementary lower bound, i.e. that the reachability problem needs a tower of exponentials of time and space. Until this work, the best lower bound has been exponential space, due to Lipton in 1976. The new lower bound is a major breakthrough for several reasons. Firstly, it shows that the reachability problem is much harder than the coverability (i.e., state reachability) problem, which is also ubiquitous but has been known to be complete for exponential space since the late 1970s. Secondly, it implies that a plethora of problems from formal languages, logic, concurrent systems, process calculi and other areas, that are known to admit reductions from the Petri nets reachability problem, are also not elementary. Thirdly, it makes obsolete the currently best lower bounds for the reachability problems for two key extensions of Petri nets: with branching and with a pushdown stack. At the heart of our proof is a novel gadget so called the factorial amplifier that, assuming availability of counters that are zero testable and bounded by k, guarantees to produce arbitrarily large pairs of values whose ratio is exactly the factorial of k. We also develop a novel construction that uses arbitrarily large pairs of values with ratio R to provide zero testable counters that are bounded by R. Repeatedly composing the factorial amplifier with itself by means of the construction then enables us to compute in linear time Petri nets that simulate Minsky machines whose counters are bounded by a tower of exponentials, which yields the non-elementary lower bound. By refining this scheme further, we in fact establish hardness for h-exponential space already for Petri nets with h + 13 counters.",Petri nets | Reachability problems | Vector addition systems,72,0,repositoryam,Green,H2020,ANR-10-IDEX-03-02,Horizon 2020 Framework Programme,STOC Theory
2-s2.0-85071253123,10.1109/ICSE.2019.00033,,,The Seven Sins: Security Smells in Infrastructure as Code Scripts,cp,Conference Paper,Rahman A.,60004923,NC State University,Raleigh,United States,3,"Rahman, Akond;Parnin, Chris;Williams, Laurie",57188647874;15136883200;35565101900,60004923;60004923;60004923,2019-05-01,May 2019,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2019-May,,8812041,164-175,"Practitioners use infrastructure as code (IaC) scripts to provision servers and development environments. While developing IaC scripts, practitioners may inadvertently introduce security smells. Security smells are recurring coding patterns that are indicative of security weakness and can potentially lead to security breaches. The goal of this paper is to help practitioners avoid insecure coding practices while developing infrastructure as code (IaC) scripts through an empirical study of security smells in IaC scripts. We apply qualitative analysis on 1,726 IaC scripts to identify seven security smells. Next, we implement and validate a static analysis tool called Security Linter for Infrastructure as Code scripts (SLIC) to identify the occurrence of each smell in 15,232 IaC scripts collected from 293 open source repositories. We identify 21,201 occurrences of security smells that include 1,326 occurrences of hard-coded passwords. We submitted bug reports for 1,000 randomly-selected security smell occurrences. We obtain 212 responses to these bug reports, of which 148 occurrences were accepted by the development teams to be fixed. We observe security smells can have a long lifetime, e.g., a hard-coded secret can persist for as long as 98 months, with a median lifetime of 20 months.",devops | devsecops | empirical study | infrastructure as code | puppet | security | smell | static analysis,114,0,,,,undefined,,ICSE Software Engineering
2-s2.0-85074848036,10.1145/3332165.3347865,,,TipText: Eyes-free text entry on a fingertip keyboard,cp,Conference Paper,Xu Z.,60033241;60026415;60013983;60010756,Universität des Saarlandes;Stony Brook University;City University of Hong Kong;Dartmouth College,Saarbrucken;Stony Brook;Hong Kong;Hanover,Germany;United States;Hong Kong;United States,10,"Xu, Zheer;Wong, Pui Chung;Gong, Jun;Wu, Te Yen;Nittala, Aditya Shekhar;Bi, Xiaojun;Steimle, Jürgen;Fu, Hongbo;Zhu, Kening;Yang, Xing Dong",57202048649;57200220878;57191996992;57188750586;56159493000;36141821700;24825371700;35770445300;35191457500;14036728900,60010756;60010756-60013983;60010756;60010756;60033241;60026415;60033241;60013983;60013983;60010756,2019-10-17,17 October 2019,UIST 2019 - Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology,,21100935091,,Conference Proceeding,,,,883-889,"In this paper, we propose and investigate a new text entry technique using micro thumb-tip gestures. Our technique features a miniature QWERTY keyboard residing invisibly on the first segment of the user's index finger. Text entry can be carried out using the thumb-tip to tap the tip of the index finger. The keyboard layout was optimized for eyes-free input by utilizing a spatial model reflecting the users' natural spatial awareness of key locations on the index finger. We present our approach of designing and optimizing the keyboard layout through a series of user studies and computer simulated text entry tests over 1, 146, 484 possibilities in the design space. The outcome is a 2 ×3 grid with the letters highly confining to the alphabetic and spatial arrangement of QWERTY. Our user evaluation showed that participants achieved an average text entry speed of 11.9 WPM and were able to type as fast as 13.3 WPM towards the end of the experiment.",Micro thumb-tip gesture | Text entry | Wearable,51,0,,,,undefined,,UIST User Interface
2-s2.0-85067614527,10.1145/3290605.3300447,,,Touchstone2: An Interactive Environment for Exploring Trade-offs in HCI Experiment Design,cp,Conference Paper,Eiselmayer A.,60106017;60012614,Université Paris-Saclay;Universität Zürich,Gif-sur-Yvette;Zurich,France;Switzerland,4,"Eiselmayer, Alexander;Wacharamanotham, Chat;Beaudouin-Lafon, Michel;Mackay, Wendy E.",57209396488;39362715700;6602828964;7102699682,60012614;60012614;60106017;60106017,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"Touchstone2 offers a direct-manipulation interface for generating and examining trade-offs in experiment designs. Based on interviews with experienced researchers, we developed an interactive environment for manipulating experiment design parameters, revealing patterns in trial tables, and estimating and comparing statistical power. We also developed TSL, a declarative language that precisely represents experiment designs. In two studies, experienced HCI researchers successfully used Touchstone2 to evaluate design trade-offs and calculate how many participants are required for particular effect sizes. We discuss Touchstone2’s benefits and limitations, as well as directions for future research.",Counterbalancing | Experiment design | Power analysis | Randomization | Reproducibility,23,0,repositoryam,Green,H2020,321135,Horizon 2020 Framework Programme,CHI Human-Computer Interaction
2-s2.0-85067680591,10.1145/3314221.3314595,,,Towards certified separate compilation for concurrent programs,cp,Conference Paper,Jiang H.,60033100;60019118,Nanjing University;University of Science and Technology of China,Nanjing;Hefei,China;China,5,"Jiang, Hanru;Xiao, Siyang;Zha, Junpeng;Liang, Hongjin;Feng, Xinyu",57219791722;57204396884;57204915673;35797267800;7403047611,60019118;60019118;60019118;60033100;,2019-06-08,8 June 2019,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,111-125,"Certified separate compilation is important for establishing end-to-end guarantees for certified systems consisting of multiple program modules. There has been much work building certified compilers for sequential programs. In this paper, we propose a language-independent framework consisting of the key semantics components and lemmas that bridge the verification gap between the compilers for sequential programs and those for (race-free) concurrent programs, so that the existing verification work for the former can be reused. One of the key contributions of the framework is a novel footprint-preserving compositional simulation as the compilation correctness criterion. The framework also provides a new mechanism to support confined benign races which are usually found in efficient implementations of synchronization primitives. With our framework, we develop CASCompCert, which extends CompCert for certified separate compilation of race-free concurrent Clight programs. It also allows linking of concurrent Clight modules with x86-TSO implementations of synchronization primitives containing benign races. All our work has been implemented in the Coq proof assistant.",Certified Compilers | Concurrency | Data-Race-Freedom | Simulations,14,0,,,NSFC,61632005,National Natural Science Foundation of China,PLDI Programming Languages
2-s2.0-85072300673,,,,Understanding lifecycle management complexity of datacenter topologies,cp,Conference Paper,Zhang M.,123977964,USC,,,4,"Zhang, Mingyang;Mysore, Radhika Niranjan;Supittayapornpong, Sucha;Govindan, Ramesh",57203190879;35183690200;35148438000;35595955700,123977964;;123977964;123977964,2019-01-01,2019,"Proceedings of the 16th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2019",,21100962613,,Conference Proceeding,,,,235-254,"Most recent datacenter topology designs have focused on performance properties such as latency and throughput. In this paper, we explore a new dimension, life cycle management complexity, which attempts to understand the complexity of deploying a topology and expanding it. By analyzing current practice in lifecycle management, we devise complexity metrics for lifecycle management, and show that existing topology classes have low lifecycle management complexity by some measures, but not by others. Motivated by this, we design a new class of topologies, FatClique, that, while being performance-equivalent to existing topologies, is comparable to, or better than them by all our lifecycle management complexity metrics.",,25,0,,,,undefined,,NSDI Networking
2-s2.0-85072302014,10.1145/3341302.3342091,,,Underwater backscatter networking,cp,Conference Paper,Jang J.,60002243,MIT Media Lab,Cambridge,United States,2,"Jang, Junsu;Adib, Fadel",57211024277;51461063300,60002243;60002243,2019-08-19,19 August 2019,SIGCOMM 2019 - Proceedings of the 2019 Conference of the ACM Special Interest Group on Data Communication,,21100929309,,Conference Proceeding,,,,187-199,"We present Piezo-Acoustic Backscatter (PAB), the first technology that enables backscatter networking in underwater environments. PAB relies on the piezoelectric effect to enable underwater communication and sensing at near-zero power. Its architecture is inspired by radio backscatter which works well in air but cannot work well underwater due to the exponential attenuation of radio signals in water. PAB nodes harvest energy from underwater acoustic signals using piezoelectric interfaces and communicate by modulating the piezoelectric impedance. Our design introduces innovations that enable concurrent multiple access through circuit-based frequency tuning of backscatter modulation and a MAC that exploits the properties of PAB nodes to deliver higher network throughput and decode network collisions. We built a prototype of our design using custom-designed, mechanically fabricated transducers and an end-to-end battery-free hardware implementation.We tested our nodes in large experimental water tanks at the MIT Sea Grant. Our results demonstrate singlelink throughputs up to 3 kbps and power-up ranges up to 10 m. Finally, we show how our design can be used to measure acidity, temperature, and pressure. Looking ahead, the system can be used in ocean exploration, marine life sensing, and underwater climate change monitoring.",Backscatter Communication | Battery-free | Energy Harvesting | Piezoelectricity | Subsea IoT | Wireless,82,1,repositoryvor,Green,ONR,undefined,Office of Naval Research,SIGCOMM Networking
2-s2.0-85073770863,10.1145/3331184.3331264,,,Variance reduction in gradient exploration for online learning to rank,cp,Conference Paper,Wang H.,60152865,University of Virginia School of Engineering and Applied Science,Charlottesville,United States,5,"Wang, Huazheng;Kim, Sonwoo;McCord-Snook, Eric;Wu, Qingyun;Wang, Hongning",57190498323;57203389621;57203383722;57190491808;48762142200,60152865;60152865;60152865;60152865;60152865,2019-07-18,18 July 2019,SIGIR 2019 - Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval,,21100933298,,Conference Proceeding,,,,835-844,"Online Learning to Rank (OL2R) algorithms learn from implicit user feedback on the fly. The key to such algorithms is an unbiased estimate of gradients, which is often (trivially) achieved by uniformly sampling from the entire parameter space. Unfortunately, this leads to high-variance in gradient estimation, resulting in high regret during model updates, especially when the dimension of the parameter space is large. In this work, we aim at reducing the variance of gradient estimation in OL2R algorithms. We project the selected updating direction (i.e., the winning direction) into a space spanned by the feature vectors from examined documents under the current query (termed the “document space” for short), after an interleaved test. Our key insight is that the result of an interleaved test is solely governed by a user's relevance evaluation over the examined documents. Hence, the true gradient introduced by this test is only reflected in the constructed document space, and components of the proposed gradient which are orthogonal to the document space can be safely removed, for variance reduction purpose. We prove that this projected gradient is still an unbiased estimation of the true gradient, and show that this lower-variance gradient estimation results in significant regret reduction. Our proposed method is compatible with all existing OL2R algorithms which rank documents using a linear model. Extensive experimental comparisons with several state-of-the-art OL2R algorithms have confirmed the effectiveness of our proposed method in reducing the variance of gradient estimation and improving overall ranking performance.",Dueling bandit | Online learning to rank | Variance Reduction,27,0,repositoryam,Green,NSF,1553568,National Science Foundation,SIGIR Information Retrieval
2-s2.0-85072274740,10.1109/ICSE.2019.00104,,,View-Centric Performance Optimization for Database-Backed Web Applications,cp,Conference Paper,Yang J.,60029278;60015481,The University of Chicago;University of Washington,Chicago;Seattle,United States;United States,5,"Yang, Junwen;Yan, Cong;Wan, Chengcheng;Lu, Shan;Cheung, Alvin",57198887668;57155621700;57190807234;35199803400;56874039700,60029278;60015481;60029278;60029278;60015481,2019-05-01,May 2019,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2019-May,,8811938,994-1004,"Web developers face the stringent task of designing informative web pages while keeping the page-load time low. This task has become increasingly challenging as most web contents are now generated by processing ever-growing amount of user data stored in back-end databases. It is difficult for developers to understand the cost of generating every web-page element, not to mention explore and pick the web design with the best trade-off between performance and functionality. In this paper, we present Panorama, a view-centric and database-aware development environment for web developers. Using database-aware program analysis and novel IDE design, Panorama provides developers with intuitive information about the cost and the performance-enhancing opportunities behind every HTML element, as well as suggesting various global code refactorings that enable developers to easily explore a wide spectrum of performance and functionality trade-offs.",database backed web applications | ORM framework | view centric,16,0,,,NSF,1514256,National Science Foundation,ICSE Software Engineering
2-s2.0-85067597898,10.1145/3290605.3300608,,,Voice user interfaces in schools: Co-designing for Inclusion with Visually-Impaired and Sighted Pupils,cp,Conference Paper,Metatla O.,60020650,University of Bristol,Bristol,United Kingdom,5,"Metatla, Oussama;Oldfield, Alison;Ahmed, Taimur;Vafeas, Antonis;Miglani, Sunny",26422343700;57021522700;57209397866;57209399376;57209396670,60020650;60020650;60020650;60020650;60020650,2019-05-02,2 May 2019,Conference on Human Factors in Computing Systems - Proceedings,,31473,,Conference Proceeding,,,,,"Voice user interfaces (VUIs) are increasingly popular, particularly in homes. However, little research has investigated their potential in other settings, such as schools. We investigated how VUIs could support inclusive education, particularly for pupils with visual impairments (VIs). We organised focused discussions with educators at a school, with support staff from local authorities and, through bodystorming, with a class of 27 pupils. We then ran a series of co-design workshops with participants with mixed-visual abilities to design an educational VUI application. This provided insights into challenges faced by pupils with VIs in mainstream schools, and opened a space for educators, sighted and visually impaired pupils to reflect on and design for their shared learning experiences through VUIs. We present scenarios, a design space and an example application that show novel ways of using VUIs for inclusive education. We also reflect on co-designing with mixed-visual-ability groups in this space.",Co-design | Education | Inclusion | Visual impairment | Voice user interfaces,65,0,repositoryam,Green,EPSRC,EP/N00616X/2,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-85134257617,10.1145/3300061.3345454,,,EBP: AWearable System for Frequent and Comfortable Blood Pressure Monitoring from User s Ear,cp,Conference Paper,Bui N.,60092830;60002476;60000221,"The Children's Hospital, Aurora;Virginia Commonwealth University;University of Colorado Boulder",Aurora;Richmond;Boulder,United States;United States;United States,13,"Bui, Nam;Pham, Nhat;Barnitz, Jessica Jacqueline;Zou, Zhanan;Nguyen, Phuc;Truong, Hoang;Kim, Taeho;Farrow, Nicholas;Nguyen, Anh;Xiao, Jianliang;Deterding, Robin;Dinh, Thang;Vu, Tam",57208825837;57214599836;57226765011;57194565083;57052122700;57195126581;57209975431;55633402400;56763404500;57189220170;6603892547;34976416800;56410461600,60000221;60000221;60000221;60000221;60000221;60000221;60000221;60000221;60000221;60000221;60092830;60002476;60000221,2019-01-01,2019,"Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM",,21101134314,,Conference Proceeding,,,53,,"Frequent blood pressure (BP) assessment is key to the diagnosis and treatment of many severe diseases, such as heart failure, kidney failure, hypertension, and hemodialysis. Current ""gold-standard'' BP measurement techniques require the complete blockage of blood flow, which causes discomfort and disruption to normal activity when the assessment is done repetitively and frequently. Unfortunately, patients with hypertension or hemodialysis often have to get their BP measured every 15 minutes for a duration of 4-5 hours or more. The discomfort of wearing a cumbersome and limited mobility device affects their normal activities. In this work, we propose a device called eBP to measure BP from inside the user's ear aiming to minimize the measurement's impact on users' normal activities while maximizing its comfort level. eBP has 3 key components: (1) a light-based pulse sensor attached on an inflatable pipe that goes inside the ear, (2) a digital air pump with a fine controller, and (3) a BP estimation algorithm. In contrast to existing devices, eBP introduces a novel technique that eliminates the need to block the blood flow inside the ear, which alleviates the user's discomfort. We prototyped eBP custom hardware and software and evaluated the system through a comparative study on 35 subjects. The study shows that eBP obtains the average error of 1.8 mmHg and -3.1 mmHg and a standard deviation error of 7.2 mmHg and 7.9 mmHg for systolic (high-pressure value) and diastolic (low-pressure value), respectively. These errors are around the acceptable margins regulated by the FDA's AAMI protocol, which allows mean errors of up to 5 mmHg and a standard deviation of up to 8 mmHg.",blood pressure | frequent blood pressure monitoring | in-ear blood pressure monitoring | in-ear sensing | wearable devices,55,0,,,NSF,CNS/CSR 1846541,National Science Foundation,MOBICOM Mobile
2-s2.0-85072274408,10.1109/ICSE.2019.00097,,,ISENSE: Completion-Aware Crowdtesting Management,cp,Conference Paper,Wang J.,60279548;60027392;60027363;60025256;123176514,NC State College of Engineering;Stevens Institute of Technology;University of Chinese Academy of Sciences;Institute of Software Chinese Academy of Sciences;Laboratory for Internet Software Technologie,Raleigh;Hoboken;Beijing;Beijing;,United States;United States;China;China;,5,"Wang, Junjie;Yang, Ye;Krishna, Rahul;Menzies, Tim;Wang, Qing",55976866600;7409385793;57282246700;7003835495;55698296000,123176514-60025256-60027363;60027392;60279548;60027392;123176514-60025256-60027363,2019-05-01,May 2019,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2019-May,,8812109,912-923,"Crowdtesting has become an effective alternative to traditional testing, especially for mobile applications. However, crowdtesting is hard to manage in nature. Given the complexity of mobile applications and unpredictability of distributed crowdtesting processes, it is difficult to estimate (a) remaining number of bugs yet to be detected or (b) required cost to find those bugs. Experience-based decisions may result in ineffective crowdtesting processes, e.g., there is an average of 32% wasteful spending in current crowdtesting practices. This paper aims at exploring automated decision support to effectively manage crowdtesting processes. It proposes an approach named ISENSE which applies incremental sampling technique to process crowdtesting reports arriving in chronological order, organizes them into fixed-size groups as dynamic inputs, and predicts two test completion indicators in an incremental manner. The two indicators are: 1) total number of bugs predicted with Capture-ReCapture model, and 2) required test cost for achieving certain test objectives predicted with AutoRegressive Integrated Moving Average model. The evaluation of ISENSE is conducted on 46,434 reports of 218 crowdtesting tasks from one of the largest crowdtesting platforms in China. Its effectiveness is demonstrated through two application studies for automating crowdtesting management and semi-automation of task closing trade-off analysis. The results show that ISENSE can provide managers with greater awareness of testing progress to achieve cost-effectiveness gains of crowdtesting. Specifically, a median of 100% bugs can be detected with 30% saved cost based on the automated close prediction.",automated close prediction | Crowdtesting | crowdtesting management | test completion,16,0,repositoryam,Green,NSFC,6143200,National Natural Science Foundation of China,ICSE Software Engineering
2-s2.0-85091298226,10.1145/3313831.3376525,,,A Design Engineering Approach for Quantitatively Exploring Context-Aware Sentence Retrieval for Nonspeaking Individuals with Motor Disabilities,cp,Conference Paper,Kristensson P.O.,60031101;60008877,University of Cambridge;University of Dundee,Cambridge;Dundee,United Kingdom;United Kingdom,4,"Kristensson, Per Ola;Lilley, James;Black, Rolf;Waller, Annalu",6507412583;57218835163;24467264200;7007166546,60031101;60031101;60008877;60008877,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376525,,"Nonspeaking individuals with motor disabilities typically have very low communication rates. This paper proposes a design engineering approach for quantitatively exploring context-aware sentence retrieval as a promising complementary input interface, working in tandem with a word-prediction keyboard. We motivate the need for complementary design engineering methodology in the design of augmentative and alternative communication and explain how such methods can be used to gain additional design insights. We then study the theoretical performance envelopes of a context-aware sentence retrieval system, identifying potential keystroke savings as a function of the parameters of the subsystems, such as the accuracy of the underlying auto-complete word prediction algorithm and the accuracy of sensed context information under varying assumptions. We find that context-aware sentence retrieval has the potential to provide users with considerable improvements in keystroke savings under reasonable parameter assumptions of the underlying subsystems. This highlights how complementary design engineering methods can reveal additional insights into design for augmentative and alternative communication.",augmentative and alternative communication | context-aware text entry | design engineering | information retrieval | sentence prediction | text entry,15,0,repositoryam,Green,EPSRC,EP/N014278/1,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-85086265862,10.1145/3375395.3387658,,,A Framework for Adversarially Robust Streaming Algorithms,cp,Conference Paper,Ben-Eliezer O.,60027950;60019674;60005681,Carnegie Mellon University;Boston University;Tel Aviv University,Pittsburgh;Boston;Tel Aviv-Yafo,United States;United States;Israel,4,"Ben-Eliezer, Omri;Jayaram, Rajesh;Woodruff, David P.;Yogev, Eylon",56888756500;57202351444;35407448600;56023823500,60005681;60027950;60027950;60005681-60019674,2020-06-14,14 June 2020,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,63-80,"We investigate the adversarial robustness of streaming algorithms. In this context, an algorithm is considered robust if its performance guarantees hold even if the stream is chosen adaptively by an adversary that observes the outputs of the algorithm along the stream and can react in an online manner. While deterministic streaming algorithms are inherently robust, many central problems in the streaming literature do not admit sublinear-space deterministic algorithms; on the other hand, classical space-efficient randomized algorithms for these problems are generally not adversarially robust. This raises the natural question of whether there exist efficient adversarially robust (randomized) streaming algorithms for these problems. In this work, we show that the answer is positive for various important streaming problems in the insertion-only model, including distinct elements and more generally $F-p$-estimation, Fp-heavy hitters, entropy estimation, and others. For all of these problems, we develop adversarially robust (1+ϵ)-approximation algorithms whose required space matches that of the best known non-robust algorithms up to a poly(log n, 1/ϵ) multiplicative factor (and in some cases even up to a constant factor). Towards this end, we develop several generic tools allowing one to efficiently transform a non-robust streaming algorithm into a robust one in various scenarios.",adversarial robustness | databases | distinct elements | frequency moments | heavy hitters | streaming algorithms,34,0,repositoryam,Green,NSF,CCF-1815840,National Science Foundation,PODS Databases
2-s2.0-85093688307,10.1145/3379597.3387461,,,A Machine Learning Approach for Vulnerability Curation,cp,Conference Paper,Chen Y.,60018933;119459199,Singapore Management University;Veracode,Singapore City;,Singapore;United States,6,"Chen, Yang;Santosa, Andrew E.;Yi, Ang Ming;Sharma, Abhishek;Sharma, Asankhaya;Lo, David",57219401915;6506343800;57219532844;57202966237;56298660300;35269388000,119459199;119459199;119459199;119459199;119459199;60018933,2020-06-29,29 June 2020,"Proceedings - 2020 IEEE/ACM 17th International Conference on Mining Software Repositories, MSR 2020",,21101023641,,Conference Proceeding,,,,32-42,"Software composition analysis depends on database of open-source library vulerabilities, curated by security researchers using various sources, such as bug tracking systems, commits, and mailing lists. We report the design and implementation of a machine learning system to help the curation by by automatically predicting the vulnerability-relatedness of each data item. It supports a complete pipeline from data collection, model training and prediction, to the validation of new models before deployment. It is executed iteratively to generate better models as new input data become available. We use self-training to significantly and automatically increase the size of the training dataset, opportunistically maximizing the improvement in the models' quality at each iteration. We devised new deployment stability metric to evaluate the quality of the new models before deployment into production, which helped to discover an error. We experimentally evaluate the improvement in the performance of the models in one iteration, with 27.59% maximum PR AUC improvements. Ours is the first of such study across a variety of data sources. We discover that the addition of the features of the corresponding commits to the features of issues/pull requests improve the precision for the recall values that matter. We demonstrate the effectiveness of self-training alone, with 10.50% PR AUC improvement, and we discover that there is no uniform ordering of word2vec parameters sensitivity across data sources.",application security | classifiers ensemble | machine learning | open-source software | self-training,28,0,repositoryvor,Green,,undefined,,ICSE Software Engineering
2-s2.0-85095503502,,,,A multi-objective approach to mitigate negative side effects,cp,Conference Paper,Saisubramanian S.,60021726;60014313,Microsoft Research;University of Massachusetts Amherst,Redmond;Amherst,United States;United States,3,"Saisubramanian, Sandhya;Kamar, Ece;Zilberstein, Shlomo",56394634100;23009039400;6603805660,60014313;60021726;60014313,2020-01-01,2020,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2021-January,,,354-361,"Agents operating in unstructured environments often create negative side effects (NSE) that may not be easy to identify at design time. We examine how various forms of human feedback or autonomous exploration can be used to learn a penalty function associated with NSE during system deployment. We formulate the problem of mitigating the impact of NSE as a multi-objective Markov decision process with lexicographic reward preferences and slack. The slack denotes the maximum deviation from an optimal policy with respect to the agent's primary objective allowed in order to mitigate NSE as a secondary objective. Empirical evaluation of our approach shows that the proposed framework can successfully mitigate NSE and that different feedback mechanisms introduce different biases, which influence the identification of NSE.",,19,0,,,SRC,2906.001,Semiconductor Research Corporation,IJCAI Artificial Intelligence
2-s2.0-85100332422,10.1109/FOCS46700.2020.00045,,,A new minimax theorem for randomized algorithms (extended abstract),cp,Conference Paper,Ben-David S.,60000463,David R. Cheriton School of Computer Science,Waterloo,Canada,2,"Ben-David, Shalev;Blais, Eric",35368072900;14041279700,60000463;60000463,2020-11-01,November 2020,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2020-November,,9317905,403-411,"The celebrated minimax principle of Yao (1977) says that for any Boolean-valued function f with finite domain, there is a distribution mu over the domain of f such that computing f to error epsilon against inputs from mu is just as hard as computing f to error epsilon on worst-case inputs. Notably, however, the distribution mu depends on the target error level epsilon: The hard distribution which is tight for bounded error might be trivial to solve to small bias, and the hard distribution which is tight for a small bias level might be far from tight for bounded error levels. In this work, we introduce a new type of minimax theorem which can provide a hard distribution mu that works for all bias levels at once. We show that this works for randomized query complexity, randomized communication complexity, some randomized circuit models, quantum query and communication complexities, approximate polynomial degree, and approximate logrank. We also prove an improved version of Impagliazzo's hardcore lemma. Our proofs rely on two innovations over the classical approach of using Von Neumann's minimax theorem or linear programming duality. First, we use Sion's minimax theorem to prove a minimax theorem for ratios of bilinear functions representing the cost and score of algorithms. Second, we introduce a new way to analyze low-bias randomized algorithms by viewing them as'forecasting algorithms' evaluated by a certain proper scoring rule. The expected score of the forecasting version of a randomized algorithm appears to be a more fine-grained way of analyzing the bias of the algorithm. We show that such expected scores have many elegant mathematical properties: For example, they can be amplified linearly instead of quadratically. We anticipate forecasting algorithms will find use in future work in which a fine-grained analysis of small-bias algorithms is required.",Circuit complexity | Communication complexity | Minimax | Polynomial degree complexity | Quantum computation | Query complexity | Randomized computation,5,0,,,,undefined,,FOCS Theory
2-s2.0-85097159404,10.1145/3368089.3409670,,,A principled approach to GraphQL query cost analysis,cp,Conference Paper,Cha A.,60077068;60011048;60009254,IBM Deutschland GmbH;IBM Research;Purdue University,Ehningen;Yorktown Heights;West Lafayette,Germany;United States;United States,6,"Cha, Alan;Wittern, Erik;Baudart, Guillaume;Davis, James C.;Mandel, Louis;Laredo, Jim A.",57202355346;47062279200;55926186800;57194212372;7101842179;57197580620,60011048;60077068;60011048;60009254;60011048;60011048,2020-11-08,8 November 2020,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101029718,,Conference Proceeding,,,,257-268,"The landscape of web APIs is evolving to meet new client requirements and to facilitate how providers fulfill them. A recent web API model is GraphQL, which is both a query language and a runtime. Using GraphQL, client queries express the data they want to retrieve or mutate, and servers respond with exactly those data or changes. GraphQL's expressiveness is risky for service providers because clients can succinctly request stupendous amounts of data, and responding to overly complex queries can be costly or disrupt service availability. Recent empirical work has shown that many service providers are at risk. Using traditional API management methods is not sufficient, and practitioners lack principled means of estimating and measuring the cost of the GraphQL queries they receive. In this work, we present a linear-time GraphQL query analysis that can measure the cost of a query without executing it. Our approach can be applied in a separate API management layer and used with arbitrary GraphQL backends. In contrast to existing static approaches, our analysis supports common GraphQL conventions that affect query cost, and our analysis is provably correct based on our formal specification of GraphQL semantics. We demonstrate the potential of our approach using a novel GraphQL query-response corpus for two commercial GraphQL APIs. Our query analysis consistently obtains upper cost bounds, tight enough relative to the true response sizes to be actionable for service providers. In contrast, existing static GraphQL query analyses exhibit over-estimates and under-estimates because they fail to support GraphQL conventions.",Algorithmic complexity attacks | GraphQL | Static analysis,7,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-85094318987,10.1145/3377811.3380330,,,A tale from the trenches: Cognitive biases and software development,cp,Conference Paper,Chattopadhyay S.,60013402;120805123,Oregon State University;Phase Change Software,Corvallis;Golden,United States;United States,7,"Chattopadhyay, Souti;Nelson, Nicholas;Au, Audrey;Morales, Natalia;Sanchez, Christopher;Pandita, Rahul;Sarma1, Anita",57200372660;57189508480;57219625635;57219625180;14030380400;36675522700;57192189617,60013402;60013402;60013402;60013402;60013402;120805123;60013402,2020-06-27,27 June 2020,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,3380330,75-86,"Cognitive biases are hard-wired behaviors that influence developer actions and can set them on an incorrect course of action, necessitating backtracking. While researchers have found that cognitive biases occur in development tasks in controlled lab studies, we still don't know how these biases affect developers' everyday behavior. Without such an understanding, development tools and practices remain inadequate. To close this gap, we conducted a 2-part field study to examine the extent to which cognitive biases occur, the consequences of these biases on developer behavior, and the practices and tools that developers use to deal with these biases. About 70% of observed actions that were reversed were associated with at least one cognitive bias. Further, even though developers recognized that biases frequently occur, they routinely are forced to deal with such issues with ad hoc processes and sub-optimal tool support. As one participant (IP12) lamented: There is no salvation!",Cognitive bias | Field study | Interviews | Software development,13,1,publisherfree2read,Bronze,NSF,1560526,National Science Foundation,ICSE Software Engineering
2-s2.0-85091824514,,,,AmphiLight: Direct air-water communication with laser light,cp,Conference Paper,Carver C.J.,60136817;60030443,Department of Computer Science;Thayer School of Engineering at Dartmouth,Hanover;Hanover,United States;United States,6,"Carver, Charles J.;Tian, Zhao;Zhang, Hongyong;Odame, Kofi M.;Li, Alberto Quattrini;Zhou, Xia",57215839379;57054689200;57219244337;21834677200;56023035800;56271430300,60136817;60136817;60030443;60030443;60136817;60136817,2020-01-01,2020,"Proceedings of the 17th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2020",,21101022472,,Conference Proceeding,,,,373-388,"Air-water communication is fundamental for efficient underwater operations, such as environmental monitoring, surveying, or coordinating of heterogeneous aerial and underwater systems. Existing wireless techniques mostly focus on a single physical medium and fall short in achieving high-bandwidth bidirectional communication across the air-water interface. We propose a bidirectional, direct air-water wireless communication link based on laser light, capable of (1) adapting to water dynamics with ultrasonic sensing and (2) steering within a full 3D hemisphere using only a MEMS mirror and passive optical elements. In real-world experiments, our system achieves static throughputs up to 5.04 Mbps, zero-BER transmission ranges up to 6.1 m in strong ambient light conditions, and connection time improvements between 47.1% and 29.5% during wave dynamics.",,21,0,,,NSF,CNS-1552924,National Science Foundation,NSDI Networking
2-s2.0-85097161758,10.1145/3368089.3417050,,,Estimating GPU memory consumption of deep learning models,cp,Conference Paper,Gao Y.,60021726;60017161;60010571,"Microsoft Research;National University of Singapore;The University of Newcastle, Australia",Redmond;Singapore City;Callaghan,United States;Singapore;Australia,7,"Gao, Yanjie;Liu, Yu;Zhang, Hongyu;Li, Zhengxian;Zhu, Yonghao;Lin, Haoxiang;Yang, Mao",57191976449;57857123700;55685668500;57220181869;57220181851;55500782500;55703321000,60021726;60017161;60010571;60021726;60021726;60021726;60021726,2020-11-08,8 November 2020,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101029718,,Conference Proceeding,,,,1342-1352,"Deep learning (DL) has been increasingly adopted by a variety of software-intensive systems. Developers mainly use GPUs to accelerate the training, testing, and deployment of DL models. However, the GPU memory consumed by a DL model is often unknown to them before the DL job executes. Therefore, an improper choice of neural architecture or hyperparameters can cause such a job to run out of the limited GPU memory and fail. Our recent empirical study has found that many DL job failures are due to the exhaustion of GPU memory. This leads to a horrendous waste of computing resources and a significant reduction in development productivity. In this paper, we propose DNNMem, an accurate estimation tool for GPU memory consumption of DL models. DNNMem employs an analytic estimation approach to systematically calculate the memory consumption of both the computation graph and the DL framework runtime. We have evaluated DNNMem on 5 real-world representative models with different hyperparameters under 3 mainstream frameworks (TensorFlow, PyTorch, and MXNet). Our extensive experiments show that DNNMem is effective in estimating GPU memory consumption.",Deep learning | Estimation model | Memory consumption | Program analysis,64,0,,,,undefined,,ICSE Software Engineering
2-s2.0-85100126491,10.1109/FOCS46700.2020.00044,,,An equivalence between private classification and online prediction,cp,Conference Paper,Bun M.,60019674;60006191;60005681,Boston University;Google LLC;Tel Aviv University,Boston;Mountain View;Tel Aviv-Yafo,United States;United States;Israel,3,"Bun, Mark;Livni, Roi;Moran, Shay",55796181400;56096564800;57210472466,60019674;60005681;60006191,2020-11-01,November 2020,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2020-November,,9317912,389-402,We prove that every concept class with finite Littlestone dimension can be learned by an (approximate) differentially-private algorithm. This answers an open question of Alon et al. (STOC 2019) who proved the converse statement (this question was also asked by Neel et al. (FOCS 2019)). Together these two results yield an equivalence between online learnability and private PAC learnability. We introduce a new notion of algorithmic stability called'global stability' which is essential to our proof and may be of independent interest. We also discuss an application of our results to boosting the privacy and accuracy parameters of differentially-private learners.,differential privacy | learning | online learning,25,0,repositoryam,Green,NSF,CCF-1947889,National Science Foundation,FOCS Theory
2-s2.0-85086820312,10.1145/3385412.3385971,,,Armada: Low-effort verification of high-performance concurrent programming,cp,Conference Paper,Lorch J.R.,60027950;60025778;60021726;124035589,"Carnegie Mellon University;University of Michigan, Ann Arbor;Microsoft Research;Calibra",Pittsburgh;Ann Arbor;Redmond;Menlo Park,United States;United States;United States;United States,8,"Lorch, Jacob R.;Chen, Yixuan;Kapritsos, Manos;Parno, Bryan;Qadeer, Shaz;Sharma, Upamanyu;Wilcox, James R.;Zhao, Xueyuan",7003372473;57217225999;25825060000;57203245130;57207615217;57217224809;57014485000;57217225685,60021726;60025778;60027950;60027950;124035589;60025778;124035589;60027950,2020-06-11,11 June 2020,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,197-210,"Safely writing high-performance concurrent programs is notoriously difficult. To aid developers, we introduce Armada, a language and tool designed to formally verify such programs with relatively little effort. Via a C-like language and a small-step, state-machine-based semantics, Armada gives developers the flexibility to choose arbitrary memory layout and synchronization primitives so they are never constrained in their pursuit of performance. To reduce developer effort, Armada leverages SMT-powered automation and a library of powerful reasoning techniques, including rely-guarantee, TSO elimination, reduction, and alias analysis. All these techniques are proven sound, and Armada can be soundly extended with additional strategies over time. Using Armada, we verify four concurrent case studies and show that we can achieve performance equivalent to that of unverified code.",Refinement | Weak memory models | x86-TSO,22,0,,,NSF,CNS-1700521,National Science Foundation,PLDI Programming Languages
2-s2.0-85090310843,10.1145/3313831.3376664,,,Articulating Experience: Reflections from Experts Applying Micro-Phenomenology to Design Research in HCI,cp,Conference Paper,Prpa M.,60276635;60018491,Laboratoire Interdisciplinaire des Sciences du Numérique;Simon Fraser University,Orsay;Burnaby,France;Canada,4,"Prpa, Mirjana;Fdili-Alaoui, Sarah;Schiphorst, Thecla;Pasquier, Philippe",56369617600;39061015100;6506745859;8850202000,60018491;60276635;60018491;60018491,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376664,,"Third wave HCI initiated a slow transformation in the methods of UX research: from widely used quantitative approaches to more recently employed qualitative techniques. Articulating the nuances, complexity, and diversity of a user's experience beyond surface descriptions remains a challenge within design. One qualitative method A- micro-phenomenology A- has been used in HCI/Design research since 2001. Yet, no systematic understanding of micro-phenomenology has been presented, particularly from the perspective of HCI/Design researchers who actively use it in design contexts. We interviewed 5 HCI/Design experts who utilize micro-phenomenology and present their experiences with the method. We illustrate how this method has been applied by the selected experts through developing a practice, and present conditions under which the descriptions of the experience unfold, and the values that this method can provide to HCI/Design field. Our contribution highlights the value of micro-phenomenology in articulating the experience of designers and participants, developing vocabulary for multi-sensory experiences, and unfolding embodied tacit knowledge.",empirical methods | micro-phenomenology | user experience,33,0,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85112423078,,,,Beyond accuracy: Behavioral testing of NLP models with checklist,cp,Conference Paper,Ribeiro M.T.,60021726;60007278;124242617,"Microsoft Research;University of California, Irvine;University of Washington",Redmond;Irvine;Allen,United States;United States;United States,4,"Ribeiro, Marco Tulio;Wu, Tongshuang;Guestrin, Carlos;Singh, Sameer",57190979956;57209360952;57195906692;58124003300,60021726;124242617;124242617;60007278,2020-01-01,2020,Proceedings of the Annual Meeting of the Association for Computational Linguistics,0736587X,21101138302,,Conference Proceeding,,,,4902-4912,"Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of NLP models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce CheckList, a task-agnostic methodology for testing NLP models. CheckList includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of CheckList with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, NLP practitioners with CheckList created twice as many tests, and found almost three times as many bugs as users without it.",,479,0,,,NSF,-1756023,National Science Foundation,ACL Natural Language Processing
2-s2.0-85091311748,10.1145/3313831.3376761,,,Beyond the Prototype: Understanding the Challenge of Scaling Hardware Device Production,cp,Conference Paper,Khurana R.,60098463;60027950,Microsoft Research Cambridge;Carnegie Mellon University,Cambridge;Pittsburgh,United Kingdom;United States,2,"Khurana, Rushil;Hodges, Steve",55322735000;15044574300,60027950;60098463,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376761,,"The hardware research and development communities have invested heavily in tools and materials that facilitate the design and prototyping of electronic devices. Numerous easy-to-access and easy-to-use tools have streamlined the prototyping of interactive and embedded devices for experts and led to a remarkable growth in non-expert builders. However, there has been little exploration of challenges associated with moving beyond a prototype and creating hundreds or thousands of exact replicas - a process that is still challenging for many. We interviewed 25 individuals with experience taking prototype hardware devices into low volume production. We systematically investigated the common issues faced and mitigation strategies adopted. We present our findings in four main categories: (1) gaps in technical knowledge; (2) gaps in non-technical knowledge; (3) minimum viable rigor in manufacturing preparation; and (4) building relationships and a professional network. Our study unearthed several opportunities for new tools and processes to support the transition beyond a working prototype to cost effective low-volume manufacturing. These would complement the aforementioned tools and materials that support design and prototyping.",hardware device realization | long tail hardware | low volume electronics manufacturing | productization,20,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85094148542,10.1145/3377811.3380342,,,Big code != big vocabulary: Open-vocabulary models for source code,cp,Conference Paper,Karampatsis R.M.,60027272;60009914,The University of Edinburgh;Free University of Bozen-Bolzano,Edinburgh;Bolzano,United Kingdom;Italy,5,"Karampatsis, Rafael Michael;Babii, Hlib;Robbes, Romain;Sutton, Charles;Janes, Andrea",57200284328;57219510091;15136854400;57204256039;7003421075,60027272;60009914;60009914;60027272;60009914,2020-06-27,27 June 2020,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,3380342,1073-1085,"Statistical language modeling techniques have successfully been applied to large source code corpora, yielding a variety of new software development tools, such as tools for code suggestion, improving readability, and API migration. A major issue with these techniques is that code introduces new vocabulary at a far higher rate than natural language, as new identifier names proliferate. Both large vocabularies and out-of-vocabulary issues severely affect Neural Language Models (NLMs) of source code, degrading their performance and rendering them unable to scale. In this paper, we address this issue by: 1) studying how various modelling choices impact the resulting vocabulary on a large-scale corpus of 13,362 projects; 2) presenting an open vocabulary source code NLM that can scale to such a corpus, 100 times larger than in previous work; and 3) showing that such models outperform the state of the art on three distinct code corpora (Java, C, Python). To our knowledge, these are the largest NLMs for code that have been reported. All datasets, code, and trained models used in this work are publicly available.",Byte-pair encoding | Naturalness of code | Neural language models,128,1,repositoryam,Green,EPSRC,EP/L016427/1,Engineering and Physical Sciences Research Council,ICSE Software Engineering
2-s2.0-85091894023,10.1145/3368089.3409748,,,Boosting fuzzer efficiency: An information theoretic perspective,cp,Conference Paper,Böhme M.,60032144;60019578,Korea Advanced Institute of Science and Technology;Monash University,Daejeon;Clayton,South Korea;Australia,3,"Böhme, Marcel;Manès, Valentin J.M.;Cha, Sang Kil",55321057200;57200501748;36668251100,60019578;60032144;60032144,2020-11-08,8 November 2020,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101029718,,Conference Proceeding,,,,678-689,"In this paper, we take the fundamental perspective of fuzzing as a learning process. Suppose before fuzzing, we know nothing about the behaviors of a program P: What does it do? Executing the first test input, we learn how P behaves for this input. Executing the next input, we either observe the same or discover a new behavior. As such, each execution reveals ""some amount""of information about P's behaviors. A classic measure of information is Shannon's entropy. Measuring entropy allows us to quantify how much is learned from each generated test input about the behaviors of the program. Within a probabilistic model of fuzzing, we show how entropy also measures fuzzer efficiency. Specifically, it measures the general rate at which the fuzzer discovers new behaviors. Intuitively, efficient fuzzers maximize information. From this information theoretic perspective, we develop Entropic, an entropy-based power schedule for greybox fuzzing which assigns more energy to seeds that maximize information. We implemented Entropic into the popular greybox fuzzer LibFuzzer. Our experiments with more than 250 open-source programs (60 million LoC) demonstrate a substantially improved efficiency and confirm our hypothesis that an efficient fuzzer maximizes information. Entropic has been independently evaluated and invited for integration into main-line LibFuzzer. Entropic now runs on more than 25,000 machines fuzzing hundreds of security-critical software systems simultaneously and continuously.",Efficiency | Entropy | Fuzzing | Information theory | Software testing,59,0,,,ARC,DE190100046,Australian Research Council,FSE Software Engineering
2-s2.0-85091320677,10.1145/3313831.3376832,,,Bug or Feature? Covert Impairments to Human Computer Interaction,cp,Conference Paper,Monaco J.V.,60033012,Naval Postgraduate School,Monterey,United States,1,"Monaco, John V.",36236882000,60033012,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376832,,"Computer users commonly experience interaction anomalies, such as the text cursor jumping to another location in a document, perturbed mouse pointer motion, or a disagreement between tactile input and touch screen location. These anomalies impair interaction and require the user to take corrective measures, such as resetting the text cursor or correcting the trajectory of the pointer to reach a desired target. Impairments can result from software bugs, physical hardware defects, and extraneous input. However, some designs alter the course of interaction through covert impairments, anomalies introduced intentionally and without the user's knowledge. There are various motivations for doing so rooted in disparate fields including biometrics, electronic voting, and entertainment. We examine this kind of deception by systematizing four different ways computer interaction may become impaired and three different goals of the designer, providing insight to the design of systems that implement covert impairments.",behavior change | cybersecurity | deception | influence | interaction,3,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85096749794,,,,Byzantine ordered consensus without byzantine oligarchy,cp,Conference Paper,Zhang Y.,60021726;60007776,Microsoft Research;Cornell University,Redmond;Ithaca,United States;United States,5,"Zhang, Yunhao;Setty, Srinath;Chen, Qi;Zhou, Lidong;Alvisi, Lorenzo",57220076174;55273246400;57215553811;8359438500;6603768937,60007776;60021726;60021726;60021726;60007776,2020-01-01,2020,"Proceedings of the 14th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2020",,21101028552,,Conference Proceeding,,,,633-649,"The specific order of commands agreed upon when running state machine replication (SMR) is immaterial to fault-tolerance: all that is required is for all correct deterministic replicas to follow it. In the permissioned blockchains that rely on Byzantine fault tolerant (BFT) SMR, however, nodes have a stake in the specific sequence that ledger records, as well as in preventing other parties from manipulating the sequencing to their advantage. The traditional specification of SMR correctness, however, has no language to express these concerns. This paper introduces Byzantine ordered consensus, a new primitive that augments the correctness specification of BFT SMR to include specific guarantees on the total orders it produces; and a new architecture for BFT SMR that, by factoring out ordering from consensus, can enforce these guarantees and prevent Byzantine nodes from controlling ordering decisions (a Byzantine oligarchy). These contributions are instantiated in Pompe,1 a BFT SMR protocol that is guaranteed to order commands in a way that respects a natural extension of linearizability.",,35,0,,,NSF,CNS-CORE 2008667,National Science Foundation,OSDI Operating Systems
2-s2.0-85084091857,,,,Chasing convex bodies optimally,cp,Conference Paper,Sellke M.,60012708,Stanford University,Stanford,United States,1,"Sellke, Mark",58476254600,60012708,2020-01-01,2020,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,2020-January,,,1509-1518,"In the chasing convex bodies problem, an online player receives a request sequence of N convex sets K1, . . ., KN contained in a normed space Rd. The player starts at x0 ∈ Rd, and after observing each Kn picks a new point xn ∈ Kn. At each step the player pays a movement cost of ||xn−xn−1||. The player aims to maintain a constant competitive ratio against the minimum cost possible in hindsight, i.e. knowing all requests in advance. The existence of a finite competitive ratio for convex body chasing was first conjectured in 1991 by Friedman and Linial in [FL93]. This conjecture was recently resolved in [BLLS19] which proved an exponential 2O(d) upper bound on the competitive ratio. In this paper, we drastically improve the exponential upper bound. We give an algorithm achieving competitive ratio d for arbitrary normed spaces, which is exactly tight for `∞. In Euclidean space, our algorithm achieves nearly optimal competitive ratio O(√dlog N), compared to a lower bound of √d. Our approach extends the recent work [BKL+20] which chases nested convex bodies using the classical Steiner point of a convex body. We define the functional Steiner point of a convex function and apply it to the work function to obtain our algorithm.",,34,0,,,NSF,undefined,National Science Foundation,SODA Theory
2-s2.0-85084048228,,,,Chasing convex bodies with linear competitive ratio,cp,Conference Paper,Argue C.J.,60027950;60006191,Carnegie Mellon University;Google LLC,Pittsburgh;Mountain View,United States;United States,4,"Argue, C. J.;Gupta, Anupam;Guruganesh, Guru;Tang, Ziye",57209236929;55491953000;56743324600;58333965100,60027950;60027950;60006191;60027950,2020-01-01,2020,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,2020-January,,,1519-1524,"We study the problem of chasing convex bodies online: given a sequence of convex bodies Kt ⊆ Rd the algorithm must respond with points xt ∈ Kt in an online fashion (i.e., xt is chosen before Kt+1 is revealed). The objective is to minimize the total distance between successive points in this sequence. Recently, Bubeck et al. (STOC 2019) gave a 2O(d)-competitive algorithm for this problem. We give an algorithm that is O(min(d, √dlog T))-competitive for any sequence of length T.",,20,0,,,NSF,CCF-1907820,National Science Foundation,SODA Theory
2-s2.0-85091274405,10.1145/3313831.3376445,,,Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI,cp,Conference Paper,Madaio M.A.,60027950;60021726,Carnegie Mellon University;Microsoft Research,Pittsburgh;Redmond,United States;United States,4,"Madaio, Michael A.;Stark, Luke;Wortman Vaughan, Jennifer;Wallach, Hanna",57190032259;55258184900;35097882600;14822797500,60027950;60027950;60021726;60027950,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376445,,"Many organizations have published principles intended to guide the ethical development and deployment of AI systems; however, their abstract nature makes them difficult to operationalize. Some organizations have therefore produced AI ethics checklists, as well as checklists for more specific concepts, such as fairness, as applied to AI systems. But unless checklists are grounded in practitioners' needs, they may be misused. To understand the role of checklists in AI ethics, we conducted an iterative co-design process with 48 practitioners, focusing on fairness. We co-designed an AI fairness checklist and identified desiderata and concerns for AI fairness checklists in general. We found that AI fairness checklists could provide organizational infrastructure for formalizing ad-hoc processes and empowering individual advocates. We highlight aspects of organizational culture that may impact the efficacy of AI fairness checklists, and suggest future design directions.",AI | checklists | co-design | ethics | fairness | ML,192,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85088959329,10.1145/3313831.3376325,,,Color and Animation Preferences for a Light Band eHMI in Interactions between Automated Vehicles and Pedestrians,cp,Conference Paper,Dey D.,60107281;60032882,RISE Research Institutes of Sweden AB;Technische Universiteit Eindhoven,Gothenburg;Eindhoven,Sweden;Netherlands,5,"Dey, Debargha;Habibovic, Azra;Pfleging, Bastian;Martens, Marieke;Terken, Jacques",57196280866;37080834900;36096016600;7102563292;6602110392,60032882;60107281;60032882;60032882;60032882,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376325,,"In this paper, we report user preferences regarding color and animation patterns to support the interaction between Automated Vehicles (AVs) and pedestrians through an external Human-Machine-Interface (eHMI). Existing concepts of eHMI differ - among other things - in their use of colors or animations to express an AV's yielding intention. In the absence of empirical research, there is a knowledge gap regarding which color and animation leads to highest usability and preferences in traffic negotiation situations. We conducted an online survey (N=400) to investigate the comprehensibility of a light band eHMI with a combination of 5 color and 3 animation patterns for a yielding AV. Results show that cyan is considered a neutral color for communicating a yielding intention. Additionally, a uniformly flashing or pulsing animation is preferred compared to any pattern that animates sideways. These insights can contribute in the future design and standardization of eHMIs.",animation | automated vehicles | autonomous vehicles | color | ehmi | interface | pedestrians | vru,83,0,repositoryam,Green,EZ,14896,Ministerie van Economische Zaken,CHI Human-Computer Interaction
2-s2.0-85097193422,10.1145/3368089.3409767,,,Community expectations for research artifacts and evaluation processes,cp,Conference Paper,Hermann B.,60020238;60011226;60008069,Universität Paderborn;Technische Universität Darmstadt;Technische Universität Chemnitz,Paderborn;Darmstadt;Chemnitz,Germany;Germany;Germany,3,"Hermann, Ben;Winter, Stefan;Siegmund, Janet",57061978900;57194552417;55420344200,60020238;60011226;60008069,2020-11-08,8 November 2020,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101029718,,Conference Proceeding,,,,469-480,"Background. Artifact evaluation has been introduced into the software engineering and programming languages research community with a pilot at ESEC/FSE 2011 and has since then enjoyed a healthy adoption throughout the conference landscape. Objective. In this qualitative study, we examine the expectations of the community toward research artifacts and their evaluation processes. Method. We conducted a survey including all members of artifact evaluation committees of major conferences in the software engineering and programming language field since the first pilot and compared the answers to expectations set by calls for artifacts and reviewing guidelines. Results. While we find that some expectations exceed the ones expressed in calls and reviewing guidelines, there is no consensus on quality thresholds for artifacts in general. We observe very specific quality expectations for specific artifact types for review and later usage, but also a lack of their communication in calls. We also find problematic inconsistencies in the terminology used to express artifact evaluation's most important purpose - replicability. Conclusion. We derive several actionable suggestions which can help to mature artifact evaluation in the inspected community and also to aid its introduction into other communities in computer science.",Artifact Evaluation | Replicability | Reproducibility | Study,12,0,,,,undefined,,FSE Software Engineering
2-s2.0-85089204691,10.1145/3313831.3376704,,,Connecting Distributed Families: Camera Work for Three-party Mobile Video Calls,cp,Conference Paper,Gan Y.,60015138;60002798,University of Nottingham;Chinese University of Hong Kong,Nottingham;Hong Kong,United Kingdom;Hong Kong,3,"Gan, Yumei;Greiffenhagen, Christian;Reeves, Stuart",57217033053;14020990600;7102635630,60002798;60002798;60015138,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376704,,"Mobile video calling technologies have become a critical link to connect distributed families. However, these technologies have been principally designed for video calling between two parties, whereas family video calls involve young children often comprise three parties, namely a co-present adult (a parent or grandparent) helping with the interaction between the child and another remote adult. We examine how manipulation of phone cameras and management of co-present children is used to stage parent-child interactions. We present results from a video-ethnographic study based on 40 video recordings of video calls between 'left-behind' children and their migrant parents in China. Our analysis reveals a key practice of 'facilitation work', performed by grandparents, as a crucial feature of three-party calls. Facilitation work offers a new concept for HCI's broader conceptualisation of mobile video calling, suggesting revisions that design might take into consideration for triadic interactions in general.",camera work | conversation analysis | distributed families | facilitation work | mobile video calls,19,0,repositoryvor,Green,EPSRC,EP/M02315X/1,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-85090145600,10.1145/3397271.3401100,,,Controlling Fairness and Bias in Dynamic Learning-to-Rank,cp,Conference Paper,Morik M.,60011604;60007776,Technische Universität Berlin;Cornell University,Berlin;Ithaca,Germany;United States,4,"Morik, Marco;Singh, Ashudeep;Hong, Jessica;Joachims, Thorsten",57195641866;55790358500;57218714107;6602804136,60011604;60007776;60007776;60007776,2020-07-25,25 July 2020,SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval,,21101021126,,Conference Proceeding,,,,429-438,"Rankings are the primary interface through which many online platforms match users to items (e.g. news, products, music, video). In these two-sided markets, not only the users draw utility from the rankings, but the rankings also determine the utility (e.g. exposure, revenue) for the item providers (e.g. publishers, sellers, artists, studios). It has already been noted that myopically optimizing utility to the users-as done by virtually all learning-to-rank algorithms-can be unfair to the item providers. We, therefore, present a learning-to-rank approach for explicitly enforcing merit-based fairness guarantees to groups of items (e.g. articles by the same publisher, tracks by the same artist). In particular, we propose a learning algorithm that ensures notions of amortized group fairness, while simultaneously learning the ranking function from implicit feedback data. The algorithm takes the form of a controller that integrates unbiased estimators for both fairness and utility, dynamically adapting both as more data becomes available. In addition to its rigorous theoretical foundation and convergence guarantees, we find empirically that the algorithm is highly practical and robust.",bias | exposure | fairness | learning-to-rank | ranking | selection bias,125,0,repositoryam,Green,NSF,1901168,National Science Foundation,SIGIR Information Retrieval
2-s2.0-85091267266,10.1145/3313831.3376722,,,"Creating Augmented and Virtual Reality Applications: Current Practices, Challenges, and Opportunities",cp,Conference Paper,Ashtari N.,60018491;60010365;60009697,Simon Fraser University;The University of British Columbia;University of Manitoba,Burnaby;Vancouver;Winnipeg,Canada;Canada;Canada,5,"Ashtari, Narges;Bunt, Andrea;McGrenere, Joanna;Nebeling, Michael;Chilana, Parmit K.",57202432036;8971348500;6505966811;25641731100;35069141700,60018491;60009697;60010365;60018491;60009697,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376722,,"Augmented Reality (AR) and Virtual Reality (VR) devices are becoming easier to access and use, but the barrier to entry for creating AR/VR applications remains high. Although the recent spike in HCI research on novel AR/VR tools is promising, we lack insights into how AR/VR creators use today's state-of-the-art authoring tools as well as the types of challenges that they face. We interviewed 21 AR/VR creators, which we grouped into hobbyists, domain experts, and professional designers. Despite having a variety of motivations and skillsets, they described similar challenges in designing and building AR/VR applications. We synthesize 8 key barriers that AR/VR creators face nowadays, starting from prototyping the initial experiences to dealing with ""the many unknowns"" during implementation, to facing difficulties in testing applications. Based on our analysis, we discuss the importance of considering end-user developers as a growing population of AR/VR creators, how we can build learning opportunities into AR/VR tools, and the need for building AR/VR toolchains that integrate debugging and testing.",AR/VR authoring | AR/VR design | AR/VR development | augmented reality | end-user development | virtual reality,116,0,,,NSERC,undefined,Natural Sciences and Engineering Research Council of Canada,CHI Human-Computer Interaction
2-s2.0-85085648193,10.1145/3313831.3376392,,,Critical Race Theory for HCI,cp,Conference Paper,Ogbonnaya-Ogburu I.F.,60027950;60025778;60007363,"Carnegie Mellon University;University of Michigan, Ann Arbor;Northwestern University",Pittsburgh;Ann Arbor;Evanston,United States;United States;United States,4,"Ogbonnaya-Ogburu, Ihudiya Finda;Smith, Angela D.R.;To, Alexandra;Toyama, Kentaro",57193528804;57218772346;57188762857;56902256500,60025778;60007363;60027950;60025778,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376392,,"The human-computer interaction community has made some efforts toward racial diversity, but the outcomes remain meager. We introduce critical race theory and adapt it for HCI to lay a theoretical basis for race-conscious efforts, both in research and within our community. Building on the theory's original tenets, we argue that racism is pervasive in everyday socio-technical systems; that the HCI community is prone to ""interest convergence"", where concessions to inclusion require benefits to those in power; and that the neoliberal underpinnings of the technology industry itself propagate racism. Critical race theory uses storytelling as a means to upend deep-seated assumptions, and we relate several personal stories to highlight ongoing problems of race in HCI. The implications: All HCI research must be attuned to issues of race; participation of underrepresented minorities must be sought in all of our activities; and as a community, we cannot become comfortable while racial disparities exist.",critical race theory | race | racism | storytelling | theory,207,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85086824380,10.1145/3385412.3385967,,,Data-driven inference of representation invariants,cp,Conference Paper,Miltner A.,60027550;60003269,"University of California, Los Angeles;Princeton University",Los Angeles;Princeton,United States;United States,4,"Miltner, Anders;Padhi, Saswat;Millstein, Todd;Walker, David",57217225789;57189898374;57207585055;7404440742,60003269;60027550;60027550;60003269,2020-06-11,11 June 2020,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,1-15,"A representation invariant is a property that holds of all values of abstract type produced by a module. Representation invariants play important roles in software engineering and program verification. In this paper, we develop a counterexample-driven algorithm for inferring a representation invariant that is sufficient to imply a desired specification for a module. The key novelty is a type-directed notion of visible inductiveness, which ensures that the algorithm makes progress toward its goal as it alternates between weakening and strengthening candidate invariants. The algorithm is parameterized by an example-based synthesis engine and a verifier, and we prove that it is sound and complete for first-order modules over finite types, assuming that the synthesizer and verifier are as well. We implement these ideas in a tool called Hanoi, which synthesizes representation invariants for recursive data types. Hanoi not only handles invariants for first-order code, but higher-order code as well. In its back end, Hanoi uses an enumerative synthesizer called Myth and an enumerative testing tool as a verifier. Because Hanoi uses testing for verification, it is not sound, though our empirical evaluation shows that it is successful on the benchmarks we investigated.",Abstract Data Types | Logical Relations | Type-Directed Synthesis,18,0,repositoryam,Green,NSF,1527923,National Science Foundation,PLDI Programming Languages
2-s2.0-85097144851,10.1145/3368089.3409761,,,Deep learning library testing via effective model generation,cp,Conference Paper,Wang Z.,60019533;125499860,Tianjin University;State Key Laboratory of Communication Content Cognition,Tianjin;Beijing,China;China,5,"Wang, Zan;Yan, Ming;Chen, Junjie;Liu, Shuang;Zhang, Dongdi",35216436800;56307496100;57145642900;57221491904;57204638958,60019533-125499860;60019533;60019533;60019533;60019533,2020-11-08,8 November 2020,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101029718,,Conference Proceeding,,,,788-799,"Deep learning (DL) techniques are rapidly developed and have been widely adopted in practice. However, similar to traditional software systems, DL systems also contain bugs, which could cause serious impacts especially in safety-critical domains. Recently, many research approaches have focused on testing DL models, while little attention has been paid for testing DL libraries, which is the basis of building DL models and directly affects the behavior of DL systems. In this work, we propose a novel approach, LEMON, to testing DL libraries. In particular, we (1) design a series of mutation rules for DL models, with the purpose of exploring different invoking sequences of library code and hard-to-trigger behaviors; and (2) propose a heuristic strategy to guide the model generation process towards the direction of amplifying the inconsistent degrees of the inconsistencies between different DL libraries caused by bugs, so as to mitigate the impact of potential noise introduced by uncertain factors in DL libraries. We conducted an empirical study to evaluate the effectiveness of LEMON with 20 release versions of 4 widely-used DL libraries, i.e., TensorFlow, Theano, CNTK, MXNet. The results demonstrate that LEMON detected 24 new bugs in the latest release versions of these libraries, where 7 bugs have been confirmed and one bug has been fixed by developers. Besides, the results confirm that the heuristic strategy for model generation indeed effectively guides LEMON in amplifying the inconsistent degrees for bugs.",Deep Learning Testing | Library Testing | Model Generation | Mutation | Search-based Software Testing,78,0,,,NSFC,20191012,National Natural Science Foundation of China,FSE Software Engineering
2-s2.0-85091291348,10.1145/3313831.3376829,,,"Design Study ""lite"" Methodology: Expediting Design Studies and Enabling the Synergy of Visualization Pedagogy and Social Good",cp,Conference Paper,Syeda U.H.,60028628,Northeastern University,Boston,United States,5,"Syeda, Uzma Haque;Murali, Prasanth;Roe, Lisa;Berkey, Becca;Borkin, Michelle A.",57196008098;57205080991;57219109939;57188881306;14057526900,60028628;60028628;60028628;60028628;60028628,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376829,,"Design studies are frequently used to conduct problem-driven visualization research by working with real-world domain experts. In visualization pedagogy, design studies are often introduced but rarely practiced due to their large time requirements. This limits students to a classroom curriculum, often involving projects that may not have implications beyond the classroom. Thus we present the Design Study ""Lite"" Methodology, a novel framework for implementing design studies with novice students in 14 weeks. We utilized the Design Study ""Lite"" Methodology in conjunction with Service-Learning to teach five Data Visualization courses and demonstrate that it benefits not only the students but also the community through service to non-profit partners. In this paper, we provide a detailed breakdown of the methodology and how Service-Learning can be incorporated with it. We also include an extensive reflection on the methodology and provide recommendations for future applications of the framework for teaching visualization courses and research.",design studies | pedagogy | service-learning | theory and methods | visualization,14,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85091267899,10.1145/3313831.3376478,,,Designing Ambient Narrative-Based Interfaces to Reflect and Motivate Physical Activity,cp,Conference Paper,Murnane E.L.,60012708,Stanford University,Stanford,United States,14,"Murnane, Elizabeth L.;Jiang, Xin;Kong, Anna;Park, Michelle;Shi, Weili;Soohoo, Connor;Vink, Luke;Xia, Iris;Yu, Xin;Yang-Sammataro, John;Young, Grace;Zhi, Jenny;Moya, Paula;Landay, James A.",55942505600;57219108873;57219110664;57202979161;56204216000;57219115628;55841425600;57219111230;57219111069;57219109071;57219113032;57219114678;14624136800;7004487828,60012708;60012708;60012708;60012708;60012708;60012708;60012708;60012708;60012708;60012708;60012708;60012708;60012708;60012708,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376478,,"Numerous technologies now exist for promoting more active lifestyles. However, while quantitative data representations (e.g., charts, graphs, and statistical reports) typify most health tools, growing evidence suggests such feedback can not only fail to motivate behavior but may also harm self-integrity and fuel negative mindsets about exercise. Our research seeks to devise alternative, more qualitative schemes for encoding personal information. In particular, this paper explores the design of data-driven narratives, given the intuitive and persuasive power of stories. We present WhoIsZuki, a smartphone application that visualizes physical activities and goals as components of a multi-chapter quest, where the main character's progress is tied to the user's. We report on our design process involving online surveys, in-lab studies, and in-the-wild deployments, aimed at refining the interface and the narrative and gaining a deep understanding of people's experiences with this type of feedback. From these insights, we contribute recommendations to guide future development of narrative-based applications for motivating healthy behavior.",ambient display | mobile health | narrative feedback,34,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85091287532,10.1145/3313831.3376159,,,Designing Clinical AAC Tablet Applications with Adults who have Mild Intellectual Disabilities,cp,Conference Paper,Gibson R.C.,60027272;60024724,The University of Edinburgh;University of Strathclyde,Edinburgh;Glasgow,United Kingdom;United Kingdom,4,"Gibson, Ryan Colin;Dunlop, Mark D.;Bouamrane, Matt Mouley;Nayar, Revathy",57203821625;55419515200;13610567600;57201978081,60024724;60024724;60027272;60024724,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376159,,"Patients with mild intellectual disabilities (ID) face significant communication barriers within primary care services. This has a detrimental effect on the quality of treatment being provided, meaning the consultation process could benefit from augmentative and alternative communication (AAC) technologies. However, little research has been conducted in this area beyond that of paper-based aids. We address this by extracting design requirements for a clinical AAC tablet application from n=10 adults with mild ID. Our results show that such technologies can promote communication between general practitioners (GPs) and patients with mild ID by extracting symptoms in advance of the consultation via an accessible questionnaire. These symptoms act as a referent and assist in raising the awareness of conditions commonly overlooked by GPs. Furthermore, the application can support people with ID in identifying and accessing healthcare services. Finally, the participants identified 6 key factors that affect the clarity of medical images.",accessibility | augmentative and alternative communication | intellectual disabilities | mobile applications | primary health care,12,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85091274914,10.1145/3313831.3376669,,,Designing Trans Technology: Defining Challenges and Envisioning Community-Centered Solutions,cp,Conference Paper,Haimson O.L.,60025778;60000745,"University of Michigan, Ann Arbor;University of Illinois Urbana-Champaign",Ann Arbor;Urbana,United States;United States,4,"Haimson, Oliver L.;Gorrell, Dykee;Starks, Denny L.;Weinger, Zu",56157014300;57219110870;57210117137;57219110546,60025778;60000745;60025778;60025778,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376669,,"Transgender and non-binary people face substantial challenges in the world, ranging from social inequities and discrimination to lack of access to resources. Though technology cannot fully solve these problems, technological solutions may help to address some of the challenges trans people and communities face. We conducted a series of participatory design sessions (total N = 21 participants) to understand trans people's most pressing challenges and to involve this population in the design process. We detail four types of technologies trans people envision: technologies for changing bodies, technologies for changing appearances / gender expressions, technologies for safety, and technologies for finding resources. We found that centering trans people in the design process enabled inclusive technology design that primarily focused on sharing community resources and prioritized connection between community members.",community | lgbtq+ | non-binary | participatory design | resources | safety | technology design | transgender,57,0,,,IRWG,undefined,"Institute for Research on Women and Gender, University of Michigan",CHI Human-Computer Interaction
2-s2.0-85091293366,10.1145/3313831.3376539,,,"Designing and Evaluating Calmer, a Device for Simulating Maternal Skin-to-Skin Holding for Premature Infants",cp,Conference Paper,Hauser S.,60031040;60010365,Umeå Universitet;The University of British Columbia,Umea;Vancouver,Sweden;Canada,5,"Hauser, Sabrina;Suto, Melinda J.;Holsti, Liisa;Ranger, Manon;MacLean, Karon E.",55872445800;7006342564;7006443774;21934612800;7006153893,60031040;60010365;60031040;60031040;60031040,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376539,,"We describe the design and deployment of Calmer, a technology that simulates key aspects of maternal skin-to-skin holding for prematurely born infants: its inspiration, approach, physical design, and introduction into the Neonatal Intensive Care Unit. Maternal skin-to-skin holding can mitigate neonatal pain during medical procedures by as much as 50%, which can improve weight gain, sleep and later development. However, parents cannot always be present, and some infants are too fragile to be held. Interventions targeting this gap could be perceived as supplanting the mother in this intimate role, exposing her to depression and endangering her maternal bond. Over 10 years, we iteratively developed Calmer and demonstrated infant health benefit in a randomized clinical trial. Here, we report and reflect on pursuing this goal in a socially and technologically complex context: constraints, strategies, features, reception of the device, and surprises, such as leading to mothers feeling channeled rather than replaced.",automation | neonatal intensive care | nicu | pain reduction | parents | premature infants | research through design,7,0,,,CIHR,undefined,Canadian Institutes of Health Research,CHI Human-Computer Interaction
2-s2.0-85097192915,10.1145/3368089.3409720,,,Detecting numerical bugs in neural network architectures,cp,Conference Paper,Zhang Y.,60024350;60008592;60001604,National University of Defense Technology China;Hong Kong University of Science and Technology;Ministry of Education of the People's Republic of China,Changsha;Hong Kong;Beijing,China;Hong Kong;China,6,"Zhang, Yuhao;Ren, Luyao;Chen, Liqian;Xiong, Yingfei;Cheung, Shing Chi;Xie, Tao",57203387582;57202888798;26021081300;35744243000;7202472792;55574210063,60001604;60001604;60024350;60001604;60008592;60001604,2020-11-08,8 November 2020,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101029718,,Conference Proceeding,,,,826-837,"Detecting bugs in deep learning software at the architecture level provides additional benefits that detecting bugs at the model level does not provide. This paper makes the first attempt to conduct static analysis for detecting numerical bugs at the architecture level. We propose a static analysis approach for detecting numerical bugs in neural architectures based on abstract interpretation. Our approach mainly comprises two kinds of abstraction techniques, i.e., one for tensors and one for numerical values. Moreover, to scale up while maintaining adequate detection precision, we propose two abstraction techniques: tensor partitioning and (elementwise) affine relation analysis to abstract tensors and numerical values, respectively. We realize the combination scheme of tensor partitioning and affine relation analysis (together with interval analysis) as DEBAR, and evaluate it on two datasets: neural architectures with known bugs (collected from existing studies) and real-world neural architectures. The evaluation results show that DEBAR outperforms other tensor and numerical abstraction techniques on accuracy without losing scalability. DEBAR successfully detects all known numerical bugs with no false positives within 1.7-2.3 seconds per architecture. On the real-world architectures, DEBAR reports 529 warnings within 2.6-135.4 seconds per architecture, where 299 warnings are true positives.",Neural Network | Numerical Bugs | Static Analysis,40,0,repositoryvor,Green,MSRA,61872445,Microsoft Research Asia,FSE Software Engineering
2-s2.0-85095864975,10.1145/3340531.3412043,,,Do People and Neural Nets Pay Attention to the Same Words: Studying Eye-tracking Data for Non-factoid QA Evaluation,cp,Conference Paper,Bolotova V.,60011362,RMIT University,Melbourne,Australia,6,"Bolotova, Valeria;Blinov, Vladislav;Zheng, Yukun;Croft, W. Bruce;Scholer, Falk;Sanderson, Mark",57194714599;57194716101;57195628755;7006788293;56254255800;7202315611,60011362;60011362;60011362;60011362;60011362;60011362,2020-10-19,19 October 2020,"International Conference on Information and Knowledge Management, Proceedings",,21101027248,,Conference Proceeding,,,,85-94,"We investigated how users evaluate passage-length answers for non-factoid questions. We conduct a study where answers were presented to users, sometimes shown with automatic word highlighting. Users were tasked with evaluating answer quality, correctness, completeness, and conciseness. Words in the answer were also annotated, both explicitly through user mark up and implicitly through user gaze data obtained from eye-tracking. Our results show that the correctness of an answer strongly depends on its completeness, conciseness is less important. Analysis of the annotated words showed correct and incorrect answers were assessed differently. Automatic highlighting helped users to evaluate answers quicker while maintaining accuracy, particularly when highlighting was similar to annotation. We fine-tuned a BERT model on a non-factoid QA task to examine if the model attends to words similar to those annotated. Similarity was found, consequently, we propose a method to exploit the BERT attention map to generate suggestions that simulate eye gaze during user evaluation.",answer interaction | answer presentation | eye tracking | information-seeking | non-factoid question answering | user behaviour analysis | user interaction,10,0,,,,undefined,,CIKM Knowledge Management
2-s2.0-85095532102,10.1109/FOCS46700.2020.00046,,,Edge-weighted online bipartite matching,cp,Conference Paper,Fahrbach M.,60030162;60006541;60006191,Columbia University;The University of Hong Kong;Google LLC,New York;Hong Kong;Mountain View,United States;Hong Kong;United States,4,"Fahrbach, Matthew;Huang, Zhiyi;Tao, Runzhou;Zadimoghaddam, Morteza",56426934300;55494568500;57209230413;18435690000,60006191;60006541;60030162;60006191,2020-11-01,November 2020,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2020-November,,9317873,412-423,"Online bipartite matching is one of the most fundamental problems in the online algorithms literature. Karp, Vazirani, and Vazirani (STOC 1990) introduced an elegant algorithm for the unweighted bipartite matching that achieves an optimal competitive ratio of 1-{{}{1}}/{e}. Aggarwal et al. (SODA 2011) later generalized their algorithm and analysis to the vertex-weighted case. Little is known, however, about the most general edge-weighted problem aside from the trivial 1/2-competitive greedy algorithm. In this paper, we present the first online algorithm that breaks the long-standing 1/2 barrier and achieves a competitive ratio of at least 0.5086. In light of the hardness result of Kapralov, Post, and Vondrák (SODA 2013) that restricts beating a 1/2 competitive ratio for the more general problem of monotone submodular welfare maximization, our result can be seen as strong evidence that edge-weighted bipartite matching is strictly easier than submodular welfare maximization in the online setting. The main ingredient in our online matching algorithm is a novel subroutine called online correlated selection (OCS), which takes a sequence of pairs of vertices as input and selects one vertex from each pair. Instead of using a fresh random bit to choose a vertex from each pair, the OCS negatively correlates decisions across different pairs and provides a quantitative measure on the level of correlation. We believe our OCS technique is of independent interest and will find further applications in other online optimization problems.",bipartite matching | negative correlation | online algorithm | primal-dual algorithm,25,0,repositoryam,Green,NSF,17203717E,National Science Foundation,FOCS Theory
2-s2.0-85093652519,10.1145/3379597.3387462,,,Ethical Mining: A Case Study on MSR Mining Challenges,cp,Conference Paper,Gold N.E.,60022148,University College London,London,United Kingdom,2,"Gold, Nicolas E.;Krinke, Jens",7004798617;6603760534,60022148;60022148,2020-06-29,29 June 2020,"Proceedings - 2020 IEEE/ACM 17th International Conference on Mining Software Repositories, MSR 2020",,21101023641,,Conference Proceeding,,,,265-276,"Research in Mining Software Repositories (MSR) is research involving human subjects, as the repositories usually contain data about developers' interactions with the repositories. Therefore, any research in the area needs to consider the ethics implications of the intended activity before starting. This paper presents a discussion of the ethics implications of MSR research, using the mining challenges from the years 2010 to 2019 as a case study to identify the kinds of data used. It highlights problems that one may encounter in creating such datasets, and discusses ethics challenges that may be encountered when using existing datasets, based on a contemporary research ethics framework. We suggest that the MSR community should increase awareness of ethics issues by openly discussing ethics considerations in published articles.",mining software repositories | research ethics,11,0,,,,undefined,,ICSE Software Engineering
2-s2.0-85091315595,10.1145/3313831.3376755,,,Exploring How Game Genre in Student-Designed Games Influences Computational Thinking Development,cp,Conference Paper,Troiano G.M.,60102018;60028628;60018940;60011410,"TERC, Massachusetts;Northeastern University;Universidad Rey Juan Carlos;Worcester Polytechnic Institute",Cambridge;Boston;Madrid;Worcester,United States;United States;Spain;United States,9,"Troiano, Giovanni Maria;Chen, Qinyu;Alba, Ángela Vargas;Robles, Gregorio;Smith, Gillian;Cassidy, Michael;Tucker-Raymond, Eli;Puttick, Gillian;Harteveld, Casper",56241353800;57211109562;57219112349;8286496000;23071941200;57200522661;15833336400;36946987200;23392508000,60028628;60028628;60018940;60018940;60011410;60102018;60028628;60028628;60028628,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376755,,"Game design is increasingly used in modern education to foster Computational Thinking (CT). Yet, it is unclear how and if the game genre of student-designed games impact CT and programming. We explore how game genre impacts CT development and programming routines in Scratch games designed by 8th-grade students using a metrics-based approach (i.e., Dr. Scratch). Our findings show that designing particular games (e.g., action, storytelling) impact CT and programming development. We observe, for instance, that CT skills develop and consolidate fast, after which students can focus on aspects more specific to game design. Based on the results, we suggest that researchers and educators in constructionist learning consider the impact of game genre when designing game-based curricula for the learning of programming and CT.",computational thinking | constructionist learning | Dr. Scratch | game design | game-based learning | scratch | video games,13,0,,,NSF,1542954,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85095486253,10.1145/3340531.3412046,,,FANG: Leveraging Social Context for Fake News Detection Using Graph Representation,cp,Conference Paper,Nguyen V.H.,60104768;60017161;60011001,Qatar Computing Research Institute;National University of Singapore;Kyoto University,Doha;Singapore City;Kyoto,Qatar;Singapore;Japan,4,"Nguyen, Van Hoang;Sugiyama, Kazunari;Nakov, Preslav;Kan, Min Yen",57217855272;55007331200;15043153900;7102599333,60017161;60011001;60104768;60017161,2020-10-19,19 October 2020,"International Conference on Information and Knowledge Management, Proceedings",,21101027248,,Conference Proceeding,,,,1165-1174,"We propose Factual News Graph (FANG), a novel graphical social context representation and learning framework for fake news detection. Unlike previous contextual models that have targeted performance, our focus is on representation learning. Compared to transductive models, FANG is scalable in training as it does not have to maintain all nodes, and it is efficient at inference time, without the need to re-process the entire graph. Our experimental results show that FANG is better at capturing the social context into a high fidelity representation, compared to recent graphical and non-graphical models. In particular, FANG yields significant improvements for the task of fake news detection, and it is robust in the case of limited training data. We further demonstrate that the representations learned by FANG generalize to related tasks, such as predicting the factuality of reporting of a news medium.",disinformation | fake news | graph neural networks | representation learning | social networks,179,0,repositoryam,Green,,undefined,,CIKM Knowledge Management
2-s2.0-85086827849,10.1145/3385412.3386021,,,Fast graph simplification for interleaved Dyck-reachability,cp,Conference Paper,Li Y.,60032179;60019647,University of Wisconsin-Madison;Georgia Institute of Technology,Madison;Atlanta,United States;United States,3,"Li, Yuanbo;Zhang, Qirun;Reps, Thomas",57217224935;36661677600;7006765616,60019647;60019647;60032179,2020-06-11,11 June 2020,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,780-793,"Many program-analysis problems can be formulated as graph-reachability problems. Interleaved Dyck language reachability. Interleaved Dyck language reachability (InterDyck-reachability) is a fundamental framework to express a wide variety of program-analysis problems over edge-labeled graphs. The InterDyck language represents an intersection of multiple matched-parenthesis languages (i.e., Dyck languages). In practice, program analyses typically leverage one Dyck language to achieve context-sensitivity, and other Dyck languages to model data dependences, such as field-sensitivity and pointer references/dereferences. In the ideal case, an InterDyck-reachability framework should model multiple Dyck languages simultaneously. Unfortunately, precise InterDyck-reachability is undecidable. Any practical solution must over-approximate the exact answer. In the literature, a lot of work has been proposed to over-approximate the InterDyck-reachability formulation. This paper offers a new perspective on improving both the precision and the scalability of InterDyck-reachability: we aim to simplify the underlying input graph G. Our key insight is based on the observation that if an edge is not contributing to any InterDyck-path, we can safely eliminate it from G. Our technique is orthogonal to the InterDyck-reachability formulation, and can serve as a pre-processing step with any over-approximating approaches for InterDyck-reachability. We have applied our graph simplification algorithm to pre-processing the graphs from a recent InterDyck-reachability-based taint analysis for Android. Our evaluation on three popular InterDyck-reachability algorithms yields promising results. In particular, our graph-simplification method improves both the scalability and precision of all three InterDyck-reachability algorithms, sometimes dramatically.",CFL-Reachability | Static Analysis,21,1,publisherfree2read,Bronze,NSF,1917924,National Science Foundation,PLDI Programming Languages
2-s2.0-85086821335,10.1145/3385412.3385994,,,From folklore to fact: Comparing implementations of stacks and continuations,cp,Conference Paper,Farvardin K.,60029278,The University of Chicago,Chicago,United States,2,"Farvardin, Kavon;Reppy, John",57205459064;7003618785,60029278;60029278,2020-06-11,11 June 2020,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,75-90,"The efficient implementation of function calls and non-local control transfers is a critical part of modern language implementations and is important in the implementation of everything from recursion, higher-order functions, concurrency and coroutines, to task-based parallelism. In a compiler, these features can be supported by a variety of mechanisms, including call stacks, segmented stacks, and heap-allocated continuation closures. An implementor of a high-level language with advanced control features might ask the question ''what is the best choice for my implementation?'' Unfortunately, the current literature does not provide much guidance, since previous studies suffer from various flaws in methodology and are outdated for modern hardware. In the absence of recent, well-normalized measurements and a holistic overview of their implementation specifics, the path of least resistance when choosing a strategy is to trust folklore, but the folklore is also suspect. This paper attempts to remedy this situation by providing an ''apples-to-apples'' comparison of six different approaches to implementing call stacks and continuations. This comparison uses the same source language, compiler pipeline, LLVM-backend, and runtime system, with the only differences being those required by the differences in implementation strategy. We compare the implementation challenges of the different approaches, their sequential performance, and their suitability to support advanced control mechanisms, including supporting heavily threaded code. In addition to the comparison of implementation strategies, the paper's contributions also include a number of useful implementation techniques that we discovered along the way.",Call stacks | Compilers | Concurrency | Continuations | Functional Programming,11,1,publisherfree2read,Bronze,NSF,1718540,National Science Foundation,PLDI Programming Languages
2-s2.0-85097001027,10.1145/3379337.3415875,,,HandMorph: A passive exoskeleton that miniaturizes grasp,cp,Conference Paper,Nishida J.,60029278;60014256;60005322,The University of Chicago;University of Tsukuba;Ruhr-Universitat Bochum,Chicago;Tsukuba;Bochum,United States;Japan;Germany,7,"Nishida, Jun;Matsuda, Soichiro;Matsui, Hiroshi;Teng, Shan Yuan;Liu, Ziwei;Suzuki, Kenji;Lopes, Pedro",56963593900;55746376100;56244151400;57192819934;57211145549;22037104400;55480857700,60029278;60014256;60005322;60029278;60029278;60014256;60029278,2020-10-20,20 October 2020,UIST 2020 - Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology,,21101029460,,Conference Proceeding,,,3415875,565-578,"We engineered an exoskeleton, which we call HandMorph, that approximates the experience of having a smaller grasping range. It uses mechanical links to transmit motion from the wearer's fingers to a smaller hand with five anatomically correct fingers. The result is that HandMorph miniaturizes a wearer's grasping range while transmitting haptic feedback. Unlike other size-illusions based on virtual reality, HandMorph achieves this in the user's real environment, preserving the user's physical and social contexts. As such, our device can be integrated into the user's workflow, e.g., to allow product designers to momentarily change their grasping range into that of a child while evaluating a toy prototype. In our first user study, we found that participants perceived objects as larger when wearing HandMorph, which suggests that their size perception was successfully transformed. In our second user study, we assessed the experience of using HandMorph in designing a simple toy trumpet for children. We found that participants felt more confident in their toy design when using HandMorph to validate its ergonomics.",Embodied design | Exoskeleton | Haptics | Perception,13,0,,,KAKEN,JP18H04182,University of Chicago,UIST User Interface
2-s2.0-85091923254,10.1145/3377811.3380352,,,Herewe go again: Why is it difficult for developers to learn another programming language,cp,Conference Paper,Shrestha N.,60004923,NC State University,Raleigh,United States,4,"Shrestha, Nischal;Botta, Colton;Barik, Titus;Parnin, Chris",57204730099;57219626886;55772354200;15136883200,60004923;60004923;60004923;60004923,2020-06-27,27 June 2020,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,3380352,691-701,"Once a programmer knows one language, they can leverage concepts and knowledge already learned, and easily pick up another programming language. But is that always the case To understand if programmers have difficulty learning additional programming languages, we conducted an empirical study of Stack Overflow questions across 18 different programming languages. We hypothesized that previous knowledge could potentially interfere with learning a new programming language. From our inspection of 450 Stack Overflow questions, we found 276 instances of interference that occurred due to faulty assumptions originating from knowledge about a different language. To understand why these difficulties occurred, we conducted semi-structured interviews with 16 professional programmers. The interviews revealed that programmers make failed attempts to relate a new programming language with what they already know. Our findings inform design implications for technical authors, toolsmiths, and language designers, such as designing documentation and automated tools that reduce interference, anticipating uncommon language transitions during language design, and welcoming programmers not just into a language, but its entire ecosystem.",Interference theory | Learning | Program comprehension | Programming environments | Programming languages,25,0,,,NSF,1559593,National Science Foundation,ICSE Software Engineering
2-s2.0-85086141077,10.1145/3372224.3380886,,,Hummingbird: Energy efficient GPS receiver for small satellites,cp,Conference Paper,Narayana S.,60023256;60014097;60006288,Politecnico di Milano;Indian Institute of Science;Delft University of Technology,Milan;Bengaluru;Delft,Italy;India;Netherlands,5,"Narayana, S.;Prasad, R. V.;Rao, V.;Mottola, L.;Prabhakar, T. V.",57052533300;57200274597;35868157200;16239301400;36878953000,60006288;60006288;60006288;60023256;60014097,2020-04-16,16 April 2020,"Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM",,21100994451,,Conference Proceeding,,,,110-122,"Global Positioning System is a widely adopted localization technique. With the increasing demand for small satellites, the need for a low-power GPS for satellites is also increasing. To enable many state-of-the-art applications, the exact position of the satellites is necessary. However, building low-power GPS receivers which operate in low earth orbit pose significant challenges. This is mainly due to the high speed (∼7.8 km/s) of small satellites. While duty-cycling the receiver is a possible solution, the high relative Doppler shift between the GPS satellites and the small satellite contributes to the increase in Time To First Fix (TTFF), thus increasing the energy consumption. Further, if the GPS receiver is tumbling along with the small satellite on which it is mounted, longer TTFF may lead to no GPS fix due to disorientation of the receiver antenna. In this paper, we elucidate the design of a low-cost, low-power GPS receiver for small satellite applications. We also propose an energy optimization algorithm called F3to improve the TTFF which is the main contributor to the energy consumption during cold start. With simulations and in-orbit evaluation from a launched nanosatellite with our μGPS and high-end GPS simulators, we show that up to 96.16% of energy savings (consuming only ∼ 1/25th energy compared to the state of the art) can be achieved using our algorithm without compromising much (∼10 m) on the navigation accuracy. The TTFF achieved is at most 33 s.",attitude | GNSS | GPS | navigation | positioning | satellite | time to first fix | TTFF,10,0,,,H2020,737422,Horizon 2020 Framework Programme,MOBICOM Mobile
2-s2.0-85086757542,10.1145/3357713.3384234,,,Improved bounds for the sunflower lemma,cp,Conference Paper,Alweiss R.,60030612;60014966;60009982;60003269,"University of California, San Diego;Peking University;Harvard University;Princeton University",La Jolla;Beijing;Cambridge;Princeton,United States;China;United States;United States,4,"Alweiss, Ryan;Lovett, Shachar;Wu, Kewen;Zhang, Jiapeng",57200557201;24399368100;57210291715;56779647000,60003269;60030612;60014966;60009982,2020-06-08,8 June 2020,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,624-630,"A sunflower with r petals is a collection of r sets so that the intersection of each pair is equal to the intersection of all. ErdA's and Rado proved the sunflower lemma: for any fixed r, any family of sets of size w, with at least about ww sets, must contain a sunflower. The famous sunflower conjecture is that the bound on the number of sets can be improved to cw for some constant c. In this paper, we improve the bound to about (logw)w. In fact, we prove the result for a robust notion of sunflowers, for which the bound we obtain is tight up to lower order terms.",Robust sunflower lemma | Sunflower conjecture | Switching lemma,26,0,repositoryam,Green,NSF,1614023,National Science Foundation,STOC Theory
2-s2.0-85091286158,10.1145/3313831.3376649,,,Isness: Using Multi-Person VR to Design Peak Mystical Type Experiences Comparable to Psychedelics,cp,Conference Paper,Glowacki D.R.,60020650;60010964;125143240,"University of Bristol;Goldsmiths, University of London;ArtSci International Foundation",Bristol;London;Bristol,United Kingdom;United Kingdom;United Kingdom,9,"Glowacki, David R.;Wonnacott, Mark D.;Freire, Rachel;Glowacki, Becca R.;Gale, Ella M.;Pike, James E.;De Haan, Tiu;Chatziapostolou, Mike;Metatla, Oussama",16424472800;57209237066;57194065116;57195223882;47061441400;57193579322;57219112136;57219113159;26422343700,60020650;60020650;60020650;60010964;60020650;125143240;125143240;125143240;60020650,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376649,,"Studies combining psychotherapy with psychedelic drugs (Ds) have demonstrated positive outcomes that are often associated with 'Ds' ability to induce 'mystical-type' experiences (MTEs) i.e., subjective experiences whose characteristics include a sense of connectedness, transcendence, and ineffability. We suggest that both PsiDs and virtual reality can be situated on a broader spectrum of psychedelic technologies. To test this hypothesis, we used concepts, methods, and analysis strategies from D research to design and evaluate 'Isness', a multi-person VR journey where participants experience the collective emergence, fluctuation, and dissipation of their bodies as energetic essences. A study (N=57) analyzing participant responses to a commonly used D experience questionnaire (MEQ30) indicates that Isness participants reported MTEs comparable to those reported in double-blind clinical studies after high doses of psilocybin and LSD. Within a supportive setting and conceptual framework, VR phenomenology can create the conditions for MTEs from which participants derive insight and meaning.",altered states | meaning in HCI | mystical-type experiences | psychedelic drugs | user experience | virtual reality,25,0,repositoryam,Green,EPSRC,EP/N00616X/2,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-85107491666,,,,Language models are few-shot learners,cp,Conference Paper,Brown T.B.,60005248,Johns Hopkins University,Baltimore,United States,31,"Brown, Tom B.;Mann, Benjamin;Ryder, Nick;Subbiah, Melanie;Kaplan, Jared;Dhariwal, Prafulla;Neelakantan, Arvind;Shyam, Pranav;Sastry, Girish;Askell, Amanda;Agarwal, Sandhini;Herbert-Voss, Ariel;Krueger, Gretchen;Henighan, Tom;Child, Rewon;Ramesh, Aditya;Ziegler, Daniel M.;Wu, Jeffrey;Winter, Clemens;Hesse, Christopher;Chen, Mark;Sigler, Eric;Litwin, Mateusz;Gray, Scott;Chess, Benjamin;Clark, Jack;Berner, Christopher;McCandlish, Sam;Radford, Alec;Sutskever, Ilya;Amodei, Dario",57202058668;57219733292;56183454400;57219740064;15762464300;57208443671;57159776800;57202459885;57204163608;57203201455;57216966424;57193756754;57219640910;35078614100;57200082965;57219742744;57219500281;57221513313;57219736727;57213830824;57219740256;57219740241;57219736141;57219623424;57219632869;57219524132;57219734350;57219628611;57194207358;24831264500;12779446200,;;;;60005248;;;;;;;;;;;;;;;;;;;;;;;;;;,2020-01-01,2020,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,2020-December,,,,"We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3’s few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.",,8203,0,,,,undefined,,NeurIPS Machine Learning
2-s2.0-85086141119,10.1145/3372224.3380892,,,M-Cube: A millimeter-wave massive MIMO software radio,cp,Conference Paper,Zhao R.,60030612,"University of California, San Diego",La Jolla,United States,5,"Zhao, Renjie;Woodford, Timothy;Wei, Teng;Qian, Kun;Zhang, Xinyu",57217089503;57217089403;56225555400;58711335300;55431215200,60030612;60030612;60030612;60030612;60030612,2020-04-16,16 April 2020,"Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM",,21100994451,,Conference Proceeding,,,,190-203,"Millimeter-wave (mmWave) technologies represent a cornerstone for emerging wireless network infrastructure, and for RF sensing systems in security, health, and automotive domains. Through a MIMO array of phased arrays with hundreds of antenna elements, mmWave can boost wireless bit-rates to 100+ Gbps, and potentially achieve near-vision sensing resolution. However, the lack of an experimental platform has been impeding research in this field. This paper fills the gap with M3 (M-Cube), the first mmWave massive MIMO software radio. M3 features a fully reconfigurable array of phased arrays, with up to 8 RF chains and 288 antenna elements. Despite the orders of magnitude larger antenna arrays, its cost is orders of magnitude lower, even when compared with state-of-the-art single RF chain mmWave software radios. The key design principle behind M3 is to hijack a low-cost commodity 802.11ad radio, separate the control path and data path inside, regenerate the phased array control signals, and recreate the data signals using a programmable baseband. Extensive experiments have demonstrated the effectiveness of the M3 design, and its usefulness for research in mmWave massive MIMO communication and sensing.",60 GHz | experimental platform | millimeter-wave | MIMO | software radio | testbed,41,1,publisherfree2read,Bronze,NSF,1925767,National Science Foundation,MOBICOM Mobile
2-s2.0-85087048298,10.1145/3313831.3376330,,,MRAT: The Mixed Reality Analytics Toolkit,cp,Conference Paper,Nebeling M.,60025778;125143170;125143126;125143030,"University of Michigan, Ann Arbor;School of Nursing;College of Literature;College of Engineering",Ann Arbor;;;,United States;Belgium;Belgium;Belgium,14,"Nebeling, Michael;Speicher, Maximilian;Wang, Xizi;Rajaram, Shwetha;Hall, Brian D.;Xie, Zijian;Raistrick, Alexander R.E.;Aebersold, Michelle;Happ, Edward G.;Wang, Jiayin;Sun, Yanan;Zhang, Lotus;Ramsier, Leah E.;Kulkarni, Rhea",25641731100;55339376500;57207885162;57219111479;57193542458;57219109620;57219114078;24605395500;57202028837;57219116653;57219113549;57219110257;57219114747;57219116280,60025778-125143030;60025778;60025778;60025778;60025778;125143126;125143030;60025778-125143170;60025778;60025778;60025778;60025778;60025778;60025778,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376330,,"Significant tool support exists for the development of mixed reality (MR) applications; however, there is a lack of tools for analyzing MR experiences. We elicit requirements for future tools through interviews with 8 university research, instructional, and media teams using AR/VR in a variety of domains. While we find a common need for capturing how users perform tasks in MR, the primary differences were in terms of heuristics and metrics relevant to each project. Particularly in the early project stages, teams were uncertain about what data should, and even could, be collected with MR technologies. We designed the Mixed Reality Analytics Toolkit (MRAT) to instrument MR apps via visual editors without programming and enable rapid data collection and filtering for visualizations of MR user sessions. With MRAT, we contribute flexible interaction tracking and task definition concepts, an extensible set of heuristic techniques and metrics to measure task success, and visual inspection tools with in-situ visualizations in MR. Focusing on a multi-user, cross-device MR crisis simulation and triage training app as a case study, we then show the benefits of using MRAT, not only for user testing of MR apps, but also performance tuning throughout the design process.",augmented/virtual reality | interaction tracking | user testing,32,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85091267288,10.1145/3313831.3376316,,,Mental Models of AI Agents in a Cooperative Game Setting,cp,Conference Paper,Gero K.I.,60030162;60011048,Columbia University;IBM Research,New York;Yorktown Heights,United States;United States,12,"Gero, Katy Ilonka;Ashktorab, Zahra;Dugan, Casey;Pan, Qian;Johnson, James;Geyer, Werner;Ruiz, Maria;Miller, Sarah;Millen, David R.;Campbell, Murray;Kumaravel, Sadhana;Zhang, Wei",57209396880;55533071900;22834285200;57219114939;57208703791;7005242070;57219108032;57219109515;6701694445;7403371273;57215316272;57219110342,60030162;60011048;60011048;60011048;60011048;60011048;60011048;60011048;60011048;60011048;60011048;60011048,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376316,,"As more and more forms of AI become prevalent, it becomes increasingly important to understand how people develop mental models of these systems. In this work we study people's mental models of AI in a cooperative word guessing game. We run think-aloud studies in which people play the game with an AI agent; through thematic analysis we identify features of the mental models developed by participants. In a large-scale study we have participants play the game with the AI agent online and use a post-game survey to probe their mental model. We find that those who win more often have better estimates of the AI agent's abilities. We present three components for modeling AI systems, propose that understanding the underlying technology is insufficient for developing appropriate conceptual models (analysis of behavior is also necessary), and suggest future work for studying the revision of mental models over time.",ai agents | artificial intelligence | conceptual models | games | mental models | think-aloud | word games,56,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85100224904,,,,No-regret learning dynamics for extensive-form correlated equilibrium,cp,Conference Paper,Celli A.,60027950;60023256,Carnegie Mellon University;Politecnico di Milano,Pittsburgh;Milan,United States;Italy,4,"Celli, Andrea;Marchesi, Alberto;Farina, Gabriele;Gatti, Nicola",57195953040;57195559882;57185229800;6602167825,60023256;60023256;60027950;60023256,2020-01-01,2020,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,2020-December,,,,"The existence of simple, uncoupled no-regret dynamics that converge to correlated equilibria in normal-form games is a celebrated result in the theory of multi-agent systems. Specifically, it has been known for more than 20 years that when all players seek to minimize their internal regret in a repeated normal-form game, the empirical frequency of play converges to a normal-form correlated equilibrium. Extensive-form (that is, tree-form) games generalize normal-form games by modeling both sequential and simultaneous moves, as well as private information. Because of the sequential nature and presence of partial information in the game, extensive-form correlation has significantly different properties than the normal-form counterpart, many of which are still open research directions. Extensive-form correlated equilibrium (EFCE) has been proposed as the natural extensive-form counterpart to normal-form correlated equilibrium. However, it was currently unknown whether EFCE emerges as the result of uncoupled agent dynamics. In this paper, we give the first uncoupled no-regret dynamics that converge to the set of EFCEs in n-player general-sum extensive-form games with perfect recall. First, we introduce a notion of trigger regret in extensive-form games, which extends that of internal regret in normal-form games. When each player has low trigger regret, the empirical frequency of play is close to an EFCE. Then, we give an efficient no-trigger-regret algorithm. Our algorithm decomposes trigger regret into local subproblems at each decision point for the player, and constructs a global strategy of the player from the local solutions at each decision point.",,26,0,,,NSF,CCF-1733556,National Science Foundation,NeurIPS Machine Learning
2-s2.0-85091288190,10.1145/3313831.3376545,,,On Being Iterated: The Affective Demands of Design Participation,cp,Conference Paper,Dourish P.,60026553;60023932;60007278,"University of Melbourne;University of Technology Sydney;University of California, Irvine",Melbourne;Sydney;Irvine,Australia;Australia;United States,4,"Dourish, Paul;Lawrence, Christopher;Leong, Tuck Wah;Wadley, Greg",7003544364;40161843900;55234419400;56948346700,60007278;60023932;60026553;60007278,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376545,,"Iteration is a central feature of most HCI design methods, creating as it does opportunities for engagements with stakeholder groups. But what does iteration demand of those groups? Under what conditions do iterative engagements arise, and with what stakes? Building on experiences with Aboriginal Australian communities, and drawing on feminist and decolonial thinking, we examine the nature of iteration for HCI and how it frames encounters between design and use, with a focus on the affective dimension of engagement in iterative design processes.",cultural computing | decolonial theory | feminist theory | iteration | participation | postcolonial theory | user-centered design,27,0,,,ARC,IN170100030,Australian Research Council,CHI Human-Computer Interaction
2-s2.0-85105168099,,,,On learning sets of symmetric elements,cp,Conference Paper,Maron H.,60076695;60012708;60002765,NVIDIA;Stanford University;Bar-Ilan University,Santa Clara;Stanford;Ramat Gan,United States;United States;Israel,4,"Maron, Haggai;Litany, Or;Chechik, Gal;Fetaya, Ethan",57190395932;55420308700;8451455800;55295819900,60076695;60012708;60002765;60076695,2020-01-01,2020,"37th International Conference on Machine Learning, ICML 2020",,21101044400,,Conference Proceeding,PartF168147-9,,,6690-6700,"Learning from unordered sets is a fundamental learning setup, recently attracting increasing attention. Research in this area has focused on the case where elements of the set are represented by feature vectors, and far less emphasis has been given to the common case where set elements themselves adhere to their own symmetries. That case is relevant to numerous applications, from deblurring image bursts to multi-view 3D shape recognition and reconstruction. In this paper, we present a principled approach to learning sets of general symmetric elements. We first characterize the space of linear layers that are equivariant both to element reordering and to the inherent symmetries of elements, like translation in the case of images. We further show that networks that are composed of these layers, called Deep Sets for Symmetric elements layers (DSS), are universal approximators of both invariant and equivariant functions. DSS layers are also straightforward to implement. Finally, we show that they improve over existing set-learning architectures in a series of experiments with images, graphs and pointclouds.",,26,0,,,ISF,737/18,Israel Science Foundation,ICML Machine Learning
2-s2.0-85090411256,10.1145/3394486.3403226,,,On Sampled Metrics for Item Recommendation,cp,Conference Paper,Krichene W.,60006191,Google LLC,Mountain View,United States,2,"Krichene, Walid;Rendle, Steffen",55605550500;14042211300,60006191;60006191,2020-08-23,23 August 2020,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,21101021267,,Conference Proceeding,,,,1748-1757,"The task of item recommendation requires ranking a large catalogue of items given a context. Item recommendation algorithms are evaluated using ranking metrics that depend on the positions of relevant items. To speed up the computation of metrics, recent work often uses sampled metrics where only a smaller set of random items and the relevant items are ranked. This paper investigates sampled metrics in more detail and shows that they are inconsistent with their exact version, in the sense that they do not persist relative statements, e.g., recommender A is better than B, not even in expectation. Moreover, the smaller the sampling size, the less difference there is between metrics, and for very small sampling size, all metrics collapse to the AUC metric. We show that it is possible to improve the quality of the sampled metrics by applying a correction, obtained by minimizing different criteria such as bias or mean squared error. We conclude with an empirical evaluation of the naive sampled metrics and their corrected variants. To summarize, our work suggests that sampling should be avoided for metric calculation, however if an experimental study needs to sample, the proposed corrections can improve the quality of the estimate.",evaluation | item recommendation | metrics | sampled metric,234,1,publisherfree2read,Bronze,,undefined,,KDD Data Mining
2-s2.0-85097153545,10.1145/3368089.3409668,,,On decomposing a deep neural network into modules,cp,Conference Paper,Pan R.,60145790,Department of Computer Science,Ames,United States,2,"Pan, Rangeet;Rajan, Hridesh",57210927869;8288073800,60145790;60145790,2020-11-08,8 November 2020,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101029718,,Conference Proceeding,,,,889-900,"Deep learning is being incorporated in many modern software systems. Deep learning approaches train a deep neural network (DNN) model using training examples, and then use the DNN model for prediction. While the structure of a DNN model as layers is observable, the model is treated in its entirety as a monolithic component. To change the logic implemented by the model, e.g. to add/remove logic that recognizes inputs belonging to a certain class, or to replace the logic with an alternative, the training examples need to be changed and the DNN needs to be retrained using the new set of examples. We argue that decomposing a DNN into DNN modules - akin to decomposing a monolithic software code into modules - can bring the benefits of modularity to deep learning. In this work, we develop a methodology for decomposing DNNs for multi-class problems into DNN modules. For four canonical problems, namely MNIST, EMNIST, FMNIST, and KMNIST, we demonstrate that such decomposition enables reuse of DNN modules to create different DNNs, enables replacement of one DNN module in a DNN with another without needing to retrain. The DNN models formed by composing DNN modules are at least as good as traditional monolithic DNNs in terms of test accuracy for our problems.",Decomposing | Deep neural networks | Modularity | Modules,21,1,repositoryvor,Green,NSF,CCF-19-34884,National Science Foundation,FSE Software Engineering
2-s2.0-85090282991,10.1109/INFOCOM41043.2020.9155504,,,On the Power of Randomization for Scheduling Real-Time Traffic in Wireless Networks,cp,Conference Paper,Tsanikidis C.,60031321,The Fu Foundation School of Engineering and Applied Science,New York,United States,2,"Tsanikidis, Christos;Ghaderi, Javad",57205566098;24773339600,60031321;60031321,2020-07-01,July 2020,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2020-July,,9155504,59-68,"In this paper, we consider the problem of scheduling real-time traffic in wireless networks under a conflict-graph interference model and single-hop traffic. The objective is to guarantee that at least a certain fraction of packets of each link are delivered within their deadlines, which is referred to as delivery ratio. This problem has been studied before under restrictive frame-based traffic models, or greedy maximal scheduling schemes like LDF (Largest-Deficit First) that can lead to poor delivery ratio for general traffic patterns. In this paper, we pursue a different approach through randomization over the choice of maximal links that can transmit at each time. We design randomized policies in collocated networks, multipartite networks, and general networks, that can achieve delivery ratios much higher than what is achievable by LDF. Further, our results apply to traffic (arrival and deadline) processes that evolve as positive recurrent Markov chains. Hence, this work is an improvement with respect to both efficiency and traffic assumptions compared to the past work. We further present extensive simulation results over various traffic patterns and interference graphs to illustrate the gains of our randomized policies over LDF variants.",Markov Processes | Real-Time Traffic | Scheduling | Stability | Wireless Networks,10,0,repositoryam,Green,NSF,1652115,National Science Foundation,INFOCOM Networking
2-s2.0-85086587938,10.1145/3366423.3380268,,,Open Intent Extraction from Natural Language Interactions,cp,Conference Paper,Vedula N.,60076047;60003500,Adobe Inc.;The Ohio State University,San Jose;Columbus,United States;United States,4,"Vedula, Nikhita;Lipka, Nedim;Maneriker, Pranav;Parthasarathy, Srinivasan",57195106393;25927367600;57192008241;7101695336,60003500;60003500;60076047;60003500,2020-04-20,20 April 2020,"The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020",,21101004818,,Conference Proceeding,,,,2009-2020,"Accurately discovering user intents from their written or spoken language plays a critical role in natural language understanding and automated dialog response. Most existing research models this as a classification task with a single intent label per utterance, grouping user utterances into a single intent type from a set of categories known beforehand. Going beyond this formulation, we define and investigate a new problem of open intent discovery. It involves discovering one or more generic intent types from text utterances, that may not have been encountered during training. We propose a novel domain-agnostic approach, OPINE, which formulates the problem as a sequence tagging task under an open-world setting. It employs a CRF on top of a bidirectional LSTM to extract intents in a consistent format, subject to constraints among intent tag labels. We apply a multi-head self-attention mechanism to effectively learn dependencies between distant words. We further use adversarial training to improve performance and robustly adapt our model across varying domains. Finally, we curate and plan to release an open intent annotated dataset of 25K real-life utterances spanning diverse domains. Extensive experiments show that our approach outperforms state-of-the-art baselines by 5-15% F1 score points. We also demonstrate the efficacy of OPINE in recognizing multiple, diverse domain intents with limited (can also be zero) training examples per unique domain.",,30,0,,,NSF,EAR-1520870,National Science Foundation,WWW World Wide Web
2-s2.0-85086874172,10.14778/3377369.3377373,,,Opportunities for optimism in contended main-memory multicore transactions,cp,Conference Paper,Huang Y.,60022195;60016247;60009982,Massachusetts Institute of Technology;Brandeis University;Harvard University,Cambridge;Waltham;Cambridge,United States;United States;United States,5,"Huang, Yihe;Qian, William;Kohler, Eddie;Liskov, Barbara;Shrira, Liuba",57189507563;57219294680;9133554700;7003295036;6603527962,60009982;60009982;60009982;60022195;60016247,2020-01-01,2020,Proceedings of the VLDB Endowment,,21100199855,21508097,Journal,13,5,,629-642,"Optimistic concurrency control, or OCC, can achieve excellent performance on uncontended workloads for main-memory transactional databases. Contention causes OCC's performance to degrade, however, and recent concurrency control designs, such as hybrid OCC/locking systems and variations on multiversion concurrency control (MVCC), have claimed to outperform the best OCC systems. We evaluate several concurrency control designs under varying contention and varying workloads, including TPCC, and find that implementation choices unrelated to concurrency control may explain much of OCC's previously-reported degradation. When these implementation choices are made sensibly, OCC performance does not collapse on high-contention TPC-C. We also present two optimization techniques, commit-time updates and timestamp splitting, that can dramatically improve the highcontention performance of both OCC and MVCC. Though these techniques are known, we apply them in a new context and highlight their potency: when combined, they lead to performance gains of 3:4 for MVCC and 3:6 for OCC in a TPC-C workload.",,31,0,repositoryam,Green,NSF,1704376,National Science Foundation,VLDB Databases
2-s2.0-85091306289,10.1145/3313831.3376147,,,PenSight: Enhanced Interaction with a Pen-Top Camera,cp,Conference Paper,Matulic F.,60120917;60025272;60014171,"Preferred Networks, Inc.;The University of Tokyo;University of Waterloo",Tokyo;Tokyo;Waterloo,Japan;Japan;Canada,4,"Matulic, Fabrice;Arakawa, Riku;Vogel, Brian;Vogel, Daniel",16239407900;57209398650;57204724380;8435582600,60120917;60025272;60120917;60014171,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376147,,"We propose mounting a downward-facing camera above the top end of a digital tablet pen. This creates a unique and practical viewing angle for capturing the pen-holding hand and the immediate surroundings which can include the other hand. The fabrication of a prototype device is described and the enabled interaction design space is explored, including dominant and non-dominant hand pose recognition, tablet grip detection, hand gestures, capturing physical content in the environment, and detecting users and pens. A deep learning computer vision pipeline is developed for classification, regression, and keypoint detection to enable these interactions. Example applications demonstrate usage scenarios and a qualitative user evaluation confirms the potential of the approach.",hand pose estimation | pen input | tablet input,17,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85086241436,10.1145/3318464.3389705,,,Pump Up the Volume: Processing Large Data on GPUs with Fast Interconnects,cp,Conference Paper,Lutz C.,60075096;60021763;60011604,German Research Center for Artificial Intelligence (DFKI);Universität Potsdam;Technische Universität Berlin,Kaiserslautern;Potsdam;Berlin,Germany;Germany;Germany,5,"Lutz, Clemens;Breß, Sebastian;Zeuch, Steffen;Rabl, Tilmann;Markl, Volker",57203024558;55418987000;57131076000;23135482100;6602853794,60075096;60011604;60075096;60021763;60075096,2020-06-14,14 June 2020,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,1633-1649,"GPUs have long been discussed as accelerators for database query processing because of their high processing power and memory bandwidth. However, two main challenges limit the utility of GPUs for large-scale data processing: (1) the on-board memory capacity is too small to store large data sets, yet (2) the interconnect bandwidth to CPU main-memory is insufficient for ad hoc data transfers. As a result, GPU-based systems and algorithms run into a transfer bottleneck and do not scale to large data sets. In practice, CPUs process large-scale data faster than GPUs with current technology. In this paper, we investigate how a fast interconnect can resolve these scalability limitations using the example of NVLink 2.0. NVLink 2.0 is a new interconnect technology that links dedicated GPUs to a CPU. The high bandwidth of NVLink 2.0 enables us to overcome the transfer bottleneck and to efficiently process large data sets stored in main-memory on GPUs. We perform an in-depth analysis of NVLink 2.0 and show how we can scale a no-partitioning hash join beyond the limits of GPU memory. Our evaluation shows speed-ups of up to 18x over PCI-e 3.0 and up to 7.3x over an optimized CPU implementation. Fast GPU interconnects thus enable GPUs to efficiently accelerate query processing.",,51,0,,,H2020,01MD19002B,Horizon 2020 Framework Programme,SIGMOD Databases
2-s2.0-85090269422,10.1109/INFOCOM41043.2020.9155402,,,Push the Limit of Acoustic Gesture Recognition,cp,Conference Paper,Wang Y.,60008928,The Hong Kong Polytechnic University,Hong Kong,Hong Kong,3,"Wang, Yanwen;Shen, Jiaxing;Zheng, Yuanqing",57195339527;57190188683;55921933300,60008928;60008928;60008928,2020-07-01,July 2020,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2020-July,,9155402,566-575,"With the flourish of the smart devices and their applications, controlling devices using gestures has attracted increasing attention for ubiquitous sensing and interaction. Recent works use acoustic signals to track hand movement and recognize gestures. However, they suffer from low robustness due to frequency selective fading, interference and insufficient training data. In this work, we propose RobuCIR, a robust contact-free gesture recognition system that can work under different usage scenarios with high accuracy and robustness. RobuCIR adopts frequency-hopping mechanism to mitigate frequency selective fading and avoid signal interference. To further increase system robustness, we investigate a series of data augmentation techniques based on a small volume of collected data to emulate different usage scenarios. The augmented data is used to effectively train neural network models and cope with various influential factors (e.g., gesture speed, distance to transceiver, etc.). Our experiment results show that RobuCIR can recognize 15 gestures and outperform state-of-the-art works in terms of accuracy and robustness.",,63,0,,,,PolyU 152165/19E,,INFOCOM Networking
2-s2.0-85088476666,10.1145/3393691.3394214,,,Rateless Codes for Near-Perfect Load Balancing in Distributed Matrix-Vector Multiplication,ar,Article,Mallick A.,60027950;60027758;60010449;124394730,Carnegie Mellon University;Oracle Corporation;Apple Computer;Automation Anywhere,Pittsburgh;Austin;Cupertino;San Jose,United States;United States;United States;United States,5,"Mallick, Ankur;Chaudhari, Malhar;Sheth, Utsav;Palanikumar, Ganesh;Joshi, Gauri",57209887587;57207584030;57192554675;57217281050;7103298819,60027950;60027758;124394730;60010449;60027950,2020-07-08,8 July 2020,Performance Evaluation Review,01635999,26742,,Journal,48,1,,95-96,Large-scale machine learning and data mining applications require computer systems to perform massive matrix-vector and matrixmatrix multiplication operations that need to be parallelized across multiple nodes. The presence of stragglers - nodes that unpredictably slowdown or fail - is a major bottleneck in such distributed computations. We propose a rateless fountain coding strategy to address this issue. Our idea is to create linear combinations of the m rows of the matrix and assign these encoded rows to different worker nodes. The original matrix-vector product can be decoded as soon as slightly more than m row-vector products are collectively finished by the nodes.We show that our approach achieves optimal latency and performs zero redundant computations asymptotically. Experiments on Amazon EC2 show that rateless coding gives as much as 3× speed-up over uncoded schemes.,erasure coded computing | large-scale parallel computing | rateless fountain codes,8,0,repositoryam,Green,NSF,1850029,National Science Foundation,SIGMETRICS Performance
2-s2.0-85091315052,10.1145/3313831.3376531,,,"ReFind: Design, Lived Experience and Ongoingness in Bereavement",cp,Conference Paper,Wallace J.,60032204;60009602;60006222;60004636,Sheffield Hallam University;University of Limerick;Newcastle University;University of Northumbria,Sheffield;Limerick;Newcastle;Newcastle,United Kingdom;Ireland;United Kingdom;United Kingdom,13,"Wallace, Jayne;Montague, Kyle;Duncan, Trevor;Carvalho, Luís P.;Koulidou, Nantia;Mahoney, Jamie;Morrissey, Kellie;Craig, Claire;Groot, Linnea Iris;Lawson, Shaun;Olivier, Patrick;Trueman, Julie;Fisher, Helen",14631446700;36701846300;57188852090;57218140245;57194763891;57202740460;55802585500;36959012300;57218135678;7102733670;57209133100;57194836307;57209286789,60004636;60004636;60004636;60004636;60004636;60004636;60009602;60032204;60006222;60004636;60004636;60004636;60004636,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376531,,"We describe the design and use of ReFind, a handheld artefact made for people who are bereaved and are ready to re-explore their relationship to the deceased person. ReFind was made within a project seeking to develop new ways to curate and create digital media to support ongoingness - an active, dynamic component of continuing bonds. We draw on bereavement theory and care championing practices that enable a continued sense of connection between someone bereaved and a person who has died. We present the design development of ReFind and the lived experience of the piece by the first author. We discuss our wider methodology which includes autobiographical design and reflections on if and how the piece supported ongoing connections, the challenges faced, and insights gained.",autobiographical | autoethnography | bereavement | continuing bonds | death | design | digital images | grief | lived experience | ongoingness | photographs | physical/digital | relational selves,16,0,repositoryam,Green,BBC,EP/P025609/1,British Broadcasting Corporation,CHI Human-Computer Interaction
2-s2.0-85090277600,10.1109/INFOCOM41043.2020.9155394,,,Reducing the Service Function Chain Backup Cost over the Edge and Cloud by a Self-adapting Scheme,cp,Conference Paper,Shang X.,60026415,Stony Brook University,Stony Brook,United States,4,"Shang, Xiaojun;Huang, Yaodong;Liu, Zhenhua;Yang, Yuanyuan",57205482054;57195338596;55714470900;35308464100,60026415;60026415;60026415;60026415,2020-07-01,July 2020,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2020-July,,9155394,2096-2105,"The fast development of virtual network functions (VNFs) brings new opportunities to network service deployment on edge networks. For complicated services, VNFs can chain up to form service function chains (SFCs). Despite the promises, it is still not clear how to backup VNFs to minimize the cost while meeting the SFC availability requirements in an online manner. In this paper, we propose a novel self-adapting scheme named SAB to efficiently backup VNFs over both the edge and the cloud. Specifically, SAB uses both static backups and dynamic ones created on the fly to accommodate the resource limitation of edge networks. For each VNF backup, SAB determines whether to place it on the edge or the cloud, and if on the edge, which edge server to use for load balancing. SAB does not assume failure rates of VNFs but instead strives to find the sweet point between the desired availability of SFCs and the backup cost. Both theoretical performance bounds and extensive simulation results highlight that SAB provides significantly higher availability with lower backup cost compared with existing baselines.",Availability | Edge computing | Service function chain | Virtual network functions,31,0,,,NSF,CCF-1526162,National Science Foundation,INFOCOM Networking
2-s2.0-85088511254,10.1145/3313831.3376270,,,Robots for Inclusive Play: Co-designing an Educational Game with Visually Impaired and sighted Children,cp,Conference Paper,Metatla O.,60102124;60020650;114939638,Université de Toulouse;University of Bristol;CNRS,Toulouse;Bristol;Singapore City,France;United Kingdom;Singapore,5,"Metatla, Oussama;Bardot, Sandra;Cullen, Clare;Serrano, Marcos;Jouffrais, Christophe",26422343700;56449085300;57202044709;17435886300;7801364165,60020650;60102124;60020650;60102124;114939638,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376270,,"Despite being included in mainstream schools, visually impaired children still face barriers to social engagement and participation. Games could potentially help, but games that cater for both visually impaired and sighted players are scarce. We used a co-design approach to design and evaluate a robot-based educational game that could be inclusive of both visually impaired and sighted children in the context of mainstream education. We ran a focus group discussion with visual impairment educators to understand barriers to inclusive play. And then a series of co-design workshops to engage visually impaired and sighted children and educators in learning about robot technology and exploring its potential to support inclusive play experiences. We present design guidelines and an evaluation workshop of a game prototype, demonstrating group dynamics conducive to collaborative learning experiences, including shared goal setting/execution, closely coupled division of labour, and interaction symmetry.",co-design | education | games | inclusion | visual impairment,56,0,repositoryvor,Green,EPSRC,ANR-14-CE17-0018,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-85094824703,10.1145/3387514.3405864,,,Routing on Multiple Optimality Criteria,cp,Conference Paper,Sobrinho J.L.,60004956,Instituto Superior Técnico,Lisbon,Portugal,2,"Sobrinho, João Luís;Ferreira, Miguel Alves",7004507015;57213769415,60004956;60004956,2020-07-30,30 July 2020,"SIGCOMM 2020 - Proceedings of the 2020 Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication",,21101024104,,Conference Proceeding,,,,211-225,"Standard vectoring protocols, such as EIGRP, BGP, DSDV, or Babel, only route on optimal paths when the total order on path attributes that substantiates optimality is consistent with the extension operation that calculates path attributes from link attributes, leaving out many optimality criteria of practical interest. We present a solution to this problem and, more generally, to the problem of routing on multiple optimality criteria. A key idea is the derivation of a partial order on path attributes that is consistent with the extension operation and respects every optimality criterion of a designated collection of such criteria. We design new vectoring protocols that compute on partial orders, with every node capable of electing multiple attributes per destination rather than a single attribute as in standard vectoring protocols. Our evaluation over publicly available network topologies and attributes shows that the proposed protocols converge fast and enable optimal path routing concurrently for many optimality criteria with only a few elected attributes at each node per destination. We further show how predicating computations on partial orders allows incorporation of service chain constraints on optimal path routing.",optimal path routing | optimality criteria | partial orders | Routing | routing algebras | routing protocols,13,0,,,,UIDB/50008/2020,,SIGCOMM Networking
2-s2.0-85086240189,10.1145/3318464.3389722,,,ShapeSearch: A Flexible and Efficient System for Shape-based Exploration of Trendlines,cp,Conference Paper,Siddiqui T.,60025038;60000745,"University of California, Berkeley;University of Illinois Urbana-Champaign",Berkeley;Urbana,United States;United States,5,"Siddiqui, Tarique;Luh, Paul;Wang, Zesheng;Karahalios, Karrie;Parameswaran, Aditya",57193783054;57205167886;57205165544;23397392600;25825526000,60000745;60000745;60000745;60000745;60025038,2020-06-14,14 June 2020,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,51-65,"Identifying trendline visualizations with desired patterns is a common task during data exploration. Existing visual analytics tools offer limited flexibility, expressiveness, and scalability for such tasks, especially when the pattern of interest is under-specified and approximate. We propose ShapeSearch, an efficient and flexible pattern-searching tool, that enables the search for desired patterns via multiple mechanisms: sketch, natural-language, and visual regular expressions. We develop a novel shape querying algebra, with a minimal set of primitives and operators that can express a wide variety of shape search queries, and design a natural- language and regex-based parser to translate user queries to the algebraic representation. To execute these queries within interactive response times, ShapeSearch uses a fast shape algebra execution engine with query-aware optimizations, and perceptually-aware scoring methodologies. We present a thorough evaluation of the system, including a user study, a case study involving genomics data analysis, as well as performance experiments, comparing against state-of-the-art trendline shape matching approaches-that together demonstrate the usability and scalability of ShapeSearch.",natural language | pattern querying | query processing | regular expression | shape algebra | time series,15,1,repositoryam,Green,NSF,1940759,National Science Foundation,SIGMOD Databases
2-s2.0-85097352354,,,,Synthesizing aspect-driven recommendation explanations from reviews,cp,Conference Paper,Le T.H.,60018933,Singapore Management University,Singapore City,Singapore,2,"Le, Trung Hoang;Lauw, Hady W.",57220546842;6602548473,60018933;60018933,2020-01-01,2020,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2021-January,,,2427-2434,"Explanations help to make sense of recommendations, increasing the likelihood of adoption. However, existing approaches to explainable recommendations tend to rely on rigid, standardized templates, customized only via fill-in-the-blank aspect sentiments. For more flexible, literate, and varied explanations covering various aspects of interest, we synthesize an explanation by selecting snippets from reviews, while optimizing for representativeness and coherence. To fit target users' aspect preferences, we contextualize the opinions based on a compatible explainable recommendation model. Experiments on datasets of several product categories showcase the efficacies of our method as compared to baselines based on templates, review summarization, selection, and text generation.",,10,0,,,,NRF-NRFF2016-07,"Prime Minister's Office, Brunei Darussalam",IJCAI Artificial Intelligence
2-s2.0-85087108596,10.1109/SP40000.2020.00090,,,TRRespass: Exploiting the many sides of target row refresh,cp,Conference Paper,Frigo P.,60025858;60008734;125160094,ETH Zürich;Vrije Universiteit Amsterdam;Qualcomm Technologies Inc,Zurich;Amsterdam;,Switzerland;Netherlands;,8,"Frigo, Pietro;Vannacc, Emanuele;Hassan, Hasan;Der Veen, Victor Van;Mutlu, Onur;Giuffrida, Cristiano;Bos, Herbert;Razavi, Kaveh",57203239513;57219176006;57189066886;57219184602;16043006700;35487484200;8946958300;55532049200,60008734;60008734;60008734-60025858;125160094;60025858;60008734;60008734;60008734,2020-05-01,May 2020,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2020-May,,9152631,747-762,"After a plethora of high-profile RowHammer attacks, CPU and DRAM vendors scrambled to deliver what was meant to be the definitive hardware solution against the RowHammer problem: Target Row Refresh (TRR). A common belief among practitioners is that, for the latest generation of DDR4 systems that are protected by TRR, RowHammer is no longer an issue in practice. However, in reality, very little is known about TRR. How does TRR exactly prevent RowHammer? Which parts of a system are responsible for operating the TRR mechanism? Does TRR completely solve the RowHammer problem or does it have weaknesses? In this paper, we demystify the inner workings of TRR and debunk its security guarantees. We show that what is advertised as a single mitigation mechanism is actually a series of different solutions coalesced under the umbrella term Target Row Refresh. We inspect and disclose, via a deep analysis, different existing TRR solutions and demonstrate that modern implementations operate entirely inside DRAM chips. Despite the difficulties of analyzing in-DRAM mitigations, we describe novel techniques for gaining insights into the operation of these mitigation mechanisms. These insights allow us to build TRRespass, a scalable black-box RowHammer fuzzer that we evaluate on 42 recent DDR4 modules. TRRespass shows that even the latest generation DDR4 chips with in-DRAM TRR, immune to all known RowHammer attacks, are often still vulnerable to new TRR-aware variants of RowHammer that we develop. In particular, TRRespass finds that, on present-day DDR4 modules, RowHammer is still possible when many aggressor rows are used (as many as 19 in some cases), with a method we generally refer to as Many-sided RowHammer. Overall, our analysis shows that 13 out of the 42 modules from all three major DRAM vendors (i.e., Samsung, Micron, and Hynix) are vulnerable to our TRR-aware RowHammer access patterns, and thus one can still mount existing state-of-the-art system-level RowHammer attacks. In addition to DDR4, we also experiment with LPDDR4(X)1 chips and show that they are susceptible to RowHammer bit flips too. Our results provide concrete evidence that the pursuit of better RowHammer mitigations must continue.",,80,1,repositoryam,Green,H2020,786669,Intel Corporation,S&P Security and Privacy
2-s2.0-85091273579,10.1145/3313831.3376777,,,Techniques for Flexible Responsive Visualization Design,cp,Conference Paper,Hoffswell J.,60076047;60015481,Adobe Inc.;University of Washington,San Jose;Seattle,United States;United States,3,"Hoffswell, Jane;Li, Wilmot;Liu, Zhicheng",56960604100;7501790814;55714445500,60015481;60076047;60015481,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376777,,"Responsive visualizations adapt to effectively present information based on the device context. Such adaptations are essential for news content that is increasingly consumed on mobile devices. However, existing tools provide little support for responsive visualization design. We analyze a corpus of 231 responsive news visualizations and discuss formative interviews with five journalists about responsive visualization design. These interviews motivate four central design guidelines: enable simultaneous cross-device edits, facilitate device-specific customization, show cross-device previews, and support propagation of edits. Based on these guidelines, we present a prototype system that allows users to preview and edit multiple visualization versions simultaneously. We demonstrate the utility of the system features by recreating four real-world responsive visualizations from our corpus.",mobile devices | news | responsive design | visualization,33,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85097138944,10.1145/3368089.3409685,,,Testing self-adaptive software with probabilistic guarantees on performance metrics,cp,Conference Paper,Mandrioli C.,60033241;60029170,Universität des Saarlandes;Lunds Universitet,Saarbrucken;Lund,Germany;Sweden,2,"Mandrioli, Claudio;Maggio, Martina",57204723757;25229008400,60029170;60033241,2020-11-08,8 November 2020,ESEC/FSE 2020 - Proceedings of the 28th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101029718,,Conference Proceeding,,,,1002-1014,"This paper discusses the problem of testing the performance of the adaptation layer in a self-adaptive system. The problem is notoriously hard, due to the high degree of uncertainty and variability inherent in an adaptive software application. In particular, providing any type of formal guarantee for this problem is extremely difficult. In this paper we propose the use of a rigorous probabilistic approach to overcome the mentioned difficulties and provide probabilistic guarantees on the software performance. We describe the set up needed for the application of a probabilistic approach. We then discuss the traditional tools from statistics that could be applied to analyse the results, highlighting their limitations and motivating why they are unsuitable for the given problem. We propose the use of a novel tool - the scenario theory - to overcome said limitations. We conclude the paper with a thorough empirical evaluation of the proposed approach, using two adaptive software applications: the Tele-Assistance Service and the Self-Adaptive Video Encoder. With the first, we empirically expose the trade-off between data collection and confidence in the testing campaign. With the second, we demonstrate how to compare different adaptation strategies.",Autonomous Systems | Self-Adaptive Software | Testing,9,0,repositoryvor,Green,H2020,871259,Horizon 2020 Framework Programme,FSE Software Engineering
2-s2.0-85090110372,10.1145/3313831.3376577,,,The Role of Everyday Sounds in Advanced Dementia Care,cp,Conference Paper,Houben M.,60032882;60023932;60017145;60016561,Technische Universiteit Eindhoven;University of Technology Sydney;Tilburg University;Philips Research,Eindhoven;Sydney;Tilburg;Eindhoven,Netherlands;Australia;Netherlands;Netherlands,6,"Houben, Maarten;Brankaert, Rens;Bakker, Saskia;Kenning, Gail;Bongers, Inge;Eggen, Berry",57209728191;56099926800;18933354000;56429334500;6601971607;14035458600,60032882;60032882;60016561;60023932;60017145;60032882,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376577,,"The representation of sounds derived from everyday life can be beneficial for people with dementia by evoking memories and emotional responses. Despite this potential, integrating sound and sound-based interventions in care facilities has not received much research attention. In this paper, we present the findings from a field study that explored the responses of 19 people with advanced dementia to a selection of everyday sounds presented to them in a care home and the role of these responses in the care environment. To study this, we deployed Vita, a 'pillow-like' sound player, in two dementia care facilities for four weeks, during which observations were recorded. Afterwards, we conducted interviews with caregivers who used Vita in everyday care practice. Our findings reveal how everyday sounds provided by Vita stimulated meaningful conversation, playfulness, and connection between residents and caregivers. Furthermore, we propose design implications for integrating everyday sounds in dementia care.",care home | dementia | design | everyday sounds | soundscapes,36,0,repositoryvor,Green,NWO,443001122,ZonMw,CHI Human-Computer Interaction
2-s2.0-85088923948,10.1145/3377811.3380402,,,Time-travel testing of android apps,cp,Conference Paper,Dong Z.,60019578;60017161;60003161,Monash University;National University of Singapore;University Politehnica of Bucharest,Clayton;Singapore City;Bucharest,Australia;Singapore;Romania,4,"Dong, Zhen;Bohme, Marcel;Cojocaru, Lucia;Roychoudhury, Abhik",56021953800;55321057200;57192818804;7005260419,60017161;60019578;60003161;60017161,2020-06-27,27 June 2020,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,3380402,481-492,"Android testing tools generate sequences of input events to exercise the state space of the app-under-test. Existing search-based techniques systematically evolve a population of event sequences so as to achieve certain objectives such as maximal code coverage. The hope is that the mutation of fit event sequences leads to the generation of even fitter sequences. However, the evolution of event sequences may be ineffective. Our key insight is that pertinent app states which contributed to the original sequence's fitness may not be reached by a mutated event sequence. The original path through the state space is truncated at the point of mutation. In this paper, we propose instead to evolve a population of states which can be captured upon discovery and resumed when needed. The hope is that generating events on a fit program state leads to the transition to even fitter states. For instance, we can quickly deprioritize testing the main screen state which is visited by most event sequences, and instead focus our limited resources on testing more interesting states that are otherwise difficult to reach. We call our approach time-travel testing because of this ability to travel back to any state that has been observed in the past. We implemented time-travel testing into TimeMachine, a time-travel enabled version of the successful, automated Android testing tool Monkey. In our experiments on a large number of open- and closed source Android apps, TimeMachine outperforms the state-of-theart search-based/model-based Android testing tools Sapienz and Stoat, both in terms of coverage achieved and crashes found.",,62,0,,,ARC,251RES1708,Australian Research Council,ICSE Software Engineering
2-s2.0-85090501855,10.1145/3313831.3376471,,,Touching and Being in Touch with the Menstruating Body,cp,Conference Paper,Campo Woytuk N.,60002014,The Royal Institute of Technology (KTH),Stockholm,Sweden,4,"Campo Woytuk, Nadia;Søndergaard, Marie Louise Juul;Ciolfi Felice, Marianela;Balaam, Madeline",57209301889;57055311400;57190406918;36095639700,60002014;60002014;60002014;60002014,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376471,,"We describe a Research through Design project-Curious Cycles-A collection of objects and interactions which encourage people to be in close contact with their menstruating body. Throughout a full menstrual cycle, five participants used Curious Cycles to look at their bodies in unfamiliar ways and to touch their bodily fluids, specifically, menstrual blood, saliva, and cervical mucus. The act of touching and looking led to the construction of new knowledge about the self and to a nurturing appreciation for the changing body. Yet, participants encountered and reflected upon frictions within themselves, their home, and their social surroundings, which stem from societal stigma and preconceptions about menstruation and bodily fluids. We call for and show how interaction design can engage with technologies that mediate self-touch as a first step towards reconfiguring the way menstruating bodies are treated in society.",feminist hci | menstrual cycles | menstruation | research through design | touching | women's health,42,1,repositoryam,Green,VR,2017-05133,Vetenskapsrådet,CHI Human-Computer Interaction
2-s2.0-85094316034,10.1145/3377811.3380351,,,Towards the use of the readily available tests from the release pipeline as performance tests. arewe there yet,cp,Conference Paper,Ding Z.,60033154,Concordia University,Montreal,Canada,3,"Ding, Zishuo;Chen, Jinfu;Shang, Weiyi",57145921100;57200285624;35093168200,60033154;60033154;60033154,2020-06-27,27 June 2020,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,3380351,1435-1446,"Performance is one of the important aspects of software quality. Performance issues exist widely in software systems, and the process of fixing the performance issues is an essential step in the release cycle of software systems. Although performance testing is widely adopted in practice, it is still expensive and time-consuming. In particular, the performance testing is usually conducted after the system is built in a dedicated testing environment. The challenges of performance testing make it difficult to fit into the common DevOps process in software development. On the other hand, there exist a large number of tests readily available, that are executed regularly within the release pipeline during software development. In this paper, we perform an exploratory study to determine whether such readily available tests are capable of serving as performance tests. In particular, we would like to see whether the performance of these tests can demonstrate performance improvements obtained from fixing real-life performance issues. We collect 127 performance issues from Hadoop and Cassandra, and evaluate the performance of the readily available tests from the commits before and after the performance issue fixes. We find that most of the improvements from the fixes to performance issues can be demonstrated using the readily available tests in the release pipeline. However, only a very small portion of the tests can be used for demonstrating the improvements. By manually examining the tests, we identify eight reasons that a test cannot demonstrate performance improvements even though it covers the changed source code of the issue fix. Finally, we build random forest classifiers determining the important metrics influencing the readily available tests (not) being able to demonstrate performance improvements from issue fixes. We find that the test code itself and the source code covered by the test are important factors, while the factors related to the code changes in the performance issues fixes have a low importance. Practitioners may focus on designing and improving the tests, instead of finetuning tests for different performance issues fixes. Our findings can be used as a guideline for practitioners to reduce the amount of effort spent on leveraging and designing tests that run in the release pipeline for performance assurance activities.",Performance issues | Performance testing | Software performance,24,0,,,,undefined,,ICSE Software Engineering
2-s2.0-85093673754,10.1145/3379597.3387440,,,Traceability Support for Multi-Lingual Software Projects,cp,Conference Paper,Liu Y.,60021508,University of Notre Dame,Notre Dame,United States,3,"Liu, Yalin;Lin, Jinfeng;Cleland-Huang, Jane",57200512589;57200513163;6506741859,60021508;60021508;60021508,2020-06-29,29 June 2020,"Proceedings - 2020 IEEE/ACM 17th International Conference on Mining Software Repositories, MSR 2020",,21101023641,,Conference Proceeding,,,,443-454,"Software traceability establishes associations between diverse software artifacts such as requirements, design, code, and test cases. Due to the non-trivial costs of manually creating and maintaining links, many researchers have proposed automated approaches based on information retrieval techniques. However, many globally distributed software projects produce software artifacts written in two or more languages. The use of intermingled languages reduces the efficacy of automated tracing solutions. In this paper, we first analyze and discuss patterns of intermingled language use across multiple projects, and then evaluate several different tracing algorithms including the Vector Space Model (VSM), Latent Semantic Indexing (LSI), Latent Dirichlet Allocation (LDA), and various models that combine mono-and cross-lingual word embeddings with the Generative Vector Space Model (GVSM). Based on an analysis of 14 Chinese-English projects, our results show that best performance is achieved using mono-lingual word embeddings integrated into GVSM with machine translation as a preprocessing step.",Cross-lingual information retrieval | Generalized Vector Space Model | Traceability,7,0,repositoryam,Green,NSF,1901059,National Science Foundation,ICSE Software Engineering
2-s2.0-85115714233,10.1109/ICSE-Companion52605.2021.00037,,,V2S: A Tool for Translating Video Recordings of Mobile App Usages into Replayable Scenarios,cp,Conference Paper,Havranek M.,60016114,William &amp; Mary,Williamsburg,United States,6,"Havranek, Madeleine;Bernal-Cardenas, Carlos;Cooper, Nathan;Chaparro, Oscar;Poshyvanyk, Denys;Moran, Kevin",57222573538;55848479200;57194646990;25631575400;13613571900;57095532500,60016114;60016114;60016114;60016114;60016114;60016114,2021-05-01,May 2021,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,65-68,"Screen recordings are becoming increasingly important as rich software artifacts that inform mobile application development processes. However, the amount of manual effort required to extract information from these graphical artifacts can hinder resource-constrained mobile developers. This paper presents Video2Scenario (V2S), an automated tool that processes video recordings of Android app usages, utilizes neural object detection and image classification techniques to classify the depicted user actions, and translates these actions into a replayable scenario. We conducted a comprehensive evaluation to demonstrate V2S's ability to reproduce recorded scenarios across a range of devices and a diverse set of usage cases and applications. The results indicate that, based on its performance with 175 videos depicting 3,534 GUI-based actions, V2S is accurate in reproducing approximately 89% of actions from collected videos.",Bug Reporting | Mobile Apps | Object Detection | Screen Recordings,6,0,repositoryam,Green,CISE,CCF-1815186,Directorate for Computer and Information Science and Engineering,ICSE Software Engineering
2-s2.0-85090224243,10.1145/3313831.3376448,,,Transparency of CHI Research Artifacts: Results of a Self-Reported Survey,cp,Conference Paper,Wacharamanotham C.,60106017;60028637;60012614,Université Paris-Saclay;Bauhaus-Universität Weimar;Universität Zürich,Gif-sur-Yvette;Weimar;Zurich,France;Germany;Switzerland,4,"Wacharamanotham, Chat;Eisenring, Lukas;Haroz, Steve;Echtler, Florian",39362715700;57209241992;15135874200;24821578300,60012614;60012614;60106017;60028637,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376448,,"Several fields of science are experiencing a ""replication crisis"" that has negatively impacted their credibility. Assessing the validity of a contribution via replicability of its experimental evidence and reproducibility of its analyses requires access to relevant study materials, data, and code. Failing to share them limits the ability to scrutinize or build-upon the research, ultimately hindering scientific progress. Understanding how the diverse research artifacts in HCI impact sharing can help produce informed recommendations for individual researchers and policy-makers in HCI. Therefore, we surveyed authors of CHI 2018-2019 papers, asking if they share their papers' research materials and data, how they share them, and why they do not. The results (34% response rate) show that sharing is uncommon, partly due to misunderstandings about the purpose of sharing and reliable hosting. We conclude with recommendations for fostering open research practices. This paper and all data and materials are freely available at https://osf.io/3bu6t.",data availability | open data | open science | public data sharing,38,0,repositoryvor,Green,NSF,undefined,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85087499283,10.1145/3313831.3376806,,,Trigeminal-based Temperature Illusions,cp,Conference Paper,Brooks J.,60029278,The University of Chicago,Chicago,United States,3,"Brooks, Jas;Nagels, Steven;Lopes, Pedro",57219108258;57493740900;55480857700,60029278;60029278;60029278,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376806,,"We explore a temperature illusion that uses low-powered electronics and enables the miniaturization of simple warm and cool sensations. Our illusion relies on the properties of certain scents, such as the coolness of mint or hotness of peppers. These odors trigger not only the olfactory bulb, but also the nose's trigeminal nerve, which has receptors that respond to both temperature and chemicals. To exploit this, we engineered a wearable device based on micropumps and an atomizer that emits up to three custom-made ""thermal"" scents directly to the user's nose. Breathing in these scents causes the user to feel warmer or cooler. We demonstrate how our device renders warmth and cooling sensations in virtual experiences. In our first study, we evaluated six candidate ""thermal"" scents. We found two hot-cold pairs, with one pair being less identifiable by odor. In our second study, pParticipants rated VR experiences with our device trigeminal stimulants as significantly warmer or cooler than the baseline conditions. Lastly, we believe this offers an alternative to existing thermal feedback devices, which unfortunately rely on power-hungry heat-lamps or Peltier-elements.",haptics | illusion | smell | thermal | trigeminal | vr,53,0,,,NSF,undefined,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85095180805,,,,Tuning-free plug-and-play proximal algorithm for inverse imaging problems,cp,Conference Paper,Wei K.,60119937;60031101;60016835,Faculty of Mathematics;University of Cambridge;Beijing Institute of Technology,Cambridge;Cambridge;Beijing,United Kingdom;United Kingdom;China,6,"Wei, Kaixuan;Aviles-Rivero, Angelica;Liang, Jingwei;Fu, Ying;Schönlieb, Carola Bibiane;Huang, Hua",57204917275;57200300191;55849073400;56118557700;24544878300;57193328047,60016835;60031101;60119937;60016835;60119937;60016835,2020-01-01,2020,"37th International Conference on Machine Learning, ICML 2020",,21101044769,,Conference Proceeding,PartF168147-14,,,10089-10100,"Plug-and-play (PnP) is a non-convex framework that combines ADMM or other proximal algorithms with advanced denoiser priors. Recently, PnP has achieved great empirical success, especially with the integration of deep learning-based denoisers. However, a key problem of PnP based approaches is that they require manual parameter tweaking. It is necessary to obtain high-quality results across the high discrepancy in terms of imaging conditions and varying scene content. In this work, we present a tuning-free PnP proximal algorithm, which can automatically determine the internal parameters including the penalty parameter, the denoising strength and the terminal time. A key part of our approach is to develop a policy network for automatic search of parameters, which can be effectively learned via mixed model-free and model-based deep reinforcement learning. We demonstrate, through numerical and visual experiments, that the learned policy can customize different parameters for different states, and often more effcient and effective than existing handcrafted criteria. Moreover, we discuss the practical considerations of the plugged denoisers, which together with our learned policy yield state-of-the-art results. This is prevalent on both linear and nonlinear exemplary inverse imaging problems, and in particular, we show promising results on Compressed Sensing MRI and phase retrieval.",,46,0,,,NSFC,61672096,National Natural Science Foundation of China,ICML Machine Learning
2-s2.0-85088293116,10.1145/3377811.3380327,,,Unblind your apps: Predicting natural-language labels for mobile gui components by deep learning,cp,Conference Paper,Chen J.,60083503;60029470;60025084;60019578;60008950,Fujian University of Technology;Commonwealth Scientific and Industrial Research Organisation;Shanghai Jiao Tong University;Monash University;The Australian National University,Fuzhou;Canberra;Shanghai;Clayton;Canberra,China;Australia;China;Australia;Australia,7,"Chen, Jieshan;Chen, Chunyang;Xing, Zhenchang;Xu, Xiwe;Zhu, Liming;Li, Guoqiang;Wang, Jinshui",57196018877;57191225906;8347413500;57226874788;57191568259;55951792200;56587049000,60008950;60019578;60008950;60029470;60008950;60025084;60083503,2020-06-27,27 June 2020,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,3380327,322-334,"According to the World Health Organization(WHO), it is estimated that approximately 1.3 billion people live with some forms of vision impairment globally, of whom 36 million are blind. Due to their disability, engaging these minority into the society is a challenging problem. The recent rise of smart mobile phones provides a new solution by enabling blind users' convenient access to the information and service for understanding the world. Users with vision impairment can adopt the screen reader embedded in the mobile operating systems to read the content of each screen within the app, and use gestures to interact with the phone. However, the prerequisite of using screen readers is that developers have to add natural-language labels to the image-based components when they are developing the app. Unfortunately, more than 77% apps have issues of missing labels, according to our analysis of 10,408 Android apps. Most of these issues are caused by developers' lack of awareness and knowledge in considering the minority. And even if developers want to add the labels to UI components, they may not come up with concise and clear description as most of them are of no visual issues. To overcome these challenges, we develop a deeplearning based model, called LabelDroid, to automatically predict the labels of image-based buttons by learning from large-scale commercial apps in Google Play. The experimental results show that our model can make accurate predictions and the generated labels are of higher quality than that from real Android developers.",Accessibility | Content description | Image-based buttons | Neural networks | User interface,76,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-85091875391,,,,"Understanding, detecting and localizing partial failures in large system software",cp,Conference Paper,Lou C.,60005248,Johns Hopkins University,Baltimore,United States,3,"Lou, Chang;Huang, Peng;Smith, Scott",57209223785;55955579700;56907862400,60005248;60005248;60005248,2020-01-01,2020,"Proceedings of the 17th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2020",,21101022472,,Conference Proceeding,,,,559-574,"Partial failures occur frequently in cloud systems and can cause serious damage including inconsistency and data loss. Unfortunately, these failures are not well understood. Nor can they be effectively detected. In this paper, we first study 100 real-world partial failures from five mature systems to understand their characteristics. We find that these failures are caused by a variety of defects that require the unique conditions of the production environment to be triggered. Manually writing effective detectors to systematically detect such failures is both time-consuming and error-prone. We thus propose OmegaGen, a static analysis tool that automatically generates customized watchdogs for a given program by using a novel program reduction technique. We have successfully applied OmegaGen to six large distributed systems. In evaluating 22 real-world partial failure cases in these systems, the generated watchdogs can detect 20 cases with a median detection time of 4.2 seconds, and pinpoint the failure scope for 18 cases. The generated watchdogs also expose an unknown, confirmed partial failure bug in the latest version of ZooKeeper.",,36,0,,,NSF,CNS-1755737,National Science Foundation,NSDI Networking
2-s2.0-85089534803,10.1109/CVPR42600.2020.00008,,,Unsupervised learning of probably symmetric deformable 3D objects from images in the wild,cp,Conference Paper,Wu S.,60026851,University of Oxford,Oxford,United Kingdom,3,"Wu, Shangzhe;Rupprecht, Christian;Vedaldi, Andrea",56779233600;55894264500;14036614600,60026851;60026851;60026851,2020-01-01,2020,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,,,9156584,1-10,"We propose a method to learn 3D deformable object categories from raw single-view images, without external supervision. The method is based on an autoencoder that factors each input image into depth, albedo, viewpoint and illumination. In order to disentangle these components without supervision, we use the fact that many object categories have, at least in principle, a symmetric structure. We show that reasoning about illumination allows us to exploit the underlying object symmetry even if the appearance is not symmetric due to shading. Furthermore, we model objects that are probably, but not certainly, symmetric by predicting a symmetry probability map, learned end-to-end with the other components of the model. Our experiments show that this method can recover very accurately the 3D shape of human faces, cat faces and cars from single-view images, without any supervision or a prior shape model. On benchmarks, we demonstrate superior accuracy compared to another method that uses supervision at the level of 2D image correspondences.",,196,0,repositoryam,Green,FB,638009,Facebook,CVPR Computer Vision
2-s2.0-85086828623,10.1145/3385412.3385985,,,Validating SMT solvers via semantic fusion,cp,Conference Paper,Winterer D.,60025858;60021200,ETH Zürich;East China Normal University,Zurich;Shanghai,Switzerland;China,3,"Winterer, Dominik;Zhang, Chengyu;Su, Zhendong",57192387874;57202891775;7402248744,60025858;60021200;60025858,2020-06-11,11 June 2020,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,718-730,"We introduce Semantic Fusion, a general, effective methodology for validating Satisfiability Modulo Theory (SMT) solvers. Our key idea is to fuse two existing equisatisfiable (i.e., both satisfiable or unsatisfiable) formulas into a new formula that combines the structures of its ancestors in a novel manner and preserves the satisfiability by construction. This fused formula is then used for validating SMT solvers. We realized Semantic Fusion as YinYang, a practical SMT solver testing tool. During four months of extensive testing, YinYang has found 45 confirmed, unique bugs in the default arithmetic and string solvers of Z3 and CVC4, the two state-of-the-art SMT solvers. Among these, 41 have already been fixed by the developers. The majority (29/45) of these bugs expose critical soundness issues. Our bug reports and testing effort have been well-appreciated by SMT solver developers.",Fuzz testing | Semantic fusion | SMT solvers,42,0,,,NSFC,61532019,National Natural Science Foundation of China,PLDI Programming Languages
2-s2.0-85096788999,,,,Virtual consensus in delos,cp,Conference Paper,Balakrishnan M.,60109024,"Facebook, Inc.",Menlo Park,United States,17,"Balakrishnan, Mahesh;Flinn, Jason;Shen, Chen;Dharamshi, Mihir;Jafri, Ahmed;Shi, Xiao;Ghosh, Santosh;Hassan, Hazem;Sagar, Aaryaman;Shi, Rhed;Liu, Jingming;Gruszczynski, Filip;Zhang, Xianan;Hoang, Huy;Yossef, Ahmed;Richard, Francois;Song, Yee Jiun",7006558408;7007104232;57220067314;57220070765;57220076359;57220068599;57220075585;57220077380;57220069529;57220075212;57220074081;57220071018;57220076076;57220492882;57338951900;57220071320;57112827500,60109024;60109024;60109024;60109024;60109024;60109024;60109024;60109024;60109024;60109024;60109024;60109024;60109024;60109024;60109024;60109024;60109024,2020-01-01,2020,"Proceedings of the 14th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2020",,21101028552,,Conference Proceeding,,,,617-632,"Consensus-based replicated systems are complex, monolithic, and difficult to upgrade once deployed. As a result, deployed systems do not benefit from innovative research, and new consensus protocols rarely reach production. We propose virtualizing consensus by virtualizing the shared log API, allowing services to change consensus protocols without downtime. Virtualization splits the logic of consensus into the VirtualLog, a generic and reusable reconfiguration layer; and pluggable ordering protocols called Loglets. Loglets are simple, since they do not need to support reconfiguration or leader election; diverse, consisting of different protocols, codebases, and even deployment modes; and composable, via RAID-like stacking and striping. We describe a production database called Delos1 which leverages virtual consensus for rapid, incremental development and deployment. Delos reached production within 8 months, and 4 months later upgraded its consensus protocol without downtime for a 10X latency improvement. Delos can dynamically change its performance properties by changing consensus protocols: we can scale throughput by up to 10X by switching to a disaggregated Loglet, and double the failure threshold of an instance without sacrificing throughput via a striped Loglet.",,15,0,,,,undefined,,OSDI Operating Systems
2-s2.0-85106619080,,,,WINOGRANDE: An adversarial winograd schema challenge at scale,cp,Conference Paper,Sakaguchi K.,126150611;124242617,Allen Institute for Artificial Intelligence;University of Washington,Allen;Allen,United States;United States,4,"Sakaguchi, Keisuke;Le Bras, Ronan;Bhagavatula, Chandra;Choi, Yejin",56900591700;37042388500;57216430904;36172231400,126150611;126150611;126150611;126150611-124242617,2020-01-01,2020,AAAI 2020 - 34th AAAI Conference on Artificial Intelligence,,21101046626,,Conference Proceeding,,,,8732-8734,"The Winograd Schema Challenge (WSC) (Levesque, Davis, and Morgenstern 2011), a benchmark for commonsense reasoning, is a set of 273 expert-crafted pronoun resolution problems originally designed to be unsolvable for statistical models that rely on selectional preferences or word associations. However, recent advances in neural language models have already reached around 90% accuracy on variants of WSC. This raises an important question whether these models have truly acquired robust commonsense capabilities or whether they rely on spurious biases in the datasets that lead to an overestimation of the true capabilities of machine commonsense. To investigate this question, we introduce WINOGRANDE, a large-scale dataset of 44k problems, inspired by the original WSC design, but adjusted to improve both the scale and the hardness of the dataset. The key steps of the dataset construction consist of (1) a carefully designed crowdsourcing procedure, followed by (2) systematic bias reduction using a novel AFLITE algorithm that generalizes human-detectable word associations to machine-detectable embedding associations. The best state-of-the-art methods on WINOGRANDE achieve 59.4 - 79.1%, which are ∼15-35% (absolute) below human performance of 94.0%, depending on the amount of the training data allowed (2% - 100% respectively). Furthermore, we establish new state-of-the-art results on five related benchmarks - WSC (→ 90.1%), DPR (→ 93.1%), COPA(→ 90.6%), Know Ref (→ 85.6%), and Winogender (→97.1%). These results have dual implications: on one hand, they demonstrate the effectiveness of WINOGRANDE when used as a resource for transfer learning. On the other hand, they raise a concern that we are likely to be overestimating the true capabilities of machine commonsense across all these benchmarks. We emphasize the importance of algorithmic bias reduction in existing and future benchmarks to mitigate such overestimation.",,204,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-85094326974,10.1145/3377811.3380331,,,White-box fairness testing through adversarial sampling,cp,Conference Paper,Zhang P.,60018933;60017161;60003970;112854590,Singapore Management University;National University of Singapore;Zhejiang University;Huawei International Pte Ltd,Singapore City;Singapore City;Hangzhou;Singapore City,Singapore;Singapore;China;Singapore,8,"Zhang, Peixin;Wang, Jingyi;Sun, Jun;Dong, Guoliang;Wang, Xinyu;Wang, Xingen;Dong, Jin Song;Dai, Ting",57211025760;57191964922;56153273100;57211024392;7501858663;36999008300;55666373900;57219492280,60003970;60017161;60018933;60003970;60003970;60003970;60017161;112854590,2020-06-27,27 June 2020,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,3380331,949-960,"Although deep neural networks (DNNs) have demonstrated astonishing performance in many applications, there are still concerns on their dependability. One desirable property of DNN for applications with societal impact is fairness (i.e., non-discrimination). In this work, we propose a scalable approach for searching individual discriminatory instances of DNN. Compared with state-of-theart methods, our approach only employs lightweight procedures like gradient computation and clustering, which makes it significantly more scalable than existing methods. Experimental results show that our approach explores the search space more effectively (9 times) and generates much more individual discriminatory instances (25 times) using much less time (half to 1/7) .",,64,0,repositoryam,Green,NUS,61972339,National University of Singapore,ICSE Software Engineering
2-s2.0-85091310449,10.1145/3313831.3376470,,,Wireality: Enabling Complex Tangible Geometries in Virtual Reality with Worn Multi-String Haptics,cp,Conference Paper,Fang C.,60027950,Carnegie Mellon University,Pittsburgh,United States,4,"Fang, Cathy;Zhang, Yang;Dworman, Matthew;Harrison, Chris",57219111672;57144720100;57219108570;35792227900,60027950;60027950;60027950;60027950,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376470,,"Today's virtual reality (VR) systems allow users to explore immersive new worlds and experiences through sight. Unfortunately, most VR systems lack haptic feedback, and even high-end consumer systems use only basic vibration motors. This clearly precludes realistic physical interactions with virtual objects. Larger obstacles, such as walls, railings, and furniture are not simulated at all. In response, we developed Wireality, a self-contained worn system that allows for individual joints on the hands to be accurately arrested in 3D space through the use of retractable wires that can be programmatically locked. This allows for convincing tangible interactions with complex geometries, such as wrapping fingers around a railing. Our approach is lightweight, low-cost, and low-power, criteria important for future, worn consumer uses. In our studies, we further show that our system is fast-acting, spatially-accurate, high-strength, comfortable, and immersive.",force feedback | grasp | haptics | string-driven | touch | virtual reality,76,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85091304418,10.1145/3313831.3376442,,,Wrex: A Unified Programming-by-Example Interaction for Synthesizing Readable Code for Data Scientists,cp,Conference Paper,Drosos I.,60030612;60026532,"University of California, San Diego;Microsoft Corporation",La Jolla;Redmond,United States;United States,5,"Drosos, Ian;Barik, Titus;Guo, Philip J.;Deline, Robert;Gulwani, Sumit",57200369021;55772354200;16238467300;6602118069;55901318200,60030612;60026532;60030612;60026532;60026532,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376442,,"Data wrangling is a difficult and time-consuming activity in computational notebooks, and existing wrangling tools do not fit the exploratory workflow for data scientists in these environments. We propose a unified interaction model based on programming-by-example that generates readable code for a variety of useful data transformations, implemented as a Jupyter notebook extension called Wrex. User study results demonstrate that data scientists are significantly more effective and efficient at data wrangling with Wrex over manual programming. Qualitative participant feedback indicates that Wrex was useful and reduced barriers in having to recall or look up the usage of various data transform functions. The synthesized code allowed data scientists to verify the intended data transformation, increased their trust and confidence in Wrex, and fit seamlessly within their cell-based notebook workflows. This work suggests that presenting readable code to professional data scientists is an indispensable component of offering data wrangling tools in notebooks.",computational notebooks | data science | program synthesis,72,1,publisherfree2read,Bronze,NSF,1735234,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85096773060,,,,hXDP: Efficient software packet processing on FPGA NICs,cp,Conference Paper,Brunella M.S.,60078342;60027509,"NEC Laboratories Europe GmbH;Università degli Studi di Roma ""Tor Vergata""",Heidelberg;Rome,Germany;Italy,10,"Brunella, Marco Spaziani;Belocchi, Giacomo;Bonola, Marco;Pontarelli, Salvatore;Siracusano, Giuseppe;Bianchi, Giuseppe;Cammarano, Aniello;Palumbo, Alessandro;Petrucci, Luca;Bifulco, Roberto",57201308787;57204630028;23501100600;6602250777;56453462600;57193527025;57216946262;57220067407;57194168218;36170457600,60027509;60027509;;;60078342;60027509;60027509;60027509;60027509;60078342,2020-01-01,2020,"Proceedings of the 14th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2020",,21101028552,,Conference Proceeding,,,,973-990,"FPGA accelerators on the NIC enable the offloading of expensive packet processing tasks from the CPU. However, FPGAs have limited resources that may need to be shared among diverse applications, and programming them is difficult. We present a solution to run Linux's eXpress Data Path programs written in eBPF on FPGAs, using only a fraction of the available hardware resources while matching the performance of high-end CPUs. The iterative execution model of eBPF is not a good fit for FPGA accelerators. Nonetheless, we show that many of the instructions of an eBPF program can be compressed, parallelized or completely removed, when targeting a purpose-built FPGA executor, thereby significantly improving performance. We leverage that to design hXDP, which includes (i) an optimizing-compiler that parallelizes and translates eBPF bytecode to an extended eBPF Instruction-set Architecture defined by us; a (ii) soft-CPU to execute such instructions on FPGA; and (iii) an FPGA-based infrastructure to provide XDP's maps and helper functions as defined within the Linux kernel. We implement hXDP on an FPGA NIC and evaluate it running real-world unmodified eBPF programs. Our implementation is clocked at 156.25MHz, uses about 15% of the FPGA resources, and can run dynamically loaded programs. Despite these modest requirements, it achieves the packet processing throughput of a high-end CPU core and provides a 10x lower packet forwarding latency.",,44,0,,,ECSEL,H2020/2014-2020,Electronic Components and Systems for European Leadership,OSDI Operating Systems
2-s2.0-85091299824,10.1145/3313831.3376155,,,TexSketch: Active Diagramming through Pen-and-Ink Annotations,cp,Conference Paper,Subramonyam H.,60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,4,"Subramonyam, Hariharan;Seifert, Colleen;Shah, Priti;Adar, Eytan",57056308000;35606631400;7403285225;8395017700,60025778;60025778;60025778;60025778,2020-04-21,21 April 2020,Conference on Human Factors in Computing Systems - Proceedings,,21101021808,,Conference Proceeding,,,3376155,,"Learning from text is a constructive activity in which sentence-level information is combined by the reader to build coherent mental models. With increasingly complex texts, forming a mental model becomes challenging due to a lack of background knowledge, and limits in working memory and attention. To address this, we are taught knowledge externalization strategies such as active reading and diagramming. Unfortunately, paper-and-pencil approaches may not always be appropriate, and software solutions create friction through difficult input modalities, limited workflow support, and barriers between reading and diagramming. For all but the simplest text, building coherent diagrams can be tedious and difficult. We propose Active Diagramming, an approach extending familiar active reading strategies to the task of diagram construction. Our prototype, texSketch, combines pen-and-ink interactions with natural language processing to reduce the cost of producing diagrams while maintaining the cognitive effort necessary for comprehension. Our user study finds that readers can effectively create diagrams without disrupting reading.",active reading | diagramming | pen-and-ink gestures,17,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85106683928,10.1145/3411764.3445410,,,Can i not be suicidal on a sunday?: Understanding technology-mediated pathways to mental health support,cp,Conference Paper,Pendse S.R.,60019647,Georgia Institute of Technology,Atlanta,United States,3,"Pendse, Sachin R.;Sharma, Amit;Vashistha, Aditya",57208584347;57214355703;36626584200,60019647;60019647;60019647,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Individuals in distress adopt varied pathways in pursuit of care that aligns with their individual needs. Prior work has established that the frst resource an individual leverages can infuence later care and recovery, but less is understood about how the design of a point of care might interact with subsequent pathways to care. We investigate how the design of the Indian mental health helpline system interacts with complex sociocultural factors to marginalize caller needs. We draw on interviews with 18 helpline stakeholders, including individuals who have engaged with helplines in the past, shedding light on how they navigate both technological and structural barriers in pursuit of relief. Finally, we use a design justice framework rooted in Amartya Sen's conceptualization of realization-focused justice to discuss implications and present recommendations towards the design of technology-mediated points of mental health support.",India | Mental health | Pathways to care | Realization-focused justice | Social justice | Technology-mediated mental health support,18,0,repositoryam,Green,NIH,R01MH117172,National Institutes of Health,CHI Human-Computer Interaction
2-s2.0-85104619239,10.1145/3411764.3445518,,,"Everyone wants to do the model work, not the data work: Data cascades in high-stakes ai",cp,Conference Paper,Sambasivan N.,60006191,Google LLC,Mountain View,United States,3,"Sambasivan, Nithya;Kapania, Shivani;Highfll, Hannah",22836402400;57205200207;57224005469,60006191;60006191;60006191,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"AI models are increasingly applied in high-stakes domains like health and conservation. Data quality carries an elevated signifcance in high-stakes AI due to its heightened downstream impact, impacting predictions like cancer detection, wildlife poaching, and loan allocations. Paradoxically, data is the most under-valued and de-glamorised aspect of AI. In this paper,we report on data practices in high-stakes AI, from interviews with 53 AI practitioners in India, East and West African countries, and USA. We defne, identify, and present empirical evidence on Data Cascades-compounding events causing negative, downstream efects from data issues-triggered by conventional AI/ML practices that undervalue data quality. Data cascades are pervasive (92% prevalence), invisible, delayed, but often avoidable. We discuss HCI opportunities in designing and incentivizing data excellence as a frst-class citizen of AI, resulting in safer and more robust systems for all.","Ai | Application-domain experts | Data | Data cascades | Data collectors | Data politics | Data quality | Developers | Ghana | High-stakes ai | India | Kenya | Ml | Nigeria | Raters | Uganda, usa",277,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85112585169,10.1109/ICSE43902.2021.00064,,,'How was your weekend?' Software development teams working from home during COVID-19,cp,Conference Paper,Miller C.,60026610;60021726;60005152;60003122,Clemson University;Microsoft Research;New College of Florida;University of Victoria,Clemson;Redmond;Sarasota;Victoria,United States;United States;United States;Canada,5,"Miller, Courtney;Rodeghero, Paige;Storey, Margaret Anne;Ford, Denae;Zimmermann, Thomas",57209888051;57188553085;7005753655;56939915300;16308551800,60005152;60026610;60003122;60021726;60021726,2021-05-01,May 2021,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,624-636,"The mass shift to working at home during the COVID-19 pandemic radically changed the way many software development teams collaborate and communicate. To investigate how team culture and team productivity may also have been affected, we conducted two surveys at a large software company. The first, an exploratory survey during the early months of the pandemic with 2,265 developer responses, revealed that many developers faced challenges reaching milestones and that their team productivity had changed. We also found through qualitative analysis that important team culture factors such as communication and social connection had been affected. For example, the simple phrase 'How was your weekend?' had become a subtle way to show peer support. In our second survey, we conducted a quantitative analysis of the team cultural factors that emerged from our first survey to understand the prevalence of the reported changes. From 608 developer responses, we found that 74% of these respondents missed social interactions with colleagues and 51% reported a decrease in their communication ease with colleagues. We used data from the second survey to build a regression model to identify important team culture factors for modeling team productivity. We found that the ability to brainstorm with colleagues, difficulty communicating with colleagues, and satisfaction with interactions from social activities are important factors that are associated with how developers report their software development team's productivity. Our findings inform how managers and leaders in large software companies can support sustained team productivity during times of crisis and beyond.",,65,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-85106681740,10.1145/3411764.3445313,,,That courage to encourage: Participation and aspirations in chat-based peer support for youth living with hiv,cp,Conference Paper,Karusala N.,60015481,University of Washington,Seattle,United States,3,"Karusala, Naveena;Seeh, David;Mugo, Cyrus",57194706635;57221292358;57192077864,60015481;60015481;60015481,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"We present a qualitative study of a six-month pilot of WhatsAppbased facilitated peer support groups, serving youth living with human immunodefciency virus (HIV) in an informal settlement in Nairobi, Kenya. Popular chat apps are increasingly being leveraged to make a combination of patient-provider communication and peer support more accessible beyond formal healthcare settings. However, how these interventions are experienced in Global South contexts with phone sharing and intermittent data access is understudied. The context of stigmatized illnesses like HIV further complicates privacy concerns. We draw on chat records and interviews with youth and the facilitator to describe their experience of the intervention. We fnd that despite tensions in group dynamics, intermittent participation, and contingencies around privacy, youth were motivated by newfound aspirations and community to manage their health. We use our fndings to discuss implications for the design of chat-based peer interventions, negotiation of privacy in mobile health applications, and the role of aspirations in health interventions.",Aspirations | Chat apps | Health | Kenya | Peer support | Whatsapp,24,0,,,NIH,K18MH122978,National Institutes of Health,CHI Human-Computer Interaction
2-s2.0-85106685937,10.1145/3411764.3445305,,,Why lose control? a study of freelancers' experiences with gig economy platforms,cp,Conference Paper,De La Vega J.C.A.,60004636,University of Northumbria,Newcastle,United Kingdom,3,"De La Vega, Juan Carlos Alvarez;Cecchinato, Marta E.;Rooksby, John",57218864265;55851220100;13008870400,60004636;60004636;60004636,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Freelancing platforms, such as Upwork, represent an expansion of the gig economy to encompass knowledge-based work. Prior research in HCI has primarily focused on forms of gig work such as ride-sharing and microwork but has not addressed how freelancing platforms are disrupting high-skilled knowledge work. To understand freelancers' perspectives on how these platforms are disrupting their work we have collected and thematically analysed 528 posts with 7499 comments from four relevant subforums on Reddit. The qualitative fndings reveal tensions between wanting autonomy and control and the necessity of opportunities and convenience. Freelancing platforms are perceived as systems that present advantages to fnd clients, gain experience and mitigate precarity. However, these platforms constrain the control over their work that freelancers value. The paper contributes an improved understanding of freelance work, the role and potential for freelancing platforms in the knowledge-based gig economy, and directions for worker-centred design.",Fiverr | Freelance work | Freelancing platforms | Gig economy | Reddit | Upwork | Worker-centered design,28,0,repositoryam,Green,,undefined,Northumbria University,CHI Human-Computer Interaction
2-s2.0-85108144972,10.1145/3406325.3451009,,,A (slightly) improved approximation algorithm for metric TSP,cp,Conference Paper,Karlin A.R.,122262718,University of Washington,Redmond,United States,3,"Karlin, Anna R.;Klein, Nathan;Gharan, Shayan Oveis",7006162482;57217210962;55401546700,122262718;122262718;122262718,2021-06-15,15 June 2021,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,32-45,For some > 10-36 we give a randomized 3/2- approximation algorithm for metric TSP.,Approximation Algorithms | Max Entropy | Near Minimum Cuts | Randomized Rounding | Strongly Rayleigh | Traveling Salesperson Problem,53,0,repositoryam,Green,NSF,CCF-1552097,National Science Foundation,STOC Theory
2-s2.0-85123413457,,,,A Universal Law of Robustness via Isoperimetry,cp,Conference Paper,Bubeck S.,60021726;60012708,Microsoft Research;Stanford University,Redmond;Stanford,United States;United States,2,"Bubeck, Sébastien;Sellke, Mark",26431237900;58476254600,60021726;60012708,2021-01-01,2021,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,34,,,28811-28822,"Classically, data interpolation with a parametrized model class is possible as long as the number of parameters is larger than the number of equations to be satisfied. A puzzling phenomenon in deep learning is that models are trained with many more parameters than what this classical theory would suggest. We propose a theoretical explanation for this phenomenon. We prove that for a broad class of data distributions and model classes, overparametrization is necessary if one wants to interpolate the data smoothly. Namely we show that smooth interpolation requires d times more parameters than mere interpolation, where d is the ambient data dimension. We prove this universal law of robustness for any smoothly parametrized function class with polynomial size weights, and any covariate distribution verifying isoperimetry (or a mixture thereof). In the case of two-layer neural networks and Gaussian covariates, this law was conjectured in prior work by Bubeck, Li and Nagaraj. We also give an interpretation of our result as an improved generalization bound for model classes consisting of smooth functions.",,46,0,,,NSF,CCF-2006489,National Science Foundation,NeurIPS Machine Learning
2-s2.0-85116273059,10.1145/3468264.3468589,,,A longitudinal analysis of bloated Java dependencies,cp,Conference Paper,Soto-Valero C.,126606586,KTH,Mark,Sweden,3,"Soto-Valero, César;Durieux, Thomas;Baudry, Benoit",57192839077;57189692747;57203847520,126606586;126606586;126606586,2021-08-20,20 August 2021,ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101060564,,Conference Proceeding,,,,1021-1031,"We study the evolution and impact of bloated dependencies in a single software ecosystem: Java/Maven. Bloated dependencies are third-party libraries that are packaged in the application binary but are not needed to run the application. We analyze the history of 435 Java projects. This historical data includes 48,469 distinct dependencies, which we study across a total of 31,515 versions of Maven dependency trees. Bloated dependencies steadily increase over time, and 89.2% of the direct dependencies that are bloated remain bloated in all subsequent versions of the studied projects. This empirical evidence suggests that developers can safely remove a bloated dependency. We further report novel insights regarding the unnecessary maintenance efforts induced by bloat. We find that 22% of dependency updates performed by developers are made on bloated dependencies, and that Dependabot suggests a similar ratio of updates on bloated dependencies.",dependencies | java | software bloat,17,0,repositoryam,Green,SSF,undefined,Stiftelsen för Strategisk Forskning,FSE Software Engineering
2-s2.0-85106193616,,,,ATP: In-network aggregation for multi-tenant learning,cp,Conference Paper,ChonLam Lao ,60032179;60025278,University of Wisconsin-Madison;Tsinghua University,Madison;Beijing,United States;China,7,"ChonLam Lao, ;Le, Yanfang;Mahajan, Kshiteej;Chen, Yixi;Wu, Wenfei;Akella, Aditya;Swift, Michael",57223821764;56275273800;57191861186;57223840023;56021762700;8383144400;57209111762,60025278;60032179;60032179;60025278;60025278;60032179;60032179,2021-01-01,2021,"Proceedings of the 18th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2021",,21101046131,,Conference Proceeding,,,,741-757,"Distributed deep neural network training (DT) systems are widely deployed in clusters where the network is shared across multiple tenants, i.e., multiple DT jobs. Each DT job computes and aggregates gradients. Recent advances in hardware accelerators have shifted the the performance bottleneck of training from computation to communication. To speed up DT jobs' communication, we propose ATP, a service for in-network aggregation aimed at modern multi-rack, multi-job DT settings. ATP uses emerging programmable switch hardware to support in-network aggregation at multiple rack switches in a cluster to speedup DT jobs. ATP performs decentralized, dynamic, best-effort aggregation, enables efficient and equitable sharing of limited switch resources across simultaneously running DT jobs, and gracefully accommodates heavy contention for switch resources. ATP outperforms existing systems accelerating training throughput by up to 38% - 66% in a cluster shared by multiple DT jobs.",,89,0,,,NSF,CNS-1565277,National Science Foundation,NSDI Networking
2-s2.0-85113514291,10.1109/ICSE43902.2021.00150,,,ATVHunter: Reliable version detection of third-party libraries for vulnerability identification in android applications,cp,Conference Paper,Zhan X.,60078616;60019578;60019533;60018038;60008928,School of Computer Science and Engineering;Monash University;Tianjin University;Nankai University;The Hong Kong Polytechnic University,Singapore City;Clayton;Tianjin;Tianjin;Hong Kong,Singapore;Australia;China;China;Hong Kong,7,"Zhan, Xian;Fan, Lingling;Chen, Sen;We, Feng;Liu, Tianming;Luo, Xiapu;Liu, Yang",57208223662;57197024797;57190395316;57272068100;57202730312;23005241300;56911879800,60008928;60018038;60019533;60078616;60019578;60008928;60078616,2021-05-01,May 2021,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,1695-1707,"Third-party libraries (TPLs) as essential parts in the mobile ecosystem have become one of the most significant contributors to the huge success of Android, which facilitate the fast development of Android applications. Detecting TPLs in Android apps is also important for downstream tasks, such as malware and repackaged apps identification. To identify in-app TPLs, we need to solve several challenges, such as TPL dependency, code obfuscation, precise version representation. Unfortunately, existing TPL detection tools have been proved that they have not solved these challenges very well, let alone specify the exact TPL versions. To this end, we propose a system, named ATVHunter, which can pinpoint the precise vulnerable in-app TPL versions and provide detailed information about the vulnerabilities and TPLs. We propose a two-phase detection approach to identify specific TPL versions. Specifically, we extract the Control Flow Graphs as the coarse-grained feature to match potential TPLs in the pre-defined TPL database, and then extract opcode in each basic block of CFG as the fine-grained feature to identify the exact TPL versions. We build a comprehensive TPL database (189,545 unique TPLs with 3,006,676 versions) as the reference database. Meanwhile, to identify the vulnerable in-app TPL versions, we also construct a comprehensive and known vulnerable TPL database containing 1,180 CVEs and 224 security bugs. Experimental results show AtVHunter outperforms state-of-the-art TPL detection tools, achieving 90.55% precision and 88.79% recall with high efficiency, and is also resilient to widely-used obfuscation techniques and scalable for large-scale TPL detection. Furthermore, to investigate the ecosystem of the vulnerable TPLs used by apps, we exploit newtool to conduct a large-scale analysis on 104,446 apps and find that 9,050 apps include vulnerable TPL versions with 53,337 vulnerabilities and 7,480 security bugs, most of which are with high risks and are not recognized by app developers.",Android | Ecosystem | Third party libraries | Version detection | Vulnerability,50,0,repositoryam,Green,NRF,NRF2018NCR-NCR005-0001,City University of Hong Kong,ICSE Software Engineering
2-s2.0-85108904283,10.1145/3453483.3454030,,,Alive2: Bounded translation validation for LLVM,cp,Conference Paper,Lopes N.P.,60025488;60021726;60013682,The University of Utah;Microsoft Research;Seoul National University,Salt Lake City;Redmond;Seoul,United States;United States;South Korea,5,"Lopes, Nuno P.;Lee, Juneyoung;Hur, Chung Kil;Liu, Zhengyang;Regehr, John",35078959800;57195075642;56184835000;57215857171;6602188226,60021726;60013682;60013682;60025488;60025488,2021-06-18,18 June 2021,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,65-79,"We designed, implemented, and deployed Alive2: a bounded translation validation tool for the LLVM compiler's intermediate representation (IR). It limits resource consumption by, for example, unrolling loops up to some bound, which means there are circumstances in which it misses bugs. Alive2 is designed to avoid false alarms, is fully automatic through the use of an SMT solver, and requires no changes to LLVM. By running Alive2 over LLVM's unit test suite, we discovered and reported 47 new bugs, 28 of which have been fixed already. Moreover, our work has led to eight patches to the LLVM Language Reference-the definitive description of the semantics of its IR-and we have participated in numerous discussions with the goal of clarifying ambiguities and fixing errors in these semantics. Alive2 is open source and we also made it available on the web, where it has active users from the LLVM community.",Automatic Software Verification | Compilers | IR Semantics | Translation Validation,29,0,,,ONR,N00014-17-1-2996,Office of Naval Research,PLDI Programming Languages
2-s2.0-85116208784,10.1145/3468264.3468587,,,AlloyMax: Bringing maximum satisfaction to relational specifications,cp,Conference Paper,Zhang C.,60106051;60027950;127322046,Universidade de Lisboa;Carnegie Mellon University;INESC-ID,Lisbon;Pittsburgh;Porto-Salvo,Portugal;United States;Portugal,7,"Zhang, Changjian;Wagner, Ryan;Orvalho, Pedro;Garlan, David;Manquinho, Vasco;Martins, Ruben;Kang, Eunsuk",57220177901;57212452242;57212021087;35582414000;6507501441;36188587200;23389819800,60027950;60027950;60027950;60027950;127322046-60106051;127322046-60106051;60027950,2021-08-20,20 August 2021,ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101060564,,Conference Proceeding,,,,155-167,"Alloy is a declarative modeling language based on a first-order relational logic. Its constraint-based analysis has enabled a wide range of applications in software engineering, including configuration synthesis, bug finding, test-case generation, and security analysis. Certain types of analysis tasks in these domains involve finding an optimal solution. For example, in a network configuration problem, instead of finding any valid configuration, it may be desirable to find one that is most permissive (i.e., it permits a maximum number of packets). Due to its dependence on SAT, however, Alloy cannot be used to specify and analyze these types of problems. We propose AlloyMax, an extension of Alloy with a capability to express and analyze problems with optimal solutions. AlloyMax introduces (1) a small addition of language constructs that can be used to specify a wide range of problems that involve optimality and (2) a new analysis engine that leverages a Maximum Satisfiability (MaxSAT) solver to generate optimal solutions. To enable this new type of analysis, we show how a specification in a first-order relational logic can be translated into an input format of MaxSAT solvers-namely, a Boolean formula in weighted conjunctive normal form (WCNF). We demonstrate the applicability and scalability of AlloyMax on a benchmark of problems. To our knowledge, AlloyMax is the first approach to enable analysis with optimality in a relational modeling language, and we believe that AlloyMax has the potential to bring a wide range of new applications to Alloy.",Alloy | MaxSAT | Model synthesis | Relational specifications | SAT,4,1,publisherfree2read,Bronze,NSF,PTDC/CCI-COM/31198/2-017,National Science Foundation,FSE Software Engineering
2-s2.0-85118226345,10.1145/3472749.3474800,,,Altering Perceived Softness of Real Rigid Objects by Restricting Fingerpad Deformation,cp,Conference Paper,Tao Y.,60029278,The University of Chicago,Chicago,United States,3,"Tao, Yujie;Teng, Shan Yuan;Lopes, Pedro",57316113100;57192819934;55480857700,60029278;60029278;60029278,2021-10-10,10 October 2021,UIST 2021 - Proceedings of the 34th Annual ACM Symposium on User Interface Software and Technology,,21101063802,,Conference Proceeding,,,,985-996,"We propose a haptic device that alters the perceived softness of real rigid objects without requiring to instrument the objects. Instead, our haptic device works by restricting the user's fingerpad lateral deformation via a hollow frame that squeezes the sides of the fingerpad. This causes the fingerpad to become bulgier than it originally was - when users touch an object's surface with their now-restricted fingerpad, they feel the object to be softer than it is. To illustrate the extent of softness illusion induced by our device, touching the tip of a wooden chopstick will feel as soft as a rubber eraser. Our haptic device operates by pulling the hollow frame using a motor. Unlike most wearable haptic devices, which cover up the user's fingerpad to create force sensations, our device creates softness while leaving the center of the fingerpad free, which allows the users to feel most of the object they are interacting with. This makes our device a unique contribution to altering the softness of everyday objects, creating ""buttons""by softening protrusions of existing appliances or tangibles, or even, altering the softness of handheld props for VR. Finally, we validated our device through two studies: (1) a psychophysics study showed that the device brings down the perceived softness of any object between 50A-90A to around 40A (on Shore A hardness scale); and (2) a user study demonstrated that participants preferred our device for interactive applications that leverage haptic props, such as making a VR prop feel softer or making a rigid 3D printed remote control feel softer on its button.",AR | compliance | haptic illusion | props | rigid | soft | tactile | VR | wearable haptics,16,0,,,NSF,2047189,National Science Foundation,UIST User Interface
2-s2.0-85111200797,10.1109/ICSE43902.2021.00116,,,Automated query reformulation for efficient search based on query logs from stack overflow,cp,Conference Paper,Cao K.,60033100;60021783;60019578;60009512,Nanjing University;Nantong University;Monash University;The University of Adelaide,Nanjing;Nantong;Clayton;Adelaide,China;China;Australia;Australia,5,"Cao, Kaibo;Chen, Chunyang;Baltes, Sebastian;Treude, Christoph;Chen, Xiang",57219592032;57191225906;56241807200;23135531900;57189091783,60033100;60019578;60009512;60009512;60021783,2021-05-01,May 2021,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,1273-1285,"As a popular Q&A site for programming, Stack Overflow is a treasure for developers. However, the amount of questions and answers on Stack Overflow make it difficult for developers to efficiently locate the information they are looking for. There are two gaps leading to poor search results: the gap between the user's intention and the textual query, and the semantic gap between the query and the post content. Therefore, developers have to constantly reformulate their queries by correcting misspelled words, adding limitations to certain programming languages or platforms, etc. As query reformulation is tedious for developers, especially for novices, we propose an automated software-specific query reformulation approach based on deep learning. With query logs provided by Stack Overflow, we construct a large-scale query reformulation corpus, including the original queries and corresponding reformulated ones. Our approach trains a Transformer model that can automatically generate candidate reformulated queries when given the user's original query. The evaluation results show that our approach outperforms five state-of-the-art baselines, and achieves a 5.6% to 33.5% boost in terms of ExactMatch and a 4.8% to 14.4% boost in terms of GLEU.",Data Mining | Deep Learning | Query Logs | Query Reformulation | Stack Overflow,51,0,repositoryam,Green,ARC,DE180100153,Australian Research Council,ICSE Software Engineering
2-s2.0-85108947427,10.1145/3448016.3452838,,,Bao: Making Learned Query Optimization Practical,cp,Conference Paper,Marcus R.,60022195,Massachusetts Institute of Technology,Cambridge,United States,6,"Marcus, Ryan;Negi, Parimarjan;Mao, Hongzi;Tatbul, Nesime;Alizadeh, Mohammad;Kraska, Tim",57190379924;57216206925;56379533100;7801574849;55658057154;25823846800,60022195;60022195;60022195;60022195;60022195;60022195,2021-01-01,2021,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,1275-1288,"Recent efforts applying machine learning techniques to query optimization have shown few practical gains due to substantive training overhead, inability to adapt to changes, and poor tail performance. Motivated by these difficulties, we introduce Bao (the \underlineBa ndit \underlineo ptimizer). Bao takes advantage of the wisdom built into existing query optimizers by providing per-query optimization hints. Bao combines modern tree convolutional neural networks with Thompson sampling, a well-studied reinforcement learning algorithm. As a result, Bao automatically learns from its mistakes and adapts to changes in query workloads, data, and schema. Experimentally, we demonstrate that Bao can quickly learn strategies that improve end-to-end query execution performance, including tail latency, for several workloads containing long-running queries. In cloud environments, we show that Bao can offer both reduced costs and better performance compared with a commercial system.",machine learning | query optimization | reinforcement learning,65,1,repositoryam,Green,NSF,IIS 1900933,National Science Foundation,SIGMOD Databases
2-s2.0-85116211207,10.1145/3468264.3468537,,,Bias in machine learning software: Why? how? what to do?,cp,Conference Paper,Chakraborty J.,60004923,NC State University,Raleigh,United States,3,"Chakraborty, Joymallya;Majumder, Suvodeep;Menzies, Tim",57210927087;57203411045;7003835495,60004923;60004923;60004923,2021-08-20,20 August 2021,ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101060564,,Conference Proceeding,,,,429-440,"Increasingly, software is making autonomous decisions in case of criminal sentencing, approving credit cards, hiring employees, and so on. Some of these decisions show bias and adversely affect certain social groups (e.g. those defined by sex, race, age, marital status). Many prior works on bias mitigation take the following form: change the data or learners in multiple ways, then see if any of that improves fairness. Perhaps a better approach is to postulate root causes of bias and then applying some resolution strategy. This paper postulates that the root causes of bias are the prior decisions that affect-(a) what data was selected and (b) the labels assigned to those examples. Our Fair-SMOTE algorithm removes biased labels; and rebalances internal distributions such that based on sensitive attribute, examples are equal in both positive and negative classes. On testing, it was seen that this method was just as effective at reducing bias as prior approaches. Further, models generated via Fair-SMOTE achieve higher performance (measured in terms of recall and F1) than other state-of-the-art fairness improvement algorithms. To the best of our knowledge, measured in terms of number of analyzed learners and datasets, this study is one of the largest studies on bias mitigation yet presented in the literature.",Bias Mitigation | Fairness Metrics | Software Fairness,63,0,repositoryam,Green,NSF,1908762,National Science Foundation,FSE Software Engineering
2-s2.0-85106681646,10.1145/3411764.3445071,,,Building for we': Safety setings for couples with memory concerns,cp,Conference Paper,McDonald N.,60014653,"University of Maryland, Baltimore (UMB)",Baltimore,United States,2,"McDonald, Nora;Mentis, Helena M.",56425507100;57203381862,60014653;60014653,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Designing technologies that support the mutual cybersecurity and autonomy of older adults facing cognitive challenges requires close collaboration of partners. As part of research to design a Safety Setting application for older adults with memory loss or mild cognitive impairment (MCI), we use a scenario-based participatory design. Our study builds on previous fndings that couples' approach to memory loss was characterized by a desire for fexibility and choice, and an embrace of role uncertainty.We fnd that couples don't want a system that fundamentally alters their relationship and are looking to maximize self-surveillance competence and minimize loss of autonomy for their partners. All desire Safety Settings to maintain their mutual safety rather than designating one partner as the target of oversight. Couples are open to more rigorous surveillance if they have control over what types of activities trigger various levels of oversight.",Cybersecurity | Memory loss | Scenario-based design,12,0,,,NSF,CNS-1714514,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85112126475,10.1145/3411764.3445621,,,CapContact: Super-resolution Contact Areas from Capacitive Touchscreens,cp,Conference Paper,Streli P.,60025858,ETH Zürich,Zurich,Switzerland,2,"Streli, Paul;Holz, Christian",57223400778;56070704000,60025858;60025858,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101055141,,Conference Proceeding,,,,,"Touch input is dominantly detected using mutual-capacitance sensing, which measures the proximity of close-by objects that change the electric feld between the sensor lines. The exponential dropof in intensities with growing distance enables software to detect touch events, but does not reveal true contact areas. In this paper, we introduce CapContact, a novel method to precisely infer the contact area between the user's fnger and the surface from a single capacitive image. At 8 super-resolution, our convolutional neural network generates refned touch masks from 16-bit capacitive images as input, which can even discriminate adjacent touches that are not distinguishable with existing methods. We trained and evaluated our method using supervised learning on data from 10 participants who performed touch gestures. Our capture apparatus integrates optical touch sensing to obtain ground-truth contact through high-resolution frustrated total internal refection.We compare our method with a baseline using bicubic upsampling as well as the ground truth from FTIR images. We separately evaluate our method's performance in discriminating adjacent touches. CapContact successfully separated closely adjacent touch contacts in 494 of 570 cases (87%) compared to the baseline's 43 of 570 cases (8%). Importantly, we demonstrate that our method accurately performs even at half of the sensing resolution at twice the grid-line pitch across the same surface area, challenging the current industrywide standard of a ~4mm sensing pitch. We conclude this paper with implications for capacitive touch sensing in general and for touch-input accuracy in particular.",Accuracy | Capacitive sensing | Contact area | Generative adversarial networks | Super-resolution | Touch input,7,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85115129251,10.1109/ICSE43902.2021.00135,,,CodeShovel: Constructing method-level source code histories,cp,Conference Paper,Grund F.,60010365,The University of British Columbia,Vancouver,Canada,5,"Grund, Felix;Chowdhury, Shaiful Alam;Bradley, Nick C.;Hall, Braxton;Holmes, Reid",57271078800;57095375100;57213985942;57222587189;56220448900,60010365;60010365;60010365;60010365;60010365,2021-05-01,May 2021,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,1510-1522,"Source code histories are commonly used by developers and researchers to reason about how software evolves. Through a survey with 42 professional software developers, we learned that developers face significant mismatches between the output provided by developers' existing tools for examining source code histories and what they need to successfully complete their historical analysis tasks. To address these shortcomings, we propose CodeShovel, a tool for uncovering method histories that quickly produces complete and accurate change histories for 90% methods (including 97% of all method changes) outperforming leading tools from both research (e.g, FinerGit) and practice (e.g., IntelliJ / git log). CodeShovel helps developers to navigate the entire history of source code methods so they can better understand how the method evolved. A field study on industrial code bases with 16 industrial developers confirmed our empirical findings of CodeShovel's correctness, low runtime overheads, and additionally showed that the approach can be useful for a wide range of industrial development tasks.",History slicing | Maintenance | Source code history,21,0,,,NSERC,PDF-533056-2019,Natural Sciences and Engineering Research Council of Canada,ICSE Software Engineering
2-s2.0-85115097988,10.1109/SP40001.2021.00084,,,Compositional security for reentrant applications,cp,Conference Paper,Cecchetti E.,60007776,Cornell University,Ithaca,United States,4,"Cecchetti, Ethan;Yao, Siqiu;Ni, Haobin;Myers, Andrew C.",57191964721;57222904128;57219587612;7202743179,60007776;60007776;60007776;60007776,2021-05-01,May 2021,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2021-May,,,1249-1267,"The disastrous vulnerabilities in smart contracts sharply remind us of our ignorance: we do not know how to write code that is secure in composition with malicious code. Information flow control has long been proposed as a way to achieve compositional security, offering strong guarantees even when combining software from different trust domains. Unfortunately, this appealing story breaks down in the presence of reentrancy attacks. We formalize a general definition of reentrancy and introduce a security condition that allows software modules like smart contracts to protect their key invariants while retaining the expressive power of safe forms of reentrancy. We present a security type system that provably enforces secure information flow; in conjunction with run-time mechanisms, it enforces secure reentrancy even in the presence of unknown code; and it helps locate and correct recent high-profile vulnerabilities.",Information flow control | Integrity | Language-based security | Smart contracts,18,0,repositoryam,Green,NSF,1704615,National Science Foundation,S&P Security and Privacy
2-s2.0-85111682866,10.1145/3404835.3462830,,,Computationally Efficient Optimization of Plackett-Luce Ranking Models for Relevance and Fairness,cp,Conference Paper,Oosterhuis H.,60016529,Radboud Universiteit,Nijmegen,Netherlands,1,"Oosterhuis, Harrie",57044414800,60016529,2021-07-11,11 July 2021,SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval,,21101054400,,Conference Proceeding,,,3462830,1023-1032,"Recent work has proposed stochastic Plackett-Luce (PL) ranking models as a robust choice for optimizing relevance and fairness metrics. Unlike their deterministic counterparts that require heuristic optimization algorithms, PL models are fully differentiable. Theoretically, they can be used to optimize ranking metrics via stochastic gradient descent. However, in practice, the computation of the gradient is infeasible because it requires one to iterate over all possible permutations of items. Consequently, actual applications rely on approximating the gradient via sampling techniques. In this paper, we introduce a novel algorithm: PL-Rank, that estimates the gradient of a PL ranking model w.r.t. both relevance and fairness metrics. Unlike existing approaches that are based on policy gradients, PL-Rank makes use of the specific structure of PL models and ranking metrics. Our experimental analysis shows that PL-Rank has a greater sample-efficiency and is computationally less costly than existing policy gradients, resulting in faster convergence at higher performance. PL-Rank further enables the industry to apply PL models for more relevant and fairer real-world ranking systems.",learning to rank | policy gradients | ranking metric optimization,34,1,repositoryam,Green,,undefined,,SIGIR Information Retrieval
2-s2.0-85131878706,,,,A Continuized View on Nesterov Acceleration for Stochastic Gradient Descent and Randomized Gossip,cp,Conference Paper,Even M.,60104653;60028186;60013373;113734158,Université Grenoble Alpes;École Polytechnique Fédérale de Lausanne;INRIA Institut National de Recherche en Informatique et en Automatique;MSR-INRIA Joint Centre,Saint Martin d'Heres;Lausanne;Le Chesnay;,France;Switzerland;France;France,8,"Even, Mathieu;Berthier, Raphaël;Bach, Francis;Flammarion, Nicolas;Gaillard, Pierre;Hendrikx, Hadrien;Massoulié, Laurent;Taylor, Adrien",57222183640;57195297984;7202286449;57190951738;14827708100;57193992610;6603753137;57189321784,60013373;60013373;60013373;60028186;60104653;60013373;60013373-113734158;60013373,2021-01-01,2021,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,33,,,28054-28066,"We introduce the “continuized” Nesterov acceleration, a close variant of Nesterov acceleration whose variables are indexed by a continuous time parameter. The two variables continuously mix following a linear ordinary differential equation and take gradient steps at random times. This continuized variant benefits from the best of the continuous and the discrete frameworks: as a continuous process, one can use differential calculus to analyze convergence and obtain analytical expressions for the parameters; and a discretization of the continuized process can be computed exactly with convergence rates similar to those of Nesterov original acceleration. We show that the discretization has the same structure as Nesterov acceleration, but with random parameters. We provide continuized Nesterov acceleration under deterministic as well as stochastic gradients, with either additive or multiplicative noise. Finally, using our continuized framework and expressing the gossip averaging problem as the stochastic minimization of a certain energy function, we provide the first rigorous acceleration of asynchronous gossip algorithms.",,4,0,,,ERC,SEQUOIA 724063,European Research Council,NeurIPS Machine Learning
2-s2.0-85106715753,10.1145/3411764.3445422,,,Coupling simulation and hardware for interactive circuit debugging,cp,Conference Paper,Strasnick E.,60012708,Stanford University,Stanford,United States,3,"Strasnick, Evan;Agrawala, Maneesh;Follmer, Sean",57190114986;57204250599;26430822900,60012708;60012708;60012708,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Simulation ofers many advantages when designing analog circuits. Designers can explore alternatives quickly, without added cost or risk of hardware faults. However, it is challenging to use simulation as an aid during interactive debugging of physical circuits, due to difculties in comparing simulated analyses with hardware measurements. Designers must continually confgure simulations to match the state of the physical circuit (e.g. capturing sensor inputs), and must manually rework the hardware to replicate changes or analyses performed in simulation. We propose techniques leveraging instrumentation and programmable test hardware to create a tight coupling between a physical circuit and its simulated model. Bridging these representations helps designers to compare simulated and measured behaviors, and to quickly perform analytical techniques on hardware (e.g. parameter-response analysis) that are typically cumbersome outside of simulation. We implement these techniques in a prototype and show how it aids in efciently debugging a variety of analog circuits.",Analysis | Circuit | Debugging | Pcb | Simulation | Testing,5,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85108904115,10.1145/3453483.3454087,,,Cyclic program synthesis,cp,Conference Paper,Itzhaky S.,60106365;60030612;60022403;60020595;60017161,"Yale-NUS College;University of California, San Diego;Technion - Israel Institute of Technology;Royal Holloway, University of London;National University of Singapore",Singapore City;La Jolla;Haifa;Egham;Singapore City,Singapore;United States;Israel;United Kingdom;Singapore,5,"Itzhaky, Shachar;Peleg, Hila;Polikarpova, Nadia;Rowe, Reuben N.S.;Sergey, Ilya",36675238500;55861476100;36502622800;35180386000;35114020100,60022403;60030612;60030612;60020595;60106365-60017161,2021-06-18,18 June 2021,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,944-959,"We describe the first approach to automatically synthesizing heap-manipulating programs with auxiliary recursive procedures. Such procedures occur routinely in data structure transformations (e.g., flattening a tree into a list) or traversals of composite structures (e.g., n-ary trees). Our approach, dubbed cyclic program synthesis, enhances deductive program synthesis with a novel application of cyclic proofs. Specifically, we observe that the machinery used to form cycles in cyclic proofs can be reused to systematically and efficiently abduce recursive auxiliary procedures. We develop the theory of cyclic program synthesis by extending Synthetic Separation Logic (SSL), a logical framework for deductive synthesis of heap-manipulating programs from Separation Logic specifications. We implement our approach as a tool called Cypress, and showcase it by automatically synthesizing a number of programs manipulating linked data structures using recursive auxiliary procedures and mutual recursion, many of which were beyond the reach of existing program synthesis tools.",Cyclic Proofs | Program Synthesis | Separation Logic,16,1,publisherfree2read,Bronze,NSF,1911149,National Science Foundation,PLDI Programming Languages
2-s2.0-85108962362,10.1145/3448016.3452816,,,DFI: The Data Flow Interface for High-Speed Networks,cp,Conference Paper,Thostrup L.,60011226,Technische Universität Darmstadt,Darmstadt,Germany,5,"Thostrup, Lasse;Skrzypczak, Jan;Jasny, Matthias;Ziegler, Tobias;Binnig, Carsten",57215356476;57210583480;57217103359;56903681300;16548747700,60011226;60011226;60011226;60011226;60011226,2021-01-01,2021,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,1825-1837,"In this paper, we propose the Data Flow Interface (DFI) as a way to make it easier for data processing systems to exploit high-speed networks without the need to deal with the complexity of RDMA. By lifting the level of abstraction, DFI factors out much of the complexity of network communication and makes it easier for developers to declaratively express how data should be efficiently routed to accomplish a given distributed data processing task. As we show in our experiments, DFI is able to support a wide variety of data-centric applications with high performance at a low complexity for the applications.",data management | high-speed networks | modern hardware | network interfaces | rdma,17,0,,,DFG,BI2011/1 &amp; BI2011/2,Deutsche Forschungsgemeinschaft,SIGMOD Databases
2-s2.0-85131937294,,,,Deep Reinforcement Learning at the Edge of the Statistical Precipice,cp,Conference Paper,Agarwal R.,60113142;60006191,Montreal Institute for Learning Algorithms;Google LLC,Montreal;Mountain View,Canada;United States,5,"Agarwal, Rishabh;Schwarzer, Max;Castro, Pablo Samuel;Courville, Aaron;Bellemare, Marc G.",57214858852;57219792296;26028751300;6507291186;16199466700,60006191;60113142;60006191;60113142;60006191,2021-01-01,2021,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,35,,,29304-29320,"Deep reinforcement learning (RL) algorithms are predominantly evaluated by comparing their relative performance on a large suite of tasks. Most published results on deep RL benchmarks compare point estimates of aggregate performance such as mean and median scores across tasks, ignoring the statistical uncertainty implied by the use of a finite number of training runs. Beginning with the Arcade Learning Environment (ALE), the shift towards computationally-demanding benchmarks has led to the practice of evaluating only a small number of runs per task, exacerbating the statistical uncertainty in point estimates. In this paper, we argue that reliable evaluation in the few-run deep RL regime cannot ignore the uncertainty in results without running the risk of slowing down progress in the field. We illustrate this point using a case study on the Atari 100k benchmark, where we find substantial discrepancies between conclusions drawn from point estimates alone versus a more thorough statistical analysis. With the aim of increasing the field’s confidence in reported results with a handful of runs, we advocate for reporting interval estimates of aggregate performance and propose performance profiles to account for the variability in results, as well as present more robust and efficient aggregate metrics, such as interquartile mean scores, to achieve small uncertainty in results. Using such statistical tools, we scrutinize performance evaluations of existing algorithms on other widely used RL benchmarks including the ALE, Procgen, and the DeepMind Control Suite, again revealing discrepancies in prior comparisons. Our findings call for a change in how we evaluate performance in deep RL, for which we present a more rigorous evaluation methodology, accompanied with an open-source library rliable2, to prevent unreliable results from stagnating the field.",,133,0,,,,undefined,,NeurIPS Machine Learning
2-s2.0-85106732166,10.1145/3411764.3445096,,,Designing interactive transfer learning tools for ml non-experts,cp,Conference Paper,Mishra S.,60007776,Cornell University,Ithaca,United States,2,"Mishra, Swati;Rzeszotarski, Jefrey M.",57195357843;35734782600,60007776;60007776,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Interactive machine learning (iML) tools help to make ML accessible to users with limited ML expertise. However, gathering necessary training data and expertise for model-building remains challenging. Transfer learning, a process where learned representations from a model trained on potentially terabytes of data can be transferred to a new, related task, ofers the possibility of providing building blocks for non-expert users to quickly and efectively apply ML in their work. However, transfer learning largely remains an expert tool due to its high complexity. In this paper, we design a prototype to understand non-expert user behavior in an interactive environment that supports transfer learning. Our fndings reveal a series of data-and perception-driven decision-making strategies non-expert users employ, to (in)efectively transfer elements using their domain expertise. Finally, we synthesize design implications which might inform future interactive transfer learning environments.",Interactive machine learning | Prototyping | Transfer learning | User study,16,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85106695339,10.1145/3411764.3445471,,,Designing menstrual technologies with adolescents,cp,Conference Paper,Sondergaard M.L.J.,60002014,The Royal Institute of Technology (KTH),Stockholm,Sweden,3,"Sondergaard, Marie Louise Juul;Felice, Marianela Ciolf;Balaam, Madeline",57055311400;57190406918;36095639700,60002014;60002014;60002014,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Starting to menstruate can restrict adolescents' movements due to physiological changes and societal stigma. We present a participatory soma design project advocating for young adolescents to listen to and care for their newly-menstruating bodies, specifcally focusing on participation in sport. We designed Menarche Bits, an open-ended prototyping toolkit consisting of shape-changing actuators and heat pads, and used it in two design workshops with seven participants aged 16-18, as part of collaboration and menstrual advocacy in their sports clubs and high school. The participants designed menstrual technologies that respond to menstrual cramps and depressive, anxious feelings before menstruating. We contribute fndings on designing menstrual technologies with adolescents using participatory soma design. We found that a toolkit approach to the design of menstrual technologies can allow for pluralist experiences of menstrual cycles. In addition, we found that participatory design with adolescents benefts from drawing on qualities of embodiment and participants' own body literacy.",Feminist hci | Menstrual health | Participatory design | Shape-changing technologies | Soma design,10,0,repositoryvor,Green,VR,2017-05133,Vetenskapsrådet,CHI Human-Computer Interaction
2-s2.0-85113846112,,,,DistAI: Data-driven automated invariant learning for distributed protocols,cp,Conference Paper,Yao J.,60030162,Columbia University,New York,United States,6,"Yao, Jianan;Tao, Runzhou;Gu, Ronghui;Nieh, Jason;Jana, Suman;Ryan, Gabriel",57217226397;57209230413;56785252200;7003645135;26221197900;57203547108,60030162;60030162;60030162;60030162;60030162;60030162,2021-01-01,2021,"Proceedings of the 15th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2021",,21101057678,,Conference Proceeding,,,,405-421,"Distributed systems are notoriously hard to implement correctly due to non-determinism. Finding the inductive invariant of the distributed protocol is a critical step in verifying the correctness of distributed systems, but takes a long time to do even for simple protocols. We present DistAI, a data-driven automated system for learning inductive invariants for distributed protocols. DistAI generates data by simulating the distributed protocol at different instance sizes and recording states as samples. Based on the observation that invariants are often concise in practice, DistAI starts with small invariant formulas and enumerates all strongest possible invariants that hold for all samples. It then feeds those invariants and the desired safety properties to an SMT solver to check if the conjunction of the invariants and the safety properties is inductive. Starting with small invariant formulas and strongest possible invariants avoids large SMT queries, improving SMT solver performance. Because DistAI starts with the strongest possible invariants, if the SMT solver fails, DistAI does not need to discard failed invariants, but knows to monotonically weaken them and try again with the solver, repeating the process until it eventually succeeds. We prove that DistAI is guaranteed to find the ?-free inductive invariant that proves the desired safety properties in finite time, if one exists. Our evaluation shows that DistAI successfully verifies 13 common distributed protocols automatically and outperforms alternative methods both in the number of protocols it verifies and the speed at which it does so, in some cases by more than two orders of magnitude.",,20,0,,,NSF,CCF-1918400,National Science Foundation,OSDI Operating Systems
2-s2.0-85116300200,10.1145/3468264.3468574,,,Efficient module-level dynamic analysis for dynamic languages with module recontextualization,cp,Conference Paper,Vasilakis N.,60022461;60022195;121478002,Technical University of Crete;Massachusetts Institute of Technology;Unaffiliated,Chania;Cambridge;Frankfurt am Main,Greece;United States;Germany,4,"Vasilakis, Nikos;Ntousakis, Grigoris;Heller, Veit;Rinard, Martin C.",57213489278;57282322600;57282949100;7003321126,60022195;60022461;121478002;60022195,2021-08-20,20 August 2021,ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101060564,,Conference Proceeding,,,,1202-1213,"Dynamic program analysis is a long-standing technique for obtaining information about program execution. We present module recontextualization, a new dynamic analysis approach that targets modern dynamic languages such as JavaScript and Racket, enabled by the fact that they feature a module-import mechanism that loads code at runtime as a string. This approach uses lightweight load-time code transformations that operate on the string representation of the module, as well as the context to which it is about to be bound, to insert developer-provided, analysis-specific code into the module before it is loaded. This code implements the dynamic analysis, enabling this approach to capture all interactions around the module in unmodified production language runtime environments. We implement this approach in two systems targeting the JavaScript and Racket ecosystems. Our evaluation shows that this approach can deliver order-of-magnitude performance improvements over state-of-the-art dynamic analysis systems while supporting a range of analyses, implemented on average in about 100 lines of code.",Analysis | Dynamic | Instrumentation | Performance | Recontextualization | Runtime | Security,4,1,repositoryvor,Green,DARPA,HR00112020013,Defense Advanced Research Projects Agency,FSE Software Engineering
2-s2.0-85111915788,10.1109/INFOCOM42981.2021.9488803,,,Exploiting simultaneous communications to accelerate data parallel distributed deep learning,cp,Conference Paper,Shi S.,60014347;60008592,Hong Kong Baptist University;Hong Kong University of Science and Technology,Hong Kong;Hong Kong,Hong Kong;Hong Kong,3,"Shi, Shaohuai;Chu, Xiaowen;Li, Bo",57195360813;15069983000;56754341100,60008592;60014347;60008592,2021-05-10,10 May 2021,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2021-May,,9488803,,"Synchronous stochastic gradient descent (S-SGD) with data parallelism is widely used for training deep learning (DL) models in distributed systems. A pipelined schedule of the computing and communication tasks of a DL training job is an effective scheme to hide some communication costs. In such pipelined S-SGD, tensor fusion (i.e., merging some consecutive layers' gradients for a single communication) is a key ingredient to improve communication efficiency. However, existing tensor fusion techniques schedule the communication tasks sequentially, which overlooks their independence nature. In this paper, we expand the design space of scheduling by exploiting simultaneous All-Reduce communications. Through theoretical analysis and experiments, we show that simultaneous All-Reduce communications can effectively improve the communication efficiency of small tensors. We formulate an optimization problem of minimizing the training iteration time, in which both tensor fusion and simultaneous communications are allowed. We develop an efficient optimal scheduling solution and implement the distributed training algorithm ASC-WFBP with Horovod and PyTorch. We conduct real-world experiments on an 8-node GPU cluster of 32 GPUs with 10Gbps Ethernet. Experimental results on four modern DNNs show that ASC-WFBP can achieve about 1.09 × -2.48× speedup over the baseline without tensor fusion, and 1.15× -1.35× speedup over the state-of-the-art tensor fusion solution.",Communication-Efficient | Distributed Deep Learning | Simultaneous Communications,16,0,,,,16206417,,INFOCOM Networking
2-s2.0-85110106923,,,,Exploration-Exploitation in Multi-Agent Learning: Catastrophe Theory Meets Game Theory,cp,Conference Paper,Leonardos S.,60104290,Singapore University of Technology and Design,Singapore City,Singapore,2,"Leonardos, Stefanos;Piliouras, Georgios",57209973460;35113645700,60104290;60104290,2021-01-01,2021,"35th AAAI Conference on Artificial Intelligence, AAAI 2021",,21101088903,,Conference Proceeding,13A,,,11263-11271,"Exploration-exploitation is a powerful and practical tool in multi-agent learning (MAL), however, its effects are far from understood. To make progress in this direction, we study a smooth analogue of Q-learning. We start by showing that our learning model has strong theoretical justification as an optimal model for studying exploration-exploitation. Specifically, we prove that smooth Q-learning has bounded regret in arbitrary games for a cost model that explicitly captures the balance between game and exploration costs and that it always converges to the set of quantal-response equilibria (QRE), the standard solution concept for games under bounded rationality, in weighted potential games with heterogeneous learning agents. In our main task, we then turn to measure the effect of exploration in collective system performance. We characterize the geometry of the QRE surface in low-dimensional MAL systems and link our findings with catastrophe (bifurcation) theory. In particular, as the exploration hyperparameter evolves over-time, the system undergoes phase transitions where the number and stability of equilibria can change radically given an infinitesimal change to the exploration parameter. Based on this, we provide a formal theoretical treatment of how tuning the exploration parameter can provably lead to equilibrium selection with both positive as well as negative (and potentially unbounded) effects to system performance.",,7,0,,,NRF,NRF2019-NRFANR095,RCVS Knowledge,AAAI Artificial Intelligence
2-s2.0-85106757640,10.1145/3411764.3445249,,,Falx: Synthesis-powered visualization authoring,cp,Conference Paper,Wang C.,60029241;117213308,"University of California, Santa Barbara;UNIVERSITY OF WASHINGTON",Santa Barbara;WASHINGTON,United States;United States,6,"Wang, Chenglong;Feng, Yu;Bodik, Rastislav;Dillig, Isil;Cheung, Alvin;Ko, Amy J.",57194614165;57026668300;6701821028;22936636100;56874039700;7007018374,117213308;60029241;117213308;117213308;117213308;117213308,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Modern visualization tools aim to allow data analysts to easily create exploratory visualizations. When the input data layout conforms to the visualization design, users can easily specify visualizations by mapping data columns to visual channels of the design. However, when there is a mismatch between data layout and the design, users need to spend signifcant efort on data transformation. We propose Falx, a synthesis-powered visualization tool that allows users to specify visualizations in a similarly simple way but without needing to worry about data layout. In Falx, users specify visualizations using examples of how concrete values in the input are mapped to visual channels, and Falx automatically infers the visualization specifcation and transforms the data to match the design. In a study with 33 data analysts on four visualization tasks involving data transformation, we found that users can effectively adopt Falx to create visualizations they otherwise cannot implement.",,27,0,repositoryam,Green,NSF,1535191,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85114949137,10.1145/3447548.3467290,,,Fast and Memory-Efficient Tucker Decomposition for Answering Diverse Time Range Queries,cp,Conference Paper,Jang J.G.,60013682,Seoul National University,Seoul,South Korea,2,"Jang, Jun Gi;Kang, U.",57204943866;35113263900,60013682;60013682,2021-08-14,14 August 2021,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,21101058999,,Conference Proceeding,,,,725-735,"Given a temporal dense tensor and an arbitrary time range, how can we efficiently obtain latent factors in the range? Tucker decomposition is a fundamental tool for analyzing dense tensors to discover hidden factors, and has been exploited in many data mining applications. However, existing decomposition methods do not provide the functionality to analyze a specific range of a temporal tensor. The existing methods are one-off, with the main focus on performing Tucker decomposition once for a whole input tensor. Although a few existing methods with a preprocessing phase can deal with a time range query, they are still time-consuming and suffer from low accuracy. In this paper, we propose Zoom-Tucker, a fast and memory-efficient Tucker decomposition method for finding hidden factors of temporal tensor data in an arbitrary time range. Zoom-Tucker fully exploits block structure to compress a given tensor, supporting an efficient query and capturing local information. Zoom-Tucker answers diverse time range queries quickly and memory-efficiently, by elaborately decoupling the preprocessed results included in the range and carefully determining the order of computations. We demonstrate that Zoom-Tucker is up to 171.9x faster and requires up to 230x less space than existing methods while providing comparable accuracy.",efficiency | time range query | tucker decomposition,12,0,,,NRF,2019R1A2C2004990,National Research Foundation of Korea,KDD Data Mining
2-s2.0-85123208555,10.1109/CVPR46437.2021.01129,,,GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields,cp,Conference Paper,Niemeyer M.,60030569;60017246,Max Planck Institute for Intelligent Systems;Eberhard Karls Universität Tübingen,Tubingen;Tubingen,Germany;Germany,2,"Niemeyer, Michael;Geiger, Andreas",57214465239;55822335800,60030569-60017246;60030569-60017246,2021-01-01,2021,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,,,,11448-11459,"Deep generative models allow for photorealistic image synthesis at high resolutions. But for many applications, this is not enough: content creation also needs to be controllable. While several recent works investigate how to disentangle underlying factors of variation in the data, most of them operate in 2D and hence ignore that our world is three-dimensional. Further, only few works consider the compositional nature of scenes. Our key hypothesis is that incorporating a compositional 3D scene representation into the generative model leads to more controllable image synthesis. Representing scenes as compositional generative neural feature fields allows us to disentangle one or multiple objects from the background as well as individual objects' shapes and appearances while learning from unstructured and unposed image collections without any additional supervision. Combining this scene representation with a neural rendering pipeline yields a fast and realistic image synthesis model. As evidenced by our experiments, our model is able to disentangle individual objects and allows for translating and rotating them in the scene as well as changing the camera pose.",,388,0,repositoryam,Green,ERC,850533,Nvidia,CVPR Computer Vision
2-s2.0-85106677931,10.1145/3411764.3445103,,,Getting ourselves together: Data-centered participatory design research and epistemic burden,cp,Conference Paper,Pierre J.,60027550,"University of California, Los Angeles",Los Angeles,United States,5,"Pierre, Jennifer;Crooks, Roderic;Currie, Morgan E.;Paris, Britt S.;Pasquetto, Irene V.",57192299495;55962245800;56559542000;57202465137;56737154100,60027550;60027550;60027550;60027550;60027550,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Data-centered participatory design research projects-wherein researchers collaborate with community members for the purpose of gathering, generating, or communicating data about the community or their causes-can place epistemic burdens on minoritized or racialized groups, even in projects focused on social justice outcomes. Analysis of epistemic burden encourages researchers to rethink the purpose and value of data in community organizing and activism more generally. This paper describes three varieties of epistemic burden drawn from two case studies based on the authors' previous work with anti-police brutality community organizations. The authors conclude with a discussion of ways to alleviate and avoid these issues through a series of questions about participatory research design. Ultimately, we call for a reorientation of knowledge production away from putative design solutions to community problems and toward a more robust interrogation of the power dynamics of research itself.",Critical/activism/ethics | Participatory design,35,1,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85115052772,10.1109/SP40001.2021.00036,,,Hardware-software contracts for secure speculation,cp,Conference Paper,Guarnieri M.,60121727;60033241;60021726,IMDEA Software Institute;Universität des Saarlandes;Microsoft Research,Pozuelo de Alarcon;Saarbrucken;Redmond,Spain;Germany;United States,4,"Guarnieri, Marco;Kopf, Boris;Reineke, Jan;Vila, Pepe",55365331100;14030046900;21741533900;57211190108,60121727;60021726;60033241;60121727,2021-05-01,May 2021,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2021-May,,,1868-1883,"Since the discovery of Spectre, a large number of hardware mechanisms for secure speculation has been proposed. Intuitively, more defensive mechanisms are less efficient but can securely execute a larger class of programs, while more permissive mechanisms may offer more performance but require more defensive programming. Unfortunately, there are no hardware-software contracts that would turn this intuition into a basis for principled co-design.In this paper, we put forward a framework for specifying such contracts, and we demonstrate its expressiveness and flexibility.On the hardware side, we use the framework to provide the first formalization and comparison of the security guarantees provided by a representative class of mechanisms for secure speculation.On the software side, we use the framework to characterize program properties that guarantee secure co-design in two scenarios traditionally investigated in isolation: (1) ensuring that a benign program does not leak information while computing on confidential data, and (2) ensuring that a potentially malicious program cannot read outside of its designated sandbox. Finally, we show how the properties corresponding to both scenarios can be checked based on existing tools for software verification, and we use them to validate our findings on executable code.",Hardware-software-co-design | Hardware-software-contracts | Secure-speculation | Spectre | Speculative-execution-attacks | Speculative-non-interference,31,0,repositoryam,Green,,2018-T2/TIC-11732A,Intel Corporation,S&P Security and Privacy
2-s2.0-85115699652,10.1109/ICSE43902.2021.00022,,,Hero: On the chaos when PATH meets modules,cp,Conference Paper,Wang Y.,60105683;60033100;60031863;60027090;60008592,Southern University of Science and Technology;Nanjing University;Northeastern University;Virginia Polytechnic Institute and State University;Hong Kong University of Science and Technology,Shenzhen;Nanjing;Shenyang;Blacksburg;Hong Kong,China;China;China;United States;Hong Kong,8,"Wang, Ying;Qiao, Liang;Xu, Chang;Liu, Yepang;Cheung, Shing Chi;Meng, Na;Yu, Hai;Zhu, Zhiliang",57022068000;57222334647;56870592600;55540648000;7202472792;42161811400;13408303800;55549832300,60031863;60031863;60033100;60105683;60008592;60027090;60031863;60031863,2021-05-01,May 2021,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,99-111,"Ever since its first release in 2009, the Go programming language (Golang) has been well received by software communities. A major reason for its success is the powerful support of library-based development, where a Golang project can be conveniently built on top of other projects by referencing them as libraries. As Golang evolves, it recommends the use of a new library-referencing mode to overcome the limitations of the original one. While these two library modes are incompatible, both are supported by the Golang ecosystem. The heterogeneous use of library-referencing modes across Golang projects has caused numerous dependency management (DM) issues, incurring reference inconsistencies and even build failures. Motivated by the problem, we conducted an empirical study to characterize the DM issues, understand their root causes, and examine their fixing solutions. Based on our findings, we developed Hero, an automated technique to detect DM issues and suggest proper fixing solutions. We applied Hero to 19,000 popular Golang projects. The results showed that Hero achieved a high detection rate of 98.5% on a DM issue benchmark and found 2,422 new DM issues in 2,356 popular Golang projects. We reported 280 issues, among which 181 (64.6%) issues have been confirmed, and 160 of them (88.4%) have been fixed or are under fixing. Almost all the fixes have adopted our fixing suggestions.",Dependency Management | Golang Ecosystem,8,0,repositoryam,Green,NSF,2020B121201001,National Science Foundation,ICSE Software Engineering
2-s2.0-85106676286,10.1145/3411764.3445312,,,Heuristic evaluation of conversational agents,cp,Conference Paper,Langevin R.,60015481,University of Washington,Seattle,United States,3,"Langevin, Raina;Lordon, Ross;Avrahami, Thi",57219754166;56437565800;12752678200,60015481;60015481;60015481,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Conversational interfaces have risen in popularity as businesses and users adopt a range of conversational agents, including chatbots and voice assistants. Although guidelines have been proposed, there is not yet an established set of usability heuristics to guide and evaluate conversational agent design. In this paper, we propose a set of heuristics for conversational agents adapted from Nielsen's heuristics and based on expert feedback. We then validate the heuristics through two rounds of evaluations conducted by participants on two conversational agents, one chatbot and one voice-based personal assistant. We fnd that, when using our heuristics to evaluate both interfaces, evaluators were able to identify more usability issues than when using Nielsen's heuristics. We propose that our heuristics successfully identify issues related to dialogue content, interaction design, help and guidance, human-like characteristics, and data privacy.",Conversational agents | Heuristic evaluation | User interface design,46,0,,,SFI,13/RC/2106,Science Foundation Ireland,CHI Human-Computer Interaction
2-s2.0-85108909642,10.1145/3453483.3454049,,,High performance correctly rounded math libraries for 32-bit floating point representations,cp,Conference Paper,Lim J.P.,123289237,Rutgers University,Alexandria,United States,2,"Lim, Jay P.;Nagarakatte, Santosh",57201092576;28167714800,123289237;123289237,2021-06-18,18 June 2021,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,359-374,"This paper proposes a set of techniques to develop correctly rounded math libraries for 32-bit float and posit types. It enhances our RLIBM approach that frames the problem of generating correctly rounded libraries as a linear programming problem in the context of 16-bit types to scale to 32-bit types. Specifically, this paper proposes new algorithms to (1) generate polynomials that produce correctly rounded outputs for all inputs using counterexample guided polynomial generation, (2) generate efficient piecewise polynomials with bit-pattern based domain splitting, and (3) deduce the amount of freedom available to produce correct results when range reduction involves multiple elementary functions. The resultant math library for the 32-bit float type is faster than state-of-the-art math libraries while producing the correct output for all inputs. We have also developed a set of correctly rounded elementary functions for 32-bit posits.",correctly rounded math libraries | elementary functions | floating point | piecewise polynomials | posits,11,0,,,NSF,1908798,National Science Foundation,PLDI Programming Languages
2-s2.0-85106717866,10.1145/3411764.3445193,,,How to evaluate object selection and manipulation in vr? guidelines from 20 years of studies,cp,Conference Paper,Bergstrom J.,60030840,Københavns Universitet,Copenhagen,Denmark,4,"Bergstrom, Joanna;Dalsgaard, Tor Salve;Alexander, Jason;Hornbaek, Kasper",35221233900;57219872783;14035159600;6602385484,60030840;60030840;60030840;60030840,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"The VR community has introduced many object selection and manipulation techniques during the past two decades. Typically, they are empirically studied to establish their benefts over the state-of-the-art. However, the literature contains few guidelines on how to conduct such studies; standards developed for evaluating 2D interaction often do not apply. This lack of guidelines makes it hard to compare techniques across studies, to report evaluations consistently, and therefore to accumulate or replicate fndings. To build such guidelines, we review 20 years of studies on VR object selection and manipulation. Based on the review, we propose recommendations for designing studies and a checklist for reporting them.We also identify research directions for improving evaluation methods and ofer ideas for how to make studies more ecologically valid and rigorous.",Experiments | Object selection and manipulation | Virtual reality,35,0,repositoryvor,Green,H2020,853063,Horizon 2020 Framework Programme,CHI Human-Computer Interaction
2-s2.0-85106764182,10.1145/3411764.3445580,,,Impact of task on atentional tunneling in handheld augmented reality,cp,Conference Paper,Syiem B.V.,60026553,University of Melbourne,Melbourne,Australia,5,"Syiem, Brandon Victor;Kelly, Ryan M.;Goncalves, Jorge;Velloso, Eduardo;Dingler, Tilman",57221494387;23488976000;7103326186;53364337000;36731098500,60026553;60026553;60026553;60026553;60026553,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Attentional tunneling describes a phenomenon in Augmented Reality (AR) where users excessively focus on virtual content while neglecting their physical surroundings. This leads to the concern that users could neglect hazardous situations when usingARapplications. However, studies have often confounded the role of the virtual content with the role of the associated task in inducing attentional tunneling. In this paper, we disentangle the impact of the associated task and of the virtual content on the attentional tunneling efect by measuring reaction times to events in two user studies.We found that presenting virtual content did not signifcantly increase user reaction times to events, but adding a task to the content did. Thiswork contributes towards our understanding of the attentional tunneling efect on handheld AR devices, and highlights the need to consider both task and context when evaluating AR application usage.",Attentional tunneling | Augmented reality | Mobile devices,9,0,repositoryvor,Green,ARC,DE180100315,Australian Government,CHI Human-Computer Interaction
2-s2.0-85117595768,10.1109/ICSE43902.2021.00066,,,Improving fault localization by integrating value and predicate based causal inference techniques,cp,Conference Paper,Kucuk Y.,60144130;60006191,Case School of Engineering;Google LLC,Cleveland;Mountain View,United States;United States,3,"Kucuk, Yigit;Henderson, Tim A.D.;Podgurski, Andy",57212607896;55842247800;6701372552,60144130;60006191;60144130,2021-05-01,May 2021,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,649-660,"Statistical fault localization (SFL) techniques use execution profiles and success/failure information from software executions, in conjunction with statistical inference, to automatically score program elements based on how likely they are to be faulty. SFL techniques typically employ one type of profile data: either coverage data, predicate outcomes, or variable values. Most SFL techniques actually measure correlation, not causation, between profile values and success/failure, and so they are subject to confounding bias that distorts the scores they produce. This paper presents a new SFL technique, named UniVal, that uses causal inference techniques and machine learning to integrate information about both predicate outcomes and variable values to more accurately estimate the true failure-causing effect of program statements. UniVal was empirically compared to several coverage-based, predicate-based, and value-based SFL techniques on 800 program versions with real faults.",Causal Inference | Fault Localization | Software Engineering | Software Fault Localization | Statistical Fault Localization,27,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-85105794699,10.1145/3411764.3445761,,,Increasing Electrical Muscle Stimulation's Dexterity by means of Back of the Hand Actuation,cp,Conference Paper,Takahashi A.,60029278,The University of Chicago,Chicago,United States,4,"Takahashi, Akifumi;Brooks, Jas;Kajimoto, Hiroyuki;Lopes, Pedro",57195231000;57219108258;6602141526;55480857700,60029278;60029278;60029278;60029278,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"We propose a technique that allows an unprecedented level of dexterity in electrical muscle stimulation (EMS), i.e., it allows interactive EMS-based devices to flex the user's fingers independently of each other. EMS is a promising technique for force feedback because of its small form factor when compared to mechanical actuators. However, the current EMS approach to flexing the user's fingers (i.e., attaching electrodes to the base of the forearm, where finger muscles anchor) is limited by its inability to flex a target finger's metacarpophalangeal (MCP) joint independently of the other fingers. In other words, current EMS devices cannot flex one finger alone, they always induce unwanted actuation to adjacent fingers. To tackle the lack of dexterity, we propose and validate a new electrode layout that places the electrodes on the back of the hand, where they stimulate the interossei/lumbricals muscles in the palm, which have never received attention with regards to EMS. In our user study, we found that our technique offers four key benefits.",Dexterity | Electrical muscle stimulation | EMS | Haptic actuation,29,1,publisherfree2read,Bronze,NSF,2047189,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85108143969,10.1145/3406325.3451093,,,Indistinguishability obfuscation from well-founded assumptions,cp,Conference Paper,Jain A.,60027550;122262718,"University of California, Los Angeles;University of Washington",Los Angeles;Redmond,United States;United States,3,"Jain, Aayush;Lin, Huijia;Sahai, Amit",57190376711;23967787300;57206236820,60027550;122262718;60027550,2021-06-15,15 June 2021,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,60-73,"Indistinguishability obfuscation, introduced by [Barak et. al. Crypto 2001], aims to compile programs into unintelligible ones while preserving functionality. It is a fascinating and powerful object that has been shown to enable a host of new cryptographic goals and beyond. However, constructions of indistinguishability obfuscation have remained elusive, with all other proposals relying on heuristics or newly conjectured hardness assumptions. In this work, we show how to construct indistinguishability obfuscation from subexponential hardness of four well-founded assumptions. We prove: Informal Theorem: Let ? e (0,?), ?e (0,1), e (0,1) be arbitrary constants. Assume sub-exponential security of the following assumptions: - the Learning With Errors (LWE) assumption with subexponential modulus-to-noise ratio 2k? and noises of magnitude polynomial in k, where k is the dimension of the LWE secret, - the Learning Parity with Noise (LPN) assumption over general prime fields Zp with polynomially many LPN samples and error rate 1/?, where ? is the dimension of the LPN secret, - the existence of a Boolean Pseudo-Random Generator (PRG) in NC0 with stretch n1+?, where n is the length of the PRG seed, - the Decision Linear (DLIN) assumption on symmetric bilinear groups of prime order. Then, (subexponentially secure) indistinguishability obfuscation for all polynomial-size circuits exists. Further, assuming only polynomial security of the aforementioned assumptions, there exists collusion resistant public-key functional encryption for all polynomial-size circuits.",indistinguishability obfuscation,106,1,repositoryam,Green,NSF,1413955,National Science Foundation,STOC Theory
2-s2.0-85130054909,,,,Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting,cp,Conference Paper,Zhou H.,60025038;60013789;123285713;117861117,"University of California, Berkeley;Beihang University;Rutgers University;Beijing Guowang Fuda Science &amp; Technology Development Co., Ltd.",Berkeley;Beijing;West Orange/New Jersey;Beijing,United States;China;United States;China,7,"Zhou, Haoyi;Zhang, Shanghang;Peng, Jieqi;Zhang, Shuai;Li, Jianxin;Xiong, Hui;Zhang, Wancai",57196123986;57054535400;57221812819;57193436457;55720560100;7201935465;57221813448,60013789;60025038;60013789;60013789;60013789;123285713;117861117,2021-01-01,2021,"35th AAAI Conference on Artificial Intelligence, AAAI 2021",,21101088903,,Conference Proceeding,12B,,,11106-11115,"Many real-world applications require the prediction of long sequence time-series, such as electricity consumption planning. Long sequence time-series forecasting (LSTF) demands a high prediction capacity of the model, which is the ability to capture precise long-range dependency coupling between output and input efficiently. Recent studies have shown the potential of Transformer to increase the prediction capacity. However, there are several severe issues with Transformer that prevent it from being directly applicable to LSTF, including quadratic time complexity, high memory usage, and inherent limitation of the encoder-decoder architecture. To address these issues, we design an efficient transformer-based model for LSTF, named Informer, with three distinctive characteristics: (i) a ProbSparse self-attention mechanism, which achieves O(L log L) in time complexity and memory usage, and has comparable performance on sequences’ dependency alignment. (ii) the self-attention distilling highlights dominating attention by halving cascading layer input, and efficiently handles extreme long input sequences. (iii) the generative style decoder, while conceptually simple, predicts the long time-series sequences at one forward operation rather than a step-by-step way, which drastically improves the inference speed of long-sequence predictions. Extensive experiments on four large-scale datasets demonstrate that Informer significantly outperforms existing methods and provides a new solution to the LSTF problem.",,1301,0,,,NSFC,61421003,National Natural Science Foundation of China,AAAI Artificial Intelligence
2-s2.0-85115708536,10.1109/ICSE43902.2021.00113,,,"Interface compliance of inline assembly: Automatically check, patch and refine",cp,Conference Paper,Recoules F.,60106017;60104653;120037457,Université Paris-Saclay;Université Grenoble Alpes;Tweag I/O,Gif-sur-Yvette;Saint Martin d'Heres;Paris,France;France;France,6,"Recoules, Frederic;Bardin, Sebastien;Bonichon, Richard;Lemerre, Matthieu;Mounier, Laurent;Potet, Marie Laure",57215287631;13105090500;6506913361;24773634800;6603106167;8727223500,60106017;60106017;120037457;60106017;60104653;60104653,2021-05-01,May 2021,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,1236-1247,"Inline assembly is still a common practice in low-level C programming, typically for efficiency reasons or for accessing specific hardware resources. Such embedded assembly codes in the GNU syntax (supported by major compilers such as GCC, Clang and ICC) have an interface specifying how the assembly codes interact with the C environment. For simplicity reasons, the compiler treats GNU inline assembly codes as blackboxes and relies only on their interface to correctly glue them into the compiled C code. Therefore, the adequacy between the assembly chunk and its interface (named compliance) is of primary importance, as such compliance issues can lead to subtle and hard-to-find bugs. We propose RUSTInA, the first automated technique for formally checking inline assembly compliance, with the extra ability to propose (proven) patches and (optimization) refinements in certain cases. RUSTInA is based on an original formalization of the inline assembly compliance problem together with novel dedicated algorithms. Our prototype has been evaluated on 202 Debian packages with inline assembly (2656 chunks), finding 2183 issues in 85 packages - 986 significant issues in 54 packages (including major projects such as ffmpeg or ALSA), and proposing patches for 92% of them. Currently, 38 patches have already been accepted (solving 156 significant issues), with positive feedback from development teams.",Compilation issues | Inline assembly | Low level programming | Program analysis,6,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-85106421990,10.1109/ICSE-Companion52605.2021.00065,,,JEST: N+1-Version Differential Testing of Both JavaScript Engines and Specification,cp,Conference Paper,Park J.,60032144,Korea Advanced Institute of Science and Technology,Daejeon,South Korea,5,"Park, Jihyeok;An, Seungmin;Youn, Dongjun;Kim, Gyeongwon;Ryu, Sukyoung",58362975400;57221467825;57222269122;57222275939;22735372000,60032144;60032144;60032144;60032144;60032144,2021-05-01,May 2021,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,156-157,"Modern programming follows the continuous integration (CI) and continuous deployment (CD) approach rather than the traditional waterfall model. Even the development of modern programming languages uses the CI/CD approach to swiftly provide new language features and to adapt to new development environments. Unlike in the conventional approach, in the modern CI/CD approach, a language specification is no more the oracle of the language semantics because both the specification and its implementations (interpreters or compilers) can co-evolve. In this setting, both the specification and implementations may have bugs, and guaranteeing their correctness is non-trivial. In this paper, we propose a novel N+1-version differential testing to resolve the problem. Unlike the traditional differential testing, our approach consists of three steps: 1) to automatically synthesize programs guided by the syntax and semantics from a given language specification, 2) to generate conformance tests by injecting assertions to the synthesized programs to check their final program states, 3) to detect bugs in the specification and implementations via executing the conformance tests on multiple implementations, and 4) to localize bugs on the specification using statistical information. We actualize our approach for the JavaScript programming language via JEST, which performs N+1-version differential testing for modern JavaScript engines and ECMAScript, the language specification describing the syntax and semantics of JavaScript in a natural language. We evaluated JEST with four JavaScript engines that support all modern JavaScript language features and the latest version of ECMAScript (ES11, 2020). JEST automatically synthesized 1,700 programs that covered 97.78% of syntax and 87.70% of semantics from ES11. Using the assertion-injected JavaScript programs, it detected 44 engine bugs in four different engines and 27 specification bugs in ES11.",conformance test generation | differential testing | JavaScript | mechanized specification,12,0,repositoryam,Green,NRF,2017M3C4A7068177,National Research Foundation of Korea,ICSE Software Engineering
2-s2.0-85119093779,10.1145/3477132.3483568,,,Kangaroo: Caching Billions of Tiny Objects on Flash,cp,Conference Paper,Mcallister S.,60027950;60021726;127214993,Carnegie Mellon University;Microsoft Research;Facebook,Pittsburgh;Redmond;,United States;United States;,9,"Mcallister, Sara;Berg, Benjamin;Tutuncu-Macias, Julian;Yang, Juncheng;Gunasekar, Sathya;Lu, Jimmy;Berger, Daniel S.;Beckmann, Nathan;Ganger, Gregory R.",57209776651;57205679491;57338975200;57190286382;57220072637;57220072797;56270528200;35106612200;35580432900,60027950;60027950;60027950;60027950;127214993;127214993;60021726;60027950;60027950,2021-10-26,26 October 2021,SOSP 2021 - Proceedings of the 28th ACM Symposium on Operating Systems Principles,,21101065501,,Conference Proceeding,,,,243-262,"Many social-media and IoT services have very large working sets consisting of billions of tiny (≈100 B) objects. Large, flash-based caches are important to serving these working sets at acceptable monetary cost. However, caching tiny objects on flash is challenging for two reasons: (i) SSDs can read/write data only in multi-KB ""pages""that are much larger than a single object, stressing the limited number of times flash can be written; and (ii) very few bits per cached object can be kept in DRAM without losing flash's cost advantage. Unfortunately, existing flash-cache designs fall short of addressing these challenges: write-optimized designs require too much DRAM, and DRAM-optimized designs require too many flash writes. We present Kangaroo, a new flash-cache design that optimizes both DRAM usage and flash writes to maximize cache performance while minimizing cost. Kangaroo combines a large, set-associative cache with a small, log-structured cache. The set-associative cache requires minimal DRAM, while the log-structured cache minimizes Kangaroo's flash writes. Experiments using traces from Facebook and Twitter show that Kangaroo achieves DRAM usage close to the best prior DRAM-optimized design, flash writes close to the best prior write-optimized design, and miss ratios better than both. Kangaroo's design is Pareto-optimal across a range of allowed write rates, DRAM sizes, and flash sizes, reducing misses by 29% over the state of the art. These results are corroborated with a test deployment of Kangaroo in a production flash cache at Facebook.",Caching | Flash | Tiny objects,18,1,publisherfree2read,Bronze,IBM,1938909,Intel Corporation,SOSP Operating Systems
2-s2.0-85108202913,,,,Keep Your Distance: Land Division With Separation,cp,Conference Paper,Elkind E.,60080064;60026851;60017161,Ariel University;University of Oxford;National University of Singapore,Ariel;Oxford;Singapore City,Israel;United Kingdom;Singapore,3,"Elkind, Edith;Segal-Halevi, Erel;Suksompong, Warut",23008155200;56422378800;55927242300,60026851;60080064;60017161,2021-01-01,2021,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,168-174,"This paper is part of an ongoing endeavor to bring the theory of fair division closer to practice by handling requirements from real-life applications. We focus on two requirements originating from the division of land estates: (1) each agent should receive a plot of a usable geometric shape, and (2) plots of different agents must be physically separated. With these requirements, the classic fairness notion of proportionality is impractical, since it may be impossible to attain any multiplicative approximation of it. In contrast, the ordinal maximin share approximation, introduced by Budish in 2011, provides meaningful fairness guarantees. We prove upper and lower bounds on achievable maximin share guarantees when the usable shapes are squares, fat rectangles, or arbitrary axes-aligned rectangles, and explore the algorithmic and query complexity of finding fair partitions in this setting.",,8,0,,,H2020,639945,Horizon 2020 Framework Programme,IJCAI Artificial Intelligence
2-s2.0-85106668864,10.1145/3411764.3445331,,,Lgbtq persons' pregnancy loss disclosures to known ties on social media disclosure decisions and ideal disclosure environments,cp,Conference Paper,Pyle C.,60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,2,"Pyle, Cassidy;Roosevelt, Lee",57223998362;56692926400,60025778;60025778,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Pregnancy loss is a common yet stigmatized experience. We inves-tigate (non)disclosure of pregnancy loss among LGBTQ people to known ties on identifed social media as well as what constitutes ideal socio-technical disclosure environments. LGBTQ persons ex-periencing loss face intersectional stigma for holding a marginalized sexual and/or gender identity and experiencing pregnancy loss.We interviewed 17 LGBTQ people in the U.S. who used social media and had recently experienced pregnancy loss. We demonstrate how the Disclosure Decision-Making (DDM) framework explains LGBTQ pregnancy loss (non)disclosure decisions, thereby asserting the framework's ability to explain (non)disclosure decisions for those facing intersectional stigma.We illustrate howone's LGBTQ identity shapes (non)disclosure decisions of loss.We argue that social media platforms can better facilitate disclosures about silenced topics by enabling selective disclosure, enabling proxy content moderation, providing education about silenced experiences, and prioritizing such disclosures in news feeds. CAUTION: This paper includes quotes about pregnancy loss.",Disclosure | Intersectional stigma | Intersectionality | Lgbtq health | Miscarriage | Pregnancy loss | Reproductive health | Social media,12,1,publisherfree2read,Bronze,U-M,undefined,University of Michigan,CHI Human-Computer Interaction
2-s2.0-85123009540,,,,Learning Generalized Unsolvability Heuristics for Classical Planning,cp,Conference Paper,Ståhlberg S.,60032942;60009358,Universitat Pompeu Fabra Barcelona;Linköpings Universitet,Barcelona;Linkoping,Spain;Sweden,3,"Ståhlberg, Simon;Francès, Guillem;Seipp, Jendrik",56024141100;56285848800;55361565700,60009358;60032942;60009358,2021-01-01,2021,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,4175-4181,"Recent work in classical planning has introduced dedicated techniques for detecting unsolvable states, i.e., states from which no goal state can be reached. We approach the problem from a generalized planning perspective and learn first-order-like formulas that characterize unsolvability for entire planning domains. We show how to cast the problem as a self-supervised classification task. Our training data is automatically generated and labeled by exhaustive exploration of small instances of each domain, and candidate features are automatically computed from the predicates used to define the domain. We investigate three learning algorithms with different properties and compare them to heuristics from the literature. Our empirical results show that our approach often captures important classes of unsolvable states with high classification accuracy. Additionally, the logical form of our heuristics makes them easy to interpret and reason about, and can be used to show that the characterizations learned in some domains capture exactly all unsolvable states of the domain.",,9,0,,,H2020,952215,Horizon 2020 Framework Programme,IJCAI Artificial Intelligence
2-s2.0-85118308655,10.1145/3477132.3483565,,,LineFS: Efficient SmartNIC Offload of a Distributed File System with Pipeline Parallelism,cp,Conference Paper,Kim J.,60025778;60013372;60002014;60000874;127215050,"University of Michigan, Ann Arbor;The University of Texas at Austin;The Royal Institute of Technology (KTH);Université Catholique de Louvain;KAIST",Ann Arbor;Austin;Stockholm;Louvain-la-Neuve;,United States;United States;Sweden;Belgium;,9,"Kim, Jongyul;Jang, Insu;Reda, Waleed;Im, Jaeseong;Canini, Marco;Kostić, Dejan;Kwon, Youngjin;Peter, Simon;Witchel, Emmett",57219619521;58630605900;57188676213;57196258599;24469881600;8619696100;57189848706;56231946100;22836994600,127215050;60025778;60000874;127215050;127215050;60002014;127215050;60013372;60013372,2021-10-26,26 October 2021,SOSP 2021 - Proceedings of the 28th ACM Symposium on Operating Systems Principles,,21101065501,,Conference Proceeding,,,,756-771,"In multi-tenant systems, the CPU overhead of distributed file systems (DFSes) is increasingly a burden to application performance. CPU and memory interference cause degraded and unstable application and storage performance, in particular for operation latency. Recent client-local DFSes for persistent memory (PM) accelerate this trend. DFS offload to SmartNICs is a promising solution to these problems, but it is challenging to fit the complex demands of a DFS onto simple SmartNIC processors located across PCIe. We present LineFS, a SmartNIC-offloaded, high-performance DFS with support for client-local PM. To fully leverage the SmartNIC architecture, we decompose DFS operations into execution stages that can be offloaded to a parallel datapath execution pipeline on the SmartNIC. LineFS offloads CPU-intensive DFS tasks, like replication, compression, data publication, index and consistency management to a Smart-NIC. We implement LineFS on the Mellanox BlueField Smart-NIC and compare it to Assise, a state-of-the-art PM DFS. LineFS improves latency in LevelDB up to 80% and throughput in Filebench up to 79%, while providing extended DFS availability during host system failures.",Distributed file system | SmartNIC offload,45,0,repositoryvor,Green,NSF,CNS-1900457,National Science Foundation,SOSP Operating Systems
2-s2.0-85113876297,,,,MAGE: Nearly zero-cost virtual memory for secure computation,cp,Conference Paper,Kumar S.,60025038,"University of California, Berkeley",Berkeley,United States,3,"Kumar, Sam;Culler, David E.;Popa, Raluca Ada",57211648008;7004874505;23985854800,60025038;60025038;60025038,2021-01-01,2021,"Proceedings of the 15th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2021",,21101057678,,Conference Proceeding,,,,367-385,"Secure Computation (SC) is a family of cryptographic primitives for computing on encrypted data in single-party and multi-party settings. SC is being increasingly adopted by industry for a variety of applications. A significant obstacle to using SC for practical applications is the memory overhead of the underlying cryptography. We develop MAGE, an execution engine for SC that efficiently runs SC computations that do not fit in memory. We observe that, due to their intended security guarantees, SC schemes are inherently oblivious—their memory access patterns are independent of the input data. Using this property, MAGE calculates the memory access pattern ahead of time and uses it to produce a memory management plan. This formulation of memory management, which we call memory programming, is a generalization of paging that allows MAGE to provide a highly efficient virtual memory abstraction for SC. MAGE outperforms the OS virtual memory system by up to an order of magnitude, and in many cases, runs SC computations that do not fit in memory at nearly the same speed as if the underlying machines had unbounded physical memory to fit the entire computation.",,7,0,,,NSF,1943347,National Science Foundation,OSDI Operating Systems
2-s2.0-85125026605,,,,MAUVE: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers,cp,Conference Paper,Pillutla K.,60141508;60028661;127861583;126150611,Stanford Engineering;UW College of Engineering;University of Washington;Allen Institute for Artificial Intelligence,Stanford;Seattle;Washington;Allen,United States;United States;United States;United States,7,"Pillutla, Krishna;Swayamdipta, Swabha;Zellers, Rowan;Thickstun, John;Welleck, Sean;Choi, Yejin;Harchaoui, Zaid",57191587179;55513212500;57193255202;57204045678;57188714884;36172231400;22234232100,60028661;126150611;60028661;60141508;60028661-126150611;60028661-126150611;127861583,2021-01-01,2021,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,6,,,4816-4828,"As major progress is made in open-ended text generation, measuring how close machine-generated text is to human language remains a critical open problem. We introduce MAUVE, a comparison measure for open-ended text generation, which directly compares the learnt distribution from a text generation model to the distribution of human-written text using divergence frontiers. MAUVE scales up to modern text generation models by computing information divergences in a quantized embedding space. Through an extensive empirical study on three open-ended generation tasks, we find that MAUVE identifies known properties of generated text, scales naturally with model size, and correlates with human judgments, with fewer restrictions than existing distributional evaluation metrics.",,94,0,,,NSF,CCF-2019844,National Science Foundation,NeurIPS Machine Learning
2-s2.0-85131891843,,,,Moser Flow: Divergence-based Generative Modeling on Manifolds,cp,Conference Paper,Rozen N.,60111190;60027550;60017563,"Facebook Research;University of California, Los Angeles;Weizmann Institute of Science Israel",Menlo Park;Los Angeles;Rehovot,United States;United States;Israel,4,"Rozen, Noam;Grover, Aditya;Nickel, Maximilian;Lipman, Yaron",57239070300;56911848400;52264441000;8540373800,60017563;60111190-60027550;60111190;60017563-60111190,2021-01-01,2021,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,21,,,17669-17680,"We are interested in learning generative models for complex geometries described via manifolds, such as spheres, tori, and other implicit surfaces. Current extensions of existing (Euclidean) generative models are restricted to specific geometries and typically suffer from high computational costs. We introduce Moser Flow (MF), a new class of generative models within the family of continuous normalizing flows (CNF). MF also produces a CNF via a solution to the change-of-variable formula, however differently from other CNF methods, its model (learned) density is parameterized as the source (prior) density minus the divergence of a neural network (NN). The divergence is a local, linear differential operator, easy to approximate and calculate on manifolds. Therefore, unlike other CNFs, MF does not require invoking or backpropagating through an ODE solver during training. Furthermore, representing the model density explicitly as the divergence of a NN rather than as a solution of an ODE facilitates learning high fidelity densities. Theoretically, we prove that MF constitutes a universal density approximator under suitable assumptions. Empirically, we demonstrate for the first time the use of flow models for sampling from general curved surfaces and achieve significant improvements in density estimation, sample quality, and training complexity over existing CNFs on challenging synthetic geometries and real-world benchmarks from the earth and climate sciences.",,4,0,,,ERC,771136,European Research Council,NeurIPS Machine Learning
2-s2.0-85108576817,10.1145/3410220.3460102,,,Nudge: Stochastically Improving upon FCFS,cp,Conference Paper,Grosof I.,60027950;60025278,Carnegie Mellon University;Tsinghua University,Pittsburgh;Beijing,United States;China,4,"Grosof, Isaac;Yang, Kunhe;Scully, Ziv;Harchol-Balter, Mor",57194043598;57215430433;57190804986;6701569542,60027950;60025278;60027950;60027950,2021-05-31,31 May 2021,SIGMETRICS 2021 - Abstract Proceedings of the 2021 ACM SIGMETRICS / International Conference on Measurement and Modeling of Computer Systems,,21101049538,,Conference Proceeding,,,,11-12,"The First-Come First-Served (FCFS) scheduling policy is the most popular scheduling algorithm used in practice. Furthermore, its usage is theoretically validated: for light-tailed job size distributions, FCFS has weakly optimal asymptotic tail of response time. But what if we don't just care about the asymptotic tail? What if we also care about the 99th percentile of response time, or the fraction of jobs that complete in under one second? Is FCFS still best? Outside of the asymptotic regime, only loose bounds on the tail of FCFS are known, and optimality is completely open. In this paper, we introduce a new policy, Nudge, which is the first policy to provably stochastically improve upon FCFS. We prove that Nudge simultaneously improves upon FCFS at every point along the tail, for light-tailed job size distributions. As a result, Nudge outperforms FCFS for every moment and every percentile of response time. Moreover, Nudge provides a multiplicative improvement over FCFS in the asymptotic tail. This resolves a long-standing open problem by showing that, counter to previous conjecture, FCFS is not strongly asymptotically optimal. This paper represents an abridged version of [2].",FCFS | latency | M/G/1 | response time | scheduling | sojourn time | stochastic dominance,3,0,repositoryam,Green,NSF,1763701,National Science Foundation,SIGMETRICS Performance
2-s2.0-85106706877,10.1145/3411764.3445641,,,"Oh, snap! a fabrication pipeline to magnetically connect conventional and 3d-printed electronics",cp,Conference Paper,Schmitz M.,60011226,Technische Universität Darmstadt,Darmstadt,Germany,3,"Schmitz, Martin;Riemann, Jan;Muller, Florian",56158083600;55920795900;57193483579,60011226;60011226;60011226,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"3D printing has revolutionized rapid prototyping by speeding up the creation of custom-shaped objects. With the rise of multi-material 3D printers, these custom-shaped objects can now be made interactive in a single pass through passive conductive structures. However, connecting conventional electronics to these conductive structures often still requires time-consuming manual assembly involving many wires, soldering or gluing. To alleviate these shortcomings, we propose Oh, Snap!: a fabrication pipeline and interfacing concept to magnetically connect a 3D-printed object equipped with passive sensing structures to conventional sensing electronics. To this end, Oh, Snap! utilizes ferromagnetic and conductive 3D-printed structures, printable in a single pass on standard printers. We further present a proof-of-concept capacitive sensing board that enables easy and robust magnetic assembly to quickly create interactive 3D-printed objects. We evaluate Oh, Snap! by assessing the robustness and quality of the connection and demonstrate its broad applicability by a series of example applications.",3d printing | Capacitive sensing | Prototyping | Proximity | Touch,9,0,,,DFG,326979514,Deutsche Forschungsgemeinschaft,CHI Human-Computer Interaction
2-s2.0-85129461282,,,,On the Expressivity of Markov Reward,cp,Conference Paper,Abel D.,60280409;60141284;60111161,Department of Computer Science;School of Engineering and Applied Science;DeepMind Technologies Limited,Providence;Princeton;London,United States;United States;United Kingdom,7,"Abel, David;Dabney, Will;Harutyunyan, Anna;Ho, Mark K.;Littman, Michael L.;Precup, Doina;Singh, Satinder",56808959000;55364888900;56401678800;57193692515;7006510438;6603288659;55548164600,60111161;60111161;60111161;60141284;60280409;60111161;60111161,2021-01-01,2021,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,10,,,7799-7812,"Reward is the driving force for reinforcement-learning agents. This paper is dedicated to understanding the expressivity of reward as a way to capture tasks that we would want an agent to perform. We frame this study around three new abstract notions of “task” that might be desirable: (1) a set of acceptable behaviors, (2) a partial ordering over behaviors, or (3) a partial ordering over trajectories. Our main results prove that while reward can express many of these tasks, there exist instances of each task type that no Markov reward function can capture. We then provide a set of polynomial-time algorithms that construct a Markov reward function that allows an agent to optimize tasks of each of these three types, and correctly determine when no such reward function exists. We conclude with an empirical study that corroborates and illustrates our theoretical findings.",,18,0,,,NSF,undefined,National Science Foundation,NeurIPS Machine Learning
2-s2.0-85125475958,,,,On the Relation Between Approximation Fixpoint Theory and Justification Theory,cp,Conference Paper,Marynissen S.,60026810;60025063,Vrije Universiteit Brussel;KU Leuven,Brussels;Leuven,Belgium;Belgium,3,"Marynissen, Simon;Bogaerts, Bart;Denecker, Marc",36028412600;55668474300;6701768512,60025063-60026810;60026810;60025063,2021-01-01,2021,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,,,,1973-1980,"Approximation Fixpoint Theory (AFT) and Justification Theory (JT) are two frameworks to unify logical formalisms. AFT studies semantics in terms of fixpoints of lattice operators, and JT in terms of so-called justifications, which are explanations of why certain facts do or do not hold in a model. While the approaches differ, the frameworks were designed with similar goals in mind, namely to study the different semantics that arise in (mainly) non-monotonic logics. The first contribution of our current paper is to provide a formal link between the two frameworks. To be precise, we show that every justification frame induces an approximator and that this mapping from JT to AFT preserves all major semantics. The second contribution exploits this correspondence to extend JT with a novel class of semantics, namely ultimate semantics: we formally show that ultimate semantics can be obtained in JT by a syntactic transformation on the justification frame, essentially performing some sort of resolution on the rules.",,3,0,,,ERC,714034,European Research Council,IJCAI Artificial Intelligence
2-s2.0-85108917907,10.1145/3453483.3454032,,,Perceus: Garbage free reference counting with reuse,cp,Conference Paper,Reinking A.,60021726;60006541,Microsoft Research;The University of Hong Kong,Redmond;Hong Kong,United States;Hong Kong,4,"Reinking, Alex;Xie, Ningning;De Moura, Leonardo;Leijen, Daan",57015336900;57201676026;23396587300;6508392337,60021726;60006541;60021726;60021726,2021-06-18,18 June 2021,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,96-111,"We introduce Perceus, an algorithm for precise reference counting with reuse and specialization. Starting from a functional core language with explicit control-flow, Perceus emits precise reference counting instructions such that (cycle-free) programs are_garbage free_, where only live references are retained. This enables further optimizations, like reuse analysis that allows for guaranteed in-place updates at runtime. This in turn enables a novel programming paradigm that we call_functional but in-place_ (FBIP). Much like tail-call optimization enables writing loops with regular function calls, reuse analysis enables writing in-place mutating algorithms in a purely functional way. We give a novel formalization of reference counting in a linear resource calculus, and prove that Perceus is sound and garbage free. We show evidence that Perceus, as implemented in Koka, has good performance and is competitive with other state-of-the-art memory collectors.",Algebraic Effects | Handlers | Reference Counting,11,0,,,NSF,1723445,National Science Foundation,PLDI Programming Languages
2-s2.0-85113872090,,,,Pollux: Co-adaptive cluster scheduling for goodput-optimized deep learning,cp,Conference Paper,Qiao A.,60195969;60114175;60027950;60025038,"Mohamed Bin Zayed University of Artificial Intelligence;Petuum, Inc.;Carnegie Mellon University;University of California, Berkeley",Abu Dhabi;Pittsburgh;Pittsburgh;Berkeley,United Arab Emirates;United States;United States;United States,8,"Qiao, Aurick;Choe, Sang Keun;Subramanya, Suhas Jayaram;Neiswanger, Willie;Ho, Qirong;Zhang, Hao;Ganger, Gregory R.;Xing, Eric P.",57212967927;57204051376;57215352673;56502177900;55213954900;56414397000;35580432900;57685890100,60114175-60027950;60027950;60027950;60114175-60027950;60114175;60114175-60025038;60027950;60114175-60027950-60195969,2021-01-01,2021,"Proceedings of the 15th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2021",,21101057678,,Conference Proceeding,,,,1-18,"Pollux improves scheduling performance in deep learning (DL) clusters by adaptively co-optimizing inter-dependent factors both at the per-job level and at the cluster-wide level. Most existing schedulers expect users to specify the number of resources for each job, often leading to inefficient resource use. Some recent schedulers choose job resources for users, but do so without awareness of how DL training can be re-optimized to better utilize the provided resources. Pollux simultaneously considers both aspects. By monitoring the status of each job during training, Pollux models how their goodput (a metric we introduce to combine system throughput with statistical efficiency) would change by adding or removing resources. Pollux dynamically (re-)assigns resources to improve cluster-wide goodput, while respecting fairness and continually optimizing each DL job to better utilize those resources. In experiments with real DL jobs and with trace-driven simulations, Pollux reduces average job completion times by 37–50% relative to state-of-the-art DL schedulers, even when they are provided with ideal resource and training configurations for every job. Pollux promotes fairness among DL jobs competing for resources, based on a more meaningful measure of useful job progress, and reveals a new opportunity for reducing DL cost in cloud environments. Pollux is implemented and publicly available as part of an open-source project at https://github.com/petuum/adaptdl.",,56,0,,,,undefined,,OSDI Operating Systems
2-s2.0-85116259826,10.1145/3468264.3468625,,,Probabilistic Delta debugging,cp,Conference Paper,Wang G.,60019533;60014966,Tianjin University;Peking University,Tianjin;Beijing,China;China,5,"Wang, Guancheng;Shen, Ruobing;Chen, Junjie;Xiong, Yingfei;Zhang, Lu",57205247231;58717116800;57145642900;35744243000;56275778800,60014966;60014966;60019533;60014966;60014966,2021-08-20,20 August 2021,ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101060564,,Conference Proceeding,,,,881-892,"The delta debugging problem concerns how to reduce an object while preserving a certain property, and widely exists in many applications, such as compiler development, regression fault localization, and software debloating. Given the importance of delta debugging, multiple algorithms have been proposed to solve the delta debugging problem efficiently and effectively. However, the efficiency and effectiveness of the state-of-the-art algorithms are still not satisfactory. For example, the state-of-the-art delta debugging tool, CHISEL, may take up to 3 hours to reduce a single program with 14,092 lines of code, while the reduced program may be up to 2 times unnecessarily large. In this paper, we propose a probabilistic delta debugging algorithm (named ProbDD) to improve the efficiency and the effectiveness of delta debugging. Our key insight is, the ddmin algorithm, the basic algorithm upon which many existing approaches are built, follows a predefined sequence of attempts to remove elements from a sequence, and fails to utilize the information from existing test results. To address this problem, ProbDD builds a probabilistic model to estimate the probabilities of the elements to be kept in the produced result, selects a set of elements to maximize the gain of the next test based on the model, and improves the model based on the test results. We prove the correctness of ProbDD, and analyze the minimality of its result and the asymptotic number of tests under the worst case. The asymptotic number of tests in the worst case of ProbDD is O(n), which is smaller than that of ddmin, O(n2) worst-case asymptotic number of tests. Furthermore, we experimentally compared ProbDD with ddmin on 40 subjects in HDD and CHISEL, two approaches that wrap ddmin for reducing trees and C programs, respectively. The results show that, after replacing ddmin with ProbDD, HDD and CHISEL produce 59.48% and 11.51% smaller results and use 63.22% and 45.27% less time, respectively.",Delta Debugging | Probabilistic Model,12,0,,,NSFC,61922003,National Natural Science Foundation of China,FSE Software Engineering
2-s2.0-85112633186,10.1109/ICSE43902.2021.00056,,,Program comprehension and code complexity metrics: An fMRI study,cp,Conference Paper,Peitek N.,60033241;60020075;60008069;60004923,Universität des Saarlandes;Leibniz Institute for Neurobiology;Technische Universität Chemnitz;NC State University,Saarbrucken;Magdeburg;Chemnitz;Raleigh,Germany;Germany;Germany;United States,5,"Peitek, Norman;Apel, Sven;Parnin, Chris;Brechmann, Andre;Siegmund, Janet",57202890928;8725218400;15136883200;6505799448;55420344200,60020075;60033241;60004923;60020075;60008069,2021-05-01,May 2021,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,524-536,"Background: Researchers and practitioners have been using code complexity metrics for decades to predict how developers comprehend a program. While it is plausible and tempting to use code metrics for this purpose, their validity is debated, since they rely on simple code properties and rarely consider particularities of human cognition. Aims: We investigate whether and how code complexity metrics reflect difficulty of program comprehension. Method: We have conducted a functional magnetic resonance imaging (fMRI) study with 19 participants observing program comprehension of short code snippets at varying complexity levels. We dissected four classes of code complexity metrics and their relationship to neuronal, behavioral, and subjective correlates of program comprehension, overall analyzing more than 41 metrics. Results: While our data corroborate that complexity metrics can-to a limited degree-explain programmers' cognition in program comprehension, fMRI allowed us to gain insights into why some code properties are difficult to process. In particular, a code's textual size drives programmers' attention, and vocabulary size burdens programmers' working memory. Conclusion: Our results provide neuro-scientific evidence supporting warnings of prior research questioning the validity of code complexity metrics and pin down factors relevant to program comprehension. Future Work: We outline several follow-up experiments investigating fine-grained effects of code complexity and describe possible refinements to code complexity metrics.",Code complexity metrics | Cognitive load | Functional magnetic resonance imaging | Program comprehension,31,0,,,,undefined,,ICSE Software Engineering
2-s2.0-85108913823,10.1145/3453483.3454061,,,Quantum abstract interpretation,cp,Conference Paper,Yu N.,60027550;60023932,"University of California, Los Angeles;University of Technology Sydney",Los Angeles;Sydney,United States;Australia,2,"Yu, Nengkun;Palsberg, Jens",35319334500;7003405605,60023932;60027550,2021-06-18,18 June 2021,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,542-558,"In quantum computing, the basic unit of information is a qubit. Simulation of a general quantum program takes exponential time in the number of qubits, which makes simulation infeasible beyond 50 qubits on current supercomputers. So, for the understanding of larger programs, we turn to static techniques. In this paper, we present an abstract interpretation of quantum programs and we use it to automatically verify assertions in polynomial time. Our key insight is to let an abstract state be a tuple of projections. For such domains, we present abstraction and concretization functions that form a Galois connection and we use them to define abstract operations. Our experiments on a laptop have verified assertions about the Bernstein-Vazirani, GHZ, and Grover benchmarks with 300 qubits.",abstract interpretation | quantum programming | scalability,26,0,,,NSF,OMA-2016245,National Science Foundation,PLDI Programming Languages
2-s2.0-85106737981,10.1145/3411764.3445367,,,Radarnet: Efficient gesture recognition technique utilizing a miniature radar sensor,cp,Conference Paper,Hayashi E.,60006191,Google LLC,Mountain View,United States,8,"Hayashi, Eiji;Lien, Jaime;Gillian, Nicholas;Giusti, Leonardo;Weber, Dave;Yamanaka, Jin;Bedal, Lauren;Poupyrev, Ivan",7101665914;57190437864;55865348300;57224010915;57222334080;57197831478;57223999518;6603553340,60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Gestures are a promising candidate as an input modality for ambient computing where conventional input modalities such as touchscreens are not available. Existing works have focused on gesture recognition using image sensors. However, their cost, high battery consumption, and privacy concerns made cameras challenging as an always-on solution. This paper introduces an efficient gesture recognition technique using a miniaturized 60 GHz radar sensor. The technique recognizes four directional swipes and an omniswipe using a radar chip (6.5 5.0 mm) integrated into a mobile phone. We developed a convolutional neural network model efficient enough for battery powered and computationally constrained processors. Its model size and inference time is less than 1/5000 compared to an existing gesture recognition technique using radar. Our evaluations with large scale datasets consisting of 558,000 gesture samples and 3,920,000 negative samples demonstrated our algorithm's efficiency, robustness, and readiness to be deployed outside of research laboratories.",Deep learning | Gesture recognition | Mobile | Radar sensing,45,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85108913104,10.1145/3453483.3454036,,,RefinedC: Automating the foundational verification of C code with refined ownership types,cp,Conference Paper,Sammler M.,60031101;60016529;60002485,University of Cambridge;Radboud Universiteit;Max Planck Institute for Software Systems,Cambridge;Nijmegen;Saarbrucken,United Kingdom;Netherlands;Germany,6,"Sammler, Michael;Lepigre, Rodolphe;Krebbers, Robbert;Memarian, Kayvan;Dreyer, Derek;Garg, Deepak",57215357238;57188571155;37111004200;55001822400;7004212179;57215514499,60002485;60002485;60016529;60031101;60002485;60002485,2021-06-18,18 June 2021,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,158-174,"Given the central role that C continues to play in systems software, and the difficulty of writing safe and correct C code, it remains a grand challenge to develop effective formal methods for verifying C programs. In this paper, we propose a new approach to this problem: a type system we call RefinedC, which combines ownership types (for modular reasoning about shared state and concurrency) with refinement types (for encoding precise invariants on C data types and Hoare-style specifications for C functions). RefinedC is both automated (requiring minimal user intervention) and foundational (producing a proof of program correctness in Coq), while at the same time handling a range of low-level programming idioms such as pointer arithmetic. In particular, following the approach of RustBelt, the soundness of the RefinedC type system is justified semantically by interpretation into the Coq-based Iris framework for higher-order concurrent separation logic. However, the typing rules of RefinedC are also designed to be encodable in a new ""separation logic programming""language we call Lithium. By restricting to a carefully chosen (yet expressive) fragment of separation logic, Lithium supports predictable, automatic, goal-directed proof search without backtracking. We demonstrate the effectiveness of RefinedC on a range of representative examples of C code.",C programming language | Coq | Iris | ownership types | proof automation | refinement types | separation logic,36,1,repositoryvor,Green,H2020,683289,Google,PLDI Programming Languages
2-s2.0-85109214310,10.1145/3452021.3458323,,,Relative error streaming quantiles,cp,Conference Paper,Cormode G.,60076757;60023927;60022020;60016605;126534370,"Amazon.com, Inc.;Georgetown University;University of Warwick;Charles University;Pinecone","Seattle;Washington, D.C.;Coventry;Prague;San Mateo",United States;United States;United Kingdom;Czech Republic;United States,5,"Cormode, Graham;Karnin, Zohar;Liberty, Edo;Thaler, Justin;Veselý, Pavel",6602625379;24801924200;23393332700;35754221700;57730515300,60022020;60076757;126534370;60023927;60016605,2021-06-20,20 June 2021,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,96-108,"Approximating ranks, quantiles, and distributions over streaming data is a central task in data analysis and monitoring. Given a stream of n items from a data universe U equipped with a total order, the task is to compute a sketch (data structure) of size poly (log(n), 1ϵ). Given the sketch and a query item y ĝ U, one should be able to approximate its rank in the stream, i.e., the number of stream elements smaller than or equal to y. Most works to date focused on additive ϵ n error approximation, culminating in the KLL sketch that achieved optimal asymptotic behavior. This paper investigates multiplicative (1±ϵ)-error approximations to the rank. Practical motivation for multiplicative error stems from demands to understand the tails of distributions, and hence for sketches to be more accurate near extreme values. The most space-efficient algorithms due to prior work store either O(log(ϵ2 n)ϵ2) or O(log3(ϵ n)ϵ) universe items. This paper presents a randomized algorithm storing O(log1.5 (ϵ n)ϵ) items, which is within an O(log(ϵ n)) factor of optimal. The algorithm does not require prior knowledge of the stream length and is fully mergeable, rendering it suitable for parallel and distributed computing environments.",Quantiles | Streaming algorithms,14,1,repositoryam,Green,NSF,CCF-1845125,National Science Foundation,PODS Databases
2-s2.0-85106748634,10.1145/3411764.3445153,,,Resisting the medicalisation of menopause: Reclaiming the body through design,cp,Conference Paper,Felice M.C.,60002014,The Royal Institute of Technology (KTH),Stockholm,Sweden,3,"Felice, Marianela Ciolf;Sndergaard, Marie Louise Juul;Balaam, Madeline",57190406918;57223994720;36095639700,60002014;60002014;60002014,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"The menopause transition involves bodily-rooted, socially-shaped changes, often in a context of medicalisation that marginalises people based on their age and gender. With the goal of addressing this social justice matter with a participatory design approach, we started to cultivate partnerships with people going through menopause. This paper reports on interviews with 12 women and a design workshop with three. Our data analysis highlights their experiences from a holistic perspective that reclaims the primacy of the body and acknowledges the entanglement of the physical and the psychosocial. Participants' design concepts show how design can come close the body to make space for menopause experiences, recognising and transforming them. We discuss how HCI can actively engage with the body to promote appreciation for it during menopause, and call for design that accompanies people in resisting the medicalisation of menopause as an enactment of social justice in everyday life.",Feminist research | Menopause | Soma design | Women's health,8,1,repositoryvor,Green,VR,2017-05133,Vetenskapsrådet,CHI Human-Computer Interaction
2-s2.0-85119180186,10.1145/3459637.3482465,,,RxNet: Rx-refill Graph Neural Network for Overprescribing Detection,cp,Conference Paper,Zhang J.,60021143;60016247;60011754;60000305,West Virginia University;Brandeis University;Auburn University;Case Western Reserve University,Morgantown;Waltham;Auburn;Cleveland,United States;United States;United States;United States,7,"Zhang, Jianfei;Kuo, Ai Te;Zhao, Jianan;Wen, Qianlong;Winstanley, Erin;Zhang, Chuxu;Ye, Yanfang",55766517200;57340633000;57815547500;57271905500;23029236300;55879440900;57323577100,60000305;60011754;60000305;60000305;60021143;60016247;60000305,2021-10-26,26 October 2021,"International Conference on Information and Knowledge Management, Proceedings",,21101065646,,Conference Proceeding,,,,2537-2546,"Prescription (aka Rx) drugs can be easily overprescribed and lead to drug abuse or opioid overdose. Accordingly, a state-run prescription drug monitoring program (PDMP) in the United States has been developed to reduce Overprescribing. However, PDMP has limited capability in detecting patients' potential overprescribing behaviors, impairing its effectiveness in preventing drug abuse and overdose in patients. Despite a few machine-learning-based methods that have been proposed for detecting overprescribing, they usually ignore the patient prescribing behavior and their performances are not satisfying. In light of this, we propose a novel model RxNet for overprescribing detection in PDMP. RxNet builds a dynamic heterogeneous graph to model Rx refills that are essentially prescribing and dispensing (P&D) relationships among various Rx entries (e.g., patients) whose representations are encoded by graph neural network. In addition, to explore the dynamic Rx-refill behavior and medical condition variation of patients, an RxLSTM network is designed to update representations of patients. Based on the output of RxLSTM, a dosing-adaptive network is leveraged to extract and recalibrate dosing patterns and obtain the refined patient representations which are finally utilized for overprescribing detection. The extensive experimental results on a 1-year Ohio PDMP data demonstrate that RxNet consistently outperforms state-of-the-art methods in predicting patients at high risk of opioid overdose and drug abuse, with an average of 5.7% and 7.3% improvement on F1 score respectively.",drug abuse | graph neural network | lstm | opioid overdose | overprescribing detection | pdmp,7,1,publisherfree2read,Bronze,NSF,CNS-1814825,National Science Foundation,CIKM Knowledge Management
2-s2.0-85150609196,10.1007/s00778-023-00790-4,,,PANE: scalable and effective attributed network embedding,cp,Conference Paper,Yang R.,60104772;60017161;60014347;60008928;60005510,Hamad Bin Khalifa University;National University of Singapore;Hong Kong Baptist University;The Hong Kong Polytechnic University;Nanyang Technological University,Doha;Singapore City;Hong Kong;Hong Kong;Singapore City,Qatar;Singapore;Hong Kong;Hong Kong;Singapore,6,"Yang, Renchi;Shi, Jieming;Xiao, Xiaokui;Yang, Yin;Bhowmick, Sourav S.;Liu, Juncheng",57195597278;56271552000;14831850700;35148742800;7006796096;57218844649,60014347;60008928;60017161;60104772;60005510;60017161,2023-11-01,November 2023,VLDB Journal,10668888,13646,0949877X,Journal,32,6,,1237-1262,"Given a graph G where each node is associated with a set of attributes, attributed network embedding (ANE) maps each node v∈ G to a compact vector Xv, which can be used in downstream machine learning tasks. Ideally, Xv should capture node v’s affinity to each attribute, which considers not only v’s own attribute associations, but also those of its connected nodes along edges in G. It is challenging to obtain high-utility embeddings that enable accurate predictions; scaling effective ANE computation to massive graphs with millions of nodes pushes the difficulty of the problem to a whole new level. Existing solutions largely fail on such graphs, leading to prohibitive costs, low-quality embeddings, or both. This paper proposes PANE, an effective and scalable approach to ANE computation for massive graphs that achieves state-of-the-art result quality on multiple benchmark datasets, measured by the accuracy of three common prediction tasks: attribute inference, link prediction, and node classification. PANE obtains high scalability and effectiveness through three main algorithmic designs. First, it formulates the learning objective based on a novel random walk model for attributed networks. The resulting optimization task is still challenging on large graphs. Second, PANE includes a highly efficient solver for the above optimization problem, whose key module is a carefully designed initialization of the embeddings, which drastically reduces the number of iterations required to converge. Finally, PANE utilizes multi-core CPUs through non-trivial parallelization of the above solver, which achieves scalability while retaining the high quality of the resulting embeddings. The performance of PANE depends upon the number of attributes in the input network. To handle large networks with numerous attributes, we further extend PANE to PANE+ +, which employs an effective attribute clustering technique. Extensive experiments, comparing 10 existing approaches on 8 real datasets, demonstrate that PANE and PANE+ + consistently outperform all existing methods in terms of result quality, while being orders of magnitude faster.",Attributed graph | Matrix factorization | Network embedding | Random walk | Scalability,0,0,repositoryam,Green,QF,25201221,Qatar Foundation,VLDB Databases
2-s2.0-85106764865,10.1145/3411764.3445186,,,Screen Recognition: Creating Accessibility Metadata for Mobile Applications from Pixels,cp,Conference Paper,Zhang X.,60010449,Apple Computer,Cupertino,United States,3,"Zhang, Xiaoyi;Greef, Lilian De;White, Samuel",56074117900;55307501300;55452528100,60010449;60010449;60010449,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Many accessibility features available on mobile platforms require applications (apps) to provide complete and accurate metadata describing user interface (UI) components. Unfortunately, many apps do not provide sufficient metadata for accessibility features to work as expected. In this paper, we explore inferring accessibility metadata for mobile apps from their pixels, as the visual interfaces often best reflect an app's full functionality. We trained a robust, fast, memory-efficient, on-device model to detect UI elements using a dataset of 77,637 screens (from 4,068 iPhone apps) that we collected and annotated. To further improve UI detections and add semantic information, we introduced heuristics (e.g., UI grouping and ordering) and additional models (e.g., recognize UI content, state, interactivity). We built Screen Recognition to generate accessibility metadata to augment iOS VoiceOver. In a study with 9 screen reader users, we validated that our approach improves the accessibility of existing mobile apps, enabling even previously inaccessible apps to be used.",Accessibility enhancement | Mobile accessibility | Ui detection,57,1,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85116207842,10.1145/3468264.3468623,,,Semantic bug seeding: A learning-based approach for creating realistic bugs,cp,Conference Paper,Patra J.,60015815,Universität Stuttgart,Stuttgart,Germany,2,"Patra, Jibesh;Pradel, Michael",56287941200;25641744400,60015815;60015815,2021-08-20,20 August 2021,ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101060564,,Conference Proceeding,,,,906-918,"When working on techniques to address the wide-spread problem of software bugs, one often faces the need for a large number of realistic bugs in real-world programs. Such bugs can either help evaluate an approach, e.g., in form of a bug benchmark or a suite of program mutations, or even help build the technique, e.g., in learning-based bug detection. Because gathering a large number of real bugs is difficult, a common approach is to rely on automatically seeded bugs. Prior work seeds bugs based on syntactic transformation patterns, which often results in unrealistic bugs and typically cannot introduce new, application-specific code tokens. This paper presents SemSeed, a technique for automatically seeding bugs in a semantics-aware way. The key idea is to imitate how a given real-world bug would look like in other programs by semantically adapting the bug pattern to the local context. To reason about the semantics of pieces of code, our approach builds on learned token embeddings that encode the semantic similarities of identifiers and literals. Our evaluation with real-world JavaScript software shows that the approach effectively reproduces real bugs and clearly outperforms a semantics-unaware approach. The seeded bugs are useful as training data for learning-based bug detection, where they significantly improve the bug detection ability. Moreover, we show that SemSeed-created bugs complement existing mutation testing operators, and that our approach is efficient enough to seed hundreds of thousands of bugs within an hour.",bug injection | bugs | dataset | machine learning | token embeddings,35,0,,,H2020,851895,Horizon 2020 Framework Programme,FSE Software Engineering
2-s2.0-85113196416,10.1145/3452296.3472928,,,Seven years in the life of Hypergiants' off-nets,cp,Conference Paper,Gigis P.,60030162;60022148;60006288;60001524;126770020,Columbia University;University College London;Delft University of Technology;University of Crete;FORTH-ICS,New York;London;Delft;Rethymnon;,United States;United Kingdom;Netherlands;Greece;,8,"Gigis, Petros;Calder, Matt;Manassakis, Lefteris;Nomikos, George;Kotronis, Vasileios;Dimitropoulos, Xenofontas;Katz-Bassett, Ethan;Smaragdakis, Georgios",56543363900;55841781900;57200000932;50262899300;55508462500;8921022000;15127399400;8361129000,60022148;60030162;126770020;60030162;126770020;60001524;60030162;60006288,2021-08-09,9 August 2021,SIGCOMM 2021 - Proceedings of the ACM SIGCOMM 2021 Conference,,21101056503,,Conference Proceeding,,,,516-533,"Content Hypergiants deliver the vast majority of Internet traffic to end users. In recent years, some have invested heavily in deploying services and servers inside end-user networks. With several dozen Hypergiants and thousands of servers deployed inside networks, these off-net (meaning outside the Hypergiant networks) deployments change the structure of the Internet. Previous efforts to study them have relied on proprietary data or specialized per-Hypergiant measurement techniques that neither scale nor generalize, providing a limited view of content delivery on today's Internet. In this paper, we develop a generic and easy to implement methodology to measure the expansion of Hypergiants' off-nets. Our key observation is that Hypergiants increasingly encrypt their traffic to protect their customers' privacy. Thus, we can analyze publicly available Internet-wide scans of port 443 and retrieve TLS certificates to discover which IP addresses host Hypergiant certificates in order to infer the networks hosting off-nets for the corresponding Hypergiants. Our results show that the number of networks hosting Hypergiant off-nets has tripled from 2013 to 2021, reaching 4.5k networks. The largest Hypergiants dominate these deployments, with almost all of these networks hosting an off-net for at least one - and increasingly two or more - of Google, Netflix, Facebook, or Akamai. These four Hypergiants have off-nets within networks that provide access to a significant fraction of end user population.",content delivery networks | Hypergiants | server deployment | TLS,28,1,repositoryvor,Green,NSF,CNS-1836872,National Science Foundation,SIGCOMM Networking
2-s2.0-85116240019,10.1145/3468264.3468551,,,SmartCommit: A graph-based interactive assistant for activity-oriented commits,cp,Conference Paper,Shen B.,60092530;60027950;60014966,"Huawei Technologies Co., Ltd.;Carnegie Mellon University;Peking University",Shenzhen;Pittsburgh;Beijing,China;United States;China,7,"Shen, Bo;Zhang, Wei;Kästner, Christian;Zhao, Haiyan;Wei, Zhao;Liang, Guangtai;Jin, Zhi",56609617800;56760589600;35547901100;57219037610;57282309200;36661190100;8961795500,60014966;60014966;60014966;60027950;60027950;60092530;60014966,2021-08-20,20 August 2021,ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101060564,,Conference Proceeding,,,,379-390,"In collaborative software development, it is considered to be a best practice to submit code changes as a sequence of cohesive commits, each of which records the work result of a specific development activity, such as adding a new feature, bug fixing, and refactoring. However, rather than following this best practice, developers often submit a set of loosely-related changes serving for different development activities as a composite commit, due to the tedious manual work and lack of effective tool support to decompose such a tangled changeset. Composite commits often obfuscate the change history of software artifacts and bring challenges to efficient collaboration among developers. To encourage activity-oriented commits, we propose SmartCommit, a graph-partitioning-based interactive approach to tangled changeset decomposition that leverages not only the efficiency of algorithms but also the knowledge of developers. To evaluate the effectiveness of our approach, we (1) deployed SmartCommit in an international IT company, and analyzed usage data collected from a field study with 83 engineers over 9 months; and (2) conducted a controlled experiment on 3,000 synthetic composite commits from 10 diverse open-source projects. Results show that SmartCommit achieves a median accuracy between 71-84% when decomposing composite commits without developer involvement, and significantly helps developers follow the best practice of submitting activity-oriented commits with acceptable interaction effort and time cost in real collaborative software development.",changes decomposition | code commit | revision control system,9,0,,,NSFC,61620106007,National Natural Science Foundation of China,FSE Software Engineering
2-s2.0-85105320947,,,,Solving sparse linear systems faster than matrix multiplication,cp,Conference Paper,Peng R.,126155536,Georgia Tech,,,2,"Peng, Richard;Vempala, Santosh",36721875600;35515883000,126155536;126155536,2021-01-01,2021,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,,,,504-521,"Can linear systems be solved faster than matrix multiplication? While there has been remarkable progress for the special cases of graph structured linear systems, in the general setting, the bit complexity of solving an n × n linear system Ax = b is Õpnωq, where ω < 2.372864 is the matrix multiplication exponent. Improving on this has been an open problem even for sparse linear systems with polypnq condition number. In this paper, we present an algorithm that solves linear systems in sparse matrices asymptotically faster than matrix multiplication for any ω ¡ 2. This speedup holds for any input matrix A with opnω-1{ logpκpAqqq non-zeros, where κpAq is the condition number of A. For polypnq-conditioned matrices with Õpnq nonzeros, and the current value of ω, the bit complexity of our algorithm to solve to within any 1{polypnq error is Opn2.331645q. Our algorithm can be viewed as an efficient, randomized implementation of the block Krylov method via recursive low displacement rank factorizations. It is inspired by the algorithm of [Eberly et al. ISSAC '06 '07] for inverting matrices over finite fields. In our analysis of numerical stability, we develop matrix anti-concentration techniques to bound the smallest eigenvalue and the smallest gap in eigenvalues of semi-random matrices.",,18,0,,,NSF,1846218,National Science Foundation,SODA Theory
2-s2.0-85118210432,10.1145/3472749.3474739,,,SoundsRide: Affordance-Synchronized Music Mixing for In-Car Audio Augmented Reality,cp,Conference Paper,Kari M.,60116483;60025858;60014264,Dr. Ing. h.c. F. Porsche AG (Porsche AG);ETH Zürich;Universität Duisburg-Essen,Stuttgart;Zurich;Duisburg,Germany;Switzerland;Germany,6,"Kari, Mohamed;Grosse-Puppendahl, Tobias;Jagaciak, Alexander;Bethge, David;Schütte, Reinhard;Holz, Christian",57282835400;54402708200;57316458600;57214470906;55104634100;56070704000,60116483;60116483;60116483;60116483;60014264;60025858,2021-10-10,10 October 2021,UIST 2021 - Proceedings of the 34th Annual ACM Symposium on User Interface Software and Technology,,21101063802,,Conference Proceeding,,,,118-133,"Music is a central instrument in video gaming to attune a player's attention to the current atmosphere and increase their immersion in the game. We transfer the idea of scene-adaptive music to car drives and propose SoundsRide, an in-car audio augmented reality system that mixes music in real-time synchronized with sound affordances along the ride. After exploring the design space of affordance-synchronized music, we design SoundsRide to temporally and spatially align high-contrast events on the route, e. g., highway entrances or tunnel exits, with high-contrast events in music, e. g., song transitions or beat drops, for any recorded and annotated GPS trajectory by a three-step procedure. In real-time, SoundsRide 1) estimates temporal distances to events on the route, 2) fuses these novel estimates with previous estimates in a cost-aware music-mixing plan, and 3) if necessary, re-computes an updated mix to be propagated to the audio output. To minimize user-noticeable updates to the mix, SoundsRide fuses new distance information with a filtering procedure that chooses the best updating strategy given the last music-mixing plan, the novel distance estimations, and the system parameterization. We technically evaluate SoundsRide and conduct a user evaluation with 8 participants to gain insights into how users perceive SoundsRide in terms of mixing, affordances, and synchronicity. We find that SoundsRide can create captivating music experiences and positively as well as negatively influence subjectively perceived driving safety, depending on the mix and user.",auditory augmented reality | context-adaptive music | sound affordances,9,0,,,,undefined,,UIST User Interface
2-s2.0-85108908684,10.1145/3453483.3454104,,,Specification synthesis with constrained Horn clauses,cp,Conference Paper,Prabhu S.,60014097;60002092;114380526,Indian Institute of Science;Florida State University;TCS Research,Bengaluru;Tallahassee;Pune,India;United States;India,4,"Prabhu, Sumanth;Fedyukovich, Grigory;Madhukar, Kumar;D'Souza, Deepak",57209986489;55441320100;55844139300;35785565800,114380526;60002092;114380526;60014097,2021-06-18,18 June 2021,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,1203-1217,"The problem of synthesizing specifications of undefined procedures has a broad range of applications, but the usefulness of the generated specifications depends on their quality. In this paper, we propose a technique for finding maximal and non-vacuous specifications. Maximality allows for more choices for implementations of undefined procedures, and non-vacuity ensures that safety assertions are reachable. To handle programs with complex control flow, our technique discovers not only specifications but also inductive invariants. Our iterative algorithm lazily generalizes non-vacuous specifications in a counterexample-guided loop. The key component of our technique is an effective non-vacuous specification synthesis algorithm. We have implemented the approach in a tool called HornSpec, taking as input systems of constrained Horn clauses. We have experimentally demonstrated the tool's effectiveness, efficiency, and the quality of generated specifications on a range of benchmarks.",automated verification | inductive invariants | SMT solvers | specification synthesis,9,0,,,,undefined,,PLDI Programming Languages
2-s2.0-85127200509,10.1109/FOCS52979.2021.00083,,,Superpolynomial Lower Bounds Against Low-Depth Algebraic Circuits,cp,Conference Paper,Limaye N.,60029616;60018567;60008134,Aarhus Universitet;IT-Universitetet i København;CNRS Centre National de la Recherche Scientifique,Aarhus;Copenhagen;Paris,Denmark;Denmark;France,3,"Limaye, Nutan;Srinivasan, Srikanth;Tavenas, Sebastien",36861485500;55431293700;55876569100,60018567;60029616;60008134,2022-01-01,2022,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2022-February,,,804-814,"An Algebraic Circuit for a polynomial P in F}[x1,.., xn] is a computational model for constructing the polynomial p using only additions and multiplications. It is a syntactic model of computation, as opposed to the Boolean Circuit model, and hence lower bounds for this model are widely expected to be easier to prove than lower bounds for Boolean circuits. Despite this, we do not have superpolynomial lower bounds against general algebraic circuits of depth 3 (except over constant-sized finite fields) and depth 4 (over fields other than F}2), while constant-depth Boolean circuit lower bounds have been known since the early 1980s. In this paper, we prove the first super polynomial lower bounds against general algebraic circuits of all constant depths over all fields of characteristic 0 (or large). We also prove the first lower bounds against homogeneous algebraic circuits of constant depth over any field. Our approach is surprisingly simple. We first prove superpolynomial lower bounds for constant-depth Set-Multilinear circuits. While strong lower bounds were already known against such circuits, most previous lower bounds were of the form f(d) poly}(N), where d denotes the degree of the polynomial. In analogy with Parameterized complexity, we call this an FPT lower bound. We extend a well-known technique of Nisan and Wigderson (FOCS 1995) to prove non-FPT lower bounds against constant-depth set-multilinear circuits computing the Iterated Matrix Multiplication polynomial IMM}n, d (which computes a fixed entry of the product of d ntimes n matrices). More precisely, we prove that any set-multilinear circuit of depth Δ computing IMM}n, d must have size at least n d\exp(-O(Δ)}. This result holds over any field, as long as d=o(log n). We then show how to convert any constant-depth algebraic circuit of size s to a constant-depth set-multilinear circuit with a blow-up in size that is exponential in d but only polynomial in s over fields of characteristic 0. (For depths greater than 3, previous results of this form increased the depth of the resulting circuit to Ω(log s). This implies our constant-depth circuit lower bounds. Finally, we observe that our superpolynomial lower bound for constant-depth circuits implies the first deterministic sub-exponential time algorithm for solving the Polynomial Identity Testing (PIT) problem for all small depth circuits using the known connection between algebraic hardness and randomness.",Algebraic complexity theory | Computational complexity | Lower bounds | Small depth circuits,19,0,repositoryam,Green,AU,183459,Aarhus Universitet,FOCS Theory
2-s2.0-85127818917,10.1109/ICCV48922.2021.00986,,,Swin Transformer: Hierarchical Vision Transformer using Shifted Windows,cp,Conference Paper,Liu Z.,60098464;60025278;60019118;60018308,Microsoft Research Asia;Tsinghua University;University of Science and Technology of China;Xi'an Jiaotong University,Beijing;Beijing;Hefei;Xi'an,China;China;China;China,8,"Liu, Ze;Lin, Yutong;Cao, Yue;Hu, Han;Wei, Yixuan;Zhang, Zheng;Lin, Stephen;Guo, Baining",57219757233;57219691938;57189341730;55923489500;57223093262;55800177000;57219012284;56513051700,60098464-60019118;60098464-60018308;60098464;60098464;60098464-60025278;60098464;60098464;60098464,2021-01-01,2021,Proceedings of the IEEE International Conference on Computer Vision,15505499,110561,,Conference Proceeding,,,,9992-10002,"This paper presents a new vision Transformer, called Swin Transformer, that capably serves as a general-purpose backbone for computer vision. Challenges in adapting Transformer from language to vision arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text. To address these differences, we propose a hierarchical Transformer whose representation is computed with Shifted windows. The shifted windowing scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. This hierarchical architecture has the flexibility to model at various scales and has linear computational complexity with respect to image size. These qualities of Swin Transformer make it compatible with a broad range of vision tasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its performance surpasses the previous state-of-the-art by a large margin of +2.7 box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the potential of Transformer-based models as vision backbones. The hierarchical design and the shifted window approach also prove beneficial for all-MLP architectures. The code and models are publicly available at https://github.com/microsoft/Swin-Transformer.",,8239,0,repositoryam,Green,,undefined,,ICCV Computer Vision
2-s2.0-85125350822,10.1109/ICSE43902.2021.00103,,,Synthesizing object state transformers for dynamic software updates,cp,Conference Paper,Zhao Z.,60118459;60033100,"Alibaba Group, USA;Nanjing University",San Mateo;Nanjing,United States;China,5,"Zhao, Zelin;Jiang, Yanyan;Xu, Chang;Gu, Tianxiao;Ma, Xiaoxing",57193120359;56006054500;56870592600;55613697500;7404550517,60033100;60033100;60033100;60118459;60033100,2021-05-01,May 2021,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,1111-1122,"There is an increasing demand for evolving software systems to deliver continuous services of no restart. Dynamic software update (DSU) aims to achieve this goal by patching the system state on the fly but is currently hindered from practice due to non-trivial cross-version object state transformations. This paper revisits this problem through an in-depth empirical study of over 190 class changes from Tomcat 8. The study produced an important finding that most non-trivial object state transformers can be constructed by reassembling existing old/new version code snippets. This paper presents a domain-specific language and an efficient algorithm for synthesizing non-trivial object transformers over code reuse. We experimentally evaluated our tool implementation PASTA with real-world software systems, reporting PASTA's effectiveness in succeeding in 7.5X non-trivial object transformation tasks compared with the best existing DSU techniques.",Dynamic software update | Object transformation | Program synthesis | Software maintenance and evolution,5,0,,,,undefined,,ICSE Software Engineering
2-s2.0-85118201484,10.1145/3472749.3474819,,,Ten Million Users and Ten Years Later: Python Tutor's Design Guidelines for Building Scalable and Sustainable Research Software in Academia,cp,Conference Paper,Guo P.,60121539,Department of Cognitive Science,La Jolla,United States,1,"Guo, Philip",16238467300,60121539,2021-10-10,10 October 2021,UIST 2021 - Proceedings of the 34th Annual ACM Symposium on User Interface Software and Technology,,21101063802,,Conference Proceeding,,,,1235-1251,"Research software is often built as prototypes that never get widespread usage and are left unmaintained after a few papers get published. To counteract this trend, we propose a method for building research software with scale and sustainability in mind so that it can organically grow a large userbase and enable longer-term research. To illustrate this method, we present the design and implementation of Python Tutor (pythontutor.com), a code visualization tool that is, to our knowledge, one of the most widely-used pieces of research software developed within a university lab. Over the past decade, it has been used by over ten million people in over 180 countries. It has also contributed to 55 publications from 35 research groups in 13 countries. We distilled lessons from working on Python Tutor into three sets of design guidelines: 1) user experience design for scale and sustainability, 2) software architecture design for long-term sustainability, and 3) designing a sustainable software development workflow within academia. These guidelines can enable a student to create long-lasting software that reaches many users and facilitates research from many independent groups.",code visualization | Python Tutor | research software | sustainability,15,1,publisherfree2read,Bronze,NSF,IIS-1845900,National Science Foundation,UIST User Interface
2-s2.0-85107905009,10.1145/3406325.3451052,,,The Complexity of Gradient Descent: CLS = PPAD PLS,cp,Conference Paper,Fearnley J.,60020661,University of Liverpool,Liverpool,United Kingdom,4,"Fearnley, John;Goldberg, Paul W.;Hollender, Alexandros;Savani, Rahul",35737065500;7102142293;57209980030;8367551600,60020661;60020661;60020661;60020661,2021-06-15,15 June 2021,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,46-59,"We study search problems that can be solved by performing Gradient Descent on a bounded convex polytopal domain and show that this class is equal to the intersection of two well-known classes: PPAD and PLS. As our main underlying technical contribution, we show that computing a Karush-Kuhn-Tucker (KKT) point of a continuously differentiable function over the domain [0,1]2 is PPAD PLS-complete. This is the first natural problem to be shown complete for this class. Our results also imply that the class CLS (Continuous Local Search) - which was defined by Daskalakis and Papadimitriou as a more ""natural""counterpart to PPAD PLS and contains many interesting problems - is itself equal to PPAD PLS.",computational complexity | continuous optimization | TFNP,25,0,repositoryam,Green,EPSRC,1892947,Engineering and Physical Sciences Research Council,STOC Theory
2-s2.0-85106735050,10.1145/3411764.3445363,,,The ethics of multiplayer game design and community management industry perspectives and challenges,cp,Conference Paper,Sparrow L.A.,60118847,School of Computing and Information Systems,Melbourne,Australia,3,"Sparrow, Lucy A.;Gibbs, Martin;Arnold, Michael",57214363425;10040667200;7402910887,60118847;60118847;60118847,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Game industry professionals are frequently implementing new methods of addressing ethical issues related to in-game toxicity and disruptive player behaviours associated with online multiplayer games. However, academic work on these behaviours tends to focus on the perspectives of players rather than the industry. To fully understand the ethics of multiplayer games and promote ethical design, we must examine the challenges facing those designing multiplayer games through an ethical lens. To this end, this paper presents a refexive thematic analysis of 21 in-depth interviews with games industry professionals on their ethical views and experiences in game design and community management. We identify a number of tensions involved in making ethics-related design decisions for divided player communities alongside current game design practices that are concerned with functionality, revenue and entertainment. We then put forward a set of design considerations for integrating ethics into multiplayer game design.",Community management | Ethics | Game design | Multiplayer games | Toxicity,13,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85106690246,10.1145/3411764.3445261,,,The landscape and gaps in open source fairness toolkits,cp,Conference Paper,Lee M.S.A.,60031101,University of Cambridge,Cambridge,United Kingdom,2,"Lee, Michelle Seng Ah;Singh, Jatinder",57215871652;56543897000,60031101;60031101,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"With the surge in literature focusing on the assessment and mitigation of unfair outcomes in algorithms, several open source fairness toolkits' recently emerged to make such methods widely accessible. However, little studied are the diferences in approach and capabilities of existing fairness toolkits, and their ft-for-purpose in commercial contexts. Towards this, this paper identifes the gaps between the existing open source fairness toolkit capabilities and the industry practitioners' needs. Specifcally, we undertake a comparative assessment of the strengths and weaknesses of six prominent open source fairness toolkits, and investigate the current landscape and gaps in fairness toolkits through an exploratory focus group, a semi-structured interview, and an anonymous survey of data science/machine learning (ML) practitioners. We identify several gaps between the toolkits' capabilities and practitioner needs, highlighting areas requiring attention and future directions towards tooling that better support fairness in practice'.",,51,1,publisherfree2read,Bronze,EPSRC,undefined,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-85106712093,10.1145/3411764.3445715,,,The show must go on: A conceptual model of conducting synchronous participatory design with children online,cp,Conference Paper,Lee K.J.,60015481,University of Washington,Seattle,United States,4,"Lee, Kung Jin;Roldan, Wendy;Zhu, Tian Qi;Zhu, Harkiran Kaur",57190164996;57203310201;57224003055;57224010277,60015481;60015481;60015481;60015481,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Co-designing with children in an online environment is increasingly important due to external factors, such as the COVID-19 pandemic, and the diversifcation and inclusion of youth participants. Many prior studies about co-design with youth focus on co-located or asynchronous online sessions. However, conducting synchronous online co-design sessions adds layers of complexity and uncertainty to collaboration. This paper introduces a model explicating factors to consider when co-designing with children synchronously in an online space. We examined ten consecutive intergenerational participatory design sessions online where children (ages 7-11) and adults designed new technologies. Along with highlighting unexpected moments and interactions, we use theories of improvisation to guide our understanding of dynamic situations that are out of the control of researchers. This work contributes to improving theoretical understanding of improvisation as a method of inquiry for co-designing with youth, and ofers practical suggestions for suitable online co-design techniques and implementation.",Children | Design methods | Improvisation | Participatory design,35,0,,,NSF,undefined,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85108003603,10.1145/3442381.3450097,,,Towards facilitating empathic conversations in online mental health support: A reinforcement learning approach,cp,Conference Paper,Sharma A.,60012708;124242617,Stanford University;University of Washington,Stanford;Allen,United States;United States,5,"Sharma, Ashish;Lin, Inna W.;Miner, Adam S.;Atkins, David C.;Althoff, Tim",57209270312;57219833713;56996997300;57216076972;55430316500,124242617;124242617;60012708;124242617;124242617,2021-04-19,19 April 2021,"The Web Conference 2021 - Proceedings of the World Wide Web Conference, WWW 2021",,21101048500,,Conference Proceeding,,,,194-205,"Online peer-to-peer support platforms enable conversations between millions of people who seek and provide mental health support. If successful, web-based mental health conversations could improve access to treatment and reduce the global disease burden. Psychologists have repeatedly demonstrated that empathy, the ability to understand and feel the emotions and experiences of others, is a key component leading to positive outcomes in supportive conversations. However, recent studies have shown that highly empathic conversations are rare in online mental health platforms. In this paper, we work towards improving empathy in online mental health support conversations. We introduce a new task of empathic rewriting which aims to transform low-empathy conversational posts to higher empathy. Learning such transformations is challenging and requires a deep understanding of empathy while maintaining conversation quality through text fluency and specificity to the conversational context. Here we propose Partner, a deep reinforcement learning (RL) agent that learns to make sentence-level edits to posts in order to increase the expressed level of empathy while maintaining conversation quality. Our RL agent leverages a policy network, based on a transformer language model adapted from GPT-2, which performs the dual task of generating candidate empathic sentences and adding those sentences at appropriate positions. During training, we reward transformations that increase empathy in posts while maintaining text fluency, context specificity, and diversity. Through a combination of automatic and human evaluation, we demonstrate that Partner successfully generates more empathic, specific, and diverse responses and outperforms NLP methods from related tasks such as style transfer and empathic dialogue generation. This work has direct implications for facilitating empathic conversations on web-based platforms.",,70,0,repositoryam,Green,NSF,IIS-1901386,National Science Foundation,WWW World Wide Web
2-s2.0-85104575743,10.1109/ICSE43902.2021.00040,,,Traceability transformed: Generating more accurate links with pre-trained BERT models,cp,Conference Paper,Lin J.,60021508,University of Notre Dame,Notre Dame,United States,5,"Lin, Jinfeng;Liu, Yalin;Zeng, Qingkai;Jiang, Meng;Cleland-Huang, Jane",57200513163;57200512589;57203392375;36179647500;6506741859,60021508;60021508;60021508;60021508;60021508,2021-05-01,May 2021,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,324-335,"Software traceability establishes and leverages associations between diverse development artifacts. Researchers have proposed the use of deep learning trace models to link natural language artifacts, such as requirements and issue descriptions, to source code; however, their effectiveness has been restricted by availability of labeled data and efficiency at runtime. In this study, we propose a novel framework called Trace BERT (T-BERT) to generate trace links between source code and natural language artifacts. To address data sparsity, we leverage a three-step training strategy to enable trace models to transfer knowledge from a closely related Software Engineering challenge, which has a rich dataset, to produce trace links with much higher accuracy than has previously been achieved. We then apply the T-BERT framework to recover links between issues and commits in Open Source Projects. We comparatively evaluated accuracy and efficiency of three BERT architectures. Results show that a Single-BERT architecture generated the most accurate links, while a Siamese-BERT architecture produced comparable results with significantly less execution time. Furthermore, by learning and transferring knowledge, all three models in the framework outperform classical IR trace models. On the three evaluated real-word OSS projects, the best T-BERT stably outperformed the VSM model with average improvements of 60.31% measured using Mean Average Precision (MAP). RNN severely underperformed on these projects due to insufficient training data, while T-BERT overcame this problem by using pretrained language models and transfer learning.",Deep learning | Langauge model | Software traceability,56,0,repositoryam,Green,RSF,SHF:1901059,Russian Science Foundation,ICSE Software Engineering
2-s2.0-85106720105,10.1145/3411764.3445334,,,U!scientist: Designing for people-powered research in museums,cp,Conference Paper,Obiorah M.G.S.,60102018;60007363,"TERC, Massachusetts;Northwestern University",Cambridge;Evanston,United States;United States,2,"Obiorah, Mmachi God Sglory;Hammerman, James K.L.",57188625235;35769385300,60007363;60102018,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Scientists have long sought to engage public audiences in research through citizen science projects such as biological surveys or distributed data collection. Recent online platforms have expanded the scope of what people-powered research can mean. Science museums are unique cultural institutions that translate scientifc discovery for public audiences, while conducting research of their own. This makes museums compelling sites for engaging audiences directly in scientifc research, but there are associated challenges as well. This project engages public audiences in contributing to real research as part of their visit to a museum. We present the design and evaluation of U!Scientist, an interactive multi-person tabletop exhibit based on the online Zooniverse project, Galaxy Zoo. We installed U!Scientist in a planetarium and collected video, computer logs, naturalistic observations, and surveys with visitors. Our fndings demonstrate the potential of exhibits to engage new audiences in collaborative scientifc discussions as part of people-powered research.",Citizen science | Interactive tabletop displays | Museums,3,1,publisherfree2read,Bronze,NSF,1713425,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85161343714,,,,Unbiased Gradient Estimation in Unrolled Computation Graphs with Persistent Evolution Strategies,cp,Conference Paper,Vicol P.,60016849;60006191,University of Toronto;Google LLC,Toronto;Mountain View,Canada;United States,3,"Vicol, Paul;Metz, Luke;Sohl-Dickstein, Jascha",56657961500;57210576440;6507007592,60016849-60006191;60006191;60006191,2021-01-01,2021,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,139,,,10553-10563,"Unrolled computation graphs arise in many scenarios, including training RNNs, tuning hyperparameters through unrolled optimization, and training learned optimizers. Current approaches to optimizing parameters in such computation graphs suffer from high variance gradients, bias, slow updates, or large memory usage. We introduce a method called Persistent Evolution Strategies (PES), which divides the computation graph into a series of truncated unrolls, and performs an evolution strategies-based update step after each unroll. PES eliminates bias from these truncations by accumulating correction terms over the entire sequence of unrolls. PES allows for rapid parameter updates, has low memory usage, is unbiased, and has reasonable variance characteristics. We experimentally demonstrate the advantages of PES compared to several other methods for gradient estimation on synthetic tasks, and show its applicability to training learned optimizers and tuning hyperparameters.",,17,0,,,,undefined,,ICML Machine Learning
2-s2.0-85105205140,10.1145/3411764.3445743,,,Understanding data accessibility for people with intellectual and developmental disabilities,cp,Conference Paper,Wu K.,60000221,University of Colorado Boulder,Boulder,United States,3,"Wu, Keke;Petersen, Emma;Ahmad, Tahmina",57211998224;57223998592;57224005213,60000221;60000221;60000221,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Using visualization requires people to read abstract visual imagery, estimate statistics, and retain information. However, people with Intellectual and Developmental Disabilities (IDD) often process information diferently, which may complicate connecting abstract visual information to real-world quantities. This population has traditionally been excluded from visualization design, and often has limited access to data related to their well being. We explore how visualizations may better serve this population. We identify three visualization design elements that may improve data accessibility: chart type, chart embellishment, and data continuity. We evaluate these elements with populations both with and without IDD, measuring accuracy and efciency in a web-based online experiment with time series and proportion data. Our study identifes performance patterns and subjective preferences for people with IDD when reading common visualizations. These fndings suggest possible solutions that may break the cognitive barriers caused by conventional design guidelines.",Graphical perception and cognition | Human-subjects quantitative studies,26,0,,,,90DNPA0003-01-00,,CHI Human-Computer Interaction
2-s2.0-85108906518,10.1145/3453483.3454035,,,Unleashing the hidden power of compiler optimization on binary code difference: An empirical study,cp,Conference Paper,Ren X.,60019578;60003467,Monash University;The University of Texas at Arlington,Clayton;Arlington,Australia;United States,5,"Ren, Xiaolei;Ho, Michael;Ming, Jiang;Lei, Yu;Li, Li",57223769393;57223722031;50861739500;57191863726;56438149900,60003467;60003467;60003467;60003467;60019578,2021-06-18,18 June 2021,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,142-157,"Hunting binary code difference without source code (i.e., binary diffing) has compelling applications in software security. Due to the high variability of binary code, existing solutions have been driven towards measuring semantic similarities from syntactically different code. Since compiler optimization is the most common source contributing to binary code differences in syntax, testing the resilience against the changes caused by different compiler optimization settings has become a standard evaluation step for most binary diffing approaches. For example, 47 top-venue papers in the last 12 years compared different program versions compiled by default optimization levels (e.g.,-Ox in GCC and LLVM). Although many of them claim they are immune to compiler transformations, it is yet unclear about their resistance to non-default optimization settings. Especially, we have observed that adversaries explored non-default compiler settings to amplify malware differences. This paper takes the first step to systematically studying the effectiveness of compiler optimization on binary code differences. We tailor search-based iterative compilation for the auto-tuning of binary code differences. We develop BinTuner to search near-optimal optimization sequences that can maximize the amount of binary code differences. We run BinTuner with GCC 10.2 and LLVM 11.0 on SPEC benchmarks (CPU2006 & CPU2017), Coreutils, and OpenSSL. Our experiments show that at the cost of 279 to 1,881 compilation iterations, BinTuner can find custom optimization sequences that are substantially better than the general-Ox settings. BinTuner's outputs seriously undermine prominent binary diffing tools' comparisons. In addition, the detection rate of the IoT malware variants tuned by BinTuner falls by more than 50%. Our findings paint a cautionary tale for security analysts that attackers have a new way to mutate malware code cost-effectively, and the research community needs to step back to reassess optimization-resistance evaluations.",Binary Code Difference | Compiler Optimization,27,1,repositoryam,Green,CISE,CNS-1850434,Directorate for Computer and Information Science and Engineering,PLDI Programming Languages
2-s2.0-85111930524,10.1109/INFOCOM42981.2021.9488826,,,Uplink multi-user beamforming on single RF chain mmWave WLANs,cp,Conference Paper,Dasala K.P.,60028628;60005286,Northeastern University;Rice University,Boston;Houston,United States;United States,3,"Dasala, Keerthi Priya;Jornet, Josep M.;Knightly, Edward W.",57218796206;26029396500;7004150113,60005286;60028628;60005286,2021-05-10,10 May 2021,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2021-May,,9488826,,"Today's mmWave WLANs can realize simultaneous multi-user multi-stream transmission solely on the downlink. In this paper, we present Uplink Multi-user Beamforming on single RF chain AP (UMBRA), a novel framework for supporting multi-stream multi-user uplink transmissions via a single RF chain. We design multi-user overlayed constellations and multi-user receiver mechanisms to enable concurrent time-triggered uplink multi-user transmissions received on a single RF chain AP. We devise exemplary beam selection policies to jointly adapt beams at users and the AP for targeting aggregate rate maximization without increasing training requirements compared to single-user systems. We implement the key components of UMBRA using a programmable WLAN testbed using software-defined radios and commercial 60-GHz transceivers and collect over-the-air measurements using phased-array antennas and horn antennas with varying beamwidth. We find that in comparison to single-user transmissions, UMBRA achieves more than 1.45× improvement in aggregate rate regardless of the choice of the user group, geometric separation, and receiver beamwidth.",,4,0,,,NSF,CNS-1801857,National Science Foundation,INFOCOM Networking
2-s2.0-85119092890,10.1145/3477132.3483540,,,Using Lightweight Formal Methods to Validate a Key-Value Storage Node in Amazon S3,cp,Conference Paper,Bornholt J.,60076757;60025858;60013372;124242671,"Amazon.com, Inc.;ETH Zürich;The University of Texas at Austin;University of Washington",Seattle;Zurich;Austin;Bethesda,United States;Switzerland;United States;United States,12,"Bornholt, James;Joshi, Rajeev;Astrauskas, Vytautas;Cully, Brendan;Kragl, Bernhard;Markle, Seth;Sauri, Kyle;Schleit, Drew;Slatton, Grant;Tasiran, Serdar;Van Geffen, Jacob;Warfield, Andrew",56103636000;57196712665;57220771509;24337289000;56035821500;57338991100;57338967600;57338944200;57339058100;6602528629;57195074175;6601955007,60013372;60076757;60025858;60076757;60076757;60076757;60076757;60076757;60076757;60076757;124242671;60076757,2021-10-26,26 October 2021,SOSP 2021 - Proceedings of the 28th ACM Symposium on Operating Systems Principles,,21101065501,,Conference Proceeding,,,,836-850,"This paper reports our experience applying lightweight formal methods to validate the correctness of ShardStore, a new key-value storage node implementation for the Amazon S3 cloud object storage service. By ""lightweight formal methods""we mean a pragmatic approach to verifying the correctness of a production storage node that is under ongoing feature development by a full-time engineering team. We do not aim to achieve full formal verification, but instead emphasize automation, usability, and the ability to continually ensure correctness as both software and its specification evolve over time. Our approach decomposes correctness into independent properties, each checked by the most appropriate tool, and develops executable reference models as specifications to be checked against the implementation. Our work has prevented 16 issues from reaching production, including subtle crash consistency and concurrency problems, and has been extended by non-formal-methods experts to check new features and properties as ShardStore has evolved.",cloud storage | lightweight formal methods,26,1,publisherfree2read,Bronze,,undefined,,SOSP Operating Systems
2-s2.0-85116255701,10.1145/3468264.3468554,,,Vet: Identifying and avoiding UI exploration tarpits,cp,Conference Paper,Wang W.,60014966;60009415;60000745,Peking University;The University of Texas at Dallas;University of Illinois Urbana-Champaign,Beijing;Richardson;Urbana,China;United States;United States,4,"Wang, Wenyu;Yang, Wei;Xu, Tianyin;Xie, Tao",57196000346;55607069500;24825809900;55574210063,60000745;60009415;60000745;60014966,2021-08-20,20 August 2021,ESEC/FSE 2021 - Proceedings of the 29th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101060564,,Conference Proceeding,,,,83-94,"Despite over a decade of research, it is still challenging for mobile UI testing tools to achieve satisfactory effectiveness, especially on industrial apps with rich features and large code bases. Our experiences suggest that existing mobile UI testing tools are prone to exploration tarpits, where the tools get stuck with a small fraction of app functionalities for an extensive amount of time. For example, a tool logs out an app at early stages without being able to log back in, and since then the tool gets stuck with exploring the app's pre-login functionalities (i.e., exploration tarpits) instead of its main functionalities. While tool vendors/users can manually hardcode rules for the tools to avoid specific exploration tarpits, these rules can hardly generalize, being fragile in face of diverted testing environments, fast app iterations, and the demand of batch testing product lines. To identify and resolve exploration tarpits, we propose VET, a general approach including a supporting system for the given specific Android UI testing tool on the given specific app under test (AUT). VET runs the tool on the AUT for some time and records UI traces, based on which VET identifies exploration tarpits by recognizing their patterns in the UI traces. VET then pinpoints the actions (e.g., clicking logout) or the screens that lead to or exhibit exploration tarpits. In subsequent test runs, VET guides the testing tool to prevent or recover from exploration tarpits. From our evaluation with state-of-the-art Android UI testing tools on popular industrial apps, VET identifies exploration tarpits that cost up to 98.6% testing time budget. These exploration tarpits reveal not only limitations in UI exploration strategies but also defects in tool implementations. VET automatically addresses the identified exploration tarpits, enabling each evaluated tool to achieve higher code coverage and improve crash-triggering capabilities.",Android testing | trace analysis | UI testing,12,0,repositoryam,Green,CISE,SHF-1816615,Microsoft,FSE Software Engineering
2-s2.0-85112103312,,,,Vocabulary learning via optimal transport for neural machine translation,cp,Conference Paper,Xu J.,60159665;60033100;60032179,ByteDance Ltd.;Nanjing University;University of Wisconsin-Madison,Beijing;Nanjing;Madison,China;China;United States,5,"Xu, Jingjing;Zhou, Hao;Gan, Chun;Zheng, Zaixiang;Li, Lei",57193795783;56898234800;57219689824;57205492823;56094074700,60159665;60159665;60159665-60032179;60159665-60033100;60159665,2021-01-01,2021,"ACL-IJCNLP 2021 - 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference",,21101065311,,Conference Proceeding,,,,7361-7373,"The choice of token vocabulary affects the performance of machine translation. This paper aims to figure out what is a good vocabulary and whether one can find the optimal vocabulary without trial training. To answer these questions, we first provide an alternative understanding of the role of vocabulary from the perspective of information theory. Motivated by this, we formulate the quest of vocabularization - finding the best token dictionary with a proper size - as an optimal transport (OT) problem. We propose VOLT, a simple and efficient solution without trial training. Empirical results show that VOLT outperforms widely-used vocabularies in diverse scenarios, including WMT-14 English-German and TED's 52 translation directions. For example, VOLT achieves 70% vocabulary size reduction and 0.5 BLEU gain on English-German translation. Also, compared to BPE-search, VOLT reduces the search time from 384 GPU hours to 30 GPU hours on English-German translation. Codes are available at https://github.com/Jingjing-NLP/VOLT.",,37,0,,,,undefined,,ACL Natural Language Processing
2-s2.0-85106679506,10.1145/3411764.3445198,,,What do hackathons do? understanding participation in hackathons through program theory analysis,cp,Conference Paper,Falk J.,60029616,Aarhus Universitet,Aarhus,Denmark,3,"Falk, Jeanette;Kannabiran, Gopinaath;Hansen, Nicolai Brodersen",57224006086;36675268900;55537536000,60029616;60029616;60029616,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Hackathons are increasingly embraced across diverse sectors as a way of democratizing the design of technology. Several attempts have been made to redefne the format and desired end goal of hackathons in recent years thereby warranting closer methodological scrutiny. In this paper, we apply program theory to analyze the processes and efects of 16 hackathon case studies through published research literature. Building upon existing research on hackathons, our work ofers a critical perspective examining the methodological validity of hackathons and exemplifes how specifc processes for organizing hackathons are modifed for diferent purposes. Our main contribution is a program theory analysis of hackathon formats that provides an exploration and juxtaposition of 16 case studies in terms of causal relations between the input, process and the efects of hackathons. Our cataloguing of examples can serve as an inspirational planning resource for future organizers of hackathons.",Hackathons | Participatory design | Program theory | Research methods,12,0,repositoryvor,Green,H2020,740548,Horizon 2020 Framework Programme,CHI Human-Computer Interaction
2-s2.0-85110497606,10.1109/ICSE43902.2021.00093,,,What makes a great maintainer of open source projects?,cp,Conference Paper,Dias E.,60031482;60027294;60014992;115535540;100623261,Universidade Federal de Pernambuco;Universidade Tecnológica Federal do Paraná;Universidade Federal de São Paulo;UFPA;NAU,Recife;Curitiba;Sao Paulo;Para;Flagstaff,Brazil;Brazil;Brazil;Brazil;United States,6,"Dias, Edson;Meirelles, Paulo;Castor, Fernando;Steinmacher, Igor;Wiese, Igor;Pinto, Gustavo",57271791800;54975098500;54945662000;36609225300;6603482090;54941690500,115535540;60014992;60031482;60027294-100623261;60027294;115535540,2021-05-01,May 2021,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,982-994,"Although Open Source Software (OSS) maintainers devote a significant proportion of their work to coding tasks, great maintainers must excel in many other activities beyond coding. Maintainers should care about fostering a community, helping new members to find their place, while also saying 'no' to patches that although are well-coded and well-tested, do not contribute to the goal of the project. To perform all these activities masterfully, maintainers should exercise attributes that software engineers (working on closed source projects) do not always need to master. This paper aims to uncover, relate, and prioritize the unique attributes that great OSS maintainers might have. To achieve this goal, we conducted 33 semi-structured interviews with well-experienced maintainers that are the gatekeepers of notable projects such as the Linux Kernel, the Debian operating system, and the GitLab coding platform. After we analyzed the interviews and curated a list of attributes, we created a conceptual framework to explain how these attributes are connected. We then conducted a rating survey with 90 OSS contributors. We noted that 'technical excellence' and 'communication' are the most recurring attributes. When grouped, these attributes fit into four broad categories: management, social, technical, and personality. While we noted that 'sustain a long term vision of the project' and being 'extremely careful' seem to form the basis of our framework, we noted through our survey that the communication attribute was perceived as the most essential one.",Great attributes | Open source maintainers | Open source software,16,0,,,NSF,APQ-0839-1.03/14,National Science Foundation,ICSE Software Engineering
2-s2.0-85117580669,10.1109/ICSE43902.2021.00054,,,Why don't developers detect improper input validation? '; DROP TABLE Papers; -,cp,Conference Paper,Braz L.,60012614,Universität Zürich,Zurich,Switzerland,4,"Braz, Larissa;Fregnan, Enrico;Calikli, Gul;Bacchelli, Alberto",57192095353;57204930710;35298437800;25924697100,60012614;60012614;60012614;60012614,2021-05-01,May 2021,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,499-511,"Improper Input Validation (IIV) is a software vulnerability that occurs when a system does not safely handle input data. Even though IIV is easy to detect and fix, it still commonly happens in practice. In this paper, we study to what extent developers can detect IIV and investigate underlying reasons. This knowledge is essential to better understand how to support developers in creating secure software systems. We conduct an online experiment with 146 participants, of which 105 report at least three years of professional software development experience. Our results show that the existence of a visible attack scenario facilitates the detection of IIV vulnerabilities and that a significant portion of developers who did not find the vulnerability initially could identify it when warned about its existence. Yet, a total of 60 participants could not detect the vulnerability even after the warning. Other factors, such as the frequency with which the participants perform code reviews, influence the detection of IIV. Preprint: https://arxiv.org/abs/2102.06251. Data and materials: https://doi.org/10.5281/zenodo.3996696.",Code review | Empirical software engineering | Improper Input validation | Software vulnerabilities | Sql injection,19,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-85106703000,10.1145/3411764.3445349,,,Xrgonomics: Facilitating the creation of ergonomic 3d interfaces,cp,Conference Paper,Belo J.,60029616,Aarhus Universitet,Aarhus,Denmark,2,"Belo, Joao;Feit, Anna Maria",57215270451;56278405900,60029616;60029616,2021-05-06,6 May 2021,Conference on Human Factors in Computing Systems - Proceedings,,21101046720,,Conference Proceeding,,,,,"Arm discomfort is a common issue in Cross Reality applications involving prolonged mid-air interaction. Solving this problem is difcult because of the lack of tools and guidelines for 3D user interface design. Therefore, we propose a method to make existing ergonomic metrics available to creators during design by estimating the interaction cost at each reachable position in the user's environment. We present XRgonomics, a toolkit to visualize the interaction cost and make it available at runtime, allowing creators to identify UI positions that optimize users' comfort. Two scenar ios show how the toolkit can support 3D UI design and dynamic adaptation of UIs based on spatial constraints. We present results from a walkthrough demonstration, which highlight the potential of XRgonomics to make ergonomics metrics accessible during the design and development of 3D UIs. Finally, we discuss how the toolkit may address design goals beyond ergonomics.",3d user interfaces | Adaptive user interfaces | Computational interaction | Ergonomics | Mid-air interaction | Optimization | Toolkit,20,1,repositoryvor,Green,H2020,6151-00006B,Horizon 2020 Framework Programme,CHI Human-Computer Interaction
2-s2.0-85111919976,10.1109/INFOCOM42981.2021.9488684,,,MCore: Achieving sub-millisecond scheduling for 5G MU-MIMO systems,cp,Conference Paper,Chen Y.,60027090,Virginia Polytechnic Institute and State University,Blacksburg,United States,4,"Chen, Yongce;Wu, Yubo;Hou, Y. Thomas;Lou, Wenjing",57196353559;57226550276;7402198673;7006030576,60027090;60027090;60027090;60027090,2021-05-10,10 May 2021,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2021-May,,9488684,,"MU-MIMO technology enables a base station (BS) to transmit signals to multiple users simultaneously on the same frequency band. It is a key technology for 5G NR to increase the data rate. In 5G specifications, an MU-MIMO scheduler needs to determine RBs allocation and MCS assignment to each user for each TTI. Under MU-MIMO, multiple users may be coscheduled on the same RB and each user may have multiple data streams simultaneously. In addition, the scheduler must meet the stringent real-time requirement (∼1 ms) during decision making to be useful. This paper presents mCore, a novel 5G scheduler that can achieve ∼1 ms scheduling with joint optimization of RB allocation and MCS assignment to MU-MIMO users. The key idea of mCore is to perform a multi-phase optimization, leveraging large-scale parallel computation. In each phase, mCore either decomposes the optimization problem into a number of independent sub-problems, or reduces the search space into a smaller but most promising subspace, or both. We implement mCore on a commercial-off-the-shelf GPU. Experimental results show that mCore can offer the best scheduling performance for up to 100 RBs, 100 users, 29 MCS levels and 4 × 12 antennas when compared to other state-of-the-art algorithms. It is also the only algorithm that can find its scheduling solution in ∼1 ms.",,12,0,,,NSF,CNS-1617634,National Science Foundation,INFOCOM Networking
2-s2.0-85135399686,10.1145/3447993.3483263,,,MSAIL: Milligram-scale multi-modal sensor platform for monarch butterfly migration tracking,cp,Conference Paper,Lee I.,60026306;60025778;60023004;60015543,"University of Nebraska–Lincoln;University of Michigan, Ann Arbor;University of Delaware;University of Pittsburgh",Lincoln;Ann Arbor;Newark;Pittsburgh,United States;United States;United States;United States,18,"Lee, Inhee;Hsiao, Roger;Carichner, Gordy;Hsu, Chin Wei;Yang, Mingyu;Shoouri, Sara;Ernst, Katherine;Carichner, Tess;Li, Yuyang;Lim, Jaechan;Julick, Cole R.;Moon, Eunseong;Sun, Yi;Phillips, Jamie;Montooth, Kristi L.;Green, Delbert A.;Kim, Hun Seok;Blaauw, David",55488572100;57219629906;56635449000;57698208400;57209602445;57221814984;57219634240;58759560100;57220199147;55622931700;57197855416;57189497511;57209581989;7404582496;57207903057;54388964900;57203630296;57216999566,60015543;60025778;60025778;60025778;60025778;60025778;60025778;60025778;60015543;60025778;60026306;60025778;60025778;60023004;60026306;60025778;60025778;60025778,2021-01-01,2021,"Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM",,21101192480,,Conference Proceeding,,,,517-530,"Each fall, millions of monarch butterflies across the northern US and Canada migrate up to 4,000 km to overwinter in the exact same cluster of mountain peaks in central Mexico. To track monarchs precisely and study their navigation, a monarch tracker must obtain daily localization of the butterfly as it progresses on its 3-month journey. And, the tracker must perform this task while having a weight in the tens of milligram (mg) and measuring a few millimeters (mm) in size to avoid interfering with monarch's flight. This paper proposes mSAIL, 8 × 8 × 2.6 mm and 62 mg embedded system for monarch migration tracking, constructed using 8 prior custom-designed ICs providing solar energy harvesting, an ultra-low power processor, light/temperature sensors, power management, and a wireless transceiver, all integrated and 3D stacked on a micro PCB with an 8 × 8 mm printed antenna. The proposed system is designed to record and compress light and temperature data during the migration path while harvesting solar energy for energy autonomy, and wirelessly transmit the data at the overwintering site in Mexico, from which the daily location of the butterfly can be estimated using a deep learning-based localization algorithm. A 2-day trial experiment of mSAIL attached on a live butterfly in an outdoor botanical garden demonstrates the feasibility of individual butterfly localization and tracking.",animal migration tracking | energy harvesting wireless sensor | miniaturized light weight sensing platform | sensor fusion localization,5,0,,,NSF,2043017,National Science Foundation,MOBICOM Mobile
2-s2.0-85128360841,10.1145/3491102.3501976,,,"""I Wanted to See How Bad it Was"": Online Self-screening as a Critical Transition Point Among Young Adults with Common Mental Health Conditions",cp,Conference Paper,Kruzan K.P.,60025222;60007363;60007278,"Mental Health America;Northwestern University;University of California, Irvine",Alexandria;Evanston;Irvine,United States;United States;United States,6,"Kruzan, Kaylee Payne;Meyerhoff, Jonah;Nguyen, Theresa;Reddy, Madhu;Mohr, David C.;Kornfield, Rachel",57207359439;56197457100;57209166205;7402242870;55614489700;36727709900,60007363;60007363;60025222;60007363;60007278;60007363,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,328,,"Young adults have high rates of mental health conditions, yet they are the age group least likely to seek traditional treatment. They do, however, seek information about their mental health online, including by filling out online mental health screeners. To better understand online self-screening, and its role in help-seeking, we conducted focus groups with 50 young adults who voluntarily completed a mental health screener hosted on an advocacy website. We explored (1) catalysts for taking the screener, (2) anticipated outcomes, (3) reactions to the results, and (4) desired next steps. For many participants, the screener results validated their lived experiences of symptoms, but they were nevertheless unsure how to use the information to improve their mental health moving forward. Our findings suggest that online screeners can serve as a transition point in young people's mental health journeys. We discuss design implications for online screeners, post-screener feedback, and digital interventions broadly.",anxiety | depression | digital intervention | help-seeking | mental health | online screening,13,1,repositoryam,Green,NIMH,K01MH125172,National Institute of Mental Health,CHI Human-Computer Interaction
2-s2.0-85130511653,10.1145/3491102.3501995,,,"""It's Kind of Like Code-Switching"": Black Older Adults' Experiences with a Voice Assistant for Health Information Seeking",cp,Conference Paper,Harrington C.N.,60118345;60031707;60027950;128134907,School of Information Studies;Michigan State University;Carnegie Mellon University;DePaul University,Syracuse;East Lansing;Pittsburgh;East Lansing,United States;United States;United States;United States,4,"Harrington, Christina N.;Garg, Radhika;Woodward, Amanda;Williams, Dimitri",57002432100;56267746100;24367844200;57704578700,60027950;60118345;60031707;128134907,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,604,,"Black older adults from lower socioeconomic environments are often neglected in health technology interventions. Voice assistants have a potential to make healthcare more accessible to older adults, yet, little is known about their experiences with this type of health information seeking, especially Black older adults. Through a three-phase exploratory study, we explored health information seeking with 30 Black older adults in lower-income environments to understand how they ask health-related questions, and their perceptions of the Google Home being used for that purpose. Through our analysis, we identified the health information needs and common search topics, and discussed the communication breakdowns and types of repair performed. We contribute an understanding of cultural code-switching that has to be done by these older adults when interacting with voice assistants, and the importance of such phenomenon when designing for historically excluded groups.",code-switching | cultural relevance | health information seeking | identity | older adults | race | speech recognition | voice assistants,22,1,repositoryam,Green,NIH,P30 AG015281,National Institutes of Health,CHI Human-Computer Interaction
2-s2.0-85133514252,10.1145/3510003.3510121,,,'This Is Damn Slick!' Estimating the Impact of Tweets on Open Source Project Popularity and New Contributors,cp,Conference Paper,Fang H.,60027950,Carnegie Mellon University,Pittsburgh,United States,4,"Fang, Hongbo;Lamba, Hemank;Herbsleb, James;Vasilescu, Bogdan",57219539270;55265658400;6603734663;42062536300,60027950;60027950;60027950;60027950,2022-01-01,2022,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2022-May,,,2116-2129,"Twitter is widely used by software developers. But how effective are tweets at promoting open source projects? How could one use Twitter to increase a project's popularity or attract new contributors? In this paper we report on a mixed-methods empirical study of 44,544 tweets containing links to 2,370 open-source GitHub repositories, looking for evidence of causal effects of these tweets on the projects attracting new GitHub stars and contributors, as well as characterizing the high-impact tweets, the people likely being attracted by them, and how they differ from contributors attracted otherwise. Among others, we find that tweets have a statistically significant and practically sizable effect on obtaining new stars and a small average effect on attracting new contributors. The popularity, content of the tweet, as well as the identity of tweet authors all affect the scale of the attraction effect. In addition, our qualitative analysis suggests that forming an active Twitter community for an open source project plays an important role in attracting new committers via tweets. We also report that developers who are new to GitHub or have a long history of Twitter usage but few tweets posted are most likely to be attracted as contributors to the repositories mentioned by tweets. Our work contributes to the literature on open source sustainability.",GitHub | Open source software | Promotion | Twitter,5,1,publisherfree2read,Bronze,NSF,1546393,National Science Foundation,ICSE Software Engineering
2-s2.0-85130567378,10.1145/3491102.3502072,,,3D Printed Street Crossings: Supporting Orientation and Mobility Training with People who are Blind or have Low Vision,cp,Conference Paper,Holloway L.,60019578,Monash University,Clayton,Australia,3,"Holloway, Leona;Butler, Matthew;Marriott, Kim",57189323083;56111374100;7005317835,60019578;60019578;60019578,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,415,,"The ability to cross the street at intersections is an essential skill, often taught to people who are blind or have low vision (BLV) with the aid of tactile maps and kits or toys. However, each of the existing mapping tools has shortcomings. We investigated whether co-designed 3D printed components can offer benefits. Guided by consultation with 11 Orientation and Mobility (O&M) professionals, we co-designed a series of 3D printed kits that they then used in their practice with BLV children who showed high levels of engagement and learning. The 3D materials were found to demonstrate the key concepts for street crossings in a portable, engaging and professional manner. They will be released for free download, enabling O&M professionals to access or modify the materials as required. We hope that use of our co-designed 3D printed tools will contribute to the safety, independence and inclusion of BLV people.",3D Printing | Blind | Intersections | Maps | Orientation &amp; Mobility,6,1,publisherfree2read,Bronze,ARC,LP170100026,Australian Research Council,CHI Human-Computer Interaction
2-s2.0-85161491987,,,,A Neural Corpus Indexer for Document Retrieval,cp,Conference Paper,Wang Y.,60026532;60025278;60014966;60000745,Microsoft Corporation;Tsinghua University;Peking University;University of Illinois Urbana-Champaign,Redmond;Beijing;Beijing;Urbana,United States;China;China;United States,16,"Wang, Yujing;Hou, Yingyan;Wang, Haonan;Miao, Ziming;Wu, Shibin;Sun, Hao;Chen, Qi;Xia, Yuqing;Chi, Chengmin;Zhao, Guoshuai;Liu, Zheng;Xie, Xing;Sun, Hao Allen;Deng, Weiwei;Zhang, Qi;Yang, Mao",56347999900;57747964600;57214938083;57747328200;57748939200;57216325974;57207582229;57746999500;57747328300;57748294100;57211759701;57221820833;57973532800;57203399957;54931372200;55703321000,60026532;60026532-60025278;60026532-60000745;60026532;60026532-60025278;60026532-60014966;60026532;60026532;60026532;60026532;60026532;60026532;60026532;60026532;60026532;60026532,2022-01-01,2022,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,35,,,,"Current state-of-the-art document retrieval solutions mainly follow an index-retrieve paradigm, where the index is hard to be directly optimized for the final retrieval target. In this paper, we aim to show that an end-to-end deep neural network unifying training and indexing stages can significantly improve the recall performance of traditional methods. To this end, we propose Neural Corpus Indexer (NCI), a sequence-to-sequence network that generates relevant document identifiers directly for a designated query. To optimize the recall performance of NCI, we invent a prefix-aware weight-adaptive decoder architecture, and leverage tailored techniques including query generation, semantic document identifiers, and consistency-based regularization. Empirical studies demonstrated the superiority of NCI on two commonly used academic benchmarks, achieving +21.4% and +16.8% relative enhancement for Recall@1 on NQ320k dataset and R-Precision on TriviaQA dataset, respectively, compared to the best baseline method.",,13,0,,,,undefined,Microsoft,NeurIPS Machine Learning
2-s2.0-85135004032,10.1145/3477495.3531926,,,A Non-Factoid Question-Answering Taxonomy,cp,Conference Paper,Bolotova V.,60103702;60014313;60011362,Uralʹskiĭ Federalʹnyĭ Universitet;University of Massachusetts Amherst;RMIT University,Yekaterinburg;Amherst;Melbourne,Russian Federation;United States;Australia,5,"Bolotova, Valeriia;Blinov, Vladislav;Scholer, Falk;Croft, W. Bruce;Sanderson, Mark",57194714599;57194716101;56254255800;7006788293;7202315611,60011362;60103702;60011362;60014313;60011362,2022-07-06,6 July 2022,SIGIR 2022 - Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval,,21101098695,,Conference Proceeding,,,,1196-1207,"Non-factoid question answering (NFQA) is a challenging and under-researched task that requires constructing long-form answers, such as explanations or opinions, to open-ended non-factoid questions - NFQs. There is still little understanding of the categories of NFQs that people tend to ask, what form of answers they expect to see in return, and what the key research challenges of each category are. This work presents the first comprehensive taxonomy of NFQ categories and the expected structure of answers. The taxonomy was constructed with a transparent methodology and extensively evaluated via crowdsourcing. The most challenging categories were identified through an editorial user study. We also release a dataset of categorised NFQs and a question category classifier. Finally, we conduct a quantitative analysis of the distribution of question categories using major NFQA datasets, showing that the NFQ categories that are the most challenging for current NFQA systems are poorly represented in these datasets. This imbalance may lead to insufficient system performance for challenging categories. The new taxonomy, along with the category classifier, will aid research in the area, helping to create more balanced benchmarks and to focus models on addressing specific categories.",dataset analysis | editorial study | non-factoid question-answering | question taxonomy,9,0,,,,undefined,,SIGIR Information Retrieval
2-s2.0-85140994389,10.14778/3529337.3529339,,,Accurate Summary-based Cardinality Estimation Through the Lens of Cardinality Estimation Graphs,cp,Conference Paper,Chen J.,60014171,University of Waterloo,Waterloo,Canada,5,"Chen, Jeremy;Huang, Yuqing;Wang, Mushi;Salihoglu, Semih;Salem, Ken",57194616640;57224508795;57224523983;24345289400;7003632842,60014171;60014171;60014171;60014171;60014171,2022-01-01,2022,Proceedings of the VLDB Endowment,,21100199855,21508097,Journal,15,8,,1533-1545,"This paper is an experimental and analytical study of two classes of summary-based cardinality estimators that use statistics about input relations and small-size joins in the context of graph database management systems: (i) optimistic estimators that make uniformity and conditional independence assumptions; and (ii) the recent pessimistic estimators that use information theoretic linear programs (LPs). We begin by analyzing how optimistic estimators use pre-computed statistics to generate cardinality estimates. We show these estimators can be modeled as picking bottom-to-top paths in a cardinality estimation graph (CEG), which contains sub-queries as nodes and edges whose weights are average degree statistics. We show that existing optimistic estimators have either undefined or fixed choices for picking CEG paths as their estimates and ignore alternative choices. Instead, we outline a space of optimistic estimators to make an estimate on CEGs, which subsumes existing estimators. We show, using an extensive empirical analysis, that effective paths depend on the structure of the queries. While on acyclic queries and queries with small-size cycles, using the maximum-weight path is effective to address the well known underestimation problem, on queries with larger cycles these estimates tend to overestimate, which can be addressed by using minimum weight paths. We next show that optimistic estimators and seemingly disparate LP-based pessimistic estimators are in fact connected. Specifically, we show that CEGs can also model some recent pessimistic estimators. This connection allows us to adopt an optimization from pessimistic estimators to optimistic ones, and provide insights into the pessimistic estimators, such as showing that they have combinatorial solutions.",,2,0,repositoryam,Green,,undefined,,VLDB Databases
2-s2.0-85130558714,10.1145/3491102.3502034,,,"AirRacket: Perceptual Design of Ungrounded, Directional Force Feedback to Improve Virtual Racket Sports Experiences",cp,Conference Paper,Tsai C.Y.,60020304;60005429,"University of Maryland, College Park;National Taiwan University",College Park;Taipei,United States;Taiwan,7,"Tsai, Ching Yi;Tsai, I. Lun;Lai, Chao Jung;Chow, Derrek;Wei, Lauren;Cheng, Lung Pan;Chen, Mike Y.",57215966884;57703651600;57704344300;57704344400;57703422700;57197460517;35766280300,60005429;60005429;60005429;60005429;60020304;60005429;60005429,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,185,,"We present AirRacket, perceptual modeling and design of ungrounded, directional force feedback for virtual racket sports. Using compressed air propulsion jets to provide directional impact forces, we iteratively designed for three popular sports that span a wide range of force magnitudes: ping-pong, badminton, and tennis. To address the limited force magnitude of ungrounded force feedback technologies, we conducted a perception study which discovered the novel illusion that users perceive larger impact force magnitudes with longer impact duration, by an average factor of 2.57x. Through a series of formative, perceptual, and user experience studies with a combined total of 72 unique participants, we explored several perceptual designs using force magnitude scaling and duration scaling methods to expand the dynamic range of perceived force magnitude. Our user experience evaluation showed that perceptual designs can significantly improve realism and preference vs. physics-based designs for ungrounded force feedback systems.",air propulsion | force perception | Haptics | perceptual design | ungrounded force feedback | virtual reality,11,1,publisherfree2read,Bronze,MOE,110L892805,Ministry of Education,CHI Human-Computer Interaction
2-s2.0-85129071886,10.1109/SP46214.2022.9833571,,,Asleep at the Keyboard? Assessing the Security of GitHub Copilot's Code Contributions,cp,Conference Paper,Pearce H.,60021784;60002306,New York University;University of Calgary,New York;Calgary,United States;Canada,5,"Pearce, Hammond;Ahmad, Baleegh;Tan, Benjamin;Dolan-Gavitt, Brendan;Karri, Ramesh",57190837137;57245945000;57217583004;17134620000;7006419874,60021784;60021784;60021784;60002306;60021784,2022-01-01,2022,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2022-May,,,754-768,"There is burgeoning interest in designing AI-based systems to assist humans in designing computing systems, including tools that automatically generate computer code. The most notable of these comes in the form of the first self-described 'AI pair programmer', GitHub Copilot, which is a language model trained over open-source GitHub code. However, code often contains bugs - and so, given the vast quantity of unvetted code that Copilot has processed, it is certain that the language model will have learned from exploitable, buggy code. This raises concerns on the security of Copilot's code contributions. In this work, we systematically investigate the prevalence and conditions that can cause GitHub Copilot to recommend insecure code. To perform this analysis we prompt Copilot to generate code in scenarios relevant to high-risk cybersecurity weaknesses, e.g. those from MITRE's 'Top 25' Common Weakness Enumeration (CWE) list. We explore Copilot's performance on three distinct code generation axes - examining how it performs given diversity of weaknesses, diversity of prompts, and diversity of domains. In total, we produce 89 different scenarios for Copilot to complete, producing 1,689 programs. Of these, we found approximately 40% to be vulnerable.",Artificial Intelligence (AI) | code generation | Common Weakness Enumerations (CWEs) | Cybersecurity,60,0,repositoryam,Green,NSF,1801495,National Science Foundation,S&P Security and Privacy
2-s2.0-85132288686,10.1145/3519935.3520017,,,Asymptotically good Quantum and locally testable classical LDPC codes,cp,Conference Paper,Panteleev P.,60007457,Lomonosov Moscow State University,Moscow,Russian Federation,2,"Panteleev, Pavel;Kalachev, Gleb",6602490313;56566645200,60007457;60007457,2022-09-06,6 September 2022,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,375-388,"We study classical and quantum LDPC codes of constant rate obtained by the lifted product construction over non-abelian groups. We show that the obtained families of quantum LDPC codes are asymptotically good, which proves the qLDPC conjecture. Moreover, we show that the produced classical LDPC codes are also asymptotically good and locally testable with constant query and soundness parameters, which proves a well-known conjecture in the field of locally testable codes.",chain complexes | expander graphs | LDPC codes | locally testable codes | quantum codes,40,0,repositoryam,Green,Minobrnauka,075-15-2020-801,Ministry of Education and Science of the Russian Federation,STOC Theory
2-s2.0-85143068631,10.1145/3540250.3549168,,,Asynchronous technical interviews: reducing the effect of supervised think-aloud on communication ability,cp,Conference Paper,Behroozi M.,60027090;60021293;60004923,Virginia Polytechnic Institute and State University;International Business Machines;NC State University,Blacksburg;Armonk;Raleigh,United States;United States;United States,3,"Behroozi, Mahnaz;Parnin, Chris;Brown, Chris",56039074500;15136883200;57213322400,60021293;60004923;60027090,2022-11-07,7 November 2022,ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101123502,,Conference Proceeding,,,,294-305,"Software engineers often face a critical test before landing a job - passing a technical interview. During these sessions, candidates must write code while thinking aloud as they work toward a solution to a problem under the watchful eye of an interviewer. While thinking aloud during technical interviews gives interviewers a picture of candidates' problem-solving ability, surprisingly, these types of interviews often prevent candidates from communicating their thought process effectively. To understand if poor performance related to interviewer presence can be reduced while preserving communication and technical skills, we introduce asynchronous technical interviews - where candidates submit recordings of think-aloud and coding. We compare this approach to traditional whiteboard interviews and find that, by eliminating interviewer supervision, asynchronicity significantly improved the clarity of think-aloud via increased informativeness and reduced stress. Moreover, we discovered asynchronous technical interviews preserved, and in some cases even enhanced, technical problem-solving strategies and code quality. This work offers insight into asynchronous technical interviews as a design for supporting communication during interviews, and discusses trade-offs and guidelines for implementing this approach in software engineering hiring practices.",asynchronous communication | skill evaluation | software engineering | technical interviews,0,1,repositoryvor,Green,,undefined,,FSE Software Engineering
2-s2.0-85145017210,,,,"Bayesian Model Selection, the Marginal Likelihood, and Generalization",cp,Conference Paper,Lotfi S.,60021784,New York University,New York,United States,5,"Lotfi, Sanae;Izmailov, Pavel;Benton, Gregory;Goldblum, Micah;Wilson, Andrew Gordon",57222380460;57205290654;57218715386;57211069935;57203334715,60021784;60021784;60021784;60021784;60021784,2022-01-01,2022,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,162,,,14223-14247,"How do we compare between hypotheses that are entirely consistent with observations? The marginal likelihood (aka Bayesian evidence), which represents the probability of generating our observations from a prior, provides a distinctive approach to this foundational question, automatically encoding Occam's razor. Although it has been observed that the marginal likelihood can overfit and is sensitive to prior assumptions, its limitations for hyperparameter learning and discrete model comparison have not been thoroughly investigated. We first revisit the appealing properties of the marginal likelihood for learning constraints and hypothesis testing. We then highlight the conceptual and practical issues in using the marginal likelihood as a proxy for generalization. Namely, we show how marginal likelihood can be negatively correlated with generalization, with implications for neural architecture search, and can lead to both underfitting and overfitting in hyperparameter learning. We provide a partial remedy through a conditional marginal likelihood, which we show is more aligned with generalization, and practically valuable for large-scale hyperparameter learning, such as in deep kernel learning.",,11,0,,,NSF,193471,National Science Foundation,ICML Machine Learning
2-s2.0-85143062043,,,,Beyond neural scaling laws: beating power law scaling via data pruning,cp,Conference Paper,Sorscher B.,60017246;60012708;127294950,Eberhard Karls Universität Tübingen;Stanford University;Meta AI,Tubingen;Stanford;Meta,Germany;United States;United States,5,"Sorscher, Ben;Geirhos, Robert;Shekhar, Shashank;Ganguli, Surya;Morcos, Ari S.",57218716119;57200525208;57206471901;8422780800;56946640900,60012708;60017246;127294950;60012708-127294950;127294950,2022-01-01,2022,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,35,,,,"Widely observed neural scaling laws, in which error falls off as a power of the training set size, model size, or both, have driven substantial performance improvements in deep learning. However, these improvements through scaling alone require considerable costs in compute and energy. Here we focus on the scaling of error with dataset size and show how in theory we can break beyond power law scaling and potentially even reduce it to exponential scaling instead if we have access to a high-quality data pruning metric that ranks the order in which training examples should be discarded to achieve any pruned dataset size. We then test this improved scaling prediction with pruned dataset size empirically, and indeed observe better than power law scaling in practice on ResNets trained on CIFAR-10, SVHN, and ImageNet. Next, given the importance of finding high-quality pruning metrics, we perform the first large-scale benchmarking study of ten different data pruning metrics on ImageNet. We find most existing high performing metrics scale poorly to ImageNet, while the best are computationally intensive and require labels for every image. We therefore developed a new simple, cheap and scalable self-supervised pruning metric that demonstrates comparable performance to the best supervised metrics. Overall, our work suggests that the discovery of good data-pruning metrics may provide a viable path forward to substantially improved neural scaling laws, thereby reducing the resource costs of modern deep learning.",,31,0,,,,undefined,Metropolitan Museum of Art,NeurIPS Machine Learning
2-s2.0-85135167908,10.1145/3528223.3530068,,,CLIPasso: Semantically-Aware Object Sketching,ar,Article,Vinker Y.,60028186;60012513;60005681,École Polytechnique Fédérale de Lausanne;Reichman University;Tel Aviv University,Lausanne;Herzliya;Tel Aviv-Yafo,Switzerland;Israel;Israel,8,"Vinker, Yael;Pajouheshgar, Ehsan;Bo, Jessica Y.;Bachmann, Roman Christian;Bermano, Amit Haim;Cohen-Or, Daniel;Zamir, Amir;Shamir, Ariel",57219735417;57219525962;57462206200;57211795101;53983538400;7004252391;56496616900;7006688650,60005681;60028186;60028186;60028186;60005681;60005681;60005681;60012513,2022-07-22,22 July 2022,ACM Transactions on Graphics,07300301,24972,15577368,Journal,41,4,3530068,,"Abstraction is at the heart of sketching due to the simple and minimal nature of line drawings. Abstraction entails identifying the essential visual properties of an object or scene, which requires semantic understanding and prior knowledge of high-level concepts. Abstract depictions are therefore challenging for artists, and even more so for machines. We present CLIPasso, an object sketching method that can achieve different levels of abstraction, guided by geometric and semantic simplifications. While sketch generation methods often rely on explicit sketch datasets for training, we utilize the remarkable ability of CLIP (Contrastive-Language-Image-Pretraining) to distill semantic concepts from sketches and images alike. We define a sketch as a set of Bézier curves and use a differentiable rasterizer to optimize the parameters of the curves directly with respect to a CLIP-based perceptual loss. The abstraction degree is controlled by varying the number of strokes. The generated sketches demonstrate multiple levels of abstraction while maintaining recognizability, underlying structure, and essential visual components of the subject drawn.",Image-based rendering | Sketch synthesis | Vector line art generation,23,0,,,ISF,2492/20,Israel Science Foundation,SIGGRAPH Graphics
2-s2.0-85130560536,10.1145/3491102.3502038,,,Care Infrastructures for Digital Security in Intimate Partner Violence,cp,Conference Paper,Tseng E.,60104837;60007776,Cornell Tech;Cornell University,New York;Ithaca,United States;United States,6,"Tseng, Emily;Sabet, Mehrnaz;Bellini, Rosanna;Sodhi, Harkiran Kaur;Ristenpart, Thomas;Dell, Nicola",57210699234;57224002756;57202047155;57703418500;23393983800;45560910100,60007776;60007776;60007776;60104837;60104837;60104837,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,123,,"Survivors of intimate partner violence (IPV) face complex threats to their digital privacy and security. Prior work has established protocols for directly helping them mitigate these harms; however, there remains a need for flexible and pluralistic systems that can support survivors' long-term needs. This paper describes the design and development of sociotechnical infrastructure that incorporates feminist notions of care to connect IPV survivors experiencing technology abuse with volunteer computer security consultants. We present findings from a mixed methods study that draws on data from an 8-month, real-world deployment, as well as interviews with 7 volunteer technology consultants and 18 IPV professionals. Our findings illuminate emergent challenges in safely and adaptively providing computer security advice as care. We discuss implications of these findings for feminist approaches to computer security and privacy, and provide broader lessons for interventions that aim to directly assist at-risk and marginalized people experiencing digital insecurity.",care | computer security and privacy | gender-based violence | intimate partner violence,20,1,publisherfree2read,Bronze,NSF,1916096,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85163090534,,,,Causal Conceptions of Fairness and their Consequences,cp,Conference Paper,Nilforoshan H.,60021784;60012708;60009982,New York University;Stanford University;Harvard University,New York;Stanford;Cambridge,United States;United States;United States,4,"Nilforoshan, Hamed;Gaebler, Johann;Shroff, Ravi;Goel, Sharad",57203125753;57206209917;57117515400;35785827100,60012708;60012708;60021784;60009982,2022-01-01,2022,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,162,,,16848-16887,"Recent work highlights the role of causality in designing equitable decision-making algorithms. It is not immediately clear, however, how existing causal conceptions of fairness relate to one another, or what the consequences are of using these definitions as design principles. Here, we first assemble and categorize popular causal definitions of algorithmic fairness into two broad families: (1) those that constrain the effects of decisions on counterfactual disparities; and (2) those that constrain the effects of legally protected characteristics, like race and gender, on decisions. We then show, analytically and empirically, that both families of definitions almost always-in a measure theoretic sense-result in strongly Pareto dominated decision policies, meaning there is an alternative, unconstrained policy favored by every stakeholder with preferences drawn from a large, natural class. For example, in the case of college admissions decisions, policies constrained to satisfy causal fairness definitions would be disfavored by every stakeholder with neutral or positive preferences for both academic preparedness and diversity. Indeed, under a prominent definition of causal fairness, we prove the resulting policies require admitting all students with the same probability, regardless of academic qualifications or group membership. Our results highlight formal limitations and potential adverse consequences of common mathematical notions of causal fairness.",,8,0,,,NSF,IIS-2040898,National Science Foundation,ICML Machine Learning
2-s2.0-85130509779,10.1145/3491102.3501836,,,Causality-preserving Asynchronous Reality,cp,Conference Paper,Fender A.R.,60025858,ETH Zürich,Zurich,Switzerland,2,"Fender, Andreas Rene;Holz, Christian",56159566600;56070704000,60025858;60025858,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,634,,"Mixed Reality is gaining interest as a platform for collaboration and focused work to a point where it may supersede current office settings in future workplaces. At the same time, we expect that interaction with physical objects and face-to-face communication will remain crucial for future work environments, which is a particular challenge in fully immersive Virtual Reality. In this work, we reconcile those requirements through a user's individual Asynchronous Reality, which enables seamless physical interaction across time. When a user is unavailable, e.g., focused on a task or in a call, our approach captures co-located or remote physical events in real-time, constructs a causality graph of co-dependent events, and lets immersed users revisit them at a suitable time in a causally accurate way. Enabled by our system AsyncReality, we present a workplace scenario that includes walk-in interruptions during a person's focused work, physical deliveries, and transient spoken messages. We then generalize our approach to a use-case agnostic concept and system architecture. We conclude by discussing the implications of Asynchronous Reality for future offices.",Asynchronous communication | Camera networks | Collaboration | Immersive workspaces | Interruption in workplaces | Mixed Reality,18,1,publisherfree2read,Bronze,ZISC,undefined,Zurich Information Security and Privacy Center,CHI Human-Computer Interaction
2-s2.0-85133304836,10.1109/INFOCOM48880.2022.9796985,,,ChARM: NextG Spectrum Sharing Through Data-Driven Real-Time O-RAN Dynamic Control,cp,Conference Paper,Baldesi L.,60028628,Northeastern University,Boston,United States,3,"Baldesi, Luca;Restuccia, Francesco;Melodia, Tommaso",56285936900;57217858608;6602320889,60028628;60028628;60028628,2022-01-01,2022,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2022-May,,,240-249,"Today's radio access networks (RANs) are monolithic entities which often operate statically on a given set of parameters for the entirety of their operations. To implement realistic and effective spectrum sharing policies, RANs will need to seamlessly and intelligently change their operational parameters. In stark contrast with existing paradigms, the new O-RAN architectures for 5G-and-beyond networks (NextG) separate the logic that controls the RAN from its hardware substrate, allowing unprecedented real-time fine-grained control of RAN components. In this context, we propose the Channel-Aware Reactive Mechanism (ChARM), a data-driven O-RAN-compliant framework that allows (i) sensing the spectrum to infer the presence of interference and (ii) reacting in real time by switching the distributed unit (DU) and radio unit (RU) operational parameters according to a specified spectrum access policy. ChARM is based on neural networks operating directly on unprocessed I/Q waveforms to determine the current spectrum context. ChARM does not require any modification to the existing 3GPP standards. It is designed to operate within the O-RAN specifications, and can be used in conjunction with other spectrum sharing mechanisms (e.g., LTE-U, LTE-LAA or MulteFire). We demonstrate the performance of ChARM in the context of spectrum sharing among LTE and Wi-Fi in unlicensed bands, where a controller operating over a RAN Intelligent Controller (RIC) senses the spectrum and switches cell frequency to avoid Wi-Fi. We develop a prototype of ChARM using srsRAN, and leverage the Colosseum channel emulator to collect a large-scale waveform dataset to train our neural networks with. To collect standard-compliant Wi-Fi data, we extended the Colosseum testbed using system-on-chip (SoC) boards running a modified version of the OpenWiFi architecture. Experimental results show that ChARM achieves accuracy of up to 96% on Colosseum and 85% on an over-the-air testbed, demonstrating the capacity of ChARMto exploit the considered spectrum channels.",,12,0,repositoryam,Green,NSF,1923789,National Science Foundation,INFOCOM Networking
2-s2.0-85132607290,10.1145/3510003.3510209,,,"Collaboration Challenges in Building ML-Enabled Systems: Communication, Documentation, Engineering, and Process",cp,Conference Paper,Nahar N.,60076258;60027950;60016849,Software Engineering Institute;Carnegie Mellon University;University of Toronto,Pittsburgh;Pittsburgh;Toronto,United States;United States;Canada,4,"Nahar, Nadia;Zhou, Shurui;Lewis, Grace;Kastner, Christian",56297687600;57188683983;7402637003;35547901100,60027950;60016849;60076258;60027950,2022-01-01,2022,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2022-May,,,413-425,"The introduction of machine learning (ML) components in software projects has created the need for software engineers to collabo-rate with data scientists and other specialists. While collaboration can always be challenging, ML introduces additional challenges with its exploratory model development process, additional skills and knowledge needed, difficulties testing ML systems, need for continuous evolution and monitoring, and non-traditional quality requirements such as fairness and explainability. Through inter-views with 45 practitioners from 28 organizations, we identified key collaboration challenges that teams face when building and deploying ML systems into production. We report on common col-laboration points in the development of production ML systems for requirements, data, and integration, as well as corresponding team patterns and challenges. We find that most of these challenges center around communication, documentation, engineering, and process, and collect recommendations to address these challenges.",Machine Learning | SE4AI | SE4ML | Software Engineering,28,1,publisherfree2read,Bronze,NSF,1813598,National Science Foundation,ICSE Software Engineering
2-s2.0-85135955777,10.1109/SP46214.2022.9833686,,,Committed to Trust: A Qualitative Study on Security &amp; Trust in Open Source Software Projects,cp,Conference Paper,Wermke D.,60277517;60117087;60004935;60003088,Max Planck Institute for Security and Privacy;CISPA - Helmholtz Center for Information Security;Gottfried Wilhelm Leibniz Universität Hannover;The George Washington University,"Bochum;Saarbrucken;Hannover;Washington, D.C.",Germany;Germany;Germany;United States,6,"Wermke, Dominik;Wohler, Noah;Klemmer, Jan H.;Fourne, Marcel;Acar, Yasemin;Fahl, Sascha",57197866694;57844993400;57843702900;56165717500;55837116400;37097082800,60117087;60117087;60004935;60277517;60003088;60117087,2022-01-01,2022,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2022-May,,,1880-1896,"Open Source Software plays an important role in many software ecosystems. Whether in operating systems, network stacks, or as low-level system drivers, software we encounter daily is permeated with code contributions from open source projects. Decentralized development and open collaboration in open source projects introduce unique challenges: code submissions from unknown entities, limited personpower for commit or dependency reviews, and bringing new contributors up-to-date in projects' best practices & processes.In 27 in-depth, semi-structured interviews with owners, maintainers, and contributors from a diverse set of open source projects, we investigate their security and trust practices. For this, we explore projects' behind-the-scene processes, provided guidance & policies, as well as incident handling & encountered challenges. We find that our participants' projects are highly diverse both in deployed security measures and trust processes, as well as their underlying motivations. Based on our findings, we discuss implications for the open source software ecosystem and how the research community can better support open source projects in trust and security considerations. Overall, we argue for supporting open source projects in ways that consider their individual strengths and limitations, especially in the case of smaller projects with low contributor numbers and limited access to resources.",interviews | open-source | security | trust,14,0,,,,undefined,,S&P Security and Privacy
2-s2.0-85132998676,10.1145/3517804.3524140,,,Convergence of Datalog over (Pre-) Semirings,cp,Conference Paper,Abo Khamis M.,60117169;60018163;60015481,"RelationalAI, Inc.;Technische Universität Wien;University of Washington",Berkeley;Vienna;Seattle,United States;Austria;United States,5,"Abo Khamis, Mahmoud;Ngo, Hung Q.;Pichler, Reinhard;Suciu, Dan;Wang, Yisu Remy",57073076300;7005488530;7005093825;7006812452;57219034446,60117169;60117169;60018163;60015481;60015481,2022-06-12,12 June 2022,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,105-117,"Recursive queries have been traditionally studied in the framework of datalog, a language that restricts recursion to monotone queries over sets, which is guaranteed to converge in polynomial time in the size of the input. But modern big data systems require recursive computations beyond the Boolean space. In this paper we study the convergence of datalog when it is interpreted over an arbitrary semiring. We consider an ordered semiring, define the semantics of a datalog program as a least fixpoint in this semiring, and study the number of steps required to reach that fixpoint, if ever. We identify algebraic properties of the semiring that correspond to certain convergence properties of datalog programs. Finally, we describe a class of ordered semirings on which one can use the semi-naive evaluation algorithm on any datalog program.",datalog | fixpoint | semirings,7,1,repositoryam,Green,NSF,IIS 1907997,National Science Foundation,PODS Databases
2-s2.0-85141663941,10.1145/3526113.3545703,,,CrossA11y: Identifying Video Accessibility Issues via Cross-modal Grounding,cp,Conference Paper,Liu X.,60150459;60076047;60027550,"Department of Computer Science;Adobe Inc.;University of California, Los Angeles",Austin;San Jose;Los Angeles,United States;United States;United States,5,"Liu, Xingyu;Wang, Ruolin;Li, Dingzeyu;Chen, Xiang Anthony;Pavel, Amy",56730163900;57209396547;55367150700;55146512600;56121790600,60027550;60027550;60076047;60027550;60150459,2022-10-29,29 October 2022,UIST 2022 - Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology,,21101120341,,Conference Proceeding,,,43,,"Authors make their videos visually accessible by adding audio descriptions (AD), and auditorily accessible by adding closed captions (CC). However, creating AD and CC is challenging and tedious, especially for non-professional describers and captioners, due to the difficulty of identifying accessibility problems in videos. A video author will have to watch the video through and manually check for inaccessible information frame-by-frame, for both visual and auditory modalities. In this paper, we present CrossA11y, a system that helps authors efficiently detect and address visual and auditory accessibility issues in videos. Using cross-modal grounding analysis, CrossA11y automatically measures accessibility of visual and audio segments in a video by checking for modality asymmetries. CrossA11y then displays these segments and surfaces visual and audio accessibility issues in a unified interface, making it intuitive to locate, review, script AD/CC in-place, and preview the described and captioned video immediately. We demonstrate the effectiveness of CrossA11y through a lab study with 11 participants, comparing to existing baseline.",accessibility | audio description | closed caption | video,7,1,repositoryam,Green,,undefined,,UIST User Interface
2-s2.0-84898981555,,,,DESPOT: Online POMDP planning with regularization,cp,Conference Paper,Somani A.,60017161,National University of Singapore,Singapore City,Singapore,4,"Somani, Adhiraj;Ye, Nan;Hsu, David;Lee, Wee Sun",56121628700;56153287700;34569904000;55663394400,60017161;60017161;60017161;60017161,2013-01-01,2013,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,,,,,"POMDPs provide a principled framework for planning under uncertainty, but are computationally intractable, due to the ""curse of dimensionality"" and the ""curse of history"". This paper presents an online POMDP algorithm that alleviates these difficulties by focusing the search on a set of randomly sampled scenarios. A Determinized Sparse Partially Observable Tree (DESPOT) compactly captures the execution of all policies on these scenarios. Our Regularized DESPOT (R-DESPOT) algorithm searches the DESPOT for a policy, while optimally balancing the size of the policy and its estimated value obtained under the sampled scenarios. We give an output-sensitive performance bound for all policies derived from a DESPOT, and show that R-DESPOT works well if a small optimal policy exists. We also give an anytime algorithm that approximates R-DESPOT. Experiments show strong results, compared with two of the fastest online POMDP algorithms. Source code along with experimental settings are available at http://bigbird.comp.nus.edu.sg/pmwiki/farm/appl/.",,235,0,,,,undefined,,IJCAI Artificial Intelligence
2-s2.0-85135045353,10.1145/3528223.3530178,,,DeepPhase: Periodic Autoencoders for Learning Motion Phase Manifolds,ar,Article,Starke S.,60109079;60027272;60006541,Electronic Arts Inc;The University of Edinburgh;The University of Hong Kong,Redwood City;Edinburgh;Hong Kong,United States;United Kingdom;Hong Kong,3,"Starke, Sebastian;Mason, Ian;Komura, Taku",57190372593;57204397533;57203194876,60027272-60109079;60027272;60006541,2022-07-22,22 July 2022,ACM Transactions on Graphics,07300301,24972,15577368,Journal,41,4,3530178,,"Learning the spatial-temporal structure of body movements is a fundamental problem for character motion synthesis. In this work, we propose a novel neural network architecture called the Periodic Autoencoder that can learn periodic features from large unstructured motion datasets in an unsupervised manner. The character movements are decomposed into multiple latent channels that capture the non-linear periodicity of different body segments while progressing forward in time. Our method extracts a multi-dimensional phase space from full-body motion data, which effectively clusters animations and produces a manifold in which computed feature distances provide a better similarity measure than in the original motion space to achieve better temporal and spatial alignment. We demonstrate that the learned periodic embedding can significantly help to improve neural motion synthesis in a number of tasks, including diverse locomotion skills, style-based movements, dance motion synthesis from music, synthesis of dribbling motions in football, and motion query for matching poses within large animation databases.",Character animation | Character control | Character interactions | Deep learning | Human motion | Neural networks,45,0,,,NEDO,JPNP21004,New Energy and Industrial Technology Development Organization,SIGGRAPH Graphics
2-s2.0-85130576280,10.1145/3491102.3502049,,,Designing for the Bittersweet: Improving Sensitive Experiences with Recommender Systems,cp,Conference Paper,Lustig C.,60271648;60015481;60000221,Meta;University of Washington;University of Colorado Boulder,Menlo Park;Seattle;Boulder,United States;United States;United States,3,"Lustig, Caitlin;Konrad, Artie;Brubaker, Jed R.",56902401100;55735436900;37103441100,60015481;60271648;60000221,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,16,,"It is difficult to design systems that honor the complex and often contradictory emotions that can be surfaced by sensitive encounters with recommender systems. To explore the design and ethical considerations in this space, we interviewed 20 people who had recently seen sensitive content through Facebook's Memories feature. Interviewees typically described how (1) expectedness, (2) context of viewing, and (3) what we describe as ""affective sense-making""were important factors for how they perceived ""bittersweet""content, a sensitizing concept from our interviews that we expand upon. To address these user needs, we pose provocations to support critical work in this area and we suggest that researchers and designers: (1) draw inspiration from no/low-technology artifacts, (2) use empirical research to identify contextual features that have negative impacts on users, and (3) conduct user studies on affective sense-making. CAUTION: This paper discusses difficult subject matter related to death and relationships.",breakup | death | social media | technology-mediated reflection,10,1,publisherfree2read,Bronze,NSF,1756028,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85138421711,,,,DIBIMT: A Novel Benchmark for Measuring Word Sense Disambiguation Biases in Machine Translation,cp,Conference Paper,Campolungo N.,60032350;126446075,Sapienza Università di Roma;University Institute SSML Carlo Bo,Rome;Rome,Italy;Italy,4,"Campolungo, Niccolò;Martelli, Federico;Saina, Francesco;Navigli, Roberto",57220547062;57210165202;57224805300;6507102454,60032350;60032350;126446075;60032350,2022-01-01,2022,Proceedings of the Annual Meeting of the Association for Computational Linguistics,0736587X,21101138302,,Conference Proceeding,1,,,4331-4352,"Lexical ambiguity poses one of the greatest challenges in the field of Machine Translation. Over the last few decades, multiple efforts have been undertaken to investigate incorrect translations caused by the polysemous nature of words. Within this body of research, some studies have posited that models pick up semantic biases existing in the training data, thus producing translation errors. In this paper, we present DIBIMT, the first entirely manually-curated evaluation benchmark which enables an extensive study of semantic biases in Machine Translation of nominal and verbal words in five different language combinations, namely, English and one or other of the following languages: Chinese, German, Italian, Russian and Spanish. Furthermore, we test state-of-the-art Machine Translation systems, both commercial and non-commercial ones, against our new test bed and provide a thorough statistical and linguistic analysis of the results. We release DIBIMT at https://nlp.uniroma1.it/dibimt as a closed benchmark with a public leaderboard.",,14,0,,,H2020,731015,Horizon 2020 Framework Programme,ACL Natural Language Processing
2-s2.0-85129785460,10.1145/3510003.3510111,,,'Did You Miss My Comment or What?' Understanding Toxicity in Open Source Discussions,cp,Conference Paper,Miller C.,60029788;60027950,Wesleyan University Middletown;Carnegie Mellon University,Middletown;Pittsburgh,United States;United States,5,"Miller, Courtney;Cohen, Sophie;Klug, Daniel;Vasilescu, Bogdan;Kastner, Christian",57209888051;57282303900;57219535128;42062536300;35547901100,60027950;60029788;60027950;60027950;60027950,2022-01-01,2022,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2022-May,,,710-722,"Online toxicity is ubiquitous across the internet and its negative impact on the people and that online communities that it effects has been well documented. However, toxicity manifests differently on various platforms and toxicity in open source communities, while frequently discussed, is not well understood. We take a first stride at understanding the characteristics of open source toxicity to better inform future work on designing effective intervention and detection methods. To this end, we curate a sample of 100 toxic GitHub issue discussions combining multiple search and sampling strategies. We then qualitatively analyze the sample to gain an understanding of the characteristics of open-source toxicity. We find that the pervasive forms of toxicity in open source differ from those observed on other platforms like Reddit or Wikipedia. In our sample, some of the most prevalent forms of toxicity are entitled, demanding, and arrogant comments from project users as well as insults arising from technical disagreements. In addition, not all toxicity was written by people external to the projects; project members were also common authors of toxicity. We also discuss the implications of our findings. Among others we hope that our findings will be useful for future detection work.",online toxicity | open source software | software development,21,1,publisherfree2read,Bronze,,undefined,,ICSE Software Engineering
2-s2.0-85129509824,10.1145/3510003.3510138,,,Diversity-Driven Automated Formal Verification,cp,Conference Paper,First E.,60014313,University of Massachusetts Amherst,Amherst,United States,2,"First, Emily;Brun, Yuriy",57220769807;23003307600,60014313;60014313,2022-01-01,2022,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2022-May,,,749-761,"Formally verified correctness is one of the most desirable properties of software systems. But despite great progress made via interactive theorem provers, such as Coq, writing proof scripts for verification remains one of the most effort-intensive (and often prohibitively difficult) software development activities. Recent work has created tools that automatically synthesize proofs or proof scripts. For example, CoqHammer can prove 26.6% of theorems completely automatically by reasoning using precomputed facts, while TacTok and ASTactic, which use machine learning to model proof scripts and then perform biased search through the proof-script space, can prove 12.9% and 12.3% of the theorems, respectively. Further, these three tools are highly complementary; together, they can prove 30.4% of the theorems fully automatically. Our key insight is that control over the learning process can produce a diverse set of models, and that, due to the unique nature of proof synthesis (the existence of the theorem prover, an oracle that infallibly judges a proof's correctness), this diversity can significantly improve these tools' proving power. Accordingly, we develop Diva, which uses a diverse set of models with TacTok's and ASTactic's search mech-anism to prove 21.7% of the theorems. That is, Diva proves 68% more theorems than TacTok and 77% more than ASTactic. Complementary to CoqHammer, Diva proves 781 theorems (27% added value) that CoqHammer does not, and 364 theorems no existing tool has proved automatically. Together with CoqHammer, Diva proves 33.8% of the theorems, the largest fraction to date. We explore nine dimensions for learning diverse models, and identify which dimensions lead to the most useful diversity. Further, we develop an optimization to speed up Diva's execution by 40×. Our study introduces a completely new idea for using diversity in machine learning to improve the power of state-of-the-art proof-script synthesis techniques, and empirically demonstrates that the improvement is significant on a dataset of 68K theorems from 122 open-source software projects.",Automated formal verification | Coq | interactive proof assistants | language models | proof synthesis,8,0,,,NSF,CCF-1763423,National Science Foundation,ICSE Software Engineering
2-s2.0-85163116548,,,,Do Differentiable Simulators Give Better Policy Gradients?,cp,Conference Paper,Suh H.J.T.,60141072,MIT Department of Electrical Engineering and Computer Science,Cambridge,United States,4,"Suh, H. J.Terry;Simchowitz, Max;Zhang, Kaiqing;Tedrake, Russ",57219586873;57192165585;57190579283;6507809929,60141072;60141072;60141072;60141072,2022-01-01,2022,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,162,,,20668-20696,"Differentiable simulators promise faster computation time for reinforcement learning by replacing zeroth-order gradient estimates of a stochastic objective with an estimate based on first-order gradients. However, it is yet unclear what factors decide the performance of the two estimators on complex landscapes that involve long-horizon planning and control on physical systems, despite the crucial relevance of this question for the utility of differentiable simulators. We show that characteristics of certain physical systems, such as stiffness or discontinuities, may compromise the efficacy of the first-order estimator, and analyze this phenomenon through the lens of bias and variance. We additionally propose an α-order gradient estimator, with α ∈ [0, 1], which correctly utilizes exact gradients to combine the efficiency of first-order estimates with the robustness of zero-order methods. We demonstrate the pitfalls of traditional estimators and the advantages of the α-order estimator on some numerical examples.",,16,0,,,NSF,EFMA-1830901,National Science Foundation,ICML Machine Learning
2-s2.0-85127832672,10.1145/3510003.3510188,,,Efficient Online Testing for DNN-Enabled Systems using Surrogate-Assisted and Many-Objective Optimization,cp,Conference Paper,Haq F.U.,60072562;60028897,University of Luxembourg;University of Ottawa,Esch-sur-Alzette;Ottawa,Luxembourg;Canada,3,"Haq, Fitash Ul;Shin, Donghwan;Briand, Lionel",57219181785;55416512700;7006613079,60072562;60072562;60072562-60028897,2022-01-01,2022,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2022-May,,,811-822,"With the recent advances of Deep Neural Networks (DNNs) in real-world applications, such as Automated Driving Systems (ADS) for self-driving cars, ensuring the reliability and safety of such DNN-enabled Systems emerges as a fundamental topic in software testing. One of the essential testing phases of such DNN-enabled systems is online testing, where the system under test is embedded into a specific and often simulated application environment (e.g., a driving environment) and tested in a closed-loop mode in interaction with the environment. However, despite the importance of online testing for detecting safety violations, automatically generating new and diverse test data that lead to safety violations presents the following challenges: (1) there can be many safety requirements to be considered at the same time, (2) running a high-fidelity simulator is often very computationally-intensive, and (3) the space of all possible test data that may trigger safety violations is too large to be exhaustively explored. In this paper, we address the challenges by proposing a novel approach, called SAMOTA (Surrogate-Assisted Many-Objective Testing Approach), extending existing many-objective search algorithms for test suite generation to efficiently utilize surrogate models that mimic the simulator, but are much less expensive to run. Empirical evaluation results on Pylot, an advanced ADS composed of multiple DNNs, using CARLA, a high-fidelity driving simulator, show that SAMOTA is significantly more effective and efficient at detecting unknown safety requirement violations than state-of-the-art many-objective test suite generation algorithms and random search. In other words, SAMOTA appears to be a key enabler technology for online testing in practice.",DNN testing | many-objective search | online testing | self-driving cars | surrogate-assisted optimization,25,1,publisherfree2read,Bronze,ERC,694277,European Research Council,ICSE Software Engineering
2-s2.0-85163219060,,,,Elucidating the Design Space of Diffusion-Based Generative Models,cp,Conference Paper,Karras T.,60076695,NVIDIA,Santa Clara,United States,4,"Karras, Tero;Aittala, Miika;Aila, Timo;Laine, Samuli",36022486900;35104427100;56007617800;56276032900,60076695;60076695;60076695;60076695,2022-01-01,2022,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,35,,,,"We argue that the theory and practice of diffusion-based generative models are currently unnecessarily convoluted and seek to remedy the situation by presenting a design space that clearly separates the concrete design choices. This lets us identify several changes to both the sampling and training processes, as well as preconditioning of the score networks. Together, our improvements yield new state-of-the-art FID of 1.79 for CIFAR-10 in a class-conditional setting and 1.97 in an unconditional setting, with much faster sampling (35 network evaluations per image) than prior designs. To further demonstrate their modular nature, we show that our design changes dramatically improve both the efficiency and quality obtainable with pre-trained score networks from previous work, including improving the FID of a previously trained ImageNet-64 model from 2.07 to near-SOTA 1.55, and after re-training with our proposed improvements to a new SOTA of 1.36.",,66,0,,,,undefined,,NeurIPS Machine Learning
2-s2.0-85130557152,10.1145/3491102.3501920,,,EmoBalloon - Conveying Emotional Arousal in Text Chats with Speech Balloons,cp,Conference Paper,Aoki T.,60025272;60010484,The University of Tokyo;Samsung Group,Tokyo;Suwon,Japan;South Korea,5,"Aoki, Toshiki;Chujo, Rintaro;Matsui, Katsufumi;Choi, Saemi;Hautasaari, Ari",57703673600;57704597400;55646652800;56442936400;36554254500,60025272;60025272;60025272;60010484;60025272,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,527,,"Text chat applications are an integral part of daily social and professional communication. However, messages sent over text chat applications do not convey vocal or nonverbal information from the sender, and detecting the emotional tone in text-only messages is challenging. In this paper, we explore the effects of speech balloon shapes on the sender-receiver agreement regarding the emotionality of a text message. We first investigated the relationship between the shape of a speech balloon and the emotionality of speech text in Japanese manga. Based on these results, we created a system that automatically generates speech balloons matching linear emotional arousal intensity by Auxiliary Classifier Generative Adversarial Networks (ACGAN). Our evaluation results from a controlled experiment suggested that the use of emotional speech balloons outperforms the use of emoticons in decreasing the differences between message senders' and receivers' perceptions about the level of emotional arousal in text messages.",emotion | speech balloon | text chat | voice input,14,1,publisherfree2read,Bronze,KAKEN,JP18K18085,Japan Society for the Promotion of Science,CHI Human-Computer Interaction
2-s2.0-85132309560,10.1145/3519939.3523427,,,Finding typing compiler bugs,cp,Conference Paper,Chaliasos S.,60028900;60019507;60015150;60006288,National and Kapodistrian University of Athens;Athens University of Economics and Business;Imperial College London;Delft University of Technology,Athens;Athens;London;Delft,Greece;Greece;United Kingdom;Netherlands,6,"Chaliasos, Stefanos;Sotiropoulos, Thodoris;Spinellis, Diomidis;Gervais, Arthur;Livshits, Benjamin;Mitropoulos, Dimitris",57211992749;57210115278;35566637400;56226039300;12139816400;36886013800,60015150;60019507;60019507-60006288;60015150;60015150;60028900,2022-06-09,9 June 2022,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,183-198,"We propose a testing framework for validating static typing procedures in compilers. Our core component is a program generator suitably crafted for producing programs that are likely to trigger typing compiler bugs. One of our main contributions is that our program generator gives rise to transformation-based compiler testing for finding typing bugs. We present two novel approaches (type erasure mutation and type overwriting mutation) that apply targeted transformations to an input program to reveal type inference and soundness compiler bugs respectively. Both approaches are guided by an intra-procedural type inference analysis used to capture type information flow. We implement our techniques as a tool, which we call Hephaestus. The extensibility of Hephaestus enables us to test the compilers of three popular JVM languages: Java, Kotlin, and Groovy. Within nine months of testing, we have found 156 bugs (137 confirmed and 85 fixed) with diverse manifestations and root causes in all the examined compilers. Most of the discovered bugs lie in the heart of many critical components related to static typing, such as type inference.",compiler bugs | compiler testing | Groovy | Java | Kotlin | static typing,7,0,repositoryvor,Green,H2020,825328,Horizon 2020 Framework Programme,PLDI Programming Languages
2-s2.0-85143064393,10.1145/3540250.3549177,,,First come first served: the impact of file position on code review,cp,Conference Paper,Fregnan E.,60012614;60006824;60001490;128930656,Universität Zürich;Università della Svizzera italiana;University of Glasgow;CodeLounge at Software Institute,Zurich;Lugano;Glasgow;,Switzerland;Switzerland;United Kingdom;Switzerland,5,"Fregnan, Enrico;Braz, Larissa;D'Ambros, Marco;Çallkll, Gül;Bacchelli, Alberto",57204930710;57192095353;18433643500;57987961200;25924697100,60012614;60012614;128930656-60006824;60001490;60012614,2022-11-07,7 November 2022,ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101123502,,Conference Proceeding,,,,483-494,"The most popular code review tools (e.g., Gerrit and GitHub) present the files to review sorted in alphabetical order. Could this choice or, more generally, the relative position in which a file is presented bias the outcome of code reviews? We investigate this hypothesis by triangulating complementary evidence in a two-step study. First, we observe developers' code review activity. We analyze the review comments pertaining to 219,476 Pull Requests (PRs) from 138 popular Java projects on GitHub. We found files shown earlier in a PR to receive more comments than files shown later, also when controlling for possible confounding factors: e.g., the presence of discussion threads or the lines added in a file. Second, we measure the impact of file position on defect finding in code review. Recruit- ing 106 participants, we conduct an online controlled experiment in which we measure participants' performance in detecting two unrelated defects seeded into two different files. Participants are assigned to one of two treatments in which the position of the defective files is switched. For one type of defect, participants are not affected by its file's position; for the other, they have 64% lower odds to identify it when its file is last as opposed to first. Overall, our findings provide evidence that the relative position in which files are presented has an impact on code reviews' outcome; we discuss these results and implications for tool design and code review.",Code Review | Cognitive Bias | Controlled Experiment,2,1,repositoryam,Green,SNF,187353,Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung,FSE Software Engineering
2-s2.0-85126948727,10.1109/SP46214.2022.9833666,,,Four Attacks and a Proof for Telegram,cp,Conference Paper,Albrecht M.R.,60025858;60020595,"ETH Zürich;Royal Holloway, University of London",Zurich;Egham,Switzerland;United Kingdom,4,"Albrecht, Martin R.;Marekova, Lenka;Paterson, Kenneth G.;Stepanovs, Igors",57194093186;57193608448;7005696468;56441712600,60020595;60020595;60025858;60025858,2022-01-01,2022,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2022-May,,,87-106,"We study the use of symmetric cryptography in the MTProto 2.0 protocol, Telegram's equivalent of the TLS record protocol. We give positive and negative results. On the one hand, we formally and in detail model a slight variant of Telegram's 'record protocol' and prove that it achieves security in a suitable bidirectional secure channel model, albeit under unstudied assumptions; this model itself advances the state-of-the-art for secure channels. On the other hand, we first motivate our modelling deviation from MTProto as deployed by giving two attacks - one of practical, one of theoretical interest - against MTProto without our modifications. We then also give a third attack exploiting timing side channels, of varying strength, in three official Telegram clients. On its own this attack is thwarted by the secrecy of salt and id fields that are established by Telegram's key exchange protocol. To recover these, we chain the third attack with a fourth one against the implementation of the key exchange protocol on Telegram's servers. In totality, our results provide the first comprehensive study of MTProto's use of symmetric cryptography.",,14,0,repositoryam,Green,EPSRC,EP/P009301/1,Engineering and Physical Sciences Research Council,S&P Security and Privacy
2-s2.0-85163081248,,,,G-Mixup: Graph Data Augmentation for Graph Classification,cp,Conference Paper,Han X.,60150231;60148980;60148288,University of Georgia School of Computing;College of Engineering;George R. Brown School of Engineering,Athens;College Station;Houston,United States;United States;United States,4,"Han, Xiaotian;Jiang, Zhimeng;Liu, Ninghao;Hu, Xia",57458237100;57201520949;57191072267;35114937200,60148980;60148980;60150231;60148288,2022-01-01,2022,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,162,,,8230-8248,"This work develops mixup for graph data. Mixup has shown superiority in improving the generalization and robustness of neural networks by interpolating features and labels between two random samples. Traditionally, Mixup can work on regular, grid-like, and Euclidean data such as image or tabular data. However, it is challenging to directly adopt Mixup to augment graph data because different graphs typically: 1) have different numbers of nodes; 2) are not readily aligned; and 3) have unique typologies in non-Euclidean space. To this end, we propose G-Mixup to augment graphs for graph classification by interpolating the generator (i.e., graphon) of different classes of graphs. Specifically, we first use graphs within the same class to estimate a graphon. Then, instead of directly manipulating graphs, we interpolate graphons of different classes in the Euclidean space to get mixed graphons, where the synthetic graphs are generated through sampling based on the mixed graphons. Extensive experiments show that G-Mixup substantially improves the generalization and robustness of GNNs.",,27,0,,,NSF,IIS-1750074,National Science Foundation,ICML Machine Learning
2-s2.0-85147904407,,,,Gradient Estimation with Discrete Stein Operators,cp,Conference Paper,Shi J.,60111161;60025278;60021726;60012708,DeepMind Technologies Limited;Tsinghua University;Microsoft Research;Stanford University,London;Beijing;Redmond;Stanford,United Kingdom;China;United States;United States,5,"Shi, Jiaxin;Zhou, Yuhao;Hwang, Jessica;Titsias, Michalis K.;Mackey, Lester",57192174048;57219740311;57205153890;6603225248;57214520890,60012708;60025278;60012708;60111161;60021726,2022-01-01,2022,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,35,,,,"Gradient estimation-approximating the gradient of an expectation with respect to the parameters of a distribution-is central to the solution of many machine learning problems. However, when the distribution is discrete, most common gradient estimators suffer from excessive variance. To improve the quality of gradient estimation, we introduce a variance reduction technique based on Stein operators for discrete distributions. We then use this technique to build flexible control variates for the REINFORCE leave-one-out estimator. Our control variates can be adapted online to minimize variance and do not require extra evaluations of the target function. In benchmark generative modeling tasks such as training binary variational autoencoders, our gradient estimator achieves substantially lower variance than state-of-the-art estimators with the same number of function evaluations.",,4,0,,,,undefined,,NeurIPS Machine Learning
2-s2.0-85130443016,,,,Graham: Synchronizing Clocks by Leveraging Local Clock Properties,cp,Conference Paper,Meta A.N.,60103987,"VMware, Inc",Palo Alto,United States,2,"Meta, Ali Najafi;Wei, Michael",57948603400;55826154400,60103987;60103987,2022-01-01,2022,"Proceedings of the 19th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2022",,21101117460,,Conference Proceeding,,,,453-466,"High performance, strongly consistent applications are beginning to require scalable sub-microsecond clock synchronization. State-of-the-art clock synchronization focuses on improving accuracy or frequency of synchronization, ignoring the properties of the local clock: lost of connectivity to the remote clock means synchronization failure. Our system, Graham, leverages the fact that the local clock still keeps time even when connectivity is lost and builds a failure model using the characteristics of the local clock and the desired synchronization accuracy. Graham characterizes the local clock using commodity sensors present in nearly every server and leverages this data to further improve clock accuracy, increasing the tolerance of Graham to failures. Graham reduces the clock drift of a commodity server by up to 2000×, reducing the maximum assumed drift in most situations from 200ppm to 100ppb.",,8,0,,,,undefined,,NSDI Networking
2-s2.0-85141552955,10.1145/3526113.3545620,,,"Grid-Coding: An Accessible, Efficient, and Structured Coding Paradigm for Blind and Low-Vision Programmers",cp,Conference Paper,Ehtesham-Ul-Haque M.,60021158;60001439,Bangladesh University of Engineering and Technology;Pennsylvania State University,Dhaka;University Park,Bangladesh;United States,3,"Ehtesham-Ul-Haque, Md;Monsur, Syed Mostofa;Billah, Syed Masum",55711823500;57221601772;56022850400,60001439;60021158;60001439,2022-10-29,29 October 2022,UIST 2022 - Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology,,21101119907,,Conference Proceeding,,,44,,"Sighted programmers often rely on visual cues (e.g., syntax coloring, keyword highlighting, code formatting) to perform common coding activities in text-based languages (e.g., Python). Unfortunately, blind and low-vision (BLV) programmers hardly benefit from these visual cues because they interact with computers via assistive technologies (e.g., screen readers), which fail to communicate visual semantics meaningfully. Prior work on making text-based programming languages and environments accessible mostly focused on code navigation and, to some extent, code debugging, but not much toward code editing, which is an essential coding activity. We present Grid-Coding to fill this gap. Grid-Coding renders source code in a structured 2D grid, where each row, column, and cell have consistent, meaningful semantics. Its design is grounded on prior work and refined by 28 BLV programmers through online participatory sessions for 2 months. We implemented the Grid-Coding prototype as a spreadsheet-like web application for Python and evaluated it with a study with 12 BLV programmers. This study revealed that, compared to a text editor (i.e., the go-to editor for BLV programmers), our prototype enabled BLV programmers to navigate source code quickly, find the context of a statement easily, detect syntax errors in existing code effectively, and write new code with fewer syntax errors. The study also revealed how BLV programmers adopted Grid-Coding and demonstrated novel interaction patterns conducive to increased programming productivity.",Accessibility | assistive technology | blind and low-vision | code reading | code writing | grid-coding | programmers. | programming languages | Python | screen readers | text-based programming languages,4,0,,,NIH,87527/2/1159967,National Institutes of Health,UIST User Interface
2-s2.0-85126198901,10.14778/3489496.3489511,,,HET: Scaling out Huge Embedding Model Training via Cache-enabled Distributed Framework,cp,Conference Paper,Miao X.,60114181;60014966,Tencent;Peking University,Shenzhen;Beijing,China;China,7,"Miao, Xupeng;Zhang, Hailin;Shi, Yining;Nie, Xiaonan;Yang, Zhi;Tao, Yangyu;Cui, Bin",57210122795;57382510100;57383391800;57225025148;56101984100;57223766297;57211734542,60014966;60014966;60014966;60014966;60014966;60114181;60014966,2021-01-01,2021,Proceedings of the VLDB Endowment,,21100199855,21508097,Journal,15,2,,312-320,"Embedding models have been an effective learning paradigm for high-dimensional data. However, one open issue of embedding models is that their representations (latent factors) often result in large parameter space. We observe that existing distributed training frameworks face a scalability issue of embedding models since updating and retrieving the shared embedding parameters from servers usually dominates the training cycle. In this paper, we propose HET, a new system framework that significantly improves the scalability of huge embedding model training. We embrace skewed popularity distributions of embeddings as a performance opportunity and leverage it to address the communication bottleneck with an embedding cache. To ensure consistency across the caches, we incorporate a new consistency model into HET design, which provides fine-grained consistency guarantees on a per-embedding basis. Compared to previous work that only allows staleness for read operations, HET also utilizes staleness for write operations. Evaluations on six representative tasks show that HET achieves up to 88% embedding communication reductions and up to 20.68⇥performance speedup over the state-of-the-art baselines.",,26,0,repositoryam,Green,NSFC,2019BD006,National Natural Science Foundation of China,VLDB Databases
2-s2.0-85137985629,10.14778/3554821.3554822,,,Hardware Acceleration of Compression and Encryption in SAP HANA,cp,Conference Paper,Chiosa Monica.Chiosa@Inf.Ethz.Ch M.,60072347;60025858,SAP SE;ETH Zürich,Walldorf;Zurich,Germany;Switzerland,5,"Chiosa Monica.Chiosa@Inf.Ethz.Ch, Monica;Maschi Fabio.Maschi@Inf.Ethz.Ch, Fabio;Müller, Ingo;Alonso, Gustavo;May, Norman",57217096769;57217101132;57197918389;7102787521;35096497700,60025858;60025858;60025858;60025858;60072347,2022-01-01,2022,Proceedings of the VLDB Endowment,,21100199855,21508097,Journal,15,12,,3277-3291,"With the advent of cloud computing, where computational resources are expensive and data movement needs to be secured and minimized, database management systems need to reconsider their architecture to accommodate such requirements. In this paper, we present our analysis, design and evaluation of an FPGA-based hardware accelerator for offloading compression and encryption for SAP HANA, SAP’s Software-as-a-Service (SaaS) in-memory database. Firstly, we identify expensive data-transformation operations in the I/O path. Then we present the design details of a system consisting of compression followed by different types of encryption to accommodate different security levels, and identify which combinations maximize performance. We also analyze the performance benefits of offloading decryption to the FPGA followed by decompression on the CPU. The experimental evaluation using SAP HANA traces shows that analytical engines can benefit from FPGA hardware offloading. The results identify a number of important trade-offs (e.g., the system can accommodate low-latency secured transactions to high-performance use cases or offer lower storage cost by also compressing payloads for less critical use cases), and provide valuable information to researchers and practitioners exploring the nascent space of hardware accelerators for database engines.",,5,0,repositoryam,Green,,undefined,Intel Corporation,VLDB Databases
2-s2.0-85140831248,10.1145/3511808.3557344,,,D-HYPR: Harnessing Neighborhood Modeling and Asymmetry Preservation for Digraph Representation Learning,cp,Conference Paper,Zhou H.,60119141;60106550,Rutgers University–New Brunswick;Hasso-Plattner-Institut für Softwaresystemtechnik GmbH,New Brunswick;Potsdam,United States;Germany,6,"Zhou, Honglu;Chegu, Advith;Sohn, Samuel S.;Fu, Zuohui;De Melo, Gerard;Kapadia, Mubbasir",57211680109;57387492100;57204160338;57209224010;23088528100;25928381400,60119141;60119141;60119141;60119141;60106550;60119141,2022-10-17,17 October 2022,"International Conference on Information and Knowledge Management, Proceedings",,21101117254,,Conference Proceeding,,,,2732-2742,"Digraph Representation Learning (DRL) aims to learn representations for directed homogeneous graphs (digraphs). Prior work in DRL is largely constrained (e.g., limited to directed acyclic graphs), or has poor generalizability across tasks (e.g., evaluated solely on one task). Most Graph Neural Networks (GNNs) exhibit poor performance on digraphs due to the neglect of modeling neighborhoods and preserving asymmetry. In this paper, we address these notable challenges by leveraging hyperbolic collaborative learning from multi-ordered and partitioned neighborhoods, and regularizers inspired by socio-psychological factors. Our resulting formalism, Digraph Hyperbolic Networks (D-HYPR) - albeit conceptually simple - generalizes to digraphs where cycles and non-transitive relations are common, and is applicable to multiple downstream tasks including node classification, link presence prediction, and link property prediction. In order to assess the effectiveness of D-HYPR, extensive evaluations were performed across 8 real-world digraph datasets involving 21 prior techniques. D-HYPR statistically significantly outperforms the current state of the art. We release our code at https://github.com/hongluzhou/dhypr.",benchmark | directed homogeneous graphs | edge attribute prediction | graph neural networks | link prediction | node classification,1,0,,,NSF,EAGER-2122119,National Science Foundation,CIKM Knowledge Management
2-s2.0-85163166690,,,,High-dimensional limit theorems for SGD: Effective dynamics and critical scaling,cp,Conference Paper,Arous G.B.,60025038;60014171;60003261,"University of California, Berkeley;University of Waterloo;Courant Institute of Mathematical Sciences",Berkeley;Waterloo;New York,United States;Canada;United States,3,"Arous, Gérard Ben;Gheissari, Reza;Jagannath, Aukosh",6701615703;56026024300;54402964300,60003261;60025038;60014171,2022-01-01,2022,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,35,,,,"We study the scaling limits of stochastic gradient descent (SGD) with constant stepsize in the high-dimensional regime. We prove limit theorems for the trajectories of summary statistics (i.e., finite-dimensional functions) of SGD as the dimension goes to infinity. Our approach allows one to choose the summary statistics that are tracked, the initialization, and the step-size. It yields both ballistic (ODE) and diffusive (SDE) limits, with the limit depending dramatically on the former choices. We find a critical scaling regime for the step-size below which this “effective dynamics"" matches gradient flow for the population loss, but at which, a new correction term appears which changes the phase diagram. About the fixed points of this effective dynamics, the corresponding diffusive limits can be quite complex and even degenerate. We demonstrate our approach on popular examples including estimation for spiked matrix and tensor models and classification via two-layer networks for binary and XOR-type Gaussian mixture models. These examples exhibit surprising phenomena including multimodal timescales to convergence as well as convergence to sub-optimal solutions with probability bounded away from zero from random (e.g., Gaussian) initializations.",,3,0,,,MIBRS,DGECR-2020-00199,"Adolph C. and Mary Sprague Miller Institute for Basic Research in Science, University of California Berkeley",NeurIPS Machine Learning
2-s2.0-85135002385,10.1145/3528223.3530055,,,Image features influence reaction time: A Learned Probabilistic Perceptual Model for Saccade Latency,ar,Article,Duinkharjav B.,60076695;60021784;60003269,NVIDIA;New York University;Princeton University,Santa Clara;New York;Princeton,United States;United States;United States,5,"Duinkharjav, Budmonde;Chakravarthula, Praneeth;Brown, Rachel;Patney, Anjul;Sun, Qi",57425993200;57203309180;57226653085;25825420800;57190442743,60021784;60003269;60076695;60076695;60021784,2022-07-22,22 July 2022,ACM Transactions on Graphics,07300301,24972,15577368,Journal,41,4,3530055,,"We aim to ask and answer an essential question ""how quickly do we react after observing a displayed visual target?""To this end, we present psychophysical studies that characterize the remarkable disconnect between human saccadic behaviors and spatial visual acuity. Building on the results of our studies, we develop a perceptual model to predict temporal gaze behavior, particularly saccadic latency, as a function of the statistics of a displayed image. Specifically, we implement a neurologically-inspired probabilistic model that mimics the accumulation of confidence that leads to a perceptual decision. We validate our model with a series of objective measurements and user studies using an eye-tracked VR display. The results demonstrate that our model prediction is in statistical alignment with real-world human behavior. Further, we establish that many sub-threshold image modifications commonly introduced in graphics pipelines may significantly alter human reaction timing, even if the differences are visually undetectable. Finally, we show that our model can serve as a metric to predict and alter reaction latency of users in interactive computer graphics applications, thus may improve gaze-contingent rendering, design of virtual experiences, and player performance in e-sports. We illustrate this with two examples: estimating competition fairness in a video game with two different team colors, and tuning display viewing distance to minimize player reaction time.",Augmented reality | Esports | Gaze-contingent rendering | Human performance | Virtual reality | Visual perception,7,0,,,DARPA,undefined,Defense Advanced Research Projects Agency,SIGGRAPH Graphics
2-s2.0-85130529355,10.1145/3491102.3501867,,,Including the Experiences of Physically Disabled Players in Mainstream Guidelines for Movement-Based Games,cp,Conference Paper,Mason L.,60026830;60025063,University of Lincoln;KU Leuven,Lincoln;Leuven,United Kingdom;Belgium,6,"Mason, Liam;Gerling, Kathrin;Dickinson, Patrick;Holopainen, Jussi;Jacobs, Lisa;Hicks, Kieran",57209399867;51663369500;25821875000;24553631500;57198443834;56159931700,60026830;60025063;60026830;60026830;60026830;60026830,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,86,,"Movement-based video games can provide engaging play experiences, and also have the potential to encourage physical activity. However, existing design guidelines for such games overwhelmingly focus on non-disabled players. Here, we explore wheelchair users' perspectives on movement-based games as an enjoyable play activity. We created eight game concepts as discussion points for semi-structured interviews (N=6) with wheelchair users, and used Interpretative Phenomenological Analysis to understand their perspectives on physical activity and play. Themes focus on independent access, challenges in social settings, and the need for comprehensive adaptation. We also conducted an online survey (N=21) using the same game concepts, and thematic analysis highlighted the importance of adequate challenge, and considerations around multiplayer experiences. Based on these findings, we re-contextualize and expand guidelines for movement-based games previously established by Mueller and Isbister to include disabled players, and suggest design strategies that take into account their perspectives on play.",Game accessibility | game design | movement-based games,4,1,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85137620200,10.1145/3528223.3530127,,,Instant neural graphics primitives with a multiresolution hash encoding,ar,Article,Müller T.,60076695,NVIDIA,Santa Clara,United States,4,"Müller, Thomas;Evans, Alex;Schied, Christoph;Keller, Alexander",57220920031;57195402744;55860580300;57223626380,60076695;60076695;60076695;60076695,2022-07-22,22 July 2022,ACM Transactions on Graphics,07300301,24972,15577368,Journal,41,4,102,,"Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. We reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality, thus significantly reducing the number of floating point and memory access operations: a small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent. The multiresolution structure allows the network to disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern GPUs. We leverage this parallelism by implementing the whole system using fully-fused CUDA kernels with a focus on minimizing wasted bandwidth and compute operations. We achieve a combined speedup of several orders of magnitude, enabling training of high-quality neural graphics primitives in a matter of seconds, and rendering in tens of milliseconds at a resolution of 1920×1080.",encodings | function approximation | GPUs | hashing | image synthesis | neural networks | parallel computation,596,1,repositoryam,Green,,undefined,,SIGGRAPH Graphics
2-s2.0-85130578063,10.1145/3491102.3501970,,,Investigating Daily Practices of Self-care to Inform the Design of Supportive Health Technologies for Living and Ageing Well with HIV,cp,Conference Paper,Claisse C.,60112923;60006222;60001490,Terrence Higgins Trust;Newcastle University;University of Glasgow,London;Newcastle;Glasgow,United Kingdom;United Kingdom;United Kingdom,4,"Claisse, Caroline;Kasadha, Bakita;Stumpf, Simone;Durrant, Abigail C.",57189040093;57219607990;10239347500;23024725800,60006222;60112923;60001490;60006222,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,524,,"We report on a Diary Study investigating daily practices of Self-care by seven UK adults living with Human Immunodeficiency Virus (HIV), to understand their routines, experiences, needs and concerns, informing Self-care technology design to support living well. We advance a developing HCI literature evidencing how digital tools for self-managing health do not meet the complex needs of those living with long-term conditions, especially those from marginalised communities. Our evaluation of using a Self-care Diary as Design Probe responds to calls to study Self-care practices so that future digital health tools are better grounded in lived experiences of managing multi-morbidity. We contribute to HCI discourses including Personal Health Informatics, Lived Informatics and Reflection by illuminating psychosocial challenges for practicing and self-reporting on Self-care. We offer design implications from a Critical Digital Health perspective, addressing barriers to technology use related to trust, privacy, and representation, gaining new significance during the COVID-19 pandemic.",Diary Study | Long-term condition | Personal Health Informatics | Self-care,9,1,repositoryvor,Green,EPSRC,EP/R033900/2,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-85130570629,10.1145/3491102.3501908,,,Investigating the Tradeoffs of Everyday Text-Entry Collection Methods,cp,Conference Paper,Rodrigues A.,60006222;60004956;60004636;60002769,"Newcastle University;Instituto Superior Técnico;University of Northumbria;Faculdade de Ciências, Universidade de Lisboa",Newcastle;Lisbon;Newcastle;Lisbon,United Kingdom;Portugal;United Kingdom;Portugal,9,"Rodrigues, André;Nicolau, Hugo;Santos, André;Branco, Diogo;Rainey, Jay;Verweij, David;Smeddinck, Jan David;Montague, Kyle;Guerreiro, Tiago",56577139300;34881822600;57277151100;57209312138;57209398318;56254637800;35811152400;36701846300;23396568900,60002769;60004956;60002769;60002769;60006222;60006222;60006222;60004636;60002769,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,378,,"Typing on mobile devices is a common and complex task. The act of typing itself thereby encodes rich information, such as the typing method, the context it is performed in, and individual traits of the person typing. Researchers are increasingly using a selection or combination of experience sampling and passive sensing methods in real-world settings to examine typing behaviours. However, there is limited understanding of the effects these methods have on measures of input speed, typing behaviours, compliance, perceived trust and privacy. In this paper, we investigate the tradeoffs of everyday data collection methods. We contribute empirical results from a four-week field study (N=26). Here, participants contributed by transcribing, composing, passively having sentences analyzed and reflecting on their contributions. We present a tradeoff analysis of these data collection methods, discuss their impact on text-entry applications, and contribute a flexible research platform for in the wild text-entry studies.",data collection | in-the-wild | performance | text-entry | touch behaviours | trade-offs | user experience,3,1,publisherfree2read,Bronze,H2020,30347,Horizon 2020 Framework Programme,CHI Human-Computer Interaction
2-s2.0-85135884127,10.1109/SP46214.2022.9833718,,,Invisible Finger: Practical Electromagnetic Interference Attack on Touchscreen-based Electronic Devices,cp,Conference Paper,Shan H.,60027646;60013959,University System of New Hampshire;University of Florida,Durham;Gainesville,United States;United States,6,"Shan, Haoqi;Zhang, Boyi;Zhan, Zihao;Sullivan, Dean;Wang, Shuo;Jin, Yier",57201943643;57194406139;57204690568;56152108800;55773506400;57445790300,60013959;60013959;60013959;60027646;60013959;60013959,2022-01-01,2022,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2022-May,,,1246-1262,"Touchscreen-based electronic devices such as smart phones and smart tablets are widely used in our daily life. While the security of electronic devices have been heavily investigated recently, the resilience of touchscreens against various attacks has yet to be thoroughly investigated. In this paper, for the first time, we show that touchscreen-based electronic devices are vulnerable to intentional electromagnetic interference (IEMI) attacks in a systematic way and how to conduct this attack in a practical way. Our contribution lies in not just demonstrating the attack, but also analyzing and quantifying the underlying mechanism allowing the novel IEMI attack on touchscreens in detail. We show how to calculate both the minimum amount of electric field and signal frequency required to induce touchscreen ghost touches. We further analyze our IEMI attack on real touchscreens with different magnitudes, frequencies, duration, and multitouch patterns. The mechanism of controlling the touchscreen-enabled electronic devices with IEMI signals is also elaborated. We design and evaluate an out-of-sight touchscreen locator and touch injection feedback mechanism to assist a practical IEMI attack. Our attack works directly on the touchscreen circuit regardless of the touchscreen scanning mechanism or operating system. Our attack can inject short-tap, long-press, and omnidirectional gestures on touchscreens from a distance larger than the average thickness of common tabletops. Compared with the state-of-the-art touchscreen attack, ours can accurately inject different types of touch events without the need for sensing signal synchronization, which makes our attack more robust and practical. In addition, rather than showing a simple proof-of-concept attack, we present and demonstrate the first ready-to-use IEMI based touchscreen attack vector with end-to-end attack scenarios",,6,0,,,NSF,1818500,National Science Foundation,S&P Security and Privacy
2-s2.0-85163186180,,,,Is Out-of-Distribution Detection Learnable?,cp,Conference Paper,Fang Z.,60153202;60026553;60025858;60023932;60021474;60014347,"School of Computer, Data &amp; Information Sciences;University of Melbourne;ETH Zürich;University of Technology Sydney;Shenyang Institute of Automation Chinese Academy of Sciences;Hong Kong Baptist University",Madison;Melbourne;Zurich;Sydney;Shenyang;Hong Kong,United States;Australia;Switzerland;Australia;China;Hong Kong,6,"Fang, Zhen;Li, Yixuan;Lu, Jie;Dong, Jiahua;Han, Bo;Liu, Feng",57211269319;57188823744;7601559842;57215778780;57191281044;57118471000,60023932;60153202;60023932;60021474-60025858;60014347;60023932-60026553,2022-01-01,2022,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,35,,,,"Supervised learning aims to train a classifier under the assumption that training and test data are from the same distribution. To ease the above assumption, researchers have studied a more realistic setting: out-of-distribution (OOD) detection, where test data may come from classes that are unknown during training (i.e., OOD data). Due to the unavailability and diversity of OOD data, good generalization ability is crucial for effective OOD detection algorithms. To study the generalization of OOD detection, in this paper, we investigate the probably approximately correct (PAC) learning theory of OOD detection, which is proposed by researchers as an open problem. First, we find a necessary condition for the learnability of OOD detection. Then, using this condition, we prove several impossibility theorems for the learnability of OOD detection under some scenarios. Although the impossibility theorems are frustrating, we find that some conditions of these impossibility theorems may not hold in some practical scenarios. Based on this observation, we next give several necessary and sufficient conditions to characterize the learnability of OOD detection in some practical scenarios. Lastly, we also offer theoretical supports for several representative OOD detection works based on our OOD theory.",,22,0,,,AFOSR,22200720,Air Force Office of Scientific Research,NeurIPS Machine Learning
2-s2.0-85130520818,10.1145/3491102.3502004,,,Jury Learning: Integrating Dissenting Voices into Machine Learning Models,cp,Conference Paper,Gordon M.L.,60012708;60010449,Stanford University;Apple Computer,Stanford;Cupertino,United States;United States,7,"Gordon, Mitchell L.;Lam, Michelle S.;Park, Joon Sung;Patel, Kayur;Hancock, Jeff;Hashimoto, Tatsunori;Bernstein, Michael S.",56159595600;57193571557;57222403758;55435659300;7202389095;57202060550;57193014048,60012708;60012708;60012708;60010449;60012708;60012708;60012708,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,115,,"Whose labels should a machine learning (ML) algorithm learn to emulate? For ML tasks ranging from online comment toxicity to misinformation detection to medical diagnosis, different groups in society may have irreconcilable disagreements about ground truth labels. Supervised ML today resolves these label disagreements implicitly using majority vote, which overrides minority groups' labels. We introduce jury learning, a supervised ML approach that resolves these disagreements explicitly through the metaphor of a jury: defining which people or groups, in what proportion, determine the classifier's prediction. For example, a jury learning model for online toxicity might centrally feature women and Black jurors, who are commonly targets of online harassment. To enable jury learning, we contribute a deep learning architecture that models every annotator in a dataset, samples from annotators' models to populate the jury, then runs inference to classify. Our architecture enables juries that dynamically adapt their composition, explore counterfactuals, and visualize dissent. A field evaluation finds that practitioners construct diverse juries that alter 14% of classification outcomes.",,58,1,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85144879118,,,,KinyaBERT: a Morphology-aware Kinyarwanda Language Model,cp,Conference Paper,Nzeyimana A.,60014313;60007592,University of Massachusetts Amherst;Universitat Politécnica de Catalunya,Amherst;Barcelona,United States;Spain,2,"Nzeyimana, Antoine;Rubungo, Andre Niyongabo",57221317514;57339834700,60014313;60007592,2022-01-01,2022,Proceedings of the Annual Meeting of the Association for Computational Linguistics,0736587X,21101138302,,Conference Proceeding,1,,,5347-5363,"Pre-trained language models such as BERT have been successful at tackling many natural language processing tasks. However, the unsupervised sub-word tokenization methods commonly used in these models (e.g., byte-pair encoding - BPE) are sub-optimal at handling morphologically rich languages. Even given a morphological analyzer, naive sequencing of morphemes into a standard BERT architecture is inefficient at capturing morphological compositionality and expressing word-relative syntactic regularities. We address these challenges by proposing a simple yet effective two-tier BERT architecture that leverages a morphological analyzer and explicitly represents morphological compositionality. Despite the success of BERT, most of its evaluations have been conducted on high-resource languages, obscuring its applicability on low-resource languages. We evaluate our proposed method on the low-resource morphologically rich Kinyarwanda language, naming the proposed model architecture KinyaBERT. A robust set of experimental results reveal that KinyaBERT outperforms solid baselines by 2% in F1 score on a named entity recognition task and by 4.3% in average score of a machine-translated GLUE benchmark. KinyaBERT fine-tuning has better convergence and achieves more robust results on multiple tasks even in the presence of translation noise.",,19,0,,,TPU,undefined,Tomsk Polytechnic University,ACL Natural Language Processing
2-s2.0-85132253826,10.1145/3519939.3523722,,,Kleene algebra modulo theories: a framework for concrete KATs,cp,Conference Paper,Greenberg M.,60027392;60021726;60007776,Stevens Institute of Technology;Microsoft Research;Cornell University,Hoboken;Redmond;Ithaca,United States;United States;United States,3,"Greenberg, Michael;Beckett, Ryan;Campbell, Eric",56637167600;56354636800;57210109941,60027392;60021726;60007776,2022-06-09,9 June 2022,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,594-608,"Kleene algebras with tests (KATs) offer sound, complete, and decidable equational reasoning about regularly structured programs. Interest in KATs has increased greatly since NetKAT demonstrated how well extensions of KATs with domain-specific primitives and extra axioms apply to computer networks. Unfortunately, extending a KAT to a new domain by adding custom primitives, proving its equational theory sound and complete, and coming up with an efficient implementation is still an expert's task. Abstruse metatheory is holding back KAT's potential. We offer a fast path to a ""minimum viable model""of a KAT, formally or in code through our framework, Kleene algebra modulo theories (KMT). Given primitives and a notion of state, we can automatically derive a corresponding KAT's semantics, prove its equational theory sound and complete with respect to a tracing semantics (programs are denoted as traces of states), and derive a normalization-based decision procedure for equivalence checking. Our framework is based on pushback, a generalization of weakest preconditions that specifies how predicates and actions interact. We offer several case studies, showing tracing variants of theories from the literature (bitvectors, NetKAT) along with novel compositional theories (products, temporal logic, and sets). We derive new results over unbounded state, reasoning about monotonically increasing, unbounded natural numbers. Our OCaml implementation closely matches the theory: users define and compose KATs with the module system.",algebraic models | program equivalence | tracing semantics | verification,4,0,repositoryam,Green,,1703493,,PLDI Programming Languages
2-s2.0-85141220370,,,,Learned Incremental Representations for Parsing,cp,Conference Paper,Kitaev N.,60025038,"University of California, Berkeley",Berkeley,United States,3,"Kitaev, Nikita;Lu, Thomas;Klein, Dan",55569597900;58729771400;23009040500,60025038;60025038;60025038,2022-01-01,2022,Proceedings of the Annual Meeting of the Association for Computational Linguistics,0736587X,21101138302,,Conference Proceeding,1,,,3086-3095,"We present an incremental syntactic representation that consists of assigning a single discrete label to each word in a sentence, where the label is predicted using strictly incremental processing of a prefix of the sentence, and the sequence of labels for a sentence fully determines a parse tree. Our goal is to induce a syntactic representation that commits to syntactic choices only as they are incrementally revealed by the input, in contrast with standard representations that must make output choices such as attachments speculatively and later throw out conflicting analyses. Our learned representations achieve 93.72 F1 on the Penn Treebank with as few as 5 bits per word, and at 8 bits per word they achieve 94.97 F1, which is comparable with other state of the art parsing models when using the same pre-trained embeddings. We also provide an analysis of the representations learned by our system, investigating properties such as the interpretable syntactic features captured by the system and mechanisms for deferred resolution of syntactic ambiguities.",,9,0,,,DARPA,undefined,Defense Advanced Research Projects Agency,ACL Natural Language Processing
2-s2.0-85137140960,10.1145/3534678.3539299,,,Learning Causal Effects on Hypergraphs,cp,Conference Paper,Ma J.,60026532;60021918,Microsoft Corporation;University of Virginia,Redmond;Charlottesville,United States;United States,6,"Ma, Jing;Wan, Mengting;Yang, Longqi;Li, Jundong;Hecht, Brent;Teevan, Jaime",57217247075;57423454500;57118384500;56186042700;24824723600;57207527470,60021918;60026532;60026532;60021918;60026532;60026532,2022-08-14,14 August 2022,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,21101105038,,Conference Proceeding,,,,1202-1212,"Hypergraphs provide an effective abstraction for modeling multi-way group interactions among nodes, where each hyperedge can connect any number of nodes. Different from most existing studies which leverage statistical dependencies, we study hypergraphs from the perspective of causality. Specifically, in this paper, we focus on the problem of individual treatment effect (ITE) estimation on hypergraphs, aiming to estimate how much an intervention (e.g., wearing face covering) would causally affect an outcome (e.g., COVID-19 infection) of each individual node. Existing works on ITE estimation either assume that the outcome on one individual should not be influenced by the treatment assignments on other individuals (i.e., no interference), or assume the interference only exists between pairs of connected individuals in an ordinary graph. We argue that these assumptions can be unrealistic on real-world hypergraphs, where higher-order interference can affect the ultimate ITE estimations due to the presence of group interactions. In this work, we investigate high-order interference modeling, and propose a new causality learning framework powered by hypergraph neural networks. Extensive experiments on real-world hypergraphs verify the superiority of our framework over existing baselines.",causal inference | graph mining | hypergraph | interference,18,1,repositoryam,Green,,undefined,,KDD Data Mining
2-s2.0-85163137388,,,,Learning Mixtures of Linear Dynamical Systems,cp,Conference Paper,Chen Y.,60141284,School of Engineering and Applied Science,Princeton,United States,2,"Chen, Yanxi;Poor, H. Vincent",57195552368;55665272100,60141284;60141284,2022-01-01,2022,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,162,,,3507-3557,"We study the problem of learning a mixture of multiple linear dynamical systems (LDSs) from unlabeled short sample trajectories, each generated by one of the LDS models. Despite the wide applicability of mixture models for time-series data, learning algorithms that come with end-to-end performance guarantees are largely absent from existing literature. There are multiple sources of technical challenges, including but not limited to (1) the presence of latent variables (i.e. the unknown labels of trajectories); (2) the possibility that the sample trajectories might have lengths much smaller than the dimension d of the LDS models; and (3) the complicated temporal dependence inherent to time-series data. To tackle these challenges, we develop a two-stage meta-algorithm, which is guaranteed to efficiently recover each ground-truth LDS model up to error Oe(pd/T), where T is the total sample size. We validate our theoretical studies with numerical experiments, confirming the efficacy of the proposed algorithm.",,5,0,,,NSF,CCF-1907661,National Science Foundation,ICML Machine Learning
2-s2.0-85140997670,,,,Learning to Communicate Effectively Between Battery-free Devices,cp,Conference Paper,Geissdoerfer K.,60018353,Technische Universität Dresden,Dresden,Germany,2,"Geissdoerfer, Kai;Zimmerling, Marco",57193006263;24726205900,60018353;60018353,2022-01-01,2022,"Proceedings of the 19th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2022",,21101117460,,Conference Proceeding,,,,419-435,"Successful wireless communication requires that sender and receiver are operational at the same time. This requirement is difficult to satisfy in battery-free networks, where the energy harvested from ambient sources varies across time and space and is often too weak to continuously power the devices. We present Bonito, the first connection protocol for battery-free systems that enables reliable and efficient bi-directional communication between intermittently powered nodes. We collect and analyze real-world energy-harvesting traces from five diverse scenarios involving solar panels and piezoelectric harvesters, and find that the nodes' charging times approximately follow well-known distributions. Bonito learns a model of these distributions online and adapts the nodes' wake-up times so that sender and receiver are operational at the same time, enabling successful communication. Experiments with battery-free prototype nodes built from off-the-shelf hardware components demonstrate that our design improves the average throughput by 10-80× compared with the state of the art.",,13,0,,,DFG,ZI 1635/2-1,Deutsche Forschungsgemeinschaft,NSDI Networking
2-s2.0-85140866754,10.1109/CVPR52688.2022.00545,,,Learning to Solve Hard Minimal Problems,cp,Conference Paper,Hruby P.,60116823;60025858;60019647;127926811,"Czech Institute of Informatics, Robotics and Cybernetics;ETH Zürich;Georgia Institute of Technology;University of Washington",Prague;Zurich;Atlanta;Jackson,Czech Republic;Switzerland;United States;United States,4,"Hruby, Petr;Duff, Timothy;Leykin, Anton;Pajdla, Tomas",58599842900;57197706464;57203136332;6602477957,60025858;127926811;60019647;60116823,2022-01-01,2022,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,2022-June,,,5522-5532,"We present an approach to solving hard geometric optimization problems in the RANSAC framework. The hard minimal problems arise from relaxing the original geometric optimization problem into a minimal problem with many spurious solutions. Our approach avoids computing large numbers of spurious solutions. We design a learning strategy for selecting a starting problem-solution pair that can be numerically continued to the problem and the solution of interest. We demonstrate our approach by developing a RANSAC solver for the problem of computing the relative pose of three calibrated cameras, via a minimal relaxation using four points in each view. On average, we can solve a single problem in under 70μ s. We also benchmark and study our engineering choices on the very familiar problem of computing the relative pose of two calibrated cameras, via the minimal case of five points in two views.",3D from multi-view and sensors | Photogrammetry and remote sensing,12,0,repositoryam,Green,NSF,CZ.02.1.01/0.0/0.0/15 003/0000468,National Science Foundation,CVPR Computer Vision
2-s2.0-85132737866,10.1145/3519935.3520024,,,"Locally testable codes with constant rate, distance, and locality",cp,Conference Paper,Dinur I.,60017563;60007903,Weizmann Institute of Science Israel;Hebrew University of Jerusalem,Rehovot;Jerusalem,Israel;Israel,5,"Dinur, Irit;Evra, Shai;Livne, Ron;Lubotzky, Alexander;Mozes, Shahar",57204335213;57188977073;6602591028;6701824083;7006223394,60017563;60007903;60007903;60017563;60007903,2022-09-06,6 September 2022,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,357-374,"A locally testable code (LTC) is an error correcting code that has a property-tester. The tester reads q bits that are randomly chosen, and rejects words with probability proportional to their distance from the code. The parameter q is called the locality of the tester. LTCs were initially studied as important components of probabilistically checkable proofs (PCP), and since then the topic has evolved on its own. High rate LTCs could be useful in practice: before attempting to decode a received word, one can save time by first quickly testing if it is close to the code. An outstanding open question has been whether there exist ""c3-LTCs"", namely LTCs with constant rate, constant distance, and constant locality. In this work we construct such codes based on a new two-dimensional complex which we call a left-right Cayley complex. This is essentially a graph which, in addition to vertices and edges, also has squares. Our codes can be viewed as a two-dimensional version of (the one-dimensional) expander codes, where the codewords are functions on the squares rather than on the edges.",error correcting codes | expander codes | locally testable codes,13,0,repositoryam,Green,IAS,2019/19,Institute for Advanced Study,STOC Theory
2-s2.0-85132245049,10.1145/3519939.3523440,,,"Low-latency, high-throughput garbage collection",cp,Conference Paper,Zhao W.,60008950;60006191,The Australian National University;Google LLC,Canberra;Mountain View,Australia;United States,3,"Zhao, Wenyu;Blackburn, Stephen M.;McKinley, Kathryn S.",57216222025;7101747600;35583751400,60008950;60008950;60006191,2022-06-09,9 June 2022,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,76-91,"To achieve short pauses, state-of-the-art concurrent copying collectors such as C4, Shenandoah, and ZGC use substantially more CPU cycles and memory than simpler collectors. They suffer from design limitations: i) concurrent copying with inherently expensive read and write barriers, ii) scalability limitations due to tracing, and iii) immediacy limitations for mature objects that impose memory overheads. This paper takes a different approach to optimizing responsiveness and throughput. It uses the insight that regular, brief stop-the-world collections deliver sufficient responsiveness at greater efficiency than concurrent evacuation. It introduces LXR, where stop-the-world collections use reference counting (RC) and judicious copying. RC delivers scalability and immediacy, promptly reclaiming young and mature objects. RC, in a hierarchical Immix heap structure, reclaims most memory without any copying. Occasional concurrent tracing identifies cyclic garbage. LXR introduces: i) RC remembered sets for judicious copying of mature objects; ii) a novel low-overhead write barrier that combines coalescing reference counting, concurrent tracing, and remembered set maintenance; iii) object reclamation while performing a concurrent trace; iv) lazy processing of decrements; and v) novel survival rate triggers that modulate pause durations. LXR combines excellent responsiveness and throughput, improving over production collectors. On the widely-used Lucene search engine in a tight heap, LXR delivers 7.8× better throughput and 10× better 99.99% tail latency than Shenandoah. On 17 diverse modern workloads in a moderate heap, LXR outperforms OpenJDK's default G1 on throughput by 4% and Shenandoah by 43%.",Garbage collection | Reference counting,6,1,repositoryam,Green,ARC,DP190103367,Australian Research Council,PLDI Programming Languages
2-s2.0-85140931277,10.1145/3495243.3560541,,,Magnetoelectric backscatter communication for millimeter-sized wireless biomedical implants,cp,Conference Paper,Yu Z.,60005286,Rice University,Houston,United States,10,"Yu, Zhanghao;Alrashdan, Fatima T.;Wang, Wei;Parker, Matthew;Chen, Xinyu;Chen, Frank Y.;Woods, Joshua;Chen, Zhiyu;Robinson, Jacob T.;Yang, Kaiyuan",57200514232;57205575409;57883557100;57946872300;57947027600;57947831200;57645856500;57883310000;8974690800;56110229800,60005286;60005286;60005286;60005286;60005286;60005286;60005286;60005286;60005286;60005286,2022-10-14,14 October 2022,"Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM",,21101117305,,Conference Proceeding,,,,432-445,"This paper presents the design, implementation, and experimental evaluation of a wireless biomedical implant platform exploiting the magnetoelectric effect for wireless power and bi-directional communication. As an emerging wireless power transfer method, magnetoelectric is promising for mm-scaled bio-implants because of its superior misalignment sensitivity, high efficiency, and low tissue absorption compared to other modalities [46, 59, 60]. Utilizing the same physical mechanism for power and communication is critical for implant miniaturization, but low-power magnetoelectric uplink communication has not been achieved yet. For the first time, we design and demonstrate near-zero power magnetoelectric backscatter from the mm-sized implants by exploiting the converse magnetostriction effects. The system for demonstration consists of an 8.2-mm3 wireless implantable device and a custom portable transceiver. The implant's ASIC interfacing with the magnetoelectric transducer encodes uplink data by changing the transducer's load, resulting in resonance frequency changes for frequency-shift-keying modulation. The magnetoelectrically backscattered signal is sensed and demodulated through frequency-To-digital conversion by the external transceiver. With design optimizations in data modulation and recovery, the proposed system archives > 1-kbps data rate at the 335-kHz carrier frequency, with a communication distance greater than 2 cm and a bit error rate less than 1E-3. Further, we validate the proposed system for wireless stimulation and sensing, and conducted ex-vivo tests through a 1.5-cm porcine tissue. The proposed magnetoelectric backscatter approach provides a path towards miniaturized wireless bio-implants for advanced biomedical applications like closed-loop neuromodulation.",backscatter communication | bioelectronics | magnetoelectric | wireless biomedical implants,6,0,,,NSF,ECCS-2023849,National Science Foundation,MOBICOM Mobile
2-s2.0-85130557496,10.1145/3491102.3501932,,,Math Augmentation: How Authors Enhance the Readability of Formulas using Novel Visual Design Practices,cp,Conference Paper,Head A.,60025038;126189978,"University of California, Berkeley;Allen Institute for AI",Berkeley;Allen,United States;United States,3,"Head, Andrew;Xie, Amber;Hearst, Marti A.",57156107000;57703422000;6603954639,126189978;60025038;60025038,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,491,,"With the increasing growth and impact of machine learning and other math-intensive fields, it is more important than ever to broaden access to mathematical notation. Can new visual and interactive displays help a wider readership successfully engage with notation? This paper provides the first detailed qualitative analysis of math augmentation - the practice of embellishing notation with novel visual design patterns to improve its readability. We present two qualitative studies of the practice of math augmentation. First is an analysis of 1.1k augmentations to 281 formulas in 47 blogs, textbooks, and other documents containing mathematical expressions. Second is an interview study with 12 authors who had previously designed custom math augmentations (""maugs""). This paper contributes a comprehensive inventory of the kinds of maugs that appear in math documents, and a detailed account of how authors' tools ought to be redesigned to support efficient creation of math augmentations. These studies open a critical new design space for HCI researchers and interface designers.",authoring | details-on-demand | mathematical notation | visual links,8,1,publisherfree2read,Bronze,APSF,undefined,Alfred P. Sloan Foundation,CHI Human-Computer Interaction
2-s2.0-85142905510,10.1109/FOCS54457.2022.00064,,,Maximum Flow and Minimum-Cost Flow in Almost-Linear Time,cp,Conference Paper,Chen L.,60097290;60025858;60016849;60014171;60012708,College of Computing;ETH Zürich;University of Toronto;University of Waterloo;Stanford University,Atlanta;Zurich;Toronto;Waterloo;Stanford,United States;Switzerland;Canada;Canada;United States,6,"Chen, Li;Kyng, Rasmus;Liu, Yang P.;Peng, Richard;Gutenberg, Maximilian Probst;Sachdeva, Sushant",57225084219;56271898200;57202917942;36721875600;57216610472;36933840400,60097290;60025858;60012708;60014171;60025858;60016849,2022-01-01,2022,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2022-October,,,612-623,"We give an algorithm that computes exact maximum flows and minimum-cost flows on directed graphs with m edges and polynomially bounded integral demands, costs, and capacities in m1+o(1) time. Our algorithm builds the flow through a sequence of m1+o(1) approximate undirected minimum-ratio cycles, each of which is computed and processed in amortized mo(1) time using a new dynamic graph data structure. Our framework extends to algorithms running in m1+o(1) time for computing flows that minimize general edge-separable convex functions to high accuracy. This gives almost-linear time algorithms for several problems including entropy-regularized optimal transport, matrix scaling, p-norm flows, and p-norm isotonic regression on arbitrary directed acyclic graphs.",Convex optimization | Data structures | Interior point methods | Maximum flow | Minimum cost flow,56,0,repositoryam,Green,NSF,200021 204787,National Science Foundation,FOCS Theory
2-s2.0-85130552425,10.1145/3491102.3502119,,,Meander Coil++: A Body-scale Wireless Power Transmission Using Safe-to-body and Energy-efficient Transmitter Coil,cp,Conference Paper,Takahashi R.,60025272,The University of Tokyo,Tokyo,Japan,5,"Takahashi, Ryo;Yukita, Wakako;Yokota, Tomoyuki;Someya, Takao;Kawahara, Yoshihiro",55755924300;56110117700;35365693400;24529073400;7202786793,60025272;60025272;60025272;60025272;60025272,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,390,,"Wearable devices for life-logging and healthcare have been studied, but the need for frequent charging imposes inconvenience for long-term use. Integrating textile-based wireless chargers (i.e., coil) into clothing enables sustainable wearable computing by charging the on-body devices in use. However, the electromagnetic field generated by conventional coil chargers strongly interferes with human body, and the high resistance of conductive threads leads to inefficient power delivery. This paper presents Meander Coil++, enabling safe, energy-efficient, and body-scale wireless power delivery. Meander Coil++ uses a wiring pattern that suppresses electromagnetic exposure to the human body without compromising power delivery performance and a liquid-metal-based low-loss conductive cord. With these advancements, Meander Coil++ transmits a few watts of power to on-body devices at 25% DC-to-DC efficiency while complying with international safety guidelines regarding electromagnetic exposure. We envision Meander Coil++ can maintain multiple devices on body for weeks beyond the confines of their small battery capacity.",coil | knit | liquid metal | magnetic resonant coupling | wireless power transfer,3,1,publisherfree2read,Bronze,ERATO,JPMJMI17F1,Exploratory Research for Advanced Technology,CHI Human-Computer Interaction
2-s2.0-85138465125,,,,MemLiner: Lining up Tracing and Application for a Far-Memory-Friendly Runtime,cp,Conference Paper,Wang C.,60029278;60027550,"The University of Chicago;University of California, Los Angeles",Chicago;Los Angeles,United States;United States,8,"Wang, Chenxi;Ma, Haoran;Liu, Shi;Qiao, Yifan;Eyolfson, Jonathan;Navasca, Christian;Lu, Shan;Xu, Guoqing Harry",57191888185;57220067417;57220070487;57224728333;40461387300;57201614481;35199803400;57214267818,60027550;60027550;60027550;60027550;60027550;60027550;60029278;60027550,2022-01-01,2022,"Proceedings of the 16th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2022",,21101117816,,Conference Proceeding,,,,35-53,"Far-memory techniques that enable applications to use remote memory are increasingly appealing in modern data centers, supporting applications' large memory footprint and improving machines' resource utilization. Unfortunately, most far-memory techniques focus on OS-level optimizations and are agnostic to managed runtimes and garbage collections (GC) underneath applications written in high-level languages. With different object-access patterns from applications, GC can severely interfere with existing far-memory techniques, breaking remote memory prefetching algorithms and causing severe local-memory misses. We developed MemLiner, a runtime technique that improves the performance of far-memory systems by “lining up” memory accesses from the application and the GC so that they follow similar memory access paths, thereby (1) reducing the local-memory working set and (2) improving remote-memory prefetching through simplified memory access patterns. We implemented MemLiner in two widely-used GCs in OpenJDK: G1 and Shenandoah. Our evaluation with a range of widely-deployed cloud systems shows MemLiner improves applications' end-to-end performance by up to 2.5×.",,14,0,,,NSF,CCF-2119184,National Science Foundation,OSDI Operating Systems
2-s2.0-85143064016,10.1145/3540250.3549107,,,Minerva: browser API fuzzing with dynamic mod-ref analysis,cp,Conference Paper,Zhou C.,60028186;60025278;60021666,École Polytechnique Fédérale de Lausanne;Tsinghua University;Nanjing University of Aeronautics and Astronautics,Lausanne;Beijing;Nanjing,Switzerland;China;China,8,"Zhou, Chijin;Zhang, Quan;Wang, Mingzhe;Guo, Lihua;Liang, Jie;Liu, Zhe;Payer, Mathias;Jiang, Yu",57205028572;57215971065;57201133949;57546293700;57202891190;56844033500;56416152300;56193157500,60025278;60025278;60025278;60025278;60025278;60021666;60028186;60025278,2022-11-07,7 November 2022,ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101123502,,Conference Proceeding,,,,1135-1147,"Browser APIs are essential to the modern web experience. Due to their large number and complexity, they vastly expand the attack surface of browsers. To detect vulnerabilities in these APIs, fuzzers generate test cases with a large amount of random API invocations. However, the massive search space formed by arbitrary API combinations hinders their effectiveness: since randomly-picked API invocations unlikely interfere with each other (i.e., compute on partially shared data), few interesting API interactions are explored. Consequently, reducing the search space by revealing inter-API relations is a major challenge in browser fuzzing. We propose Minerva, an efficient browser fuzzer for browser API bug detection. The key idea is to leverage API interference relations to reduce redundancy and improve coverage. Minerva consists of two modules: dynamic mod-ref analysis and guided code generation. Before fuzzing starts, the dynamic mod-ref analysis module builds an API interference graph. It first automatically identifies individual browser APIs from the browser's code base. Next, it instruments the browser to dynamically collect mod-ref relations between APIs. During fuzzing, the guided code generation module synthesizes highly-relevant API invocations guided by the mod-ref relations. We evaluate Minerva on three mainstream browsers, i.e. Safari, FireFox, and Chromium. Compared to state-of-the-art fuzzers, Minerva improves edge coverage by 19.63% to 229.62% and finds 2x to 3x more unique bugs. Besides, Minerva has discovered 35 previously-unknown bugs out of which 20 have been fixed with 5 CVEs assigned and acknowledged by browser vendors.",browser security | dynamic analysis | interface fuzzing,2,1,publisherfree2read,Bronze,H2020,850868,Horizon 2020 Framework Programme,FSE Software Engineering
2-s2.0-85130572944,10.1145/3491102.3502054,,,"Mobile-Friendly Content Design for MOOCs: Challenges, Requirements, and Design Opportunities",cp,Conference Paper,Kim J.,60032144,Korea Advanced Institute of Science and Technology,Daejeon,South Korea,4,"Kim, Jeongyeon;Choi, Yubin;Xia, Meng;Kim, Juho",57218495133;57704802600;57202803261;39361826000,60032144;60032144;60032144;60032144,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,92,,"Most video-based learning content is designed for desktops without considering mobile environments. We (1) investigate the gap between mobile learners' challenges and video engineers' considerations using mixed methods and (2) provide design guidelines for creating mobile-friendly MOOC videos. To uncover learners' challenges, we conducted a survey (n=134) and interviews (n=21), and evaluated the mobile adequacy of current MOOCs by analyzing 41,722 video frames from 101 video lectures. Interview results revealed low readability and situationally-induced impairments as major challenges. The content analysis showed a low guideline compliance rate for key design factors. We then interviewed 11 video production engineers to investigate design factors they mainly consider. The engineers mainly focus on the size and amount of content while lacking consideration for color, complex images, and situationally-induced impairments. Finally, we present and validate guidelines for designing mobile-friendly MOOCs, such as providing adaptive and customizable visual design and context-aware accessibility support.",Content Design | Learning Difficulty | Mobile Learning | MOOCs | Video-based Learning,10,1,repositoryam,Green,MSIP,NRF-2020R1C1C1007587,"Ministry of Science, ICT and Future Planning",CHI Human-Computer Interaction
2-s2.0-85130580389,10.1145/3491102.3501960,,,Mouth Haptics in VR using a Headset Ultrasound Phased Array,cp,Conference Paper,Shen V.,60027950,Carnegie Mellon University,Pittsburgh,United States,3,"Shen, Vivian;Shultz, Craig;Harrison, Chris",57345036900;55924693900;35792227900,60027950;60027950;60027950,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,275,,"Today's consumer virtual reality (VR) systems offer limited haptic feedback via vibration motors in handheld controllers. Rendering haptics to other parts of the body is an open challenge, especially in a practical and consumer-friendly manner. The mouth is of particular interest, as it is a close second in tactile sensitivity to the fingertips, offering a unique opportunity to add fine-grained haptic effects. In this research, we developed a thin, compact, beamforming array of ultrasonic transducers, which can render haptic effects onto the mouth. Importantly, all components are integrated into the headset, meaning the user does not need to wear an additional accessory, or place any external infrastructure in their room. We explored several effects, including point impulses, swipes, and persistent vibrations. Our haptic sensations can be felt on the lips, teeth and tongue, which can be incorporated into new and interesting VR experiences.",,18,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85142865130,10.1109/FOCS54457.2022.00063,,,Negative-Weight Single-Source Shortest Paths in Near-linear Time,cp,Conference Paper,Bernstein A.,60120529;60030840,Department of Computer Science;Københavns Universitet,Piscataway;Copenhagen,United States;Denmark,3,"Bernstein, Aaron;Nanongkai, Danupon;Wulff-Nilsen, Christian",36005223200;27067877400;23568967500,60120529;60030840;60030840,2022-01-01,2022,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,2022-October,,,600-611,"We present a randomized algorithm that computes single-source shortest paths (SSSP) in O(m log8 (n) log W) time when edge weights are integral and can be negative.1 This essentially resolves the classic negative-weight SSSP problem. The previous bounds are O((m+n1.5) log W) [BLNPSSSW FOCS'20] and m4/3+o(1) log W [AMV FOCS'20]. Near-linear time algorithms were known previously only for the special case of planar directed graphs [Fakcharoenphol and Rao FOCS'01]. In contrast to all recent developments that rely on sophisticated continuous optimization methods and dynamic algorithms, our algorithm is simple: it requires only a simple graph decomposition and elementary combinatorial tools. In fact, ours is the first combinatorial algorithm for negative-weight SSSP to break through the classic O(m vn log W) bound from over three decades ago [Gabow and Tarjan SICOMP'89].",analysis of algorithms | graph algorithms | graphs and networks | path and circuit problems,15,0,repositoryam,Green,NSF,1942010,National Science Foundation,FOCS Theory
2-s2.0-85130556701,10.1145/3491102.3501823,,,Neo: Generalizing Confusion Matrix Visualization to Hierarchical and Multi-Output Labels,cp,Conference Paper,Görtler J.,60025525;127850181;127807799;121690135,Universität Konstanz;Apple;Apple;Apple,Konstanz;Heidelberg;Pittsburgh;Seattle,Germany;Germany;United States;United States,8,"Görtler, Jochen;Hohman, Fred;Moritz, Dominik;Wongsuphasawat, Kanit;Ren, Donghao;Nair, Rahul;Kirchner, Marc;Patel, Kayur",55981273100;57194277192;56272615400;57212250607;55907202100;57326216200;57325459900;55435659300,60025525;121690135;127807799;121690135;121690135;127850181;127850181;121690135,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,408,,"The confusion matrix, a ubiquitous visualization for helping people evaluate machine learning models, is a tabular layout that compares predicted class labels against actual class labels over all data instances. We conduct formative research with machine learning practitioners at Apple and find that conventional confusion matrices do not support more complex data-structures found in modern-day applications, such as hierarchical and multi-output labels. To express such variations of confusion matrices, we design an algebra that models confusion matrices as probability distributions. Based on this algebra, we develop Neo, a visual analytics system that enables practitioners to flexibly author and interact with hierarchical and multi-output confusion matrices, visualize derived metrics, renormalize confusions, and share matrix specifications. Finally, we demonstrate Neo's utility with three model evaluation scenarios that help people better understand model performance and reveal hidden confusions.",Confusion matrices | interactive systems | machine learning | model evaluation | visual analytics,19,1,repositoryam,Green,DFG,251654672 – TRR 161,Deutsche Forschungsgemeinschaft,CHI Human-Computer Interaction
2-s2.0-85132835132,10.1145/3470496.3527413,,,NvMR: Non-Volatile Memory Renaming for Intermittent Computing,cp,Conference Paper,Bhattacharyya A.,60032179;60010449,University of Wisconsin-Madison;Apple Computer,Madison;Cupertino,United States;United States,3,"Bhattacharyya, Abhishek;Somashekhar, Abhijith;Miguel, Joshua San",57763800900;57763635700;56732599800,60032179;60010449;60032179,2022-06-18,18 June 2022,Proceedings - International Symposium on Computer Architecture,10636897,145750,,Conference Proceeding,,,,1-13,"Intermittent systems on energy-harvesting devices have to frequently back up data because of an unreliable energy supply to make forward progress. These devices come with non-volatile memories like Flash/FRAM on board that are used to back up the system state. However, quite paradoxically, writing to a non-volatile memory consumes a lot of energy that makes backups expensive. Idempotency violations inherent to intermittent programs are major contributors to the problem, as they render system state inconsistent and force backups to occur even when plenty of energy is available. In this work, we !rst characterize the complex persist dependencies that are unique to intermittent computing. Based on these insights, we propose NvMR, an intermittent architecture that eliminates idempotency violations in the program by renaming non-volatile memory addresses. This can reduce the number of backups to their theoretical minimum and decouple the decision of when to perform backups from the memory access constraints imposed by the program. Our evaluations show that compared to a state-of-the-art intermittent architecture, NvMR can save about 20% energy on average when running common embedded applications.",Energy-harvesting | Idempotency | Intermittent computing,3,0,,,NSF,2010830,National Science Foundation,ISCA Architecture
2-s2.0-85148758146,,,,On-Demand Sampling: Learning Optimally from Multiple Distributions,cp,Conference Paper,Haghtalab N.,60025038,"University of California, Berkeley",Berkeley,United States,3,"Haghtalab, Nika;Jordan, Michael I.;Zhao, Eric",56394619900;57220715546;57224933126,60025038;60025038;60025038,2022-01-01,2022,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,35,,,,"Societal and real-world considerations such as robustness, fairness, social welfare and multi-agent tradeoffs have given rise to multi-distribution learning paradigms, such as collaborative [5], group distributionally robust [36], and fair federated learning [27]. In each of these settings, a learner seeks to minimize its worst-case loss over a set of n predefined distributions, while using as few samples as possible. In this paper, we establish the optimal sample complexity of these learning paradigms and give algorithms that meet this sample complexity. Importantly, our sample complexity bounds exceed that of the sample complexity of learning a single distribution only by an additive factor of (Equation presented). These improve upon the best known sample complexity of agnostic federated learning by Mohri et al. [27] by a multiplicative factor of n, the sample complexity of collaborative learning by Nguyen and Zakynthinou [29] by a multiplicative factor (Equation presented), and give the first sample complexity bounds for the group DRO objective of Sagawa et al. [36]. To achieve optimal sample complexity, our algorithms learn to sample and learn from distributions on demand. Our algorithm design and analysis extends stochastic optimization techniques to solve zero-sum games in a new stochastic setting.",,0,0,,,NSF,CCF-2145898,National Science Foundation,NeurIPS Machine Learning
2-s2.0-85143079654,10.1145/3540250.3549144,,,Online testing of RESTful APIs: promises and challenges,cp,Conference Paper,Martin-Lopez A.,60033284,Universidad de Sevilla,Sevilla,Spain,3,"Martin-Lopez, Alberto;Segura, Sergio;Ruiz-Cortés, Antonio",57212275741;25629936300;15120180100,60033284;60033284;60033284,2022-11-07,7 November 2022,ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101123502,,Conference Proceeding,,,,408-420,"Online testing of web APIs - testing APIs in production - is gaining traction in industry. Platforms such as RapidAPI and Sauce Labs provide online testing and monitoring services of web APIs 24/7, typically by re-executing manually designed test cases on the target APIs on a regular basis. In parallel, research on the automated generation of test cases for RESTful APIs has seen significant advances in recent years. However, despite their promising results in the lab, it is unclear whether research tools would scale to industrial-size settings and, more importantly, how they would perform in an online testing setup, increasingly common in practice. In this paper, we report the results of an empirical study on the use of automated test case generation methods for online testing of RESTful APIs. Specifically, we used the RESTest framework to automatically generate and execute test cases in 13 industrial APIs for 15 days non-stop, resulting in over one million test cases. To scale at this level, we had to transition from a monolithic tool approach to a multi-bot architecture with over 200 bots working cooperatively in tasks like test generation and reporting. As a result, we uncovered about 390K failures, which we conservatively triaged into 254 bugs, 65 of which have been acknowledged or fixed by developers to date. Among others, we identified confirmed faults in the APIs of Amadeus, Foursquare, Yelp, and YouTube, accessed by millions of applications worldwide. More importantly, our reports have guided developers on improving their APIs, including bug fixes and documentation updates in the APIs of Amadeus and YouTube. Our results show the potential of online testing of RESTful APIs as the next must-have feature in industry, but also some of the key challenges to overcome for its full adoption in practice.",black-box testing | bot | online testing | REST | web API,10,0,,,UCB,US-1264651,University of California Berkeley,FSE Software Engineering
2-s2.0-85129523271,,,,Online Certification of Preference-Based Fairness for Personalized Recommender Systems,cp,Conference Paper,Do V.,60105740;127294950,Laboratoire d’Analyse et de Modélisation de Systèmes pour l’Aide à la Décision;Meta AI,Paris;Meta,France;United States,4,"Do, Virginie;Corbett-Davies, Sam;Atif, Jamal;Usunier, Nicolas",57224481958;55579310100;23007702600;8558715300,60105740-127294950;127294950;60105740;127294950,2022-06-30,30 June 2022,"Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022",,21101133594,,Conference Proceeding,36,,,6532-6540,"Recommender systems are facing scrutiny because of their growing impact on the opportunities we have access to. Current audits for fairness are limited to coarse-grained parity assessments at the level of sensitive groups. We propose to audit for envy-freeness, a more granular criterion aligned with individual preferences: every user should prefer their recommendations to those of other users. Since auditing for envy requires to estimate the preferences of users beyond their existing recommendations, we cast the audit as a new pure exploration problem in multi-armed bandits. We propose a sample-efficient algorithm with theoretical guarantees that it does not deteriorate user experience. We also study the tradeoffs achieved on real-world recommendation datasets.",,12,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-85133025093,10.1145/3517804.3526225,,,Optimal Bounds for Approximate Counting,cp,Conference Paper,Nelson J.,60025038;60003269,"University of California, Berkeley;Princeton University",Berkeley;Princeton,United States;United States,2,"Nelson, Jelani;Yu, Huacheng",22734928100;56198706600,60025038;60003269,2022-06-12,12 June 2022,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,119-127,"Storing a counter incremented N times would naively consume O(log N) bits of memory. In 1978 Morris described the very first streaming algorithm: The ""Morris Counter""[15]. His algorithm's space bound is a random variable, and it has been shown to be O(log log N + log(1/?) + log(1/)) bits in expectation to provide a (1+?)-Approximation with probability $1-dto the counter's value. We provide a new simple algorithm with a simple analysis showing that randomized space O(log log N + log(1/?) + log log(1/)) bits suffice for the same task, i.e. an exponentially improved dependence on the inverse failure probability. We then provide a new analysis showing that the original Morris Counter itself, after a minor but necessary tweak, actually also enjoys this same improved upper bound. Lastly, we prove a new lower bound for this task showing optimality of our upper bound. We thus completely resolve the asymptotic space complexity of approximate counting. Furthermore all our constants are explicit, and our lower bound and tightest upper bound differ by a multiplicative factor of at most 3+o(1).",approximate counting | lower bounds | streaming,4,1,repositoryam,Green,NSF,CCF-1951384,National Science Foundation,PODS Databases
2-s2.0-85133498331,10.1145/3510003.3510075,,,PUS: A Fast and Highly Efficient Solver for Inclusion-based Pointer Analysis,cp,Conference Paper,Liu P.,60020547,Texas A&amp;M University,College Station,United States,4,"Liu, Peiming;Li, Yanze;Swain, Brad;Huang, Jeff",57209133881;57210919462;57217605811;57013582200,60020547;60020547;60020547;60020547,2022-01-01,2022,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2022-May,,,1781-1792,"A crucial performance bottleneck in most interprocedural static analyses is solving pointer analysis constraints. We present Pus, a highly efficient solver for inclusion-based pointer analysis. At the heart of Pus is a new constraint solving algorithm that signifi-cantly advances the state-of-the-art. Unlike the existing algorithms (i.e., wave and deep propagation) which construct a holistic constraint graph, at each stage Pus only considers partial constraints that causally affect the final fixed-point computation. In each iteration Pus extracts a small causality subgraph and it guarantees that only processing the causality subgraph is sufficient to reach the same global fixed point. Our extensive evaluation of Pus on a wide range of real-world large complex programs yields highly promising results. Pus is able to analyze millions of lines of code such as PostgreSQL in 10 minutes on a commodity laptop. On average, Pus is more than 7x faster in solving context-sensitive constraints, and more than 2x faster in solving context-insensitive constraints compared to the state of the art wave and deep propagation algorithms. Moreover, Pus has been used to find tens of previous unknown bugs in high-profile codebases including Linux, Redis, and Memcached.",Causality Subgraph | Pointer Analysis | Static Analysis,0,0,,,,undefined,,ICSE Software Engineering
2-s2.0-85129867983,10.1145/3485447.3511986,,,PaSca: A Graph Neural Architecture Search System under the Scalable Paradigm,cp,Conference Paper,Zhang W.,60114181;60014966,Tencent;Peking University,Shenzhen;Beijing,China;China,9,"Zhang, Wentao;Shen, Yu;Lin, Zheyu;Li, Yang;Li, Xiaosen;Ouyang, Wen;Tao, Yangyu;Yang, Zhi;Cui, Bin",57193707840;57223756506;57222720947;57221715937;57217029446;37122512300;57223766297;56101984100;57211734542,60014966-60114181;60014966;60014966;60014966;60114181;60114181;60114181;60014966;60014966,2022-04-25,25 April 2022,WWW 2022 - Proceedings of the ACM Web Conference 2022,,21101088463,,Conference Proceeding,,,,1817-1828,"Graph neural networks (GNNs) have achieved state-of-the-art performance in various graph-based tasks. However, as mainstream GNNs are designed based on the neural message passing mechanism, they do not scale well to data size and message passing steps. Although there has been an emerging interest in the design of scalable GNNs, current researches focus on specific GNN design, rather than the general design space, limiting the discovery of potential scalable GNN models. This paper proposes PaSca, a new paradigm and system that offers a principled approach to systemically construct and explore the design space for scalable GNNs, rather than studying individual designs. Through deconstructing the message passing mechanism, PaSca presents a novel Scalable Graph Neural Architecture Paradigm (SGAP), together with a general architecture design space consisting of 150k different designs. Following the paradigm, we implement an auto-search engine that can automatically search well-performing and scalable GNN architectures to balance the trade-off between multiple criteria (e.g., accuracy and efficiency) via multi-objective optimization. Empirical studies on ten benchmark datasets demonstrate that the representative instances (i.e., PaSca-V1, V2, and V3) discovered by our system achieve consistent performance among competitive baselines. Concretely, PaSca-V3 outperforms the state-of-the-art GNN method JK-Net by 0.4% in terms of predictive accuracy on our large industry dataset while achieving up to 28.3 × training speedups.",Design Space | Graph Neural Networks | Scalable Graph Learning,16,0,repositoryam,Green,NSFC,62072458,National Natural Science Foundation of China,WWW World Wide Web
2-s2.0-85140983450,,,,Packet Order Matters! Improving Application Performance by Deliberately Delaying Packets,cp,Conference Paper,Ghasemirahni H.,60016575;60002014,Ericsson Sweden;The Royal Institute of Technology (KTH),Stockholm;Stockholm,Sweden;Sweden,9,"Ghasemirahni, Hamid;Barbette, Tom;Katsikas, Georgios P.;Farshin, Alireza;Roozbeh, Amir;Girondi, Massimo;Chiesa, Marco;Maguire, Gerald Q.;Kostić, Dejan",57217135443;56712897700;17342665500;57193526579;56185790300;57239013600;44661149100;8414298400;8619696100,60002014;60002014;60002014;60002014;60002014-60016575;60002014;60002014;60002014;60002014,2022-01-01,2022,"Proceedings of the 19th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2022",,21101117460,,Conference Proceeding,,,,807-827,"Data centers increasingly deploy commodity servers with high-speed network interfaces to enable low-latency communication. However, achieving low latency at high data rates crucially depends on how the incoming traffic interacts with the system's caches. When packets that need to be processed in the same way are consecutive, i.e., exhibit high temporal and spatial locality, caches deliver great benefits. In this paper, we systematically study the impact of temporal and spatial traffic locality on the performance of commodity servers equipped with high-speed network interfaces. Our results show that (i) the performance of a variety of widely deployed applications degrades substantially with even the slightest lack of traffic locality, and (ii) a traffic trace from our organization reveals poor traffic locality as networking protocols, drivers, and the underlying switching/routing fabric spread packets out in time (reducing locality). To address these issues, we built Reframer, a software solution that deliberately delays packets and reorders them to increase traffic locality. Despite introducing µs-scale delays of some packets, we show that Reframer increases the throughput of a network service chain by up to 84% and reduces the flow completion time of a web server by 11% while improving its throughput by 20%.",,5,0,,,H2020,770889,Horizon 2020 Framework Programme,NSDI Networking
2-s2.0-85163217092,,,,Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding,cp,Conference Paper,Saharia C.,60016849;60006191,University of Toronto;Google LLC,Toronto;Mountain View,Canada;United States,14,"Saharia, Chitwan;Chan, William;Saxena, Saurabh;Li, Lala;Whang, Jay;Denton, Emily;Ghasemipour, Seyed Kamyar Seyed;Ayan, Burcu Karagol;Mahdavi, S. Sara;Gontijo-Lopes, Raphael;Salimans, Tim;Ho, Jonathan;Fleet, David J.;Norouzi, Mohammad",57210640805;55338413200;57213481797;57218718937;57220360238;55338354300;57210570038;57216965669;57712451000;57219498344;55320289800;55921701300;57206712712;55366718300,60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191;60006191-60016849;60006191,2022-01-01,2022,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,35,,,,"We present Imagen, a text-to-image diffusion model with an unprecedented degree of photorealism and a deep level of language understanding. Imagen builds on the power of large transformer language models in understanding text and hinges on the strength of diffusion models in high-fidelity image generation. Our key discovery is that generic large language models (e.g. T5), pretrained on text-only corpora, are surprisingly effective at encoding text for image synthesis: increasing the size of the language model in Imagen boosts both sample fidelity and image-text alignment much more than increasing the size of the image diffusion model. Imagen achieves a new state-of-the-art FID score of 7.27 on the COCO dataset, without ever training on COCO, and human raters find Imagen samples to be on par with the COCO data itself in image-text alignment. To assess text-to-image models in greater depth, we introduce DrawBench, a comprehensive and challenging benchmark for text-to-image models. With DrawBench, we compare Imagen with recent methods including VQ-GAN+CLIP, Latent Diffusion Models, GLIDE and DALL-E 2, and find that human raters prefer Imagen over other models in side-by-side comparisons, both in terms of sample quality and image-text alignment.",,350,0,,,,undefined,,NeurIPS Machine Learning
2-s2.0-85121597679,10.1109/INFOCOM48880.2022.9796778,,,PreGAN: Preemptive Migration Prediction Network for Proactive Fault-Tolerant Edge Computing,cp,Conference Paper,Tuli S.,60015150;60000891,Imperial College London;Loughborough University,London;Loughborough,United Kingdom;United Kingdom,3,"Tuli, Shreshth;Casale, Giuliano;Jennings, Nicholas R.",57208274339;21742204200;7005888644,60015150;60015150;60015150-60000891,2022-01-01,2022,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2022-May,,,670-679,"Building a fault-tolerant edge system that can quickly react to node overloads or failures is challenging due to the unreliability of edge devices and the strict service deadlines of modern applications. Moreover, unnecessary task migrations can stress the system network, giving rise to the need for a smart and parsimonious failure recovery scheme. Prior approaches often fail to adapt to highly volatile workloads or accurately detect and diagnose faults for optimal remediation. There is thus a need for a robust and proactive fault-tolerance mechanism to meet service level objectives. In this work, we propose PreGAN, a composite AI model using a Generative Adversarial Network (GAN) to predict preemptive migration decisions for proactive fault-tolerance in containerized edge deployments. PreGAN uses co-simulations in tandem with a GAN to learn a few-shot anomaly classifier and proactively predict migration decisions for reliable computing. Extensive experiments on a Raspberry-Pi based edge environment show that PreGAN can outperform state-of-the-art baseline methods in fault-detection, diagnosis and classification, thus achieving high quality of service. PreGAN accomplishes this by 5.1% more accurate fault detection, higher diagnosis scores and 23.8% lower overheads compared to the best method among the considered baselines.",Edge Computing | Fault Tolerance | Generative Adversarial Networks | Preemptive Migrations,18,0,repositoryam,Green,,undefined,,INFOCOM Networking
2-s2.0-85163137311,,,,Privacy for Free: How does Dataset Condensation Help Privacy?,cp,Conference Paper,Dong T.,60027272;60025084;129865667,The University of Edinburgh;Shanghai Jiao Tong University;Sony AI,Edinburgh;Shanghai;,United Kingdom;China;,3,"Dong, Tian;Zhao, Bo;Lyu, Lingjuan",57221418303;57194457536;57189234207,60025084-129865667;60027272;129865667,2022-01-01,2022,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,162,,,5378-5396,"To prevent unintentional data leakage, research community has resorted to data generators that can produce differentially private data for model training. However, for the sake of the data privacy, existing solutions suffer from either expensive training cost or poor generalization performance. Therefore, we raise the question whether training efficiency and privacy can be achieved simultaneously. In this work, we for the first time identify that dataset condensation (DC) which is originally designed for improving training efficiency is also a better solution to replace the traditional data generators for private data generation, thus providing privacy for free. To demonstrate the privacy benefit of DC, we build a connection between DC and differential privacy, and theoretically prove on linear feature extractors (and then extended to non-linear feature extractors) that the existence of one sample has limited impact (O(m/n)) on the parameter distribution of networks trained on m samples synthesized from n(n ≫ m) raw samples by DC. We also empirically validate the visual privacy and membership privacy of DC-synthesized data by launching both the loss-based and the state-of-the-art likelihood-based membership inference attacks. We envision this work as a milestone for data-efficient and privacy-preserving machine learning.",,10,0,,,,undefined,,ICML Machine Learning
2-s2.0-85163217770,,,,ProcTHOR: Large-Scale Embodied AI Using Procedural Generation,cp,Conference Paper,Deitke M.,60015481;126489860,University of Washington;PRIOR @ Allen Institute for AI,Seattle;Allen,United States;United States,11,"Deitke, Matt;VanderBilt, Eli;Herrasti, Alvaro;Weihs, Luca;Salvador, Jordi;Ehsani, Kiana;Han, Winson;Kolve, Eric;Farhadi, Ali;Kembhavi, Aniruddha;Mottaghi, Roozbeh",57219671843;57219666905;57191189350;57035350600;57219668313;57207777076;57219492602;57191433866;36099817000;57208117160;14632225600,126489860-60015481;126489860;126489860;126489860;126489860;126489860;126489860;126489860;60015481;126489860-60015481;126489860-60015481,2022-01-01,2022,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,35,,,,"Massive datasets and high-capacity models have driven many recent advancements in computer vision and natural language understanding. This work presents a platform to enable similar success stories in Embodied AI. We propose PROCTHOR, a framework for procedural generation of Embodied AI environments. PROCTHOR enables us to sample arbitrarily large datasets of diverse, interactive, customizable, and performant virtual environments to train and evaluate embodied agents across navigation, interaction, and manipulation tasks. We demonstrate the power and potential of PROCTHOR via a sample of 10,000 generated houses and a simple neural model. Models trained using only RGB images on PROCTHOR, with no explicit mapping and no human task supervision produce state-of-the-art results across 6 embodied AI benchmarks for navigation, rearrangement, and arm manipulation, including the presently running Habitat 2022, AI2-THOR Rearrangement 2022, and RoboTHOR challenges. We also demonstrate strong 0-shot results on these benchmarks, via pre-training on PROCTHOR with no fine-tuning on the downstream benchmark, often beating previous state-of-the-art systems that access the downstream training data.",,19,0,,,,undefined,,NeurIPS Machine Learning
2-s2.0-85141576852,10.1145/3526113.3545623,,,Prototyping Soft Devices with Interactive Bioplastics,cp,Conference Paper,Koelle M.,60072947;60033241;60012749;60002306,Pôle Léonard De Vinci;Universität des Saarlandes;Oldenburger Forschungs- Und Entwicklungsinstitut fur Informatik-Werkzeuge Und -Systeme;University of Calgary,Paris-La Defense;Saarbrucken;Oldenburg;Calgary,France;Germany;Germany;Canada,5,"Koelle, Marion;Nicolae, Madalina;Nittala, Aditya Shekhar;Teyssier, Marc;Steimle, Jürgen",56023740400;57959251200;56159493000;51665727800;24825371700,60033241-60012749;60033241-60072947;60033241-60002306;60012749;60033241,2022-10-29,29 October 2022,UIST 2022 - Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology,,21101119907,,Conference Proceeding,,,19,,"Designers and makers are increasingly interested in leveraging bio-based and bio-degradable do-it-yourself' (DIY) materials for sustainable prototyping. Their self-produced bioplastics possess compelling properties such as self-adhesion but have so far not been functionalized to create soft interactive devices, due to a lack of DIY techniques for the fabrication of functional electronic circuits and sensors. In this paper, we contribute a DIY approach for creating Interactive Bioplastics that is accessible to a wide audience, making use of easy-to-obtain bio-based raw materials and familiar tools. We present three types of conductive bioplastic materials and their formulation: sheets, pastes and foams. Our materials enable additive and subtractive fabrication of soft circuits and sensors. Furthermore, we demonstrate how these materials can substitute conventional prototyping materials, be combined with off-the-shelf electronics, and be fed into a sustainable material life-cycle' including disassembly, re-use, and re-melting of materials. A formal characterization of our conductors highlights that they are even on-par with commercially available carbon-based conductive pastes.",biomaterials | bioplastics | DIY | do-it-yourself | sustainability,13,1,publisherfree2read,Bronze,H2020,714797,Horizon 2020 Framework Programme,UIST User Interface
2-s2.0-85122471668,10.1145/3514221.3517844,,,R2T: Instance-optimal Truncation for Differentially Private Query Evaluation with Foreign Keys,cp,Conference Paper,Dong W.,60008724;60008592,Duke University;Hong Kong University of Science and Technology,Durham;Hong Kong,United States;Hong Kong,5,"Dong, Wei;Fang, Juanru;Yi, Ke;Tao, Yuchao;MacHanavajjhala, Ashwin",57659086200;57761951600;35800286800;57211134284;8380049100,60008592;60008592;60008592;60008724;60008724,2022-06-10,10 June 2022,Proceedings of the ACM SIGMOD International Conference on Management of Data,07308078,30611,,Conference Proceeding,,,,759-772,"Answering SPJA queries under differential privacy (DP), including graph pattern counting under node-DP as an important special case, has received considerable attention in recent years. The dual challenge of foreign-key constraints and self-joins is particularly tricky to deal with, and no existing DP mechanisms can correctly handle both. For the special case of graph pattern counting under node-DP, the existing mechanisms are correct (i.e., satisfy DP), but they do not offer nontrivial utility guarantees or are very complicated and costly. In this paper, we propose the first DP mechanism for answering arbitrary SPJA queries in a database with foreign-key constraints. Meanwhile, it achieves a fairly strong notion of optimality, which can be considered as a small and natural relaxation of instance optimality. Finally, our mechanism is simple enough that it can be easily implemented on top of any RDBMS and an LP solver. Experimental results show that it offers order-of-magnitude improvements in terms of utility over existing techniques, even those specifically designed for graph pattern counting.",differential privacy | foreign-key constraint | SPJA query,11,0,repositoryvor,Green,NSF,16201318,National Science Foundation,SIGMOD Databases
2-s2.0-85148422010,,,,Requirements and Motivations of Low-Resource Speech Synthesis for Language Revitalization,cp,Conference Paper,Pine A.,60027272;60016005;60009839,The University of Edinburgh;Queen’s University;National Research Council Canada,Edinburgh;Kingston;Ottawa,United Kingdom;Canada;Canada,5,"Pine, Aidan;Wells, Dan;Brinklow, Nathan Thanyehténhas;Littell, Patrick;Richmond, Korin",57346529300;57932318900;57497081900;57191998859;14018214600,60009839;60027272;60016005;60009839;60027272,2022-01-01,2022,Proceedings of the Annual Meeting of the Association for Computational Linguistics,0736587X,21101138302,,Conference Proceeding,1,,,7346-7359,"This paper describes the motivation and development of speech synthesis systems for the purposes of language revitalization. By building speech synthesis systems for three Indigenous languages spoken in Canada, Kanien'kéha, Gitksan & SENCOTEN, we re-evaluate the question of how much data is required to build low-resource speech synthesis systems featuring state-of-the-art neural models. For example, preliminary results with English data show that a FastSpeech2 model trained with 1 hour of training data can produce speech with comparable naturalness to a Tacotron2 model trained with 10 hours of data. Finally, we motivate future research in evaluation and classroom integration in the field of speech synthesis for language revitalization.",,11,0,,,LALS,EP/S022481/1,School of Linguistics and Applied Language Studies,ACL Natural Language Processing
2-s2.0-85129867088,10.1145/3485447.3512143,,,Rewiring What-to-Watch-Next Recommendations to Reduce Radicalization Pathways,cp,Conference Paper,Fabbri F.,60108713;60073287;60032942;60021200;60002952,"Eurecat, Technology Centre of Catalonia;Institute for Scientific Interchange Foundation;Universitat Pompeu Fabra Barcelona;East China Normal University;Helsingin Yliopisto",Barcelona;Turin;Barcelona;Shanghai;Helsinki,Spain;Italy;Spain;China;Finland,5,"Fabbri, Francesco;Wang, Yanhao;Bonchi, Francesco;Castillo, Carlos;Mathioudakis, Michael",57221321703;57195221014;8409976700;7101918821;7004746717,60032942;60021200;60073287-60108713;60032942;60002952,2022-04-25,25 April 2022,WWW 2022 - Proceedings of the ACM Web Conference 2022,,21101088463,,Conference Proceeding,,,,2719-2728,"Recommender systems typically suggest to users content similar to what they consumed in the past. If a user happens to be exposed to strongly polarized content, she might subsequently receive recommendations which may steer her towards more and more radicalized content, eventually being trapped in what we call a ""radicalization pathway"". In this paper, we study the problem of mitigating radicalization pathways using a graph-based approach. Specifically, we model the set of recommendations of a ""what-to-watch-next""recommender as a d-regular directed graph where nodes correspond to content items, links to recommendations, and paths to possible user sessions. We measure the ""segregation""score of a node representing radicalized content as the expected length of a random walk from that node to any node representing non-radicalized content. High segregation scores are associated to larger chances to get users trapped in radicalization pathways. Hence, we define the problem of reducing the prevalence of radicalization pathways by selecting a small number of edges to ""rewire"", so to minimize the maximum of segregation scores among all radicalized nodes, while maintaining the relevance of the recommendations. We prove that the problem of finding the optimal set of recommendations to rewire is NP-hard and NP-hard to approximate within any factor. Therefore, we turn our attention to heuristics, and propose an efficient yet effective greedy algorithm based on the absorbing random walk theory. Our experiments on real-world datasets in the context of video and news recommendations confirm the effectiveness of our proposal.",extremist content | filter bubbles | polarization | radicalization | random walks | recommender systems,12,0,repositoryam,Green,NSF,1814816,National Science Foundation,WWW World Wide Web
2-s2.0-85151072886,,,,Riemannian Score-Based Generative Modelling,cp,Conference Paper,De Bortoli V.,60026851;60000179,University of Oxford;École Normale Supérieure,Oxford;Paris,United Kingdom;France,6,"De Bortoli, Valentin;Mathieu, Émile;Hutchinson, Michael;Thornton, James;Teh, Yee Whye;Doucet, Arnaud",57203416890;57205284491;57220161449;57222378392;6701781188;7101901945,60000179;60026851;60026851;60026851;60026851;60026851,2022-01-01,2022,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,35,,,,"Score-based generative models (SGMs) are a powerful class of generative models that exhibit remarkable empirical performance. Score-based generative modelling (SGM) consists of a “noising” stage, whereby a diffusion is used to gradually add Gaussian noise to data, and a generative model, which entails a “denoising” process defined by approximating the time-reversal of the diffusion. Existing SGMs assume that data is supported on a Euclidean space, i.e. a manifold with flat geometry. In many domains such as robotics, geoscience or protein modelling, data is often naturally described by distributions living on Riemannian manifolds and current SGM techniques are not appropriate. We introduce here Riemannian Score-based Generative Models (RSGMs), a class of generative models extending SGMs to Riemannian manifolds. We demonstrate our approach on a variety of manifolds, and in particular with earth and climate science spherical data.",,10,0,,,EPSRC,EP/R013616/1,Engineering and Physical Sciences Research Council,NeurIPS Machine Learning
2-s2.0-85132302935,10.1145/3519939.3523704,,,RustHornBelt: a semantic foundation for functional verification of Rust programs with unsafe code,cp,Conference Paper,Matsushita Y.,60105997;60025272;60002485,Laboratoire Méthodes Formelles;The University of Tokyo;Max Planck Institute for Software Systems,Gif-sur-Yvette;Tokyo;Saarbrucken,France;Japan;Germany,4,"Matsushita, Yusuke;Denis, Xavier;Jourdan, Jacques Henri;Dreyer, Derek",57216581976;57217949064;55154421500;7004212179,60025272;60105997;60105997;60002485,2022-06-09,9 June 2022,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,841-856,"Rust is a systems programming language that offers both low-level memory operations and high-level safety guarantees, via a strong ownership type system that prohibits mutation of aliased state. In prior work, Matsushita et al. developed RustHorn, a promising technique for functional verification of Rust code: it leverages the strong invariants of Rust types to express the behavior of stateful Rust code with first-order logic (FOL) formulas, whose verification is amenable to off-the-shelf automated techniques. RustHorn's key idea is to use prophecies to describe the behavior of mutable borrows. However, the soundness of RustHorn was only established for a safe subset of Rust, and it has remained unclear how to extend it to support various safe APIs that encapsulate unsafe code (i.e., code where Rust's aliasing discipline is relaxed). In this paper, we present RustHornBelt, the first machine-checked proof of soundness for RustHorn-style verification which supports giving FOL specs to safe APIs implemented with unsafe code. RustHornBelt employs the approach of semantic typing used in Jung et al.'s RustBelt framework, but it extends RustBelt's model to reason not only about safety but also functional correctness. The key challenge in RustHornBelt is to develop a semantic model of RustHorn-style prophecies, which we achieve via a new separation-logic mechanism we call parametric prophecies.",Iris | prophecy variables | Rust | separation logic | type systems | verification,11,1,repositoryvor,Green,H2020,683289,Horizon 2020 Framework Programme,PLDI Programming Languages
2-s2.0-85143068770,10.1145/3540250.3549176,,,SPINE: a scalable log parser with feedback guidance,cp,Conference Paper,Wang X.,60026532;60025278;60021726;60010571,"Microsoft Corporation;Tsinghua University;Microsoft Research;The University of Newcastle, Australia",Redmond;Beijing;Redmond;Callaghan,United States;China;United States;Australia,12,"Wang, Xuheng;Zhang, Xu;Li, Liqun;He, Shilin;Zhang, Hongyu;Liu, Yudong;Zheng, Lingling;Kang, Yu;Lin, Qingwei;Dang, Yingnong;Rajmohan, Saravanakumar;Zhang, Dongmei",57988069300;57212045781;58249839800;57191853952;55685668500;57462181500;55315003000;51461513900;55370882300;41561172500;57224576879;55717568500,60025278;60021726;60021726;60021726;60010571;60021726;60026532;60021726;60021726;60026532;60026532;60021726,2022-11-07,7 November 2022,ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101123502,,Conference Proceeding,,,,1198-1208,"Log parsing, which extracts log templates and parameters, is a critical prerequisite step for automated log analysis techniques. Though existing log parsers have achieved promising accuracy on public log datasets, they still face many challenges when applied in the industry. Through studying the characteristics of real-world log data and analyzing the limitations of existing log parsers, we identify two problems. Firstly, it is non-trivial to scale a log parser to a vast number of logs, especially in real-world scenarios where the log data is extremely imbalanced. Secondly, existing log parsers overlook the importance of user feedback, which is imperative for parser fine-tuning under the continuous evolution of log data. To overcome the challenges, we propose SPINE, which is a highly scalable log parser with user feedback guidance. Based on our log parser equipped with initial grouping and progressive clustering,we propose a novel log data scheduling algorithm to improve the efficiency of parallelization under the large-scale imbalanced log data. Besides, we introduce user feedback to make the parser fast adapt to the evolving logs. We evaluated SPINE on 16 public log datasets. SPINE achieves more than 0.90 parsing accuracy on average with the highest parsing efficiency, which outperforms the state-of-the-art log parsers. We also evaluated SPINE in the production environment of Microsoft, in which SPINE can parse 30million logs in less than 8 minutes under 16 executors, achieving near real-time performance. In addition, our evaluations show that SPINE can consistently achieve good accuracy under log evolution with a moderate number of user feedback.",Feedback Guidance | Log Data Analysis | Log parsing,11,0,,,,undefined,,FSE Software Engineering
2-s2.0-85134366062,10.14778/3538598.3538614,,,SANCUS: Staleness-Aware Communication-Avoiding Full-Graph Decentralized Training in Large-Scale Graph Neural Networks,cp,Conference Paper,Peng J.,60025084;60016930;60008928;60008592,Shanghai Jiao Tong University;Beijing University of Posts and Telecommunications;The Hong Kong Polytechnic University;Hong Kong University of Science and Technology,Shanghai;Beijing;Hong Kong;Hong Kong,China;China;Hong Kong;Hong Kong,6,"Peng, Jingshu;Chen, Zhao;Shao, Yingxia;Shen, Yanyan;Chen, Lei;Cao, Jiannong",57203398162;56192073500;55790671500;57193342639;56442948300;7403354073,60008592;60008592;60016930;60025084;60008592;60008928,2022-01-01,2022,Proceedings of the VLDB Endowment,,21100199855,21508097,Journal,15,9,,1937-1950,"Graph neural networks (GNNs) have emerged due to their success at modeling graph data. Yet, it is challenging for GNNs to efficiently scale to large graphs. Thus, distributed GNNs come into play. To avoid communication caused by expensive data movement between workers, we propose SANCUS, a staleness-aware communication-avoiding decentralized GNN system. By introducing a set of novel bounded embedding staleness metrics and adaptively skipping broadcasts, SANCUS abstracts decentralized GNN processing as sequential matrix multiplication and uses historical embeddings via cache. Theoretically, we show bounded approximation errors of embeddings and gradients with convergence guarantee. Empirically, we evaluate SANCUS with common GNN models via different system setups on large-scale benchmark datasets. Compared to SOTA works, SANCUS can avoid up to 74% communication with at least 1.86⇥ faster throughput on average without accuracy loss.",,9,0,repositoryam,Green,MSRA,16202218,Microsoft Research Asia,VLDB Databases
2-s2.0-85138057594,10.1145/3544216.3544244,,,Software-defined network assimilation: Bridging the last mile towards centralized network configuration management with nassim,cp,Conference Paper,Chen H.,60276981;60028333;60016930;60011592;60008592;60002798;128514196;125506825,The Hong Kong University of Science and Technology (Guangzhou);UNSW Sydney;Beijing University of Posts and Telecommunications;Qilu University of Technology;Hong Kong University of Science and Technology;Chinese University of Hong Kong;Zhongguancun Laboratory;Huawei Theory Lab,Guangzhou;Sydney;Beijing;Jinan;Hong Kong;Hong Kong;Beijing;,China;Australia;China;China;Hong Kong;Hong Kong;China;China,8,"Chen, Huangxun;Miao, Yukai;Chen, Li;Sun, Haifeng;Xu, Hong;Liu, Libin;Zhang, Gong;Wang, Wei",57195407042;57195626178;58606223300;57190948696;55703821900;57191090677;57198462638;57234263600,125506825;60028333;128514196;60016930;60002798;60011592;125506825;60276981-60008592,2022-08-22,22 August 2022,SIGCOMM 2022 - Proceedings of the ACM SIGCOMM 2022 Conference,,21101107990,,Conference Proceeding,,,,281-297,"On-boarding new devices into an existing SDN network is a pain for network operations (NetOps) teams, because much expert effort is required to bridge the gap between the configuration models of the new devices and the unified data model in the SDN controller. In this work, we present an assistant framework NAssim, to help NetOps accelerate the process of assimilating a new device into a SDN network. Our solution features a unified parser framework to parse diverse device user manuals into preliminary configuration models, a rigorous validator that confirm the correctness of the models via formal syntax analysis, model hierarchy validation and empirical data validation, and a deep-learning-based mapping algorithm that uses state-of-The-Art neural language processing techniques to produce human-comprehensible recommended mapping between the validated configuration model and the one in the SDN controller. In all, NAssim liberates the NetOps from most tedious tasks by learning directly from devices' manuals to produce data models which are comprehensible by both the SDN controller and human experts. Our evaluation shows, NAssim can accelerate the assimilation process by 9.1x. In this process, we also identify and correct 243 errors in four mainstream vendors' device manuals, and release a validated and expert-curated dataset of parsed manual corpus for future research.",multi-vendor networks | network configuration management | software-defined networks,8,1,publisherfree2read,Bronze,研究資助局,11209520,"Research Grants Council, University Grants Committee",SIGCOMM Networking
2-s2.0-85163090167,,,,Solving Stackelberg Prediction Game with Least Squares Loss via Spherically Constrained Least Squares Reformulation,cp,Conference Paper,Wang J.,60136640;60018205;60009860,School of Computer Science;Xiamen University;Fudan University,Pittsburgh;Xiamen;Shanghai,United States;China;China,5,"Wang, Jiali;Huang, Wen;Jiang, Rujun;Li, Xudong;Wang, Alex L.",57205669737;56035098600;57191472153;57202295074;57211167078,60009860;60018205;60009860;60009860;60136640,2022-01-01,2022,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,162,,,22665-22679,"The Stackelberg prediction game (SPG) is popular in characterizing strategic interactions between a learner and an attacker. As an important special case, the SPG with least squares loss (SPG-LS) has recently received much research attention. Although initially formulated as a difficult bi-level optimization problem, SPG-LS admits tractable reformulations which can be polynomially globally solved by semidefinite programming or second order cone programming. However, all the available approaches are not well-suited for handling large-scale datasets, especially those with huge numbers of features. In this paper, we explore an alternative reformulation of the SPG-LS. By a novel nonlinear change of variables, we rewrite the SPG-LS as a spherically constrained least squares (SCLS) problem. Theoretically, we show that an ϵ optimal solution to the SCLS (and the SPG-LS) can be achieved in Õ(N/√ϵ) floating-point operations, where N is the number of nonzero entries in the data matrix. Practically, we apply two well-known methods for solving this new reformulation, i.e., the Krylov subspace method and the Riemannian trust region method. Both algorithms are factorization free so that they are suitable for solving large scale problems. Numerical results on both synthetic and real-world datasets indicate that the SPG-LS, equipped with the SCLS reformulation, can be solved orders of magnitude faster than the state of the art.",,1,0,,,NSFC,22ZR1405100,Natural Science Foundation of Shanghai,ICML Machine Learning
2-s2.0-85137765754,10.1145/3528223.3530155,,,Spelunking the Deep: Guaranteed Queries on General Neural Implicit Surfaces via Range Analysis,ar,Article,Sharp N.,60016849,University of Toronto,Toronto,Canada,2,"Sharp, Nicholas;Jacobson, Alec",57204672226;36552585300,60016849;60016849,2022-07-22,22 July 2022,ACM Transactions on Graphics,07300301,24972,15577368,Journal,41,4,107,,"Neural implicit representations, which encode a surface as the level set of a neural network applied to spatial coordinates, have proven to be remarkably effective for optimizing, compressing, and generating 3D geometry. Although these representations are easy to fit, it is not clear how to best evaluate geometric queries on the shape, such as intersecting against a ray or finding a closest point. The predominant approach is to encourage the network to have a signed distance property. However, this property typically holds only approximately, leading to robustness issues, and holds only at the conclusion of training, inhibiting the use of queries in loss functions. Instead, this work presents a new approach to perform queries directly on general neural implicit functions for a wide range of existing architectures. Our key tool is the application of range analysis to neural networks, using automatic arithmetic rules to bound the output of a network over a region; we conduct a study of range analysis on neural networks, and identify variants of affine arithmetic which are highly effective. We use the resulting bounds to develop geometric queries including ray casting, intersection testing, constructing spatial hierarchies, fast mesh extraction, closest-point evaluation, evaluating bulk properties, and more. Our queries can be efficiently evaluated on GPUs, and offer concrete accuracy guarantees even on randomly-initialized networks, enabling their use in training objectives and beyond. We also show a preliminary application to inverse rendering.",geometry processing | implicit surfaces | neural networks | range analysis,13,1,publisherfree2read,Bronze,NSERC,NFRFE-201,Natural Sciences and Engineering Research Council of Canada,SIGGRAPH Graphics
2-s2.0-85130531619,10.1145/3491102.3501981,,,Squeezy-Feely: Investigating Lateral Thumb-Index Pinching as an Input Modality,cp,Conference Paper,Schmitz M.,60028717;60011226,Ludwig-Maximilians-Universität München;Technische Universität Darmstadt,Munich;Darmstadt,Germany;Germany,4,"Schmitz, Martin;Günther, Sebastian;Schön, Dominik;Müller, Florian",56158083600;55804000700;57202942272;57193483579,60011226;60011226;60011226;60028717,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,61,,"From zooming on smartphones and mid-air gestures to deformable user interfaces, thumb-index pinching grips are used in many interaction techniques. However, there is still a lack of systematic understanding of how the accuracy and efficiency of such grips are affected by various factors such as counterforce, grip span, and grip direction. Therefore, in this paper, we contribute an evaluation (N = 18) of thumb-index pinching performance in a visual targeting task using scales up to 75 items. As part of our findings, we conclude that the pinching interaction between the thumb and index finger is a promising modality also for one-dimensional input on higher scales. Furthermore, we discuss and outline implications for future user interfaces that benefit from pinching as an additional and complementary interaction modality.",Deformation | Input | Mixed Reality | Pinching | Thumb-to-finger | User Studies,8,1,publisherfree2read,Bronze,DFG,251654672,Deutsche Forschungsgemeinschaft,CHI Human-Computer Interaction
2-s2.0-85140426982,,,,Stable Conformal Prediction Sets,cp,Conference Paper,Ndiaye E.,60136858,College of Engineering,Atlanta,United States,1,"Ndiaye, Eugene",57189097699,60136858,2022-01-01,2022,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,162,,,16462-16479,"When one observes a sequence of variables (x1, y1),..., (xn, yn), Conformal Prediction (CP) is a methodology that allows to estimate a confidence set for yn+1 given xn+1 by merely assuming that the distribution of the data is exchangeable. CP sets have guaranteed coverage for any finite population size n. While appealing, the computation of such a set turns out to be infeasible in general, e.g., when the unknown variable yn+1 is continuous. The bottleneck is that it is based on a procedure that readjusts a prediction model on data where we replace the unknown target by all its possible values in order to select the most probable one. This requires computing an infinite number of models, which often makes it intractable. In this paper, we combine CP techniques with classical algorithmic stability bounds to derive a prediction set computable with a single model fit. We demonstrate that our proposed confidence set does not lose any coverage guarantees while avoiding the need for data splitting as currently done in the literature. We provide some numerical experiments to illustrate the tightness of our estimation when the sample size is sufficiently large, on both synthetic and real datasets.",,6,0,,,,undefined,,ICML Machine Learning
2-s2.0-85130585911,10.1145/3491102.3502112,,,Still Creepy After All These Years:The Normalization of Affective Discomfort in App Use,cp,Conference Paper,Seberger J.S.,60150772;60031707;60030840;60010875,"John and Marcia Price College of Engineering;Michigan State University;Københavns Universitet;Luddy School of Informatics, Computing, and Engineering",Salt Lake City;East Lansing;Copenhagen;Bloomington,United States;United States;Denmark;United States,4,"Seberger, John S.;Shklovski, Irina;Swiatek, Emily;Patil, Sameer",57216649924;10042838800;57703209300;13007127000,60031707;60030840;60010875;60150772,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,159,,"It is not well understood why people continue to use privacy-invasive apps they consider creepy. We conducted a scenario-based study (n = 751) to investigate how the intention to use an app is influenced by affective perceptions and privacy concerns. We show that creepiness is one facet of affective discomfort, which is becoming normalized in app use. We found that affective discomfort can be negatively associated with the intention to use a privacy-invasive app. However, the influence is mitigated by other factors, including data literacy, views regarding app data practices, and ambiguity of the privacy threat. Our findings motivate a focus on affective discomfort when designing user experiences related to privacy-invasive data practices. Treating affective discomfort as a fundamental aspect of user experience requires scaling beyond the point where the thumb meets the screen and accounting for entrenched data practices and the sociotechnical landscape within which the practices are embedded.",affect | affective discomfort | creepiness | creepy | data practices | mobile apps | privacy | privacy paradox,14,1,publisherfree2read,Bronze,NSF,undefined,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85133514638,10.1145/3510003.3510185,,,SYMTUNER: Maximizing the Power of Symbolic Execution by Adaptively Tuning External Parameters,cp,Conference Paper,Cha S.,60007511;60005273,Sungkyunkwan University;Korea University,Seoul;Seoul,South Korea;South Korea,4,"Cha, Sooyoung;Lee, Myungho;Lee, Seokhyun;Oh, Hakjoo",57191692982;56159565300;57218365597;35275738100,60007511;60005273;60005273;60005273,2022-01-01,2022,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2022-May,,,2068-2079,"We present SYMTUNER, a novel technique to automatically tune external parameters of symbolic execution. Practical symbolic execution tools have important external parameters (e.g., symbolic arguments, seed input) that critically affect their performance. Due to the huge parameter space, however, manually customizing those parameters is notoriously difficult even for experts. As a consequence, symbolic execution tools have typically been used in a suboptimal manner that, for example, simply relies on the default parameter settings of the tools and loses the opportunity for better performance. In this paper, we aim to change this situation by automatically configuring symbolic execution parameters. With Symtuner that takes parameter spaces to be tuned, symbolic executors are run without manual parameter configurations; instead, appropriate parameter values are learned and adjusted during symbolic execution. To achieve this, we present a learning algorithm that observes the behavior of symbolic execution and accordingly updates the sampling probability of each parameter space. We evaluated Symtuner with KLEE on 12 open-source C programs. The results show that Symtuner increases branch coverage of KLEE by 56% on average and finds 8 more bugs than KLEE with its default parameters over the latest releases of the programs.",Software Testing | Symbolic Execution,1,0,,,MSIP,SRFC-IT1701-51,Samsung,ICSE Software Engineering
2-s2.0-85132275488,10.1145/3519939.3523712,,,Synthesizing analytical SQL queries from computation demonstration,cp,Conference Paper,Zhou X.,60025038;60021726;124252072,"University of California, Berkeley;Microsoft Research;University of Washington",Berkeley;Redmond;Urbana,United States;United States;United States,4,"Zhou, Xiangyu;Bodik, Rastislav;Cheung, Alvin;Wang, Chenglong",57668178800;6701821028;56874039700;57194614165,124252072;124252072;60025038;60021726,2022-06-09,9 June 2022,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,168-182,"Analytical SQL is widely used in modern database applications and data analysis. However, its partitioning and grouping operators are challenging for novice users. Unfortunately, programming by example, shown effective on standard SQL, are less attractive because examples for analytical queries are more laborious to solve by hand. To make demonstrations easier to author, we designed a new end-user specification, programming by computation demonstration, that allows the user to demonstrate the task using a (possibly incomplete) cell-level computation trace. This specification is exploited in a new abstraction-based synthesis algorithm to prove that a partially formed query cannot be completed to satisfy the specification, allowing us to prune the search tree. We implemented our approach in a tool named Sickle and tested it on 80 real-world analytical SQL tasks. Results show that even from small demonstrations, Sickle can solve 76 tasks, in 12.8 seconds on average, while the prior approaches can solve only 60 tasks and are on average 22.5 times slower. Furthermore, our user study with 13 participants reveals that our specification increases user efficiency and confidence on challenging tasks.",program synthesis | programing languages,9,1,repositoryam,Green,NSF,CCF-1723352,National Science Foundation,PLDI Programming Languages
2-s2.0-85133519784,10.1145/3510003.3510141,,,TOGA: A Neural Method for Test Oracle Generation,cp,Conference Paper,Dinella E.,60030162;60021726;60006297,Columbia University;Microsoft Research;University of Pennsylvania,New York;Redmond;Philadelphia,United States;United States;United States,4,"Dinella, Elizabeth;Ryan, Gabriel;Mytkowicz, Todd;Lahiri, Shuvendu K.",57224567119;57203547108;15923562800;8938407600,60006297;60030162;60021726;60021726,2022-01-01,2022,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2022-May,,,2130-2141,"Testing is widely recognized as an important stage of the software development lifecycle. Effective software testing can provide benefits such as bug finding, preventing regressions, and documentation. In terms of documentation, unit tests express a unit's intended functionality, as conceived by the developer. A test oracle, typically expressed as an condition, documents the intended behavior of a unit under a given test prefix. Synthesizing a functional test oracle is a challenging problem, as it must capture the intended functionality rather than the implemented functionality. In this paper, we propose TOGA (a neural method for Test Oracle GenerAtion), a unified transformer-based neural approach to infer both exceptional and assertion test oracles based on the context of the focal method. Our approach can handle units with ambiguous or missing documentation, and even units with a missing implementation. We evaluate our approach on both oracle inference accuracy and functional bug-finding. Our technique improves accuracy by 33% over existing oracle inference approaches, achieving 96% over-all accuracy on a held out test dataset. Furthermore, we show that when integrated with a automated test generation tool (EvoSuite), our approach finds 57 real world bugs in large-scale Java programs, including 30 bugs that are not found by any other automated testing method in our evaluation.",language models | machine learning | software testing | test oracles | Testing | transformers,19,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-85143071006,10.1145/3540250.3549114,,,The evolution of type annotations in python: an empirical study,cp,Conference Paper,Di Grazia L.,60015815,Universität Stuttgart,Stuttgart,Germany,2,"Di Grazia, Luca;Pradel, Michael",57209298216;25641744400,60015815;60015815,2022-11-07,7 November 2022,ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101123502,,Conference Proceeding,,,,209-220,"Type annotations and gradual type checkers attempt to reveal errors and facilitate maintenance in dynamically typed programming languages. Despite the availability of these features and tools, it is currently unclear how quickly developers are adopting them, what strategies they follow when doing so, and whether adding type annotations reveals more type errors. This paper presents the first large-scale empirical study of the evolution of type annotations and type errors in Python. The study is based on an analysis of 1,414,936 type annotation changes, which we extract from 1,123,393 commits among 9,655 projects. Our results show that (i) type annotations are getting more popular, and once added, often remain unchanged in the projects for a long time, (ii) projects follow three evolution patterns for type annotation usage - regular annotation, type sprints, and occasional uses - and that the used pattern correlates with the number of contributors, (iii) more type annotations help find more type errors (0.704 correlation), but nevertheless, many commits (78.3%) are committed despite having such errors. Our findings show that better developer training and automated techniques for adding type annotations are needed, as most code still remains unannotated, and they call for a better integration of gradual type checking into the development process.",empirical study | Python | Type annotations | type errors,3,0,,,ERC,851895,European Research Council,FSE Software Engineering
2-s2.0-85163096286,,,,The Importance of Non-Markovianity in Maximum State Entropy Exploration,cp,Conference Paper,Mutti M.,60028218;60025858;60023256,Alma Mater Studiorum Università di Bologna;ETH Zürich;Politecnico di Milano,Bologna;Zurich;Milan,Italy;Switzerland;Italy,3,"Mutti, Mirco;De Santi, Riccardo;Restelli, Marcello",57204810348;57453681400;6603404086,60023256-60028218;60025858;60023256,2022-01-01,2022,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,162,,,16223-16239,"In the maximum state entropy exploration framework, an agent interacts with a reward-free environment to learn a policy that maximizes the entropy of the expected state visitations it is inducing. Hazan et al. (2019) noted that the class of Markovian stochastic policies is sufficient for the maximum state entropy objective, and exploiting non-Markovianity is generally considered pointless in this setting. In this paper, we argue that non-Markovianity is instead paramount for maximum state entropy exploration in a finite-sample regime. Especially, we recast the objective to target the expected entropy of the induced state visitations in a single trial. Then, we show that the class of non-Markovian deterministic policies is sufficient for the introduced objective, while Markovian policies suffer non-zero regret in general. However, we prove that the problem of finding an optimal non-Markovian policy is NP-hard. Despite this negative result, we discuss avenues to address the problem in a tractable way and how non-Markovian exploration could benefit the sample efficiency of online reinforcement learning in future works.",,4,0,,,,undefined,,ICML Machine Learning
2-s2.0-85129594023,10.1145/3491102.3502039,,,The TAC Toolkit: Supporting Design for User Acceptance of Health Technologies from a Macro-Temporal Perspective,cp,Conference Paper,Nadal C.,60117772;60011373;60011149,"School of Computing and Communications, Lancaster University;Technical University of Denmark;Trinity College Dublin",Lancaster;Lyngby;Dublin,United Kingdom;Denmark;Ireland,5,"Nadal, Camille;McCully, Shane;Doherty, Kevin;Sas, Corina;Doherty, Gavin",57204610132;57704111500;57192910271;9636939200;13006308800,60011149;60011149;60011373;60117772;60011149,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,233,,"User acceptance is key for the successful uptake and use of health technologies, but also impacted by numerous factors not always easily accessible nor operationalised by designers in practice. This work seeks to facilitate the application of acceptance theory in design practice through the Technology Acceptance (TAC) toolkit: a novel theory-based design tool and method comprising 16 cards, 3 personas, 3 scenarios, a virtual think-space, and a website, which we evaluated through workshops conducted with 21 designers of health technologies. Findings showed that the toolkit revised and extended designers' knowledge of technology acceptance, fostered their appreciation, empathy and ethical values while designing for acceptance, and contributed towards shaping their future design practice. We discuss implications for considering user acceptance a dynamic, multi-stage process in design practice, and better supporting designers in imagining distant acceptance challenges. Finally, we examine the generative value of the TAC toolkit and its possible future evolution.",design cards | macro-temporal perspective | technology acceptance | technology acceptance lifecycle | user-centered design,13,1,repositoryvor,Green,H2020,13/RC/2094_P2,Horizon 2020 Framework Programme,CHI Human-Computer Interaction
2-s2.0-85124562842,10.1145/3491102.3501826,,,Towards Relatable Explainable AI with the Perceptual Process,cp,Conference Paper,Zhang W.,60017161,National University of Singapore,Singapore City,Singapore,2,"Zhang, Wencan;Lim, Brian Y.",57221774018;23091411300,60017161;60017161,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,181,,"Machine learning models need to provide contrastive explanations, since people often seek to understand why a puzzling prediction occurred instead of some expected outcome. Current contrastive explanations are rudimentary comparisons between examples or raw features, which remain difficult to interpret, since they lack semantic meaning. We argue that explanations must be more relatable to other concepts, hypotheticals, and associations. Inspired by the perceptual process from cognitive psychology, we propose the XAI Perceptual Processing Framework and RexNet model for relatable explainable AI with Contrastive Saliency, Counterfactual Synthetic, and Contrastive Cues explanations. We investigated the application of vocal emotion recognition, and implemented a modular multi-task deep neural network to predict and explain emotions from speech. From think-aloud and controlled studies, we found that counterfactual explanations were useful and further enhanced with semantic cues, but not saliency explanations. This work provides insights into providing and evaluating relatable contrastive explainable AI for perception applications.",audio | contrastive explanations | Explainable AI | vocal emotion,28,1,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85163092301,,,,Understanding Dataset Difficulty with V-Usable Information,cp,Conference Paper,Ethayarajh K.,60028661;60012708;126150611,UW College of Engineering;Stanford University;Allen Institute for Artificial Intelligence,Seattle;Stanford;Allen,United States;United States;United States,3,"Ethayarajh, Kawin;Choi, Yejin;Swayamdipta, Swabha",57193887168;36172231400;55513212500,60012708;126150611-60028661;126150611,2022-01-01,2022,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,162,,,5988-6008,"Estimating the difficulty of a dataset typically involves comparing state-of-the-art models to humans; the bigger the performance gap, the harder the dataset is said to be. However, this comparison provides little understanding of how difficult each instance in a given distribution is, or what attributes make the dataset difficult for a given model. To address these questions, we frame dataset difficulty-w.r.t. a model V-as the lack of V-usable information (Xu et al., 2019), where a lower value indicates a more difficult dataset for V. We further introduce pointwise V-information (PVI) for measuring the difficulty of individual instances w.r.t. a given distribution. While standard evaluation metrics typically only compare different models for the same dataset, V-usable information and PVI also permit the converse: for a given model V, we can compare different datasets, as well as different instances/slices of the same dataset. Furthermore, our framework allows for the interpretability of different input attributes via transformations of the input, which we use to discover annotation artefacts in widely-used NLP benchmarks.",,25,0,,,,undefined,,ICML Machine Learning
2-s2.0-85143076530,10.1145/3540250.3549104,,,Using nudges to accelerate code reviews at scale,cp,Conference Paper,Shan Q.,60271648;60033154,Meta;Concordia University,Menlo Park;Montreal,United States;Canada,8,"Shan, Qianhua;Sukhdeo, David;Huang, Qianying;Rogers, Seth;Chen, Lawrence;Paradis, Elise;Rigby, Peter C.;Nagappan, Nachiappan",57988006800;57988335900;57988181400;57987786000;57987666700;57987555000;17346820500;8261920700,60271648;60271648;60271648;60271648;60271648;60271648;60271648-60033154;60271648,2022-11-07,7 November 2022,ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101123502,,Conference Proceeding,,,,472-482,"We describe a large-scale study to reduce the amount of time code review takes. Each quarter at Meta we survey developers. Combining sentiment data from a developer experience survey and telemetry data from our diff review tool, we address, ""When does a diff review feel too slow?""From the sentiment data alone, we learn that 84.7% of developers are satisfied with the time their diffs spend in review. By enriching the survey results with telemetry for each respondent, we determined that sentiment is closely associated with the 75th percentile time in review for that respondent's diffs, ie those that take more than 24 hours. To encourage developers to act on stale diffs that have had no action for 24 or more hours, we designed a NudgeBot to notify, ie nudge, reviewers. To determine who to nudge when a diff is stale, we created a model to rank the reviewers based on the probability that they will make a comment or perform some other action on a diff. This model outperformed models that looked at files the reviewer had modified in the past. Combining this information with prior author-review relationships, we achieved an MRR and AUC of .81 and .88, respectively. To evaluate NudgeBot in production, we conducted an A/B cluster-randomized experiment on over 30k engineers. We observed substantial statistically significant decrease in both time in review (-6.8%, p=0.049) and time to first reviewer action (-9.9%, p=0.010). We also used guard metrics to ensure that most reviews were still done in fewer than 24 hours and that reviewers still spend the same amount of time looking at diffs, and saw no statistically significant change in these metrics. NudgeBot is now rolled out company wide and is used daily by thousands of engineers at Meta.",Code Review | Efficiency | Nudging,3,0,,,,undefined,,FSE Software Engineering
2-s2.0-85159484600,,,,Using natural language and program abstractions to instill human inductive biases in machines,cp,Conference Paper,Kumar S.,60141284;60111161;60003269;113146654,School of Engineering and Applied Science;DeepMind Technologies Limited;Princeton University;Princeton Neuroscience Institute,Princeton;London;Princeton;Princeton,United States;United Kingdom;United States;United States,10,"Kumar, Sreejan;Correa, Carlos G.;Dasgupta, Ishita;Marjieh, Raja;Hu, Michael Y.;Hawkins, Robert D.;Daw, Nathaniel D.;Cohen, Jonathan D.;Narasimhan, Karthik;Griffiths, Thomas L.",57210601181;57221322617;57194405744;56709654100;57221157962;57914608000;7005134854;54992680400;56577616300;57222226477,113146654;113146654;60111161;60003269;60141284;113146654-60003269;113146654-60003269;113146654-60003269;60141284;60003269-60141284,2022-01-01,2022,Advances in Neural Information Processing Systems,10495258,23669,,Conference Proceeding,35,,,,"Strong inductive biases give humans the ability to quickly learn to perform a variety of tasks. Although meta-learning is a method to endow neural networks with useful inductive biases, agents trained by meta-learning may sometimes acquire very different strategies from humans. We show that co-training these agents on predicting representations from natural language task descriptions and programs induced to generate such tasks guides them toward more human-like inductive biases. Human-generated language descriptions and program induction models that add new learned primitives both contain abstract concepts that can compress description length. Co-training on these representations result in more human-like behavior in downstream meta-reinforcement learning agents than less abstract controls (synthetic language descriptions, program induction without learned primitives), suggesting that the abstraction supported by these representations is key.",,4,0,,,NIH,T32MH065214,National Institutes of Health,NeurIPS Machine Learning
2-s2.0-85132265999,10.1145/3519939.3523709,,,Visualization question answering using introspective program synthesis,cp,Conference Paper,Chen Y.,60142701,UC Santa Barbara College of Engineering,Santa Barbara,United States,3,"Chen, Yanju;Yan, Xifeng;Feng, Yu",57210928384;36083601600;57026668300,60142701;60142701;60142701,2022-06-09,9 June 2022,Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),,90600,,Conference Proceeding,,,,137-151,"While data visualization plays a crucial role in gaining insights from data, generating answers over complex visualizations from natural language questions is far from an easy task. Mainstream approaches reduce data visualization queries to a semantic parsing problem, which either relies on expensive-to-annotate supervised training data that pairs natural language questions with logical forms, or weakly supervised models that incorporate a larger corpus but fail on long-tailed queries without explanations. This paper aims to answer data visualization queries by automatically synthesizing the corresponding program from natural language. At the core of our technique is an abstract synthesis engine that is bootstrapped by an off-the-shelf weakly supervised model and an optimal synthesis algorithm guided by triangle alignment constraints, which represent consistency among natural language, visualization, and the synthesized program. Starting with a few tentative answers obtained from an off-the-shelf statistical model, our approach first involves an abstract synthesizer that generates a set of sketches that are consistent with the answers. Then we design an instance of optimal synthesis to complete one of the candidate sketches by satisfying common type constraints and maximizing the consistency among three parties, i.e., natural language, the visualization, and the candidate program. We implement the proposed idea in a system called Poe that can answer visualization queries from natural language. Our method is fully automated and does not require users to know the underlying schema of the visualizations. We evaluate Poe on 629 visualization queries and our experiment shows that Poe outperforms state-of-the-arts by improving the accuracy from 44% to 59%.",Machine Learning | Natural Language Processing | Program Synthesis | Visualization,0,1,publisherfree2read,Bronze,NSF,1908494,National Science Foundation,PLDI Programming Languages
2-s2.0-85131680289,10.1145/3530892,,,WISEFUSE: Workload Characterization and DAG Transformation for Serverless Workflows,ar,Article,Mahgoub A.,60027950;60021726;60009254,Carnegie Mellon University;Microsoft Research;Purdue University,Pittsburgh;Redmond;West Lafayette,United States;United States;United States,7,"Mahgoub, Ashraf;Yi, Edgardo Barsallo;Shankar, Karthick;Minocha, Eshaan;Elnikety, Sameh;Bagchi, Saurabh;Chaterji, Somali",56878717700;57203268424;57215202832;57734726400;8366429300;14821898700;18133715900,60009254;60009254;60027950;60009254;60021726;60009254;60009254,2022-06-01,June 2022,Proceedings of the ACM on Measurement and Analysis of Computing Systems,,21101048533,24761249,Journal,6,2,3530892,,"We characterize production workloads of serverless DAGs at a major cloud provider. Our analysis highlights two major factors that limit performance: (a) lack of efficient communication methods between the serverless functions in the DAG, and (b) stragglers when a DAG stage invokes a set of parallel functions that must complete before starting the next DAG stage. To address these limitations, we propose WISEFUSE, an automated approach to generate an optimized execution plan for serverless DAGs for a user-specified latency objective or budget. We introduce three optimizations: (1) Fusion combines in-series functions together in a single VM to reduce the communication overhead between cascaded functions. (2) Bundling executes a group of parallel invocations of a function in one VM to improve resource sharing among the parallel workers to reduce skew. (3) Resource Allocation assigns the right VM size to each function or function bundle in the DAG to reduce the E2E latency and cost. We implement WISEFUSE to evaluate it experimentally using three popular serverless applications with different DAG structures, memory footprints, and intermediate data sizes. Compared to competing approaches and other alternatives, WISEFUSE shows significant improvements in E2E latency and cost. Specifically, for a machine learning pipeline, WISEFUSE achieves P95 latency that is 67% lower than Photons, 39% lower than Faastlane, and 90% lower than SONIC without increasing the cost.",Dag transformation | Serverless | Workload characterization,14,1,publisherfree2read,Bronze,NSF,CCF-1919197,National Science Foundation,SIGMETRICS Performance
2-s2.0-85129713632,10.1145/3491102.3501901,,,Weaving Stories: Toward Repertoires for Designing Things,cp,Conference Paper,Oogjes D.,60032882;60018491,Technische Universiteit Eindhoven;Simon Fraser University,Eindhoven;Burnaby,Netherlands;Canada,2,"Oogjes, Doenja;Wakkary, Ron",57189034863;9633977700,60018491;60018491-60032882,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,98,,"While much work is underway within the context of posthuman design, this research is often described from a dominantly human perspective. It rarely accounts for the creative capacities of nonhumans in design, such as materials, tools, and software. There is a need to further engage with posthuman theories conceptually, materially, and methodologically. We approach this challenge through Ron Wakkary's concept of repertoires: actions the human designer can take to increase participation of nonhumans in design research practice. This paper reports on potential repertoires' development by exploring three approaches from outside of HCI: describing the landscape, noticing, and translations. We use these methods to account for weaving events that the first author was engaged in. Through critical reflection of these accounts, we contribute three repertoires and an example of applying the theoretical framework of Designing Things.","designing things | posthuman design, more-than-human, posthumanism, repertoires, first-person, research through design, e-textiles | weaving",24,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85133508423,10.1145/3510003.3510205,,,What Makes a Good Commit Message?,cp,Conference Paper,Tian Y.,60025160;60016835,University College Cork;Beijing Institute of Technology,Cork;Beijing,Ireland;China,5,"Tian, Yingchen;Zhang, Yuxia;Stol, Klaas Jan;Jiang, Lin;Liu, Hui",57453723600;57195345510;6603128515;57215299752;56862404100,60016835;60016835;60025160;60016835;60016835,2022-01-01,2022,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,2022-May,,,2389-2401,"A key issue in collaborative software development is communication among developers. One modality of communication is a commit message, in which developers describe the changes they make in a repository. As such, commit messages serve as an 'audit trail' by which developers can understand how the source code of a project has changed-and why. Hence, the quality of commit messages affects the effectiveness of communication among developers. Commit messages are often of poor quality as developers lack time and motivation to craft a good message. Several automatic approaches have been proposed to generate commit messages. However, these are based on uncurated datasets including considerable proportions of poorly phrased commit messages. In this multi-method study, we first define what constitutes a 'good' commit message, and then establish what proportion of commit messages lack information using a sample of almost 1,600 messages from five highly active open source projects. We find that an average of circa 44% of messages could be improved, suggesting the use of uncurated datasets may be a major threat when commit message generators are trained with such data. We also observe that prior work has not considered semantics of commit messages, and there is surprisingly little guidance available for writing good commit messages. To that end, we develop a taxonomy based on recurring patterns in commit messages' expressions. Finally, we investigate whether 'good' commit messages can be automatically identified; such automation could prompt developers to write better commit messages.",commit message quality | Commit-based software development | open collaboration,15,1,repositoryam,Green,SFI,13/RC/2094-P2,Science Foundation Ireland,ICSE Software Engineering
2-s2.0-85127831640,10.1145/3491102.3501967,,,When Confidence Meets Accuracy: Exploring the Effects of Multiple Performance Indicators on Trust in Machine Learning Models,cp,Conference Paper,Rechkemmer A.,60009254,Purdue University,West Lafayette,United States,2,"Rechkemmer, Amy;Yin, Ming",57190815274;57220860849,60009254;60009254,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,535,,"Previous research shows that laypeople's trust in a machine learning model can be affected by both performance measurements of the model on the aggregate level and performance estimates on individual predictions. However, it is unclear how people would trust the model when multiple performance indicators are presented at the same time. We conduct an exploratory human-subject experiment to answer this question. We find that while the level of model confidence significantly affects people's belief in model accuracy, both the model's stated and observed accuracy generally have a larger impact on people's willingness to follow the model's predictions as well as their self-reported levels of trust in the model, especially after observing the model's performance in practice. We hope the empirical evidence reported in this work could open doors to further studies to advance understanding of how people perceive, process, and react to performance-related information of machine learning.",accuracy | confidence | human-subject experiments | Machine learning | trust,29,1,publisherfree2read,Bronze,NSF,IIS-1850335,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85141039795,,,,XRP: In-Kernel Storage Functions with eBPF,cp,Conference Paper,Zhong Y.,60030162;60025488;60006191,Columbia University;The University of Utah;Google LLC,New York;Salt Lake City;Mountain View,United States;United States;United States,11,"Zhong, Yuhong;Li, Haoyu;Wu, Yu Jian;Zarkadas, Ioannis;Tao, Jeffrey;Mesterhazy, Evan;Makris, Michael;Yang, Junfeng;Tai, Amy;Stutsman, Ryan;Cidon, Asaf",57222381167;57950518700;57215929523;57950024900;57425074200;57950644800;57950893100;36676080800;57212507432;14055061000;36674660200,60030162;60030162;60030162;60030162;60030162;60030162;60030162;60030162;60006191;60025488;60030162,2022-01-01,2022,"Proceedings of the 16th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2022",,21101117816,,Conference Proceeding,,,,375-393,"With the emergence of microsecond-scale NVMe storage devices, the Linux kernel storage stack overhead has become significant, almost doubling access times. We present XRP, a framework that allows applications to execute user-defined storage functions, such as index lookups or aggregations, from an eBPF hook in the NVMe driver, safely bypassing most of the kernel's storage stack. To preserve file system semantics, XRP propagates a small amount of kernel state to its NVMe driver hook where the user-registered eBPF functions are called. We show how two key-value stores, BPF-KV, a simple B+-tree key-value store, and WiredTiger, a popular log-structured merge tree storage engine, can leverage XRP to significantly improve throughput and latency.",,20,0,,,NSF,CNS-1750558,National Science Foundation,OSDI Operating Systems
2-s2.0-85130511818,10.1145/3491102.3501973,,,Zoom Obscura: Counterfunctional Design for Video-Conferencing,cp,Conference Paper,Elsden C.,60176037;60027272;60011520;60010964,"Faculty of Social Sciences &amp; Health;The University of Edinburgh;King's College London;Goldsmiths, University of London",Durham;Edinburgh;London;London,United Kingdom;United Kingdom;United Kingdom;United Kingdom,5,"Elsden, Chris;Chatting, David;Duggan, Michael;Dwyer, Andrew Carl;Thornton, Pip",56278061700;15057603600;57194194475;57224540198;56879865700,60027272;60010964;60011520;60176037;60027272,2022-04-29,29 April 2022,Conference on Human Factors in Computing Systems - Proceedings,,21101089608,,Conference Proceeding,,,143,,"This paper reports on Zoom Obscura - an artist-based design research project, responding to the ubiquity of video-conferencing as a technical and cultural phenomenon throughout the Covid-19 pandemic. As enterprise software, such as Zoom, rapidly came to mediate even the most personal and intimate interactions, we supported and collaborated with seven independent artists to explore technical and creative interventions in video-conferencing. Our call for participation sought critical interventions that would help users counter, and regain agency in regard to the various ways in which personal data is captured, transmitted and processed in video-conferencing tools. In this design study, we analyse post-hoc how each of the seven projects employed aspects of counterfunctional design to achieve these aims. Each project reveals different avenues and strategies for counterfunctionality in video-conferencing software, as well as opportunities to design critically towards interactions and experiences that challenge existing norms and expectations around these platforms.",Counterfunctional Design | Covid-19 | Design Research | Surveillance | Video Conferencing | Zoom,9,1,repositoryam,Green,EPSRC,AH/S002782/1,Engineering and Physical Sciences Research Council,CHI Human-Computer Interaction
2-s2.0-85166470751,10.1109/SP46215.2023.10179410,,,"""In Eighty Percent of the Cases, i Select the Password for Them"": Security and Privacy Challenges, Advice, and Opportunities at Cybercafes in Kenya",cp,Conference Paper,Munyendo C.W.,60020238;60003088,Universität Paderborn;The George Washington University,"Paderborn;Washington, D.C.",Germany;United States,3,"Munyendo, Collins W.;Acar, Yasemin;Aviv, Adam J.",57224899919;55837116400;24490560000,60003088;60003088-60020238;60003088,2023-01-01,2023,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2023-May,,,570-587,"Cybercafes remain a popular way to access the Internet in the developing world as many users still lack access to personal computers. Coupled with the recent digitization of government services, e.g. in Kenya, many users have turned to cybercafes to access essential services. Many of these users may have never used a computer, and face significant security and privacy issues at cybercafes. Yet, these challenges as well as the advice offered remain largely unexplored. We investigate these challenges along with the security advice and support provided by the operators at cybercafes in Kenya through n = 36 semi-structured interviews (n = 14 with cybercafe managers and n = 22 with customers). We find that cybercafes serve a crucial role in Kenya by enabling access to printing and government services. However, most customers face challenges with computer usage as well as security and usability challenges with account creation and password management. As a workaround, customers often rely on the support and advice of cybercafe managers who mostly direct them to use passwords that are memorable, e.g. simply using their national ID numbers or names. Some managers directly manage passwords for their customers, with one even using the same password for all their customers. These results suggest the need for more awareness about phone-based password managers, as well as a need for computer training and security awareness among these users. There is also a need to explore security and privacy advice beyond Western peripheries to support broader populations.",Cybercafes | Kenya | Privacy | Security,1,0,,,NSF,1845300,National Science Foundation,S&P Security and Privacy
2-s2.0-85158127970,10.1145/3544548.3580702,,,"""My Zelda Cane"": Strategies Used by Blind Players to Play Visual-Centric Digital Games",cp,Conference Paper,Gonçalves D.,60002769,"Faculdade de Ciências, Universidade de Lisboa",Lisbon,Portugal,5,"Gonçalves, David;Piçarra, Manuel;Pais, Pedro;Guerreiro, João;Rodrigues, André",56612935600;58079235300;57531988000;56967056100;56577139300,60002769;60002769;60002769;60002769;60002769,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,289,,"Mainstream games are typically designed around the visual experience, with behaviors and interactions highly dependent on vision. Despite this, blind people are playing mainstream games while dealing with and overcoming inaccessible content, often together with friends and audiences. In this work, we analyze over 70 hours of YouTube videos, where blind content-creators play visual-centric games. We point out the various strategies employed by players to overcome barriers that permeate mainstream games. We reflect on ways to enable and improve blind players' experience with these games, shedding light on the positive and negative consequences of apparently benign design choices. Our observations underline how game elements are appropriated for accessibility, the incidental consequences of audio design, and the trade-offs between accessibility, agency, and engagement.",accessibility | blind | digital games | gaming | navigation,5,1,repositoryam,Green,FCT,2022.08895,Fundação para a Ciência e a Tecnologia,CHI Human-Computer Interaction
2-s2.0-85160013836,10.1145/3544548.3580933,,,"'Treat me as your friend, not a number in your database': Co-designing with Children to Cope with Datafication Online",cp,Conference Paper,Wang G.,60026851,University of Oxford,Oxford,United Kingdom,4,"Wang, Ge;Zhao, Jun;Van Kleek, Max;Shadbolt, Nigel",57209399294;58142167500;6507917811;56867428600,60026851;60026851;60026851;60026851,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,95,,"Datafication refers to the practices through which children's online actions are pervasively recorded, tracked, aggregated, analysed, and exploited by online services in ways including behavioural engineering and monetisation. Previous research has shown that not only do children care significantly about various aspects of datafication, but they demand a chance to take action. Through 10 co-design sessions with 53 children, we examined how children in the UK want to be supported to cope with the datafication practices. Our findings provide insights for creating age-appropriate support for children's algorithmic literacy development, highlighting and unpacking the importance of no one-size-fitting-all designs to support children's coping with datafication. We contribute a first understanding of how children aged 7-14 would like to be supported with datafication and what future data-driven digital experiences should be like for them, who demand a shift of the current data ecosystem towards a more humane-by-design and autonomy-supportive future.",Children | Co-design | Data Inference | Datafication | Online Platforms,2,0,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85166312196,10.1145/3592433,,,3D Gaussian Splatting for Real-Time Radiance Field Rendering,ar,Article,Kerbl B.,60110693;60032385;60000256,Université Côte d'Azur;Centre Inria Sophia Antipolis - Méditerranée;Max Planck Institute for Informatics,Nice;Sophia Antipolis;Saarbrucken,France;France;Germany,4,"Kerbl, Bernhard;Kopanas, Georgios;Leimkuehler, Thomas;Drettakis, George",55505216500;57190136199;58514370800;6603449604,60110693;60032385-60110693;60000256;60032385,2023-08-01,1 August 2023,ACM Transactions on Graphics,07300301,24972,15577368,Journal,42,4,3592433,,"Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos. However, achieving high visual quality still requires neural networks that are costly to train and render, while recent faster methods inevitably trade off speed for quality. For unbounded and complete scenes (rather than isolated objects) and 1080p resolution rendering, no current method can achieve real-time display rates. We introduce three key elements that allow us to achieve state-of-the-art visual quality while maintaining competitive training times and importantly allow high-quality real-time (≥ 30 fps) novel-view synthesis at 1080p resolution. First, starting from sparse points produced during camera calibration, we represent the scene with 3D Gaussians that preserve desirable properties of continuous volumetric radiance fields for scene optimization while avoiding unnecessary computation in empty space; Second, we perform interleaved optimization/density control of the 3D Gaussians, notably optimizing anisotropic covariance to achieve an accurate representation of the scene; Third, we develop a fast visibility-aware rendering algorithm that supports anisotropic splatting and both accelerates training and allows realtime rendering. We demonstrate state-of-the-art visual quality and real-time rendering on several established datasets.",3D gaussians | novel view synthesis | radiance fields | real-time rendering,36,1,repositoryam,Green,,undefined,,SIGGRAPH Graphics
2-s2.0-85180548259,10.1145/3611643.3616250,,,A Four-Year Study of Student Contributions to OSS vs. OSS4SG with a Lightweight Intervention,cp,Conference Paper,Fang Z.,60025778;60021726;60003915,"University of Michigan, Ann Arbor;Microsoft Research;Vanderbilt University",Ann Arbor;Redmond;Nashville,United States;United States;United States,7,"Fang, Zihan;Endres, Madeline;Zimmermann, Thomas;Ford, Denae;Weimer, Westley;Leach, Kevin;Huang, Yu",58778449900;57215300297;16308551800;56939915300;7003629741;57908411800;57188585234,60003915;60025778;60021726;60021726;60025778;60003915;60003915,2023-11-30,30 November 2023,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101194128,,Conference Proceeding,,,,3-15,"Modern software engineering practice and training increasingly rely on Open Source Software (OSS). The recent growth in demand for professional software engineers has led to increased contributions to, and usage of, OSS. However, there is limited understanding of the factors affecting how developers, and how new or student developers in particular, decide which OSS projects to contribute to, a process critical to OSS sustainability, access, adoption, and growth. To better understand OSS contributions from the developers of tomorrow, we conducted a four-year study with 1,361 students investigating the life cycle of their contributions (from project selection to pull request acceptance). During the study, we also delivered a lightweight intervention to promote the awareness of open source projects for social good (OSS4SG), OSS projects that have positive impacts in other domains. Using both quantitative and qualitative methods, we analyze student experience reports and the pull requests they submit. Compared to general OSS projects, we find significant differences in project selection ( < 0.0001, effect size = 0.84), student motivation ( < 0.01, effect size = 0.13), and increased pull-request acceptance rates for OSS4SG contributions. We also find that our intervention correlates with increased student contributions to OSS4SG ( < 0.0001, effect size = 0.38). Finally, we analyze correlations of factors such as gender or working with a partner. Our findings may help improve the experience for new developers participating in OSS4SG and the quality of their contributions. We also hope our work helps educators, project leaders, and contributors to build a mutually-beneficial framework for the future growth of OSS4SG.",CS Education | Open Source Software | Social Good,0,0,,,,undefined,,FSE Software Engineering
2-s2.0-85180552694,10.1145/3611643.3616246,,,"A Highly Scalable, Hybrid, Cross-Platform Timing Analysis Framework Providing Accurate Differential Throughput Estimation via Instruction-Level Tracing",cp,Conference Paper,Hsu M.Y.,60007278;129811289,"University of California, Irvine;SiFive",Irvine;,United States;United States,5,"Hsu, Min Yih;Hetzelt, Felicitas;Gens, David;Maitland, Michael;Franz, Michael",57421694100;57194116109;56964079100;58424335600;35757394900,60007278;60007278;60007278;129811289;60007278,2023-11-30,30 November 2023,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101194128,,Conference Proceeding,,,,821-831,"Differential throughput estimation, i.e., predicting the performance impact of software changes, is critical when developing applications that rely on accurate timing bounds, such as automotive, avionic, or industrial control systems. However, developers often lack access to the target hardware to perform on-device measurements, and hence rely on instruction throughput estimation tools to evaluate performance impacts. State-of-the-art techniques broadly fall into two categories: dynamic and static. Dynamic approaches emulate program execution using cycle-accurate microarchitectural simulators resulting in high precision at the cost of long turnaround times and convoluted setups. Static approaches reduce overhead by predicting cycle counts outside of a concrete runtime environment. However, they are limited by the lack of dynamic runtime information and mostly focus on predictions over single basic blocks which requires developers to manually construct critical instruction sequences. We present MCAD, a hybrid timing analysis framework that combines the advantages of dynamic and static approaches. Instead of relying on heavyweight cycle-accurate emulation, MCAD collects instruction traces along with dynamic runtime information from QEMU and streams them to a static throughput estimator. This allows developers to accurately estimate the performance impact of software changes for complete programs within minutes, reducing turnaround times by orders of magnitude compared to existing approaches with similar accuracy. Our evaluation shows that MCAD scales to real-world applications such as FFmpeg and Clang with millions of instructions, achieving <3% geo.mean error compared to ground truth timings from hardware-performance counters on x86 andARM machines.",combining static and dynamic analyses | differential throughput analysis | performance | throughput analysis,0,1,repositoryam,Green,DARPA,N66001-20-C-4027,Defense Advanced Research Projects Agency,FSE Software Engineering
2-s2.0-85152289717,10.1109/ICSE48619.2023.00047,,,A Qualitative Study on the Implementation Design Decisions of Developers,cp,Conference Paper,Liang J.T.,60279735;60136640;60027090;60015481,College of Engineering and Computing;School of Computer Science;Virginia Polytechnic Institute and State University;University of Washington,Fairfax;Pittsburgh;Blacksburg;Seattle,United States;United States;United States;United States,5,"Liang, Jenny T.;Arab, Maryam;Ko, Minhyuk;Ko, Amy J.;Latoza, Thomas D.",57224570366;57216082729;58095353600;7007018374;16230457100,60136640;60279735;60027090;60015481;60279735,2023-01-01,2023,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,435-447,"Decision-making is a key software engineering skill. Developers constantly make choices throughout the software development process, from requirements to implementation. While prior work has studied developer decision-making, the choices made while choosing what solution to write in code remain understudied. In this mixed-methods study, we examine the phenomenon where developers select one specific way to implement a behavior in code, given many potential alternatives. We call these decisions implementation design decisions. Our mixed-methods study includes 46 survey responses and 14 semi-structured interviews with professional developers about their decision types, considerations, processes, and expertise for implementation design decisions. We find that implementation design decisions, rather than being a natural outcome from higher levels of design, require constant monitoring of higher level design choices, such as requirements and architecture. We also show that developers have a consistent general structure to their implementation decision-making process, but no single process is exactly the same. We discuss the implications of our findings on research, education, and practice, including insights on teaching developers how to make implementation design decisions.",implementation design decisions | software design,1,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-85174397433,,,,A Watermark for Large Language Models,cp,Conference Paper,Kirchenbauer J.,60020304,"University of Maryland, College Park",College Park,United States,6,"Kirchenbauer, John;Geiping, Jonas;Wen, Yuxin;Katz, Jonathan;Miers, Ian;Goldstein, Tom",57712873800;57201420593;57215596635;55613231842;55815678900;57225132014,60020304;60020304;60020304;60020304;60020304;60020304,2023-01-01,2023,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,202,,,17061-17084,"Potential harms of large language models can be mitigated by watermarking model output, i.e., embedding signals into generated text that are invisible to humans but algorithmically detectable from a short span of tokens. We propose a watermarking framework for proprietary language models. The watermark can be embedded with negligible impact on text quality, and can be detected using an efficient open-source algorithm without access to the language model API or parameters. The watermark works by selecting a randomized set of “green” tokens before a word is generated, and then softly promoting use of green tokens during sampling. We propose a statistical test for detecting the watermark with interpretable p-values, and derive an information-theoretic framework for analyzing the sensitivity of the watermark. We test the watermark using a multi-billion parameter model from the Open Pretrained Transformer (OPT) family, and discuss robustness and security.",,5,0,,,NSF,HR00112020007,National Science Foundation,ICML Machine Learning
2-s2.0-85174403232,,,,Adapting to game trees in zero-sum imperfect information games,cp,Conference Paper,Fiegel C.,60272370;60111161;60010447;60005667;114886459,OMRON SINIC X Corporation;DeepMind Technologies Limited;Centre de Recherche en Économie et Statistique;École Normale Supérieure de Lyon;Criteo AI Lab,Tokyo;London;Palaiseau;Lyon;Paris,Japan;United Kingdom;France;France;France,6,"Fiegel, Côme;Ménard, Pierre;Kozuno, Tadashi;Munos, Rémi;Perchet, Vianney;Valko, Michal",58040835300;57209736581;42961642900;6603222926;36020384800;25642222500,60010447;60005667;60272370;60111161;60010447-114886459;60111161,2023-01-01,2023,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,202,,,10093-10135,"Imperfect information games (IIG) are games in which each player only partially observes the current game state. We study how to learn ε-optimal strategies in a zero-sum IIG through self-play with trajectory feedback. We give a problem-independent lower bound Õ(H(AX + BY)/ε2) on the required number of realizations to learn these strategies with high probability, where H is the length of the game, AX and BY are the total number of actions for the two players. We also propose two Follow the Regularized leader (FTRL) algorithms for this setting: Balanced FTRL which matches this lower bound, but requires the knowledge of the information set structure beforehand to define the regularization; and Adaptive FTRL which needs Õ(H2(AX + BY)/ε2) realizations without this requirement by progressively adapting the regularization to the observations.",,1,0,,,ANR,ANR-19-CE23-0026,Agence Nationale de la Recherche,ICML Machine Learning
2-s2.0-85180790816,10.1109/ICCV51070.2023.00355,,,Adding Conditional Control to Text-to-Image Diffusion Models,cp,Conference Paper,Zhang L.,60012708,Stanford University,Stanford,United States,3,"Zhang, Lvmin;Rao, Anyi;Agrawala, Maneesh",57205560483;57219483727;57204250599,60012708;60012708;60012708,2023-01-01,2023,Proceedings of the IEEE International Conference on Computer Vision,15505499,110561,,Conference Proceeding,,,,3813-3824,"We present ControlNet, a neural network architecture to add spatial conditioning controls to large, pretrained text-to-image diffusion models. ControlNet locks the production-ready large diffusion models, and reuses their deep and robust encoding layers pretrained with billions of images as a strong backbone to learn a diverse set of conditional controls. The neural architecture is connected with ""zero convolutions""(zero-initialized convolution layers) that progressively grow the parameters from zero and ensure that no harmful noise could affect the finetuning. We test various conditioning controls, e.g., edges, depth, segmentation, human pose, etc., with Stable Diffusion, using single or multiple conditions, with or without prompts. We show that the training of ControlNets is robust with small (<50k) and large (>1m) datasets. Extensive results show that ControlNet may facilitate wider applications to control image diffusion models.",,33,0,repositoryam,Green,HAI,undefined,"Stanford Institute for Human-Centered Artificial Intelligence, Stanford University",ICCV Computer Vision
2-s2.0-85171388828,10.1145/3580305.3599256,,,All in One: Multi-Task Prompting for Graph Neural Networks,cp,Conference Paper,Sun X.,60073652;60008592;60005244;60002798,Tongji University;Hong Kong University of Science and Technology;Southeast University;Chinese University of Hong Kong,Shanghai;Hong Kong;Nanjing;Hong Kong,China;Hong Kong;China;Hong Kong,5,"Sun, Xiangguo;Cheng, Hong;Li, Jia;Liu, Bo;Guan, Jihong",57203371177;7404284983;57203396812;55574235161;24314945300,60002798;60002798;60008592;60005244;60073652,2023-08-06,6 August 2023,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,21101177500,,Conference Proceeding,,,,2120-2131,"Recently, ""pre-training and fine-tuning'' has been adopted as a standard workflow for many graph tasks since it can take general graph knowledge to relieve the lack of graph annotations from each application. However, graph tasks with node level, edge level, and graph level are far diversified, making the pre-training pretext often incompatible with these multiple tasks. This gap may even cause a ""negative transfer'' to the specific application, leading to poor results. Inspired by the prompt learning in natural language processing (NLP), which has presented significant effectiveness in leveraging prior knowledge for various NLP tasks, we study the prompting topic for graphs with the motivation of filling the gap between pre-trained models and various graph tasks. In this paper, we propose a novel multi-task prompting method for graph models. Specifically, we first unify the format of graph prompts and language prompts with the prompt token, token structure, and inserting pattern. In this way, the prompting idea from NLP can be seamlessly introduced to the graph area. Then, to further narrow the gap between various graph tasks and state-of-the-art pre-training strategies, we further study the task space of various graph applications and reformulate downstream problems to the graph-level task. Afterward, we introduce meta-learning to efficiently learn a better initialization for the multi-task prompt of graphs so that our prompting framework can be more reliable and general for different tasks. We conduct extensive experiments, results from which demonstrate the superiority of our method.",graph neural networks | pre-training | prompt tuning,4,0,repositoryam,Green,NSFC,2023A03J0673,National Natural Science Foundation of China,KDD Data Mining
2-s2.0-85161987319,10.1145/3591270,,,An Automata-Based Framework for Verification and Bug Hunting in Quantum Circuits,ar,Article,Chen Y.F.,60083321;60013651;60005429;60002485,"Brno University of Technology, Faculty of Information Technology;Institute of Information Science, Academia Sinica;National Taiwan University;Max Planck Institute for Software Systems",Brno;Taipei;Taipei;Saarbrucken,Czech Republic;Taiwan;Taiwan;Germany,6,"Chen, Yu Fang;Chung, Kai Min;Lengál, Ondåej;Lin, Jyun Ao;Tsai, Wei Lun;Yen, Di De",36110777300;7404086095;24822331700;57193699580;57315111800;56797711400,60013651;60013651;60083321;60013651;60013651-60005429;60002485,2023-06-06,6 June 2023,Proceedings of the ACM on Programming Languages,,21101020042,24751421,Journal,7,,156,,"We introduce a new paradigm for analysing and finding bugs in quantum circuits. In our approach, the problem is given by agtriple {P}gCg{Q} and the question is whether, given a set P of quantum states on the input of a circuit C, the set of quantum states on the output is equal to (or included in) a set Q. While this is not suitable to specify, e.g., functional correctness of a quantum circuit, it is sufficient to detect many bugs in quantum circuits. We propose a technique based on tree automata to compactly represent sets of quantum states and develop transformers to implement the semantics of quantum gates over this representation. Our technique computes with an algebraic representation of quantum states, avoiding the inaccuracy of working with floating-point numbers. We implemented the proposed approach in a prototype tool and evaluated its performance against various benchmarks from the literature. The evaluation shows that our approach is quite scalable, e.g., we managed to verify a large circuit with 40 qubits and 141,527 gates, or catch bugs injected into a circuit with 320 qubits and 1,758 gates, where all tools we compared with failed. In addition, our work establishes a connection between quantum program verification and automata, opening new possibilities to exploit the richness of automata theory and automata-based verification in the world of quantum computing.",quantum circuits | tree automata | verification,3,1,repositoryam,Green,,undefined,,PLDI Programming Languages
2-s2.0-85180550389,10.1145/3611643.3616261,,,An Automated Approach to Extracting Local Variables,cp,Conference Paper,Chi X.,60023380;60016835;124201230,Chongqing University;Beijing Institute of Technology;National Innovation Institute of Defense Technology,Chongqing;Beijing;Beijing,China;China;China,8,"Chi, Xiaye;Liu, Hui;Li, Guangjie;Wang, Weixiao;Xia, Yunni;Jiang, Yanjie;Zhang, Yuxia;Ji, Weixing",58221888000;56862404100;57204144584;58778352900;13409263300;57207334833;57195345510;13805144900,60016835;60016835;124201230;60016835;60023380;60016835;60016835;60016835,2023-11-30,30 November 2023,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101194128,,Conference Proceeding,,,,313-325,"Extract local variable is a well-known and widely used refactoring. It is frequently employed to replace one or more occurrences of a complex expression with simple accesses to a newly added variable. Although most IDEs provide tool support for extract local variables, such tools without deep analysis of the refactorings may result in semantic errors. To this end, in this paper, we propose a novel and more reliable approach, called ValExtractor, to conduct extract variable refactorings automatically. The major challenge of automated extract local variable refactorings is how to efficiently and accurately identify the side effect of the extracted expressions and the potential interaction between the extracted expressions and their contexts without time-consuming dynamic execution of the involved programs. To resolve this challenge, ValExtractor leverages a lightweight static source code analysis to validate the side effect of the selected expression, and to identify which occurrences of the selected expression could be extracted together without changing the semantics of the program or introducing potential new exceptions. Our evaluation results on open-source Java applications suggest that Eclipse and IntelliJ IDEA, the state-of-the-practice refactoring engines, resulted in a large number of faulty extract variable refactorings whereas ValExtractor successfully avoided all such errors. The proposed approach has been merged into (and distributed with) Eclipse to improve the safety of extract local variable refactoring.",Bugs | Extract Local Variable | Reliable | Software Refactoring,0,0,,,NSFC,62172037,National Natural Science Foundation of China,FSE Software Engineering
2-s2.0-85171868030,10.14778/3611479.3611534,,,Auto-Tables: Synthesizing Multi-Step Transformations to Relationalize Tables without Using Examples,cp,Conference Paper,Li P.,60021726;60019647,Microsoft Research;Georgia Institute of Technology,Redmond;Atlanta,United States;United States,5,"Li, Peng;He, Yeye;Yan, Cong;Wang, Yue;Chaudhuri, Surajit",57219544620;56017265600;57155621700;57202584732;7402978010,60019647;60021726;60021726;60021726;60021726,2023-01-01,2023,Proceedings of the VLDB Endowment,,21100199855,21508097,Journal,16,11,,3391-3403,"Relational tables, where each row corresponds to an entity and each column corresponds to an attribute, have been the standard for tables in relational databases. However, such a standard cannot be taken for granted when dealing with tables “in the wild”. Our survey of real spreadsheet-tables and web-tables shows that over 30% of such tables do not conform to the relational standard, for which complex table-restructuring transformations are needed before these tables can be queried easily using SQL-based tools. Unfortunately, the required transformations are non-trivial to program, which has become a substantial pain point for technical and non-technical users alike, as evidenced by large numbers of forum questions in places like StackOverflow and Excel/Tableau forums. We develop an Auto-Tables system that can automatically synthesize pipelines with multi-step transformations (in Python or other languages), to transform non-relational tables into standard relational forms for downstream analytics, obviating the need for users to manually program transformations. We compile an extensive benchmark for this new task, by collecting 244 real test cases from user spreadsheets and online forums. Our evaluation suggests that Auto-Tables can successfully synthesize transformations for over 70% of test cases at interactive speeds, without requiring any input from users, making this an effective tool for both technical and non-technical users to prepare data for analytics.",,0,0,repositoryam,Green,,undefined,,VLDB Databases
2-s2.0-85165657273,10.1145/3611643.3616243,,,Baldur: Whole-Proof Generation and Repair with Large Language Models,cp,Conference Paper,First E.,60014313;60000745;130627133,University of Massachusetts Amherst;University of Illinois Urbana-Champaign;Augment Computing,Amherst;Urbana;Palo Alto,United States;United States;United States,4,"First, Emily;Rabe, Markus;Ringer, Talia;Brun, Yuriy",57220769807;57196674972;57191953132;23003307600,60014313;130627133;60000745;60014313,2023-11-30,30 November 2023,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101194128,,Conference Proceeding,,,,1229-1241,"Formally verifying software is a highly desirable but labor-intensive task. Recent work has developed methods to automate formal verification using proof assistants, such as Coq and Isabelle/HOL, e.g., by training a model to predict one proof step at a time and using that model to search through the space of possible proofs. This paper introduces a new method to automate formal verification: We use large language models, trained on natural language and code and fine-tuned on proofs, to generate whole proofs at once. We then demonstrate that a model fine-tuned to repair generated proofs further increasing proving power. This paper: (1) Demonstrates that whole-proof generation using transformers is possible and is as effective but more efficient than search-based techniques. (2) Demonstrates that giving the learned model additional context, such as a prior failed proof attempt and the ensuing error message, results in proof repair that further improves automated proof generation. (3) Establishes, together with prior work, a new state of the art for fully automated proof synthesis. We reify our method in a prototype, Baldur, and evaluate it on a benchmark of 6,336 Isabelle/HOL theorems and their proofs, empirically showing the effectiveness of whole-proof generation, repair, and added context. We also show that Baldur complements the state-of-the-art tool, Thor, by automatically generating proofs for an additional 8.7% of the theorems. Together, Baldur and Thor can prove 65.7% of the theorems fully automatically. This paper paves the way for new research into using large language models for automating formal verification.",automated formal verification | large language models | machine learning | Proof assistants | proof repair | proof synthesis,1,0,repositoryam,Green,NSF,CCF-2210243,National Science Foundation,FSE Software Engineering
2-s2.0-85167780518,,,,Bayesian Design Principles for Frequentist Sequential Learning,cp,Conference Paper,Xu Y.,60027552,Columbia Business School,New York,United States,2,"Xu, Yunbei;Zeevi, Assaf",57219757811;7102794829,60027552;60027552,2023-01-01,2023,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,202,,,38768-38800,"We develop a general theory to optimize the frequentist regret for sequential learning problems, where efficient bandit and reinforcement learning algorithms can be derived from unified Bayesian principles. We propose a novel optimization approach to create “algorithmic beliefs” at each round, and use Bayesian posteriors to make decisions. This is the first approach to make Bayesian-type algorithms prior-free and applicable to adversarial settings, in a generic and optimal manner. Moreover, the algorithms are simple and often efficient to implement. As a major application, we present a novel algorithm for multi-armed bandits that achieves the “best-of-all-worlds” empirical performance in the stochastic, adversarial, and non-stationary environments. And we illustrate how these principles can be used in linear bandits, convex bandits, and reinforcement learning.",,0,0,,,,undefined,,ICML Machine Learning
2-s2.0-85180548137,10.1145/3611643.3616278,,,Benchmarking Robustness of AI-Enabled Multi-sensor Fusion Systems: Challenges and Opportunities,cp,Conference Paper,Gao X.,60033100;60030835;60025272,Nanjing University;University of Alberta;The University of Tokyo,Nanjing;Edmonton;Tokyo,China;Canada;Japan,6,"Gao, Xinyu;Wang, Zhijie;Feng, Yang;Ma, Lei;Chen, Zhenyu;Xu, Baowen",57218364257;57348891900;57214739527;55479591700;55579848600;57205479681,60033100;60030835;60033100;60030835-60025272;60033100;60033100,2023-11-30,30 November 2023,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101194128,,Conference Proceeding,,,,871-882,"Multi-Sensor Fusion (MSF) based perception systems have been the foundation in supporting many industrial applications and domains, such as self-driving cars, robotic arms, and unmanned aerial vehicles. Over the past few years, the fast progress in datadriven artificial intelligence (AI) has brought a fast-increasing trend to empower MSF systems by deep learning techniques to further improve performance, especially on intelligent systems and their perception systems. Although quite a few AI-enabled MSF perception systems and techniques have been proposed, up to the present, limited benchmarks that focus on MSF perception are publicly available. Given that many intelligent systems such as self-driving cars are operated in safety-critical contexts where perception systems play an important role, there comes an urgent need for a more in-depth understanding of the performance and reliability of these MSF systems. To bridge this gap, we initiate an early step in this direction and construct a public benchmark of AI-enabled MSF-based perception systems including three commonly adopted tasks (i.e., object detection, object tracking, and depth completion). Based on this, to comprehensively understand MSF systems' robustness and reliability, we design 14 common and realistic corruption patterns to synthesize large-scale corrupted datasets. We further perform a systematic evaluation of these systems through our large-scale evaluation and identify the following key findings: (1) existing AI-enabled MSF systems are not robust enough against corrupted sensor signals; (2) small synchronization and calibration errors can lead to a crash of AI-enabled MSF systems; (3) existing AI-enabled MSF systems are usually tightly-coupled in which bugs/errors from an individual sensor could result in a system crash; (4) the robustness of MSF systems can be enhanced by improving fusion mechanisms. Our results reveal the vulnerability of the current AI-enabled MSF perception systems, calling for researchers and practitioners to take robustness and reliability into account when designing AI-enabled MSF. Our benchmark, code, and detailed evaluation results are publicly available at https://sites.google.com/view/ai-msf-benchmark.",AI Systems | Benchmarks | Multi-Sensor Fusion | Perception Systems,0,0,repositoryam,Green,NSERC,61832009,Natural Sciences and Engineering Research Council of Canada,FSE Software Engineering
2-s2.0-85150947971,10.1145/3544548.3581108,,,Breaking Out of the Ivory Tower: A Large-scale Analysis of Patent Citations to HCI Research,cp,Conference Paper,Cao H.,60142701;60141508;60136640;60025911,UC Santa Barbara College of Engineering;Stanford Engineering;School of Computer Science;Stanford Graduate School of Education,Santa Barbara;Stanford;Pittsburgh;Stanford,United States;United States;United States;United States,5,"Cao, Hancheng;Lu, Yujie;Deng, Yuting;McFarland, Daniel;Bernstein, Michael S.",57209896240;57220898051;58106245600;57203382561;57193014048,60141508;60142701;60136640;60025911;60141508,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,760,,"What is the impact of human-computer interaction research on industry? While it is impossible to track all research impact pathways, the growing literature on translational research impact measurement offers patent citations as one measure of how industry recognizes and draws on research in its inventions. In this paper, we perform a large-scale measurement study primarily of 70, 000 patent citations to premier HCI research venues, tracing how HCI research are cited in United States patents over the last 30 years. We observe that 20.1% of papers from these venues, including 60-80% of papers at UIST and 13% of papers in a broader dataset of SIGCHI-sponsored venues overall, are cited by patents - far greater than premier venues in science overall (9.7%) and NLP (11%). However, the time lag between a patent and its paper citations is long (10.5 years) and getting longer, suggesting that HCI research and practice may not be efficiently connected.",citation analysis | Industry impact | patent | technology transfer | translational science,2,0,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85159260444,,,,"Building Flexible, Low-Cost Wireless Access Networks With Magma",cp,Conference Paper,Hasan S.,60027090;129685064;127294950;117425272;114520646,Virginia Polytechnic Institute and State University;Systems Approach;Meta AI;Princeton;Databricks,Blacksburg;;Meta;Princeton;San Francisco,United States;;United States;United States;United States,22,"Hasan, Shaddi;Padmanabhan, Amar;Davie, Bruce;Rexford, Jennifer;Kozat, Ulas;Gatewood, Hunter;Sanadhya, Shruti;Yurchenko, Nick;Al-Khasib, Tariq;Batalla, Oriol;Bremner, Marie;Lee, Andrei;Makeev, Evgeniy;Moeller, Scott;Rodriguez, Alex;Shelar, Pravin;Subraveti, Karthik;Kandi, Sudarshan;Xoconostle, Alejandro;Ramakrishnan, Praveen Kumar;Tian, Xiaochen;Tomar, Anoop",35777838800;57193090359;6603031480;7003493334;6602215558;57908709800;44661991200;57909540600;8868364300;57908913800;57909540700;57909123300;57189257161;58464716300;57212372450;57189267830;57909970300;57909335100;57909540800;57909751500;57909540900;57222524716,60027090;114520646;129685064;117425272;127294950;127294950;127294950;127294950;127294950;127294950;127294950;127294950;127294950;127294950;127294950;127294950;127294950;127294950;127294950;127294950;;127294950,2023-01-01,2023,"Proceedings of the 20th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2023",,21101151807,,Conference Proceeding,,,,1667-1681,"Billions of people remain without Internet access due to availability or affordability of service. In this paper, we present Magma, an open and flexible system for building low-cost wireless access networks. Magma aims to connect users where operator economics are difficult due to issues such as low population density or income levels, while preserving features expected in cellular networks such as authentication and billing policies. To achieve this, and in contrast to traditional cellular networks, Magma adopts an approach that extensively leverages Internet design patterns, terminating access network-specific protocols at the edge and abstracting the access network from the core architecture. This decision allows Magma to refactor the wireless core using SDN (software-defined networking) principles and leverage other techniques from modern distributed systems. In doing so, Magma lowers cost and operational complexity for network operators while achieving resilience, scalability, and rich policy support.",,2,0,,,ESDC,undefined,Employment and Social Development Canada,NSDI Networking
2-s2.0-85180548424,10.1145/3611643.3616352,,,Can Machine Learning Pipelines Be Better Configured?,cp,Conference Paper,Wang Y.,60118693;60031863;60024350;60008592,"Engineering Laboratory of Operations Analytics and Optimization for Smart Industry, Liaoning Province, Northeastern University;Northeastern University;National University of Defense Technology China;Hong Kong University of Science and Technology",Shenyang;Shenyang;Changsha;Hong Kong,China;China;China;Hong Kong,7,"Wang, Yibo;Wang, Ying;Zhang, Tingwei;Yu, Yue;Cheung, Shing Chi;Yu, Hai;Zhu, Zhiliang",57225920860;57022068000;58778479700;55566298800;7202472792;58109556500;57443597100,60031863;60031863-60008592;60031863;60024350;60008592;60031863;60118693,2023-11-30,30 November 2023,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101194128,,Conference Proceeding,,,,463-475,"A Machine Learning (ML) pipeline configures the workflow of a learning task using the APIs provided by ML libraries. However, a pipeline's performance can vary significantly across different configurations of ML library versions. Misconfigured pipelines can result in inferior performance, such as poor execution time and memory usage, numeric errors and even crashes. A pipeline is subject to misconfiguration if it exhibits significantly inconsistent performance upon changes in the versions of its configured libraries or the combination of these libraries. We refer to such performance inconsistency as a pipeline configuration (PLC) issue. There is no prior systematic study on the pervasiveness, impact and root causes of PLC issues. A systematic understanding of these issues helps configure effective ML pipelines and identify misconfigured ones. In this paper, we conduct the first empirical study of PLC issues. To better dig into the problem, we propose Piecer, an infrastructure that automatically generates a set of pipeline variants by varying different version combinations of ML libraries and compares their performance inconsistencies. We apply Piecer to the 3,380 pipelines that can be deployed out of the 11,363 ML pipelines collected from multiple ML competitions at Kaggle platform. The empirical study results show that 1,092 (32.3",Empirical Study | Machine Learning Libraries,0,0,,,GRF,16205722,Glaucoma Research Foundation,FSE Software Engineering
2-s2.0-85159380941,,,,CausalSim: A Causal Framework for Unbiased Trace-Driven Simulation,cp,Conference Paper,Alomar A.,60022195,Massachusetts Institute of Technology,Cambridge,United States,6,"Alomar, Abdullah;Hamadanian, Pouya;Nasr-Esfahany, Arash;Agarwal, Anish;Alizadeh, Mohammad;Shah, Devavrat",57195072143;57219686601;57219685142;57209968441;55658057154;7402371516,60022195;60022195;60022195;60022195;60022195;60022195,2023-01-01,2023,"Proceedings of the 20th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2023",,21101151807,,Conference Proceeding,,,,1115-1147,"We present CausalSim, a causal framework for unbiased trace-driven simulation. Current trace-driven simulators assume that the interventions being simulated (e.g., a new algorithm) would not affect the validity of the traces. However, real-world traces are often biased by the choices algorithms make during trace collection, and hence replaying traces under an intervention may lead to incorrect results. CausalSim addresses this challenge by learning a causal model of the system dynamics and latent factors capturing the underlying system conditions during trace collection. It learns these models using an initial randomized control trial (RCT) under a fixed set of algorithms, and then applies them to remove biases from trace data when simulating new algorithms. Key to CausalSim is mapping unbiased trace-driven simulation to a tensor completion problem with extremely sparse observations. By exploiting a basic distributional invariance property present in RCT data, CausalSim enables a novel tensor completion method despite the sparsity of observations. Our extensive evaluation of CausalSim on both real and synthetic datasets, including more than ten months of real data from the Puffer video streaming system shows it improves simulation accuracy, reducing errors by 53% and 61% on average compared to expert-designed and supervised learning baselines. Moreover, CausalSim provides markedly different insights about ABR algorithms compared to the biased baseline simulator, which we validate with a real deployment.",,4,0,,,NSF,1751009,National Science Foundation,NSDI Networking
2-s2.0-85160018260,10.1145/3544548.3580848,,,"Changes in Research Ethics, Openness, and Transparency in Empirical Studies between CHI 2017 and CHI 2022",cp,Conference Paper,Salehzadeh Niksirat K.,60101868;60004572;60000239,University of Applied Sciences Western Switzerland;Swansea University;Université de Lausanne (UNIL),Delemont;Swansea;Lausanne,Switzerland;United Kingdom;Switzerland,9,"Salehzadeh Niksirat, Kavous;Goswami, Lahari;S. B. Rao, Pooja;Tyler, James;Silacci, Alessandro;Aliyu, Sadiq;Aebli, Annika;Wacharamanotham, Chat;Cherubini, Mauro",55979429500;58285371500;58285426000;57217309199;57210805181;58285477800;57210152247;39362715700;24467455900,60000239;60000239;60000239;60000239;60000239-60101868;60000239;60000239;60004572;60000239,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,505,,"In recent years, various initiatives from within and outside the HCI field have encouraged researchers to improve research ethics, openness, and transparency in their empirical research. We quantify how the CHI literature might have changed in these three aspects by analyzing samples of 118 CHI 2017 and 127 CHI 2022 papers - randomly drawn and stratified across conference sessions. We operationalized research ethics, openness, and transparency into 45 criteria and manually annotated the sampled papers. The results show that the CHI 2022 sample was better in 18 criteria, but in the rest of the criteria, it has no improvement. The most noticeable improvements were related to research transparency (10 out of 17 criteria). We also explored the possibility of assisting the verification process by developing a proof-of-concept screening system. We tested this tool with eight criteria. Six of them achieved high accuracy and F1 score. We discuss the implications for future research practices and education. This paper and all supplementary materials are freely available at https://doi.org/10.17605/osf.io/n25d6.",CHI | data availability | ethics | open science | replicability | reproducibility | transparency,2,1,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85166480638,10.1109/SP46215.2023.10179476,,,Characterizing Everyday Misuse of Smart Home Devices,cp,Conference Paper,Moh P.,60020304;60000745,"University of Maryland, College Park;University of Illinois Urbana-Champaign",College Park;Urbana,United States;United States,6,"Moh, Phoebe;Datta, Pubali;Warford, Noel;Bates, Adam;Malkin, Nathan;Mazurek, Michelle L.",57209288670;56134741900;57215424748;55498417300;57193571979;36095672600,60020304;60000745;60020304;60000745;60020304;60020304,2023-01-01,2023,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2023-May,,,2835-2849,"Exploration of Internet of Things (IoT) security often focuses on threats posed by external and technically-skilled attackers. While it is important to understand these most extreme cases, it is equally important to understand the most likely risks of harm posed by smart device ownership. In this paper, we explore how smart devices are misused - used without permission in a manner that causes harm - by device owners' everyday associates such as friends, family, and romantic partners. In a preliminary characterization survey (n = 100), we broadly capture the kinds of unauthorized use and misuse incidents participants have experienced or engaged in. Then, in a prevalence survey (n = 483), we assess the prevalence of these incidents in a demographically-representative population. Our findings show that unauthorized use of smart devices is widespread (experienced by 43% of participants), and that misuse is also common (experienced by at least 19% of participants). However, highly individual factors determine whether these unauthorized use events constitute misuse. Through a focus on everyday abuses, this work sheds light on the most prevalent security and privacy threats faced by smart-home owners today.",,4,0,,,NSF,1955228,National Science Foundation,S&P Security and Privacy
2-s2.0-85160016531,10.1145/3544548.3581113,,,ChartDetective: Easy and Accurate Interactive Data Extraction from Complex Vector Charts,cp,Conference Paper,Masson D.,60104665;60029631;60000463,Université de Lille;Institut Universitaire de France;David R. Cheriton School of Computer Science,Lille;Paris;Waterloo,France;France;Canada,5,"Masson, Damien;Malacria, Sylvain;Vogel, Daniel;Lank, Edward;Casiez, Géry",57215029360;26767934800;8435582600;8224503900;22333666200,60000463;60000463-60104665;60000463;60000463;60000463-60104665-60029631,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,147,,"Extracting underlying data from rasterized charts is tedious and inaccurate; values might be partially occluded or hard to distinguish, and the quality of the image limits the precision of the data being recovered. To address these issues, we introduce a semi-automatic system leveraging vector charts to extract the underlying data easily and accurately. The system is designed to make the most of vector information by relying on a drag-and-drop interface combined with selection, filtering, and previsualization features. A user study showed that participants spent less than 4 minutes to accurately recover data from charts published at CHI with diverse styles, thousands of data points, a combination of different encodings, and elements partially or completely occluded. Compared to other approaches relying on raster images, our tool successfully recovered all data, even when hidden, with a 78% lower relative error.",chart reverse-engineering | data extraction | vector graphics,5,0,,,NSERC,2018-05187,Natural Sciences and Engineering Research Council of Canada,CHI Human-Computer Interaction
2-s2.0-85152260136,10.1145/3544548.3580847,,,CiteSee: Augmenting Citations in Scientific Papers with Persistent and Personalized Historical Context,cp,Conference Paper,Chang J.C.,60015481;60006297;102050297,University of Washington;University of Pennsylvania;Allen Institute for AI,Seattle;Philadelphia;Seattle,United States;United States;United States,7,"Chang, Joseph Chee;Zhang, Amy X.;Bragg, Jonathan;Head, Andrew;Lo, Kyle;Downey, Doug;Weld, Daniel S.",57191996286;55892530500;57188813507;57156107000;57209713101;35956201800;7003334103,102050297;60015481;102050297;60006297;102050297;102050297;102050297-60015481,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,737,,"When reading a scholarly article, inline citations help researchers contextualize the current article and discover relevant prior work. However, it can be challenging to prioritize and make sense of the hundreds of citations encountered during literature reviews. This paper introduces CiteSee, a paper reading tool that leverages a user's publishing, reading, and saving activities to provide personalized visual augmentations and context around citations. First, CiteSee connects the current paper to familiar contexts by surfacing known citations a user had cited or opened. Second, CiteSee helps users prioritize their exploration by highlighting relevant but unknown citations based on saving and reading history. We conducted a lab study that suggests CiteSee is significantly more effective for paper discovery than three baselines. A field deployment study shows CiteSee helps participants keep track of their explorations and leads to better situational awareness and increased paper discovery via inline citation when conducting real-world literature reviews.",personalization | reading interfaces | scientific papers,6,0,repositoryam,Green,TIP,OIA-2033558,"Directorate for Technology, Innovation and Partnerships",CHI Human-Computer Interaction
2-s2.0-85160009832,10.1145/3544548.3580879,,,Collaborating Across Realities: Analytical Lenses for Understanding Dyadic Collaboration in Transitional Interfaces,cp,Conference Paper,Schröder J.H.,60012408,Universität zu Lübeck,Lubeck,Germany,5,"Schröder, Jan Henrik;Schacht, Daniel;Peper, Niklas;Hamurculu, Anita Marie;Jetter, Hans Christian",57349023600;58285309500;58285309600;58285413400;6603080259,60012408;60012408;60012408;60012408;60012408,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,97,,"Transitional Interfaces are a yet underexplored, emerging class of cross-reality user interfaces that enable users to freely move along the reality-virtuality continuum during collaboration. To analyze and understand how such collaboration unfolds, we propose four analytical lenses derived from an exploratory study of transitional collaboration with 15 dyads. While solving a complex spatial optimization task, participants could freely switch between three contexts, each with different displays (desktop screens, tablet-based augmented reality, head-mounted virtual reality), input techniques (mouse, touch, handheld controllers), and visual representations (monoscopic and allocentric 2D/3D maps, stereoscopic egocentric views). Using the rich qualitative and quantitative data from our study, we evaluated participants' perceptions of transitional collaboration and identified commonalities and differences between dyads. We then derived four lenses including metrics and visualizations to analyze key aspects of transitional collaboration: (1) place and distance, (2) temporal patterns, (3) group use of contexts, (4) individual use of contexts.",analytical lenses | transitional collaboration | transitional interfaces | user study,12,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85167737566,10.1109/ICSE48619.2023.00212,,,Compatible Remediation on Vulnerabilities from Third-Party Libraries for Java Projects,cp,Conference Paper,Zhang L.,60078616;60019533;60018038,School of Computer Science and Engineering;Tianjin University;Nankai University,Singapore City;Tianjin;Tianjin,Singapore;China;China,8,"Zhang, Lyuye;Liu, Chengwei;Xu, Zhengzi;Chen, Sen;Fan, Lingling;Zhao, Lida;Wu, Jiahui;Liu, Yang",57203020355;57423363300;57190973090;57190395316;57197024797;58080251800;57886740100;56911879800,60078616;60078616;60078616;60019533;60018038;60078616;60078616;60078616,2023-01-01,2023,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,2540-2552,"With the increasing disclosure of vulnerabilities in open-source software, software composition analysis (SCA) has been widely applied to reveal third-party libraries and the associated vulnerabilities in software projects. Beyond the revelation, SCA tools adopt various remediation strategies to fix vulnerabilities, the quality of which varies substantially. However, ineffective remediation could induce side effects, such as compi-lation failures, which impede acceptance by users. According to our studies, existing SCA tools could not correctly handle the concerns of users regarding the compatibility of remediated projects. To this end, we propose Compatible Remediation of Third-party libraries (CORAL) for Maven projects to fix vulnerabilities without breaking the projects. The evaluation proved that Coralnot only fixed 87.56% of vulnerabilities which outperformed other tools (best 75.32%) and achieved a 98.67% successful compilation rate and a 92.96% successful unit test rate. Furthermore, we found that 78.45% of vulnerabilities in popular Maven projects could be fixed without breaking the compilation, and the rest of the vulnerabilities (21.55%) could either be fixed by upgrades that break the compilations or even be impossible to fix by upgrading.",Compatibility | Java | Open-source software | Remediation,4,0,repositoryam,Green,NRF,AISG2-RP-2020-019,National Research Foundation Singapore,ICSE Software Engineering
2-s2.0-85160011720,10.1145/3544548.3580984,,,Contestable Camera Cars: A Speculative Design Exploration of Public AI That Is Open and Responsive to Dispute,cp,Conference Paper,Alfrink K.,60117882;60006288,"The Department of Values, Technology and Innovation, TU Delft;Delft University of Technology",Delft;Delft,Netherlands;Netherlands,4,"Alfrink, Kars;Keller, Ianus;Doorn, Neelke;Kortuem, Gerd",57558653800;7006615736;6507143700;6602781855,60006288;60006288;60117882;60006288,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,8,,"Local governments increasingly use artificial intelligence (AI) for automated decision-making. Contestability, making systems responsive to dispute, is a way to ensure they respect human rights to autonomy and dignity. We investigate the design of public urban AI systems for contestability through the example of camera cars: human-driven vehicles equipped with image sensors. Applying a provisional framework for contestable AI, we use speculative design to create a concept video of a contestable camera car. Using this concept video, we then conduct semi-structured interviews with 17 civil servants who work with AI employed by a large northwestern European city. The resulting data is analyzed using reflexive thematic analysis to identify the main challenges facing the implementation of contestability in public AI. We describe how civic participation faces issues of representation, public AI systems should integrate with existing democratic practices, and cities must expand capacities for responsible AI development and operation.",artificial intelligence | automated decision-making | camera cars | contestability | local government | machine learning | public administration | public AI | speculative design | urban AI | urban sensing | vehicular urban sensing,1,1,repositoryam,Green,,CISC.CC.018,,CHI Human-Computer Interaction
2-s2.0-85168879191,10.1145/3579371.3589079,,,Contiguitas: The Pursuit of Physical Memory Contiguity in Datacenters,cp,Conference Paper,Zhao K.,60027950,Carnegie Mellon University,Pittsburgh,United States,11,"Zhao, Kaiyang;Schatzberg, Dan;Weiner, Johannes;Xue, Kaiwen;Yang, Leon;van Riel, Rik;Wang, Ziqi;Manousis, Antonis;Sharma, Bikash;Tang, Chunqiang;Skarlatos, Dimitrios",58551726700;57212527320;57489073900;58491595800;57489056200;58551837200;57202582141;57191092897;58664188400;8845243400;58582074900,60027950;;;60027950;;;60027950;;;;60027950,2023-06-17,17 June 2023,Proceedings - International Symposium on Computer Architecture,10636897,145750,,Conference Proceeding,,,,618-632,"The unabating growth of the memory needs of emerging datacenter applications has exacerbated the scalability bottleneck of virtual memory. However, reducing the excessive overhead of address translation will remain onerous until the physical memory contiguity predicament gets resolved. To address this problem, this paper presents Contiguitas, a novel redesign of memory management in the operating system and hardware that provides ample physical memory contiguity. We identify that the primary cause of memory fragmentation in Meta’s datacenters is unmovable allocations scattered across the address space that impede large contiguity from being formed. To provide ample physical memory contiguity by design, Contiguitas first separates regular movable allocations from unmovable ones by placing them into two different continuous regions in physical memory and dynamically adjusts the boundary of the two regions based on memory demand. Drastically reducing unmovable allocations is challenging because the majority of unmovable pages cannot be moved with software alone given that access to the page cannot be blocked for a migration to take place. Furthermore, page migration is expensive as it requires a long downtime to (a) perform TLB shootdowns that scale poorly with the number of victim TLBs, and (b) copy the page. To this end, Contiguitas eliminates the primary source of unmovable allocations by introducing hardware extensions in the last-level cache to enable the transparent and efficient migration of unmovable pages even while the pages remain in use.",,1,1,publisherfree2read,Bronze,NSF,CCF-2217016,National Science Foundation,ISCA Architecture
2-s2.0-85162032106,10.1145/3591271,,,Covering All the Bases: Type-Based Verification of Test Input Generators,ar,Article,Zhou Z.,60009254,Purdue University,West Lafayette,United States,4,"Zhou, Zhe;Mishra, Ashish;Delaware, Benjamin;Jagannathan, Suresh",57234121300;57327859000;35742891200;57202888433,60009254;60009254;60009254;60009254,2023-06-06,6 June 2023,Proceedings of the ACM on Programming Languages,,21101020042,24751421,Journal,7,,157,,"Test input generators are an important part of property-based testing (PBT) frameworks. Because PBT is intended to test deep semantic and structural properties of a program, the outputs produced by these generators can be complex data structures, constrained to satisfy properties the developer believes is most relevant to testing the function of interest. An important feature expected of these generators is that they be capable of producing all acceptable elements that satisfy the function's input type and generator-provided constraints. However, it is not readily apparent how we might validate whether a particular generator's output satisfies this coverage requirement. Typically, developers must rely on manual inspection and post-mortem analysis of test runs to determine if the generator is providing sufficient coverage; these approaches are error-prone and difficult to scale as generators become more complex. To address this important concern, we present a new refinement type-based verification procedure for validating the coverage provided by input test generators, based on a novel interpretation of types that embeds ""must-style""underapproximate reasoning principles as a fundamental part of the type system. The types associated with expressions now capture the set of values guaranteed to be produced by the expression, rather than the typical formulation that uses types to represent the set of values an expression may produce. Beyond formalizing the notion of coverage types in the context of a rich core language with higher-order procedures and inductive datatypes, we also present a detailed evaluation study to justify the utility of our ideas.",property-based testing | refinement types | underapproximate reasoning,0,1,repositoryam,Green,,undefined,,PLDI Programming Languages
2-s2.0-85162008882,10.1145/3591272,,,CryptOpt: Verified Compilation with Randomized Program Search for Cryptographic Primitives,ar,Article,Kuepper J.,60026553;60022195;60019647;60019578;60012708;60009512;60005322,University of Melbourne;Massachusetts Institute of Technology;Georgia Institute of Technology;Monash University;Stanford University;The University of Adelaide;Ruhr-Universitat Bochum,Melbourne;Cambridge;Atlanta;Clayton;Stanford;Adelaide;Bochum,Australia;United States;United States;Australia;United States;Australia;Germany,12,"Kuepper, Joel;Erbsen, Andres;Gross, Jason;Conoly, Owen;Sun, Chuyue;Tian, Samuel;Wu, David;Chlipala, Adam;Chuengsatiansup, Chitchanok;Genkin, Daniel;Wagner, Markus;Yarom, Yuval",57997552400;57202941709;56291989200;57997509200;57997383200;57997593400;57997428100;10041238300;55584864800;36135431800;55238331400;25825786400,60009512;60022195;60022195;60022195;60012708;60022195;60009512;60022195;60026553;60019647;60019578;60005322,2023-06-06,6 June 2023,Proceedings of the ACM on Programming Languages,,21101020042,24751421,Journal,7,,158,,"Most software domains rely on compilers to translate high-level code to multiple different machine languages, with performance not too much worse than what developers would have the patience to write directly in assembly language. However, cryptography has been an exception, where many performance-critical routines have been written directly in assembly (sometimes through metaprogramming layers). Some past work has shown how to do formal verification of that assembly, and other work has shown how to generate C code automatically along with formal proof, but with consequent performance penalties vs.The best-known assembly. We present CryptOpt, the first compilation pipeline that specializes high-level cryptographic functional programs into assembly code significantly faster than what GCC or Clang produce, with mechanized proof (in Coq) whose final theorem statement mentions little beyond the input functional program and the operational semantics of x86-64 assembly. On the optimization side, we apply randomized search through the space of assembly programs, with repeated automatic benchmarking on target CPUs. On the formal-verification side, we connect to the Fiat Cryptography framework (which translates functional programs into C-like IR code) and extend it with a new formally verified program-equivalence checker, incorporating a modest subset of known features of SMT solvers and symbolic-execution engines. The overall prototype is quite practical, e.g. producing new fastest-known implementations of finite-field arithmetic for both Curve25519 (part of the TLS standard) and the Bitcoin elliptic curve secp256k1 for the Intel 12g and 13g generations.",assembly | elliptic-curve cryptography | search-based software engineering,1,1,repositoryvor,Green,,undefined,,PLDI Programming Languages
2-s2.0-85159406083,10.14778/3587136.3587137,,,DBSP: Automatic Incremental View Maintenance for Rich Query Languages,cp,Conference Paper,Budiu M.,60103987;60006297;126315132,"VMware, Inc;University of Pennsylvania;Materialize, Inc.",Palo Alto;Philadelphia;350 Hooper St Apt 1 Brooklyn,United States;United States;United States,5,"Budiu, Mihai;Chajed, Tej;McSherry, Frank;Ryzhyk, Leonid;Tannen, Val",6506040266;56023207200;6603207363;25825629600;6603293896,60103987;60103987;126315132;60103987;60006297,2023-01-01,2023,Proceedings of the VLDB Endowment,,21100199855,21508097,Journal,16,7,,1601-1614,"Incremental view maintenance (IVM) has long been a central problem in database theory. Many solutions have been proposed for restricted classes of database languages, such as the relational algebra, or Datalog. These techniques do not naturally generalize to richer languages. In this paper we give a general, heuristic-free solution to this problem in 3 steps: (1) we describe a simple but expressive language called DBSP for describing computations over data streams; (2) we give a new mathematical definition of IVM and a general algorithm for solving IVM for arbitrary DBSP programs, and (3) we show how to model many rich database query languages using DBSP (including the full relational algebra, queries over sets and multisets, arbitrarily nested relations, aggregation, flatmap (unnest), monotonic and non-monotonic recursion, streaming aggregation, and arbitrary compositions of all of these). SQL and Datalog can both be implemented in DBSP. As a consequence, we obtain efficient incremental view maintenance algorithms for queries written in all these languages.",,0,0,repositoryam,Green,,undefined,,VLDB Databases
2-s2.0-85166302256,10.1145/3592454,,,DOC: Differentiable Optimal Control for Retargeting Motions onto Legged Robots,ar,Article,Grandia R.,60032776;60025858,The Walt Disney Company;ETH Zürich,Burbank;Zurich,United States;Switzerland,6,"Grandia, Ruben;Farshidian, Farbod;Knoop, Espen;Schumacher, Christian;Hutter, Marco;Bächer, Moritz",57202577540;55480761600;55922286800;55554546700;35409405200;25627224600,60032776;60025858;60032776;60032776;60025858;60032776,2023-08-01,1 August 2023,ACM Transactions on Graphics,07300301,24972,15577368,Journal,42,4,3592454,,"Legged robots are designed to perform highly dynamic motions. However, it remains challenging for users to retarget expressive motions onto these complex systems. In this paper, we present a Differentiable Optimal Control (DOC) framework that facilitates the transfer of rich motions from either animals or animations onto these robots. Interfacing with either motion capture or animation data, we formulate retargeting objectives whose parameters make them agnostic to differences in proportions and numbers of degrees of freedom between input and robot. Optimizing these parameters over the manifold spanned by optimal state and control trajectories, we minimize the retargeting error. We demonstrate the utility and efficacy of our modeling by applying DOC to a Model-Predictive Control (MPC) formulation, showing retargeting results for a family of robots of varying proportions and mass distribution. With a hardware deployment, we further show that the retargeted motions are physically feasible, while MPC ensures that the robots retain their capability to react to unexpected disturbances.",differentiable optimal control | differential dynamic programming | model-predictive control | motion retargeting,2,0,,,,undefined,,SIGGRAPH Graphics
2-s2.0-85159362842,,,,DOTE: Rethinking (Predictive) WAN Traffic Engineering,cp,Conference Paper,Perry Y.,60021726;60007903;126790815,Microsoft Research;Hebrew University of Jerusalem;Technion,Redmond;Jerusalem;,United States;Israel;Israel,7,"Perry, Yarin;Frujeri, Felipe Vieira;Hoch, Chaim;Kandula, Srikanth;Menache, Ishai;Schapira, Michael;Tamar, Aviv",58141369700;57219698427;58141331400;10143021400;8353757900;11439780800;52264620600,60007903;60021726;60007903;60021726;60021726;60007903;126790815,2023-01-01,2023,"Proceedings of the 20th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2023",,21101151807,,Conference Proceeding,,,,1557-1581,"We explore a new design point for traffic engineering on wide-area networks (WANs): directly optimizing traffic flow on the WAN using only historical data about traffic demands. Doing so obviates the need to explicitly estimate, or predict, future demands. Our method, which utilizes stochastic optimization, provably converges to the global optimum in well-studied theoretical models. We employ deep learning to scale to large WANs and real-world traffic. Our extensive empirical evaluation on real-world traffic and network topologies establishes that our approach's TE quality almost matches that of an (infeasible) omniscient oracle, outperforming previously proposed approaches, and also substantially lowers runtimes.",,4,0,,,ERC,101041250,Microsoft,NSDI Networking
2-s2.0-85160015430,10.1145/3544548.3581472,,,DataParticles: Block-based and Language-oriented Authoring of Animated Unit Visualizations,cp,Conference Paper,Cao Y.,60030612;60009982,"University of California, San Diego;Harvard University",La Jolla;Cambridge,United States;United States,4,"Cao, Yining;Jane, J. E.;Chen, Zhutian;Xia, Haijun",57451360400;58285355100;57189640527;56427427600,60030612;60030612;60009982;60030612,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,808,,"Unit visualizations have been widely used in data storytelling within interactive articles and videos. However, authoring data stories that contain animated unit visualizations is challenging due to the tedious, time-consuming process of switching back and forth between writing a narrative and configuring the accompanying visualizations and animations. To streamline this process, we present DataParticles, a block-based story editor that leverages the latent connections between text, data, and visualizations to help creators flexibly prototype, explore, and iterate on a story narrative and its corresponding visualizations. To inform the design of DataParticles, we interviewed 6 domain experts and studied a dataset of 44 existing animated unit visualizations to identify the narrative patterns and congruence principles they employed. A user study with 9 experts showed that DataParticles can significantly simplify the process of authoring data stories with animated unit visualizations by encouraging exploration and supporting fast prototyping.",animation | natural language | storytelling | unit visualization,5,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85160008900,10.1145/3544548.3581258,,,Deceptive Design Patterns in Safety Technologies: A Case Study of the Citizen App,cp,Conference Paper,Chordia I.,60020304;60015481,"University of Maryland, College Park;University of Washington",College Park;Seattle,United States;United States,7,"Chordia, Ishita;Tran, Lena Phuong;Tayebi, Tala June;Parrish, Emily;Erete, Sheena;Yip, Jason;Hiniker, Alexis",57211803616;58285533900;57804849900;58285534000;55735785700;55321666200;55800655000,60015481;60015481;60015481;60015481;60020304;60015481;60015481,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,193,,"Deceptive design patterns (known as dark patterns) are interface characteristics which modify users' choice architecture to gain users' attention, data, and money. Deceptive design patterns have yet to be documented in safety technologies despite evidence that designers of safety technologies make decisions that can powerfully influence user behavior. To address this gap, we conduct a case study of the Citizen app, a commercially available technology which notifies users about local safety incidents. We bound our study to Atlanta and triangulate interview data with an analysis of the user interface. Our results indicate that Citizen heightens users' anxiety about safety while encouraging the use of profit-generating features which offer security. These findings contribute to an emerging conversation about how deceptive design patterns interact with sociocultural factors to produce deceptive infrastructure. We propose the need to expand an existing taxonomy of harm to include emotional load and social injustice and offer recommendations for designers interested in dismantling the deceptive infrastructure of safety technologies.",anxiety | community safety | crime | dark infrastructure | dark patterns | deceptive design | fear | manipulative design | safety | safety technologies,2,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85168547323,10.1145/3592114,,,Differentiable Stripe Patterns for Inverse Design of Structured Surfaces,ar,Article,Montes Maestre J.S.,60025858,ETH Zürich,Zurich,Switzerland,5,"Montes Maestre, Juan Sebastian;Du, Yinwei;Hinchet, Ronan;Coros, Stelian;Thomaszewski, Bernhard",58545248600;58316682900;53363645600;24536706700;16311231900,60025858;60025858;60025858;60025858;60025858,2023-08-01,1 August 2023,ACM Transactions on Graphics,07300301,24972,15577368,Journal,42,4,102,,"Stripe patterns are ubiquitous in nature and everyday life. While the synthesis of these patterns has been thoroughly studied in the literature, their potential to control the mechanics of structured materials remains largely unexplored. In this work, we introduce Differentiable Stripe Patterns-A computational approach for automated design of physical surfaces structured with stripe-shaped bi-material distributions. Our method builds on the work by Knöppel and colleagues [2015] for generating globally-continuous and equally-spaced stripe patterns. To unlock the full potential of this design space, we propose a gradient-based optimization tool to automatically compute stripe patterns that best approximate macromechanical performance goals. Specifically, we propose a computational model that combines solid shell finite elements with XFEM for accurate and fully-differentiable modeling of elastic bi-material surfaces. To resolve non-uniqueness problems in the original method, we furthermore propose a robust formulation that yields unique and differentiable stripe patterns. We combine these components with equilibrium state derivatives into an end-To-end differentiable pipeline that enables inverse design of mechanical stripe patterns. We demonstrate our method on a diverse set of examples that illustrate the potential of stripe patterns as a design space for structured materials. Our simulation results are experimentally validated on physical prototypes.",,1,0,repositoryam,Green,,undefined,,SIGGRAPH Graphics
2-s2.0-85160002286,10.1145/3544548.3581161,,,"Disentangling Fairness Perceptions in Algorithmic Decision-Making: the Effects of Explanations, Human Oversight, and Contestability",cp,Conference Paper,Yurrita M.,60018869;60006288,Universiteit Maastricht;Delft University of Technology,Maastricht;Delft,Netherlands;Netherlands,6,"Yurrita, Mireia;Draws, Tim;Balayn, Agathe;Murray-Rust, Dave;Tintarev, Nava;Bozzon, Alessandro",57226192357;57216248592;57193700401;14827312400;23092113300;16548743400,60006288;60006288;60006288;60006288;60018869;60006288,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,134,,"Recent research claims that information cues and system attributes of algorithmic decision-making processes affect decision subjects' fairness perceptions. However, little is still known about how these factors interact. This paper presents a user study (N = 267) investigating the individual and combined effects of explanations, human oversight, and contestability on informational and procedural fairness perceptions for high- and low-stakes decisions in a loan approval scenario. We find that explanations and contestability contribute to informational and procedural fairness perceptions, respectively, but we find no evidence for an effect of human oversight. Our results further show that both informational and procedural fairness perceptions contribute positively to overall fairness perceptions but we do not find an interaction effect between them. A qualitative analysis exposes tensions between information overload and understanding, human involvement and timely decision-making, and accounting for personal circumstances while maintaining procedural consistency. Our results have important design implications for algorithmic decision-making processes that meet decision subjects' standards of justice.",algorithmic decision-making | contestability | explanations | fairness perceptions | human oversight,5,1,repositoryvor,Green,H2020,955990,Horizon 2020 Framework Programme,CHI Human-Computer Interaction
2-s2.0-85174422842,,,,Do Androids Laugh at Electric Sheep? Humor “Understanding” Benchmarks from The New Yorker Caption Contest,cp,Conference Paper,Hessel J.,60121131;60025488;60007776;130354000;126189978;124242617,"OpenAI, Inc.;The University of Utah;Cornell University;Air Mail and Cartoon Collections;Allen Institute for AI;University of Washington",San Francisco;Salt Lake City;Ithaca;;Allen;Allen,United States;United States;United States;United States;United States;United States,8,"Hessel, Jack;Marasović, Ana;Hwang, Jena D.;Lee, Lillian;Da, Jeff;Zellers, Rowan;Mankoff, Robert;Choi, Yejin",57190382287;57205444527;35109145400;7404389769;57219501131;57193255202;54917998100;36172231400,126189978;60025488;126189978;60007776;124242617;60121131;130354000;126189978-124242617,2023-01-01,2023,Proceedings of the Annual Meeting of the Association for Computational Linguistics,0736587X,21101138302,,Conference Proceeding,1,,,688-714,"Large neural networks can now generate jokes, but do they really “understand” humor? We challenge AI models with three tasks derived from the New Yorker Cartoon Caption Contest: matching a joke to a cartoon, identifying a winning caption, and explaining why a winning caption is funny. These tasks encapsulate progressively more sophisticated aspects of “understanding” a cartoon; key elements are the complex, often surprising relationships between images and captions and the frequent inclusion of indirect and playful allusions to human experience and culture. We investigate both multimodal and language-only models: the former are challenged with the cartoon images directly, while the latter are given multifaceted descriptions of the visual scene to simulate human-level visual understanding. We find that both types of models struggle at all three tasks. For example, our best multimodal models fall 30 accuracy points behind human performance on the matching task, and, even when provided ground-truth visual scene descriptors, human-authored explanations are preferred head-to-head over the best machine-authored ones (few-shot GPT-4) in more than 2/3 of cases. We release models, code, leaderboard, and corpus, which includes newly-gathered annotations describing the image's locations/entities, what's unusual in the scene, and an explanation of the joke.",,3,0,,,CU,N66001-19-2-4031,Cornell University,ACL Natural Language Processing
2-s2.0-85150194322,10.1109/ICSE48619.2023.00038,,,Do I Belong? Modeling Sense of Virtual Community Among Linux Kernel Contributors,cp,Conference Paper,Trinkenreich B.,60025160;60023517;60013402;60003122,University College Cork;Northern Arizona University;Oregon State University;University of Victoria,Cork;Flagstaff;Corvallis;Victoria,Ireland;United States;United States;Canada,6,"Trinkenreich, Bianca;Stol, Klaas Jan;Sarma, Anita;German, Daniel M.;Gerosa, Marco A.;Steinmacher, Igor",56786270500;6603128515;7004458190;57207886015;10043515400;36609225300,60023517;60025160;60013402;60003122;60023517;60023517,2023-01-01,2023,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,319-331,"The sense of belonging to a community is a basic human need that impacts an individual's behavior, long-term engagement, and job satisfaction, as revealed by research in disciplines such as psychology, healthcare, and education. Despite much research on how to retain developers in Open Source Software (OSS) projects and other virtual, peer-production communities, there is a paucity of research investigating what might contribute to a sense of belonging in these communities. To that end, we develop a theoretical model that seeks to understand the link between OSS developer motives and a Sense of Virtual Community (SVC). We test the model with a dataset collected in the Linux Kernel developer community (N=225), using structural equation modeling techniques. Our results for this case study show that intrinsic motivations (social or hedonic motives) are positively associated with a sense of virtual community, but living in an authoritative country and being paid to contribute can reduce the sense of virtual community. Based on these results, we offer suggestions for open source projects to foster a sense of virtual community, with a view to retaining contributors and Improving projects' sustainability.",belonging | human factors | open source | PLS-SEM | sense of virtual community | software developers | survey,4,0,repositoryam,Green,NSF,1900903,National Science Foundation,ICSE Software Engineering
2-s2.0-85163140747,10.1145/3564246.3585175,,,Doubly Efficient Private Information Retrieval and Fully Homomorphic RAM Computation from Ring LWE,cp,Conference Paper,Lin W.K.,60028628;123108589,Northeastern University;NTT Research,Boston;Sunnyvale,United States;United States,3,"Lin, Wei Kai;Mook, Ethan;Wichs, Daniel",57189240238;57221156954;24336779600,60028628;60028628;60028628-123108589,2023-06-02,2 June 2023,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,595-608,"A (single server) private information retrieval (PIR) allows a client to read data from a public database held on a remote server, without revealing to the server which locations she is reading. In a doubly efficient PIR (DEPIR), the database is first preprocessed, but the server can subsequently answer any client's query in time that is sub-linear in the database size. Prior work gave a plausible candidate for a public-key variant of DEPIR, where a trusted party is needed to securely preprocess the database and generate a corresponding public key for the clients; security relied on a new non-standard code-based assumption and a heuristic use of ideal obfuscation. In this work we construct the stronger unkeyed notion of DEPIR, where the preprocessing is a deterministic procedure that the server can execute on its own. Moreover, we prove security under just the standard ring learning-with-errors (RingLWE) assumption. For a database of size N and any constant ϵ>0, the preprocessing run-time and size is O(N1+ϵ), while the run-time and communication-complexity of each PIR query is polylog(N). We also show how to update the preprocessed database in time O(Nϵ). Our approach is to first construct a standard PIR where the server's computation consists of evaluating a multivariate polynomial; we then convert it to a DEPIR by preprocessing the polynomial to allow for fast evaluation, using the techniques of Kedlaya and Umans (STOC '08). Building on top of our DEPIR, we construct general fully homomorphic encryption for random-access machines (RAM-FHE), which allows a server to homomorphically evaluate an arbitrary RAM program P over a client's encrypted input x and the server's preprocessed plaintext input y to derive an encryption of the output P(x,y) in time that scales with the RAM run-time of the computation rather than its circuit size. Prior work only gave a heuristic candidate construction of a restricted notion of RAM-FHE. In this work, we construct RAM-FHE under the RingLWE assumption with circular security. For a RAM program P with worst-case run-time T, the homomorphic evaluation runs in time T1+ϵ · (|x| + |y|).",doubly efficient PIR | FHE for RAM,2,0,,,,CNS-1750795,,STOC Theory
2-s2.0-85143716834,,,,Dynamic Algorithms for Maximum Matching Size,cp,Conference Paper,Behnezhad S.,60141178,Khoury College of Computer Sciences,Boston,United States,1,"Behnezhad, Soheil",57195148749,60141178,2023-01-01,2023,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,2023-January,,,129-162,"We study fully dynamic algorithms for maximum matching. This is a well-studied problem, known to admit several update-time/approximation trade-offs. For instance, it is known how to maintain a 1/2-approximate matching in (poly log n) update time or a 2/3-approximate matching in O(√n) update time, where n is the number of vertices. It has been a long-standing open problem to determine whether either of these bounds can be improved. In this paper, we show that when the goal is to maintain just the size of the matching (and not its edge-set), then these bounds can indeed be improved. First, we give an algorithm that takes (poly log n) update-time and maintains a.501-approximation (.585-approximation if the graph is bipartite). Second, we give an algorithm that maintains a (2/3 + Ω(1))-approximation in O(√n) time for bipartite graphs. Our results build on new connections to sublinear time algorithms. In particular, a key tool for both is an algorithm of the author for estimating the size of maximal matchings in Oe(n) time [Behnezhad; FOCS 2021]. Our second result also builds on the edge-degree constrained subgraph (EDCS) of Bernstein and Stein [ICALP'15, SODA'16]. In particular, while it has been known that EDCS may not include a better than 2/3-approximation, we give a new characterization of such tight instances which allows us to break it. We believe this characterization might be of independent interest.",,8,0,,,,undefined,,SODA Theory
2-s2.0-85148977518,,,,Dynamic Matching with Better-than-2 Approximation in Polylogarithmic Update Time,cp,Conference Paper,Bhattacharya S.,60025778;60022020;60006191,"University of Michigan, Ann Arbor;University of Warwick;Google LLC",Ann Arbor;Coventry;Mountain View,United States;United Kingdom;United States,4,"Bhattacharya, Sayan;Kiss, Peter;Saranurak, Thatchaphol;Wajc, David",47761006600;57225433063;56928468000;54394654100,60022020;60022020;60025778;60006191,2023-01-01,2023,Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms,,110527,,Conference Proceeding,2023-January,,,100-128,"We present dynamic algorithms with polylogarithmic update time for estimating the size of the maximum matching of a graph undergoing edge insertions and deletions with approximation ratio strictly better than 2. Specifically, we obtain a 1+ √12 +ϵ ≈ 1.707+ϵ approximation in bipartite graphs and a 1.973+ϵ approximation in general graphs. We thus answer in the affirmative the value version of the major open question repeatedly asked in the dynamic graph algorithms literature. Our randomized algorithms' approximation and worst-case update time bounds both hold w.h.p. against adaptive adversaries. Our algorithms are based on simulating new two-pass streaming matching algorithms in the dynamic setting. Our key new idea is to invoke the recent sublinear-time matching algorithm of Behnezhad (FOCS'21) in a white-box manner to efficiently simulate the second pass of our streaming algorithms, while bypassing the well-known vertex-update barrier.",,6,0,,,SU,EP/S03353X/1,Stanford University,SODA Theory
2-s2.0-85168646866,10.1109/ICSE48619.2023.00084,,,Efficiency Matters: Speeding Up Automated Testing with GUI Rendering Inference,cp,Conference Paper,Feng S.,60019578;60008950,Monash University;The Australian National University,Clayton;Canberra,Australia;Australia,3,"Feng, Sidong;Xie, Mulong;Chen, Chunyang",57211802256;57220181228;57191225906,60019578;60008950;60019578,2023-01-01,2023,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,906-918,"Due to the importance of Android app quality assurance, many automated GUI testing tools have been developed. Although the test algorithms have been improved, the impact of GUI rendering has been overlooked. On the one hand, setting a long waiting time to execute events on fully rendered GUIs slows down the testing process. On the other hand, setting a short waiting time will cause the events to execute on partially rendered GUIs, which negatively affects the testing effectiveness. An optimal waiting time should strike a balance between effectiveness and efficiency. We propose AdaT, a lightweight image-based approach to dynamically adjust the inter-event time based on GUI rendering state. Given the real-time streaming on the GUI, AdaT presents a deep learning model to infer the rendering state, and synchronizes with the testing tool to schedule the next event when the GUI is fully rendered. The evaluations demonstrate the accuracy, efficiency, and effectiveness of our approach. We also integrate our approach with the existing automated testing tool to demonstrate the usefulness of AdaT in covering more activities and executing more events on fully rendered GUIs.",Efficient android GUI testing | GUI rendering | Machine Learning,4,0,repositoryam,Green,MU,undefined,Monash University,ICSE Software Engineering
2-s2.0-85176933031,10.1145/3600006.3613171,,,Enabling High-Performance and Secure Userspace NVM File Systems with the Trio Architecture,cp,Conference Paper,Zhou D.,60119141;60028186,Rutgers University–New Brunswick;École Polytechnique Fédérale de Lausanne,New Brunswick;Lausanne,United States;Switzerland,6,"Zhou, Diyu;Aschenbrenner, Vojtech;Lyu, Tao;Zhang, Jian;Kannan, Sudarsun;Kashyap, Sanidhya",58728054900;57190129596;58698384500;58395363700;21734779200;57113111000,60028186;60028186;60028186;60119141;60119141;60028186,2023-10-23,23 October 2023,SOSP 2023 - Proceedings of the 29th ACM Symposium on Operating Systems Principles,,21101186888,,Conference Proceeding,,,,150-165,"Userspace library file systems (LibFSes) promise to unleash the performance potential of non-volatile memory (NVM) by directly accessing it and enabling unprivileged applications to customize their LibFSes to their workloads. Unfortunately, such benefits pose a significant challenge to ensuring metadata integrity. Existing works either underutilize NVM's performance or forgo critical file system security guarantees.We present Trio, a userspace NVM file system architecture that resolves this inherent tension with a clean decoupling among file system design, access control, and metadata integrity enforcement. Our key insight is that other state (i.e., auxiliary state) in a file system can be regenerated from its ""ground truth""state (i.e., core state). Thus, Trio explicitly defines the data structure of a single core state and shares it as common knowledge among its LibFSes and the trusted entity. Enabled by this, a LibFS can directly access NVM without involving the trusted entity and can be customized with its private auxiliary state. The trusted entity enforces metadata integrity by verifying the core state of a file when its write access is transferred from one LibFS to another. We design a generic POSIX-like file system called ArckFS and two customized file systems based on the Trio architecture. Our evaluation shows that ArckFS outperforms existing NVM file systems by 3.1× to 17× on LevelDB while the customized file systems further outperform ArckFS by 1.3×.",direct access | file system customization | file system integrity | library file systems | persistent memory | userspace file systems,0,0,,,NSF,CNS-1730043,National Science Foundation,SOSP Operating Systems
2-s2.0-85153854298,10.1145/3544548.3580688,,,Evaluating Large Language Models in Generating Synthetic HCI Research Data: a Case Study,cp,Conference Paper,Hämäläinen P.,60103653;60002952,Aalto University;Helsingin Yliopisto,Espoo;Helsinki,Finland;Finland,3,"Hämäläinen, Perttu;Tavast, Mikke;Kunnari, Anton",10040911400;57211793503;57204772241,60103653;60103653;60002952,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,433,,"Collecting data is one of the bottlenecks of Human-Computer Interaction (HCI) research. Motivated by this, we explore the potential of large language models (LLMs) in generating synthetic user research data. We use OpenAI's GPT-3 model to generate open-ended questionnaire responses about experiencing video games as art, a topic not tractable with traditional computational user models. We test whether synthetic responses can be distinguished from real responses, analyze errors of synthetic data, and investigate content similarities between synthetic and real data. We conclude that GPT-3 can, in this context, yield believable accounts of HCI experiences. Given the low cost and high speed of LLM data generation, synthetic data should be useful in ideating and piloting new experiments, although any findings must obviously always be validated with real data. The results also raise concerns: if employed by malicious users of crowdsourcing services, LLMs may make crowdsourcing of self-report data fundamentally unreliable.",GPT-3 | Language models | User experience | User models,17,1,repositoryvor,Green,EC,101017779,European Commission,CHI Human-Computer Interaction
2-s2.0-85164258192,10.1145/3584372.3588655,,,Extremal Fitting Problems for Conjunctive Queries,cp,Conference Paper,Ten Cate B.,60032942;60008042;60002483,Universitat Pompeu Fabra Barcelona;Universität Leipzig;Universiteit van Amsterdam,Barcelona;Leipzig;Amsterdam,Spain;Germany;Netherlands,4,"Ten Cate, Balder;Dalmau, Victor;Funk, Maurice;Lutz, Carsten",8964763900;6603155780;57209282329;7103325866,60002483;60032942;60008042;60008042,2023-06-18,18 June 2023,Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems,,81474,,Conference Proceeding,,,,89-98,"The fitting problem for conjunctive queries (CQs) is the problem to construct a CQ that fits a given set of labeled data examples. When a fitting CQ exists, it is in general not unique. This leads us to proposing natural refinements of the notion of a fitting CQ, such as most-general fitting CQ, most-specific fitting CQ, and unique fitting CQ. We give structural characterizations of these notions in terms of (suitable refinements of) homomorphism dualities, frontiers, and direct products, which enable the construction of the refined fitting CQs when they exist. We also pinpoint the complexity of the associated existence and verification problems, and determine the size of fitting CQs. We study the same problems for UCQs and for the more restricted class of tree CQs.",conjunctive queries | data examples | database queries | fitting | homomorphism dualities,4,1,repositoryam,Green,H2020,MSCA-101031081,Horizon 2020 Framework Programme,PODS Databases
2-s2.0-85160004727,10.1145/3544548.3580993,,,FIDO2 the Rescue? Platform vs. Roaming Authentication on Smartphones,cp,Conference Paper,Würsching L.,60011226,Technische Universität Darmstadt,Darmstadt,Germany,4,"Würsching, Leon;Putz, Florentin;Haesler, Steffen;Hollick, Matthias",57226402712;57219266261;57207032762;22334431100,60011226;60011226;60011226;60011226,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,68,,"Modern smartphones support FIDO2 passwordless authentication using either external security keys or internal biometric authentication, but it is unclear whether users appreciate and accept these new forms of web authentication for their own accounts. We present the first lab study (N=87) comparing platform and roaming authentication on smartphones, determining the practical strengths and weaknesses of FIDO2 as perceived by users in a mobile scenario. Most participants were willing to adopt passwordless authentication during our in-person user study, but closer analysis shows that participants prioritize usability, security, and availability differently depending on the account type. We identify remaining adoption barriers that prevent FIDO2 from succeeding password authentication, such as missing support for contemporary usage patterns, including account delegation and usage on multiple clients.",Accounts | Biometrics | Passwordless | Security | Usability | User Authentication,2,0,repositoryam,Green,BMBF,16KISK014,Bundesministerium für Bildung und Forschung,CHI Human-Computer Interaction
2-s2.0-85174398830,,,,From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models,cp,Conference Paper,Feng S.,60027950;60018308;124242617,Carnegie Mellon University;Xi'an Jiaotong University;University of Washington,Pittsburgh;Xi'an;Allen,United States;China;United States,4,"Feng, Shangbin;Park, Chan Young;Liu, Yuhan;Tsvetkov, Yulia",57225889811;57219755124;58394081800;51665958500,124242617;60027950;60018308;124242617,2023-01-01,2023,Proceedings of the Annual Meeting of the Association for Computational Linguistics,0736587X,21101138302,,Conference Proceeding,1,,,11737-11762,"Language models (LMs) are pretrained on diverse data sources, including news, discussion forums, books, and online encyclopedias. A significant portion of this data includes opinions and perspectives which, on one hand, celebrate democracy and diversity of ideas, and on the other hand are inherently socially biased. Our work develops new methods to (1) measure political biases in LMs trained on such corpora, along social and economic axes, and (2) measure the fairness of downstream NLP models trained on top of politically biased LMs. We focus on hate speech and misinformation detection, aiming to empirically quantify the effects of political (social, economic) biases in pretraining data on the fairness of high-stakes social-oriented tasks. Our findings reveal that pretrained LMs do have political leanings that reinforce the polarization present in pretraining corpora, propagating social biases into hate speech predictions and misinformation detectors. We discuss the implications of our findings for NLP research and propose future directions to mitigate unfairness. Warning: This paper contains examples of hate speech.",,13,0,,,NSF,IIS2142739,National Science Foundation,ACL Natural Language Processing
2-s2.0-85158164667,10.1145/3544549.3583919,,,Demonstrating Full-hand Electro-Tactile Feedback without Obstructing Palmar Side of Hand,cp,Conference Paper,Tanaka Y.,60029278,The University of Chicago,Chicago,United States,4,"Tanaka, Yudai;Shen, Alan;Kong, Andy;Lopes, Pedro",57219866016;57221720310;58236784400;55480857700,60029278;60029278;60029278;60029278,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101150667,,Conference Proceeding,,,435,,"We present a technique to render tactile feedback to the palmar side of the hand while keeping it unobstructed and, thus, preserving manual dexterity during interactions with physical objects. We implement this by applying electro-tactile stimulation only to the back of the hand and to the wrist. In our approach, there are no electrodes on the palmar side, yet that is where tactile sensations are felt. While we place electrodes outside the user's palm, we do so in strategic locations that conduct the electrical currents to the median/ulnar nerves, causing tactile sensations on the palmar side of the hand.",Electro-tactile | Haptics | Mixed Reality | Virtual Reality,2,0,,,NSF,2047189,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85178511168,10.1145/3586183.3606735,,,GenAssist: Making Image Generation Accessible,cp,Conference Paper,Huh M.,60150459;60136640,Department of Computer Science;School of Computer Science,Austin;Pittsburgh,United States;United States,3,"Huh, Mina;Peng, Yi Hao;Pavel, Amy",57224013715;57222988295;56121790600,60150459;60136640;60150459,2023-10-29,29 October 2023,UIST 2023 - Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,,21101189049,,Conference Proceeding,,,38,,"Blind and low vision (BLV) creators use images to communicate with sighted audiences. However, creating or retrieving images is challenging for BLV creators as it is difficult to use authoring tools or assess image search results. Thus, creators limit the types of images they create or recruit sighted collaborators. While text-to-image generation models let creators generate high-fidelity images based on a text description (i.e. prompt), it is difficult to assess the content and quality of generated images. We present GenAssist, a system to make text-to-image generation accessible. Using our interface, creators can verify whether generated image candidates followed the prompt, access additional details in the image not specified in the prompt, and skim a summary of similarities and differences between image candidates. To power the interface, GenAssist uses a large language model to generate visual questions, vision-language models to extract answers, and a large language model to summarize the results. Our study with 12 BLV creators demonstrated that GenAssist enables and simplifies the process of image selection and generation, making visual authoring more accessible to all.",Accessibility | Creativity Support Tools | Generative AI | Image Generation,0,1,repositoryam,Green,,undefined,,UIST User Interface
2-s2.0-85174390110,,,,"Generalization on the Unseen, Logic Reasoning and Degree Curriculum",cp,Conference Paper,Abbe E.,126394243;121099459,EPFL;Apple,Neuchatel;Sunnyvale,Switzerland;United States,4,"Abbe, Emmanuel;Bengio, Samy;Lotfi, Aryo;Rizk, Kevin",16237841500;57203254475;57222185156;58095452100,126394243-121099459;121099459;126394243;126394243,2023-01-01,2023,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,202,,,31-60,"This paper considers the learning of logical (Boolean) functions with focus on the generalization on the unseen (GOTU) setting, a strong case of out-of-distribution generalization. This is motivated by the fact that the rich combinatorial nature of data in certain reasoning tasks (e.g., arithmetic/logic) makes representative data sampling challenging, and learning successfully under GOTU gives a first vignette of an 'extrapolating' or 'reasoning' learner. We then study how different network architectures trained by (S)GD perform under GOTU and provide both theoretical and experimental evidence that for a class of network models including instances of Transformers, random features models, and diagonal linear networks, a min-degree-interpolator is learned on the unseen. We also provide evidence that other instances with larger learning rates or mean-field networks reach leaky min-degree solutions. These findings lead to two implications: (1) we provide an explanation to the length generalization problem (e.g., Anil et al. 2022); (2) we introduce a curriculum learning algorithm called Degree-Curriculum that learns monomials more efficiently by incrementing supports.",,0,0,,,,undefined,,ICML Machine Learning
2-s2.0-85175682854,10.1145/3586183.3606763,,,Generative Agents: Interactive Simulacra of Human Behavior,cp,Conference Paper,Park J.S.,60141508;60111161;60006191,Stanford Engineering;DeepMind Technologies Limited;Google LLC,Stanford;London;Mountain View,United States;United Kingdom;United States,6,"Park, Joon Sung;O'Brien, Joseph;Cai, Carrie Jun;Morris, Meredith Ringel;Liang, Percy;Bernstein, Michael S.",57222403758;58615377900;57219528527;8619759600;56646712700;57193014048,60141508;60141508;60006191;60111161;60141508;60141508,2023-10-29,29 October 2023,UIST 2023 - Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,,21101189049,,Conference Proceeding,,,2,,"Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent's experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine's Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture - observation, planning, and reflection - each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.",agents | generative AI | Human-AI interaction | large language models,24,1,repositoryam,Green,MSR,undefined,Microsoft Research,UIST User Interface
2-s2.0-85166658533,10.1145/3592129,,,Globally Consistent Normal Orientation for Point Clouds by Regularizing the Winding-Number Field,ar,Article,Xu R.,60031031;60020547;60019496;60009415;60006541,Shandong University;Texas A&amp;M University;Qingdao University of Science and Technology;The University of Texas at Dallas;The University of Hong Kong,Jinan;College Station;Qingdao;Richardson;Hong Kong,China;United States;China;United States;Hong Kong,9,"Xu, Rui;Dou, Zhiyang;Wang, Ningna;Xin, Shiqing;Chen, Shuangmin;Jiang, Mingyan;Guo, Xiaohu;Wang, Wenping;Tu, Changhe",57219823966;57219817398;58264102100;23013368700;55979892100;55745383300;12791011700;35147101600;7402578832,60031031;60006541;60009415;60031031;60019496;60031031;60009415;60020547;60031031,2023-08-01,1 August 2023,ACM Transactions on Graphics,07300301,24972,15577368,Journal,42,4,111,,"Estimating normals with globally consistent orientations for a raw point cloud has many downstream geometry processing applications. Despite tremendous efforts in the past decades, it remains challenging to deal with an unoriented point cloud with various imperfections, particularly in the presence of data sparsity coupled with nearby gaps or thin-walled structures. In this paper, we propose a smooth objective function to characterize the requirements of an acceptable winding-number field, which allows one to find the globally consistent normal orientations starting from a set of completely random normals. By taking the vertices of the Voronoi diagram of the point cloud as examination points, we consider the following three requirements: (1) the winding number is either 0 or 1, (2) the occurrences of 1 and the occurrences of 0 are balanced around the point cloud, and (3) the normals align with the outside Voronoi poles as much as possible. Extensive experimental results show that our method outperforms the existing approaches, especially in handling sparse and noisy point clouds, as well as shapes with complex geometry/topology.",normal orientation | optimization | raw point cloud | Voronoi diagram | winding number,6,0,repositoryam,Green,,undefined,,SIGGRAPH Graphics
2-s2.0-85178514382,10.1145/3586183.3606754,,,Going Incognito in the Metaverse: Achieving Theoretically Optimal Privacy-Usability Tradeoffs in VR,cp,Conference Paper,Nair V.C.,60121438;60019722,Department of Electrical Engineering and Computer Sciences;Technische Universität München,Berkeley;Munich,United States;Germany,3,"Nair, Vivek C.;Munilla-Garrido, Gonzalo;Song, Dawn",57848628300;57866293500;57225849829,60121438;60019722;60121438,2023-10-29,29 October 2023,UIST 2023 - Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology,,21101189049,,Conference Proceeding,,,61,,"Virtual reality (VR) telepresence applications and the so-called ""metaverse""promise to be the next major medium of human-computer interaction. However, with recent studies demonstrating the ease at which VR users can be profiled and deanonymized, metaverse platforms carry many of the privacy risks of the conventional internet (and more) while at present offering few of the defensive utilities that users are accustomed to having access to. To remedy this, we present the first known method of implementing an ""incognito mode""for VR. Our technique leverages local ϵ-differential privacy to quantifiably obscure sensitive user data attributes, with a focus on intelligently adding noise when and where it is needed most to maximize privacy while minimizing usability impact. Our system is capable of flexibly adapting to the unique needs of each VR application to further optimize this trade-off. We implement our solution as a universal Unity (C#) plugin that we then evaluate using several popular VR applications. Upon faithfully replicating the most well-known VR privacy attack studies, we show a significant degradation of attacker capabilities when using our solution.",data harvesting | differential privacy | identification | incognito mode | private browsing | profiling | usable security | virtual reality,2,1,repositoryam,Green,NSF,undefined,National Science Foundation,UIST User Interface
2-s2.0-85160013224,10.1145/3544548.3581259,,,"Going, Going, Gone: Exploring Intention Communication for Multi-User Locomotion in Virtual Reality",cp,Conference Paper,Rasch J.,60033241;60028717,Universität des Saarlandes;Ludwig-Maximilians-Universität München,Saarbrucken;Munich,Germany;Germany,4,"Rasch, Julian;Rusakov, Vladislav Dmitrievic;Schmitz, Martin;Müller, Florian",57704128100;58285325200;56158083600;57193483579,60028717;60028717;60033241;60028717,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,785,,"Exploring virtual worlds together with others adds a social component to the Virtual Reality (VR) experience that increases connectedness. In the physical world, joint locomotion comes naturally through implicit intention communication and subsequent adjustments of the movement patterns. In VR, however, discrete locomotion techniques such as point&teleport come without prior intention communication, hampering the collective experience. Related work proposes fixed groups, with a single person controlling the group movement, resulting in the loss of individual movement capabilities. To close the gap and mediate between these two extremes, we introduce three intention communication methods and explore them with two baseline methods. We contribute the results of a controlled experiment (n=20) investigating these methods from the perspective of a leader and a follower in a dyadic locomotion task. Our results suggest shared visualizations support the understanding of movement intentions, increasing the group feeling while maintaining individual freedom of movement.",Connectedness | Locomotion | Multi-User | SocialVR | Teleportation | Virtual Reality,2,0,,,H2020,683008,Horizon 2020 Framework Programme,CHI Human-Computer Interaction
2-s2.0-85160010909,10.1145/3544548.3581040,,,Infrastructuring Care: How Trans and Non-Binary People Meet Health and Well-Being Needs through Technology,cp,Conference Paper,Wilcox L.,60025778;60023927;60006191,"University of Michigan, Ann Arbor;Georgetown University;Google LLC","Ann Arbor;Washington, D.C.;Mountain View",United States;United States;United States,7,"Wilcox, Lauren;Shelby, Renee;Veeraraghavan, Rajesh;Haimson, Oliver L.;Erickson, Gabriela Cruz;Turken, Michael;Gulotta, Rebecca",23040470800;56222132600;24468863700;56157014300;58285314700;57222198354;36018319000,60006191;60006191;60023927;60025778;60006191;60006191;60006191,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,489,,"We present a cross-cultural diary study with 64 transgender (trans) and non-binary adults in Mexico, the U.S., and India, to understand experiences keeping track of and managing aspects of personal health and well-being. Based on a reflexive thematic analysis of diary data, we highlight sociotechnical interactions that shape how trans and non-binary people track and manage aspects of their health and well-being. Specifically, we surface the ways in which trans and non-binary people infrastructure forms of care, by assembling together elements of informal social ecologies, formalized knowledge sources, and self-reflective media. We examine the forms of precarity that interact with care infrastructure and shape management of health and well-being, including management of gender identity transitions. We discuss the ways in which our findings extend knowledge at the intersection of technology and marginalized health needs, and conclude by arguing for the importance of a research agenda to move toward TGNB-inclusive design.",algorithmic harms | gender | infrastructuring | marginalized health | personal informatics | technology harms | trans and non-binary health,2,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85160006026,10.1145/3544548.3580774,,,Investigating the Role of Context in the Delivery of Text Messages for Supporting Psychological Wellbeing,cp,Conference Paper,Bhattacharjee A.,60016849;60007363,University of Toronto;Northwestern University,Toronto;Evanston,Canada;United States,6,"Bhattacharjee, Ananya;Williams, Joseph Jay;Meyerhoff, Jonah;Kumar, Harsh;Mariakakis, Alex;Kornfield, Rachel",57224002207;56159570600;56197457100;57673888100;55322351600;36727709900,60016849;60016849;60007363;60016849;60016849;60007363,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,494,,"Without a nuanced understanding of users' perspectives and contexts, text messaging tools for supporting psychological wellbeing risk delivering interventions that are mismatched to users' dynamic needs. We investigated the contextual factors that influence young adults' day-to-day experiences when interacting with such tools. Through interviews and focus group discussions with 36 participants, we identified that people's daily schedules and affective states were dominant factors that shape their messaging preferences. We developed two messaging dialogues centered around these factors, which we deployed to 42 participants to test and extend our initial understanding of users' needs. Across both studies, participants provided diverse opinions of how they could be best supported by messages, particularly around when to engage users in more passive versus active ways. They also proposed ways of adjusting message length and content during periods of low mood. Our findings provide design implications and opportunities for context-aware mental health management systems.",contextual factors | daily schedule | energy | JITAI | mental wellbeing | mood | text messages,3,0,,,ONR,N00014-18-1-2755,Office of Naval Research,CHI Human-Computer Interaction
2-s2.0-85166483579,10.1109/SP46215.2023.10179403,,,"It's (DOM) Clobbering Time: Attack Techniques, Prevalence, and Defenses",cp,Conference Paper,Khodayari S.,60117087,CISPA - Helmholtz Center for Information Security,Saarbrucken,Germany,2,"Khodayari, Soheil;Pellegrino, Giancarlo",57219750633;57008821200,60117087;60117087,2023-01-01,2023,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2023-May,,,1041-1058,"DOM Clobbering is a type of code-less injection attack where attackers insert a piece of non-script, seemingly benign HTML markup into a webpage and transform it to executable code by exploiting the unforeseen interactions between JavaScript code and the runtime environment. The attack techniques, browser behaviours, and vulnerable code patterns that enable DOM Clobbering has not been studied yet, and in this paper, we undertake one of the first evaluations of the state of DOM Clobbering on the Web platform. Starting with a comprehensive survey of existing literature and dynamic analysis of 19 different mobile and desktop browsers, we systematize DOM Clobbering attacks, uncovering 31.4K distinct markups that use five different techniques to unexpectedly overwrite JavaScript variables in at least one browser. Then, we use our systematization to identify and characterize program instructions that can be overwritten by DOM Clobbering, and use it to present TheThing, an automated system that detects clobberable data flows to security-sensitive instructions. We instantiate TheThing on the top of the Tranco top 5K sites, quantifying the prevalence and impact of DOM Clobbering in the wild. Our evaluation uncovers that DOM Clobbering vulnerabilities are ubiquitous, with a total of 9,467 vulnerable data flows across 491 affected sites, making it possible to mount arbitrary code execution, open redirections, or client-side request forgery attacks also against popular websites such as Fandom, Trello, Vimeo, TripAdvisor, WikiBooks and GitHub, that were not exploitable through the traditional attack vectors. Finally, in this paper, we also evaluate the robustness of the existing countermeasures, such as HTML sanitizers and Content Security Policy, against DOM Clobbering.",Attack Techniques | Defenses | DOM Clobbering | Prevalence,2,0,,,H2020,101019206,Horizon 2020 Framework Programme,S&P Security and Privacy
2-s2.0-85178165910,10.1145/3583780.3614942,,,Joint Rebalancing and Charging for Shared Electric Micromobility Vehicles with Energy-informed Demand,cp,Conference Paper,Tan H.,60119141;60002804;60000060,Rutgers University–New Brunswick;University of Tennessee at Chattanooga;Lehigh University,New Brunswick;Chattanooga;Bethlehem,United States;United States;United States,4,"Tan, Heng;Yuan, Yukun;Zhong, Shuxin;Yang, Yu",58535484900;57203919027;57195479426;57057046700,60000060;60002804;60119141;60000060,2023-10-21,21 October 2023,"International Conference on Information and Knowledge Management, Proceedings",,21101188776,,Conference Proceeding,,,,2392-2401,"Shared electric micromobility (e.g., shared electric bikes and electric scooters), as an emerging way of urban transportation, has been increasingly popular in recent years. However, managing thousands of micromobility vehicles in a city, such as rebalancing and charging vehicles to meet spatial-temporally varied demand, is challenging. Existing management frameworks generally consider demand as the number of requests without the energy consumption of these requests, which can lead to less effective management. To address this limitation, we design RECOMMEND, a rebalancing and charging framework for shared electric micromobility vehicles with energy-informed demand to improve the system revenue. Specifically, we first re-define the demand from the perspective of energy consumption and predict the future energy-informed demand based on the state-of-the-art spatial-temporal prediction method. Then we fuse the predicted energy-informed demand into different components of a rebalancing and charging framework based on reinforcement learning. We evaluate the RECOMMEND system with 2-month real-world electric micromobility system operation data. Experimental results show that our method can be easily integrated into a general RL framework and outperform state-of-the-art baselines by at least 26.89% in terms of net revenue.",Charging | E-scooter | Rebalancing | Reinforcement Learning,1,1,publisherhybridgold,Hybrid Gold,NSF,1951890,National Science Foundation,CIKM Knowledge Management
2-s2.0-85160003200,10.1145/3544548.3581255,,,Kaleidoscope: A Reflective Documentation Tool for a User Interface Design Course,cp,Conference Paper,Sterman S.,60025038,"University of California, Berkeley",Berkeley,United States,5,"Sterman, Sarah;Nicholas, Molly Jane;Vivrekar, Janaki;Mindel, Jessica R.;Paulos, Eric",57193546080;57201450019;57223399242;58236794800;6603491550,60025038;60025038;60025038;60025038;60025038,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,702,,"Documentation can support design work and create opportunities for learning and reflection. We explore how a novel documentation tool for a remote interaction design course provides insight into design process and integrates strategies from expert practice to support studio-style collaboration and reflection. Using Research through Design, we develop and deploy Kaleidoscope, an online tool for documenting design process, in an upper-level HCI class during the COVID-19 pandemic, iteratively developing it in response to student feedback and needs. We discuss key themes from the real-world deployment of Kaleidoscope, including: tensions between documentation and creation; effects of centralizing discussion; privacy and visibility in shared spaces; balancing evidence of achievement with feelings of overwhelm; and the effects of initial perceptions and incentives on tool usage. These successes and challenges provide insights to guide future tools for design documentation and HCI education that scaffold learning process as an equal partner to execution.",documentation | HCI education | online learning | reflection | studio,3,0,,,NSF,DGE 1752814,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85180550565,10.1145/3611643.3616254,,,LExecutor: Learning-Guided Execution,cp,Conference Paper,Souza B.,60015815,Universität Stuttgart,Stuttgart,Germany,2,"Souza, Beatriz;Pradel, Michael",57212475863;25641744400,60015815;60015815,2023-11-30,30 November 2023,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101194128,,Conference Proceeding,,,,1522-1534,"Executing code is essential for various program analysis tasks, e.g., to detect bugs that manifest through exceptions or to obtain execution traces for further dynamic analysis. How- ever, executing an arbitrary piece of code is often difficult in practice, e.g., because of missing variable definitions, miss- ing user inputs, and missing third-party dependencies. This paper presents LExecutor, a learning-guided approach for executing arbitrary code snippets in an underconstrained way. The key idea is to let a neural model predict missing values that otherwise would cause the program to get stuck, and to inject these values into the execution. For example, LExecutor injects likely values for otherwise undefined vari- ables and likely return values of calls to otherwise missing functions. We evaluate the approach on Python code from popular open-source projects and on code snippets extracted from Stack Overflow. The neural model predicts realistic values with an accuracy between 79.5% and 98.2%, allowing LExecutor to closely mimic real executions. As a result, the approach successfully executes significantly more code than any available technique, such as simply executing the code as-is. For example, executing the open-source code snippets as-is covers only 4.1% of all lines, because the code crashes early on, whereas LExecutor achieves a coverage of 51.6%.",dynamic analysis | execution | neural models,0,0,repositoryam,Green,ERC,851895,European Research Council,FSE Software Engineering
2-s2.0-85159308532,,,,LeakyScatter: A Frequency-Agile Directional Backscatter Network Above 100 GHz,cp,Conference Paper,Kludze A.,60003269,Princeton University,Princeton,United States,2,"Kludze, Atsutse;Ghasempour, Yasaman",57215872220;57193991695,60003269;60003269,2023-01-01,2023,"Proceedings of the 20th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2023",,21101151807,,Conference Proceeding,,,,375-388,"Wireless backscattering has been deemed suitable for various emerging energy-constrained applications given its low-power architectures. Although existing backscatter nodes often operate at sub-6 GHz frequency bands, moving to the sub-THz bands offers significant advantages in scaling low-power connectivity to dense user populations; as concurrent transmissions can be separated in both spectral and spatial domains given the large swath of available bandwidth and laser-shaped beam directionality in this frequency regime. However, the power consumption and complexity of wireless devices increase significantly with frequency. In this paper, we present LeakyScatter, the first backscatter system that enables directional, low-power, and frequency-agile wireless links above 100 GHz. LeakyScatter departs from conventional backscatter designs and introduces a novel architecture that relies on aperture reciprocity in leaky-wave devices. We have fabricated LeakyScatter and evaluated its performance through extensive simulations and over-the-air experiments. Our results demonstrate a scalable wireless link above 100 GHz that is retrodirective and operates at a large bandwidth (tens of GHz) and ultra-low-power (zero power consumed for directional steering and ≤ 1 mW for data modulation).",,3,0,,,NSF,CNS-2145240,National Science Foundation,NSDI Networking
2-s2.0-85174426016,,,,Learning-Rate-Free Learning by D-Adaptation,cp,Conference Paper,Defazio A.,60008134;128343326,CNRS Centre National de la Recherche Scientifique;Meta AI,Paris;New York,France;United States,2,"Defazio, Aaron;Mishchenko, Konstantin",6701745412;57204803503,128343326;60008134,2023-01-01,2023,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,202,,,7449-7479,"D-Adaptation is an approach to automatically setting the learning rate which asymptotically achieves the optimal rate of convergence for minimizing convex Lipschitz functions, with no back-tracking or line searches, and no additional function value or gradient evaluations per step. Our approach is the first hyper-parameter free method for this class without additional multiplicative log factors in the convergence rate. We present extensive experiments for SGD and Adam variants of our method, where the method automatically matches hand-tuned learning rates across more than a dozen diverse machine learning problems, including large-scale vision and language problems. An open-source implementation is available.",,0,0,,,Biogemma SAS,undefined,Biogemma,ICML Machine Learning
2-s2.0-85171785468,10.1109/ICSE48619.2023.00142,,,Lejacon: A Lightweight and Efficient Approach to Java Confidential Computing on SGX,cp,Conference Paper,Miao X.,60118460;60025084;60004538,Alibaba Group Holding Limited;Shanghai Jiao Tong University;Dalian University of Technology,Yu Hang;Shanghai;Dalian,China;China;China,10,"Miao, Xinyuan;Lin, Ziyi;Wang, Shaojun;Yu, Lei;Li, Sanhong;Wang, Zihan;Nie, Pengbo;Chen, Yuting;Shen, Beijun;Jiang, He",58532880200;58458951000;58609483500;57470642400;57194235382;58744168200;57220050654;8929240400;23089553000;57205479128,60025084;60118460;60118460;60118460;60118460;60025084;60025084;60025084;60025084;60004538,2023-01-01,2023,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,1648-1660,"Intel's SGX is a confidential computing technique. It allows key functionalities of C/C++/native applications to be confidentially executed in hardware enclaves. However, numerous cloud applications are written in Java. For supporting their confidential computing, state-of-the-art approaches deploy Java Virtual Machines (JVMs) in enclaves and perform confidential computing on JVMs. Meanwhile, these JVM-in-enclave solutions still suffer from serious limitations, such as heavy overheads of running JVMs in enclaves, large attack surfaces, and deep computation stacks. To mitigate the above limitations, we for-malize a Secure Closed-World (SCW) principle and then propose Lejacon, a lightweight and efficient approach to Java confidential computing. The key idea is, given a Java application, to (1) separately compile its confidential computing tasks into a bundle of Native Confidential Computing (NCC) services; (2) run the NCC services in enclaves on the Trusted Execution Environment (TEE) side, and meanwhile run the non-confidential code on a JVM on the Rich Execution Environment (REE) side. The two sides interact with each other, protecting confidential computing tasks and as well keeping the Trusted Computing Base (TCB) size small. We implement Lejacon and evaluate it against OcclumJ (a state-of-the-art JVM-in-enclave solution) on a set of benchmarks using the BouncyCastle cryptography library. The evaluation results clearly show the strengths of Lejacon: it achieves compet-itive performance in running Java confidential code in enclaves; compared with OcclumJ, Lejacon achieves speedups by up to 16.2x in running confidential code and also reduces the TCB sizes by 90+% on average.",Native Confidential Computing Service | Runtime | Secure Closed-World | Separation Compilation | Software Guard Extensions,0,0,,,NSFC,62032004,National Natural Science Foundation of China,ICSE Software Engineering
2-s2.0-85170372986,,,,Levin Tree Search with Context Models,cp,Conference Paper,Orseau L.,60193824;60111161;60030835,Alberta Machine Intelligence Institute;DeepMind Technologies Limited;University of Alberta,Edmonton;London;Edmonton,Canada;United Kingdom;Canada,3,"Orseau, Laurent;Hutter, Marcus;Lelis, Levi H.S.",36146416600;11042473800;35812244500,60111161;60111161;60030835-60193824,2023-01-01,2023,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2023-August,,,5622-5630,"Levin Tree Search (LTS) is a search algorithm that makes use of a policy (a probability distribution over actions) and comes with a theoretical guarantee on the number of expansions before reaching a goal node, depending on the quality of the policy. This guarantee can be used as a loss function, which we call the LTS loss, to optimize neural networks representing the policy (LTS+NN). In this work we show that the neural network can be substituted with parameterized context models originating from the online compression literature (LTS+CM). We show that the LTS loss is convex under this new model, which allows for using standard convex optimization tools, and obtain convergence guarantees to the optimal parameters in an online setting for a given set of solution trajectories - guarantees that cannot be provided for neural networks. The new LTS+CM algorithm compares favorably against LTS+NN on several benchmarks: Sokoban (Boxoban), The Witness, and the 24-Sliding Tile puzzle (STP). The difference is particularly large on STP, where LTS+NN fails to solve most of the test instances while LTS+CM solves each test instance in a fraction of a second. Furthermore, we show that LTS+CM is able to learn a policy that solves the Rubik's cube in only a few hundred expansions, which considerably improves upon previous machine learning techniques.",,0,0,,,NSERC,undefined,Natural Sciences and Engineering Research Council of Canada,IJCAI Artificial Intelligence
2-s2.0-85160005818,10.1145/3544548.3581465,,,LipLearner: Customizable Silent Speech Interactions on Mobile Devices,cp,Conference Paper,Su Z.,60107446;60025272,"Sony Computer Science Laboratories, Inc.;The University of Tokyo",Tokyo;Tokyo,Japan;Japan,3,"Su, Zixiong;Fang, Shitao;Rekimoto, Jun",57221077928;57956148200;6603848632,60025272;60025272;60025272-60107446,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,696,,"Silent speech interface is a promising technology that enables private communications in natural language. However, previous approaches only support a small and inflexible vocabulary, which leads to limited expressiveness. We leverage contrastive learning to learn efficient lipreading representations, enabling few-shot command customization with minimal user effort. Our model exhibits high robustness to different lighting, posture, and gesture conditions on an in-the-wild dataset. For 25-command classification, an F1-score of 0.8947 is achievable only using one shot, and its performance can be further boosted by adaptively learning from more data. This generalizability allowed us to develop a mobile silent speech interface empowered with on-device fine-tuning and visual keyword spotting. A user study demonstrated that with LipLearner, users could define their own commands with high reliability guaranteed by an online incremental learning scheme. Subjective feedback indicated that our system provides essential functionalities for customizable silent speech interactions with high usability and learnability.",Customization | Few-shot Learning | Lipreading | Silent Speech Interface,5,0,repositoryam,Green,JST,JPMJCR17A3,Japan Science and Technology Agency,CHI Human-Computer Interaction
2-s2.0-85161470080,10.1109/SP46215.2023.10179290,,,MEGA: Malleable Encryption Goes Awry,cp,Conference Paper,Backendal M.,60025858,ETH Zürich,Zurich,Switzerland,3,"Backendal, Matilda;Haller, Miro;Paterson, Kenneth G.",57204827530;57219688764;7005696468,60025858;60025858;60025858,2023-01-01,2023,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2023-May,,,146-163,"MEGA is a leading cloud storage platform with more than 250 million users and 1000 Petabytes of stored data. MEGA claims to offer user-controlled, end-to-end security. This is achieved by having all data encryption and decryption operations done on MEGA clients, under the control of keys that are only available to those clients. This is intended to protect MEGA users from attacks by MEGA itself, or by adversaries who have taken control of MEGA's infrastructure.We provide a detailed analysis of MEGA's use of cryptography in such a malicious server setting. We present five distinct attacks against MEGA, which together allow for a full compromise of the confidentiality of user files. Additionally, the integrity of user data is damaged to the extent that an attacker can insert malicious files of their choice which pass all authenticity checks of the client. We built proof-of-concept versions of all the attacks. Four of the five attacks are eminently practical. They have all been responsibly disclosed to MEGA and remediation is underway.Taken together, our attacks highlight significant shortcomings in MEGA's cryptographic architecture. We present immediately deployable countermeasures, as well as longer-term recommendations. We also provide a broader discussion of the challenges of cryptographic deployment at massive scale under strong threat models.",Bleichenbacher | Cloud-storage | Cryptanalysis | ECB-mode | Key-compromise | Plaintext-recovery | RSA-CRT,3,0,,,,undefined,,S&P Security and Privacy
2-s2.0-85173171001,10.1145/3611643.3616309,,,Mate! Are You Really Aware? An Explainability-Guided Testing Framework for Robustness of Malware Detectors,cp,Conference Paper,Sun R.,60271961;60029470;60025084;60008592,Peng Cheng Laboratory;Commonwealth Scientific and Industrial Research Organisation;Shanghai Jiao Tong University;Hong Kong University of Science and Technology,Shenzhen;Canberra;Shanghai;Hong Kong,China;Australia;China;Hong Kong,9,"Sun, Ruoxi;Xue, Minhui;Tyson, Gareth;Dong, Tian;Li, Shaofeng;Wang, Shuo;Zhu, Haojin;Camtepe, Seyit;Nepal, Surya",57218938779;56890437900;25960456600;57221418303;57212252504;57192102600;19640836400;8940517200;14029165900,60029470;60029470;60008592;60025084;60271961;60029470;60025084;60029470;60029470,2023-11-30,30 November 2023,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101194128,,Conference Proceeding,,,,1573-1585,"Numerous open-source and commercial malware detectors are available. However, their efficacy is threatened by new adversarial attacks, whereby malware attempts to evade detection, e.g., by performing feature-space manipulation. In this work, we propose an explainability-guided and model-agnostic testing framework for robustness of malware detectors when confronted with adversarial attacks. The framework introduces the concept of Accrued Malicious Magnitude (AMM) to identify which malware features could be manipulated to maximize the likelihood of evading detection. We then use this framework to test several state-of-the-art malware detectors' ability to detect manipulated malware. We find that (i) commercial antivirus engines are vulnerable to AMM-guided test cases; (ii) the ability of a manipulated malware generated using one detector to evade detection by another detector (i.e., transferability) depends on the overlap of features with large AMM values between the different detectors; and (iii) AMM values effectively measure the fragility of features (i.e., capability of feature-space manipulation to flip the prediction results) and explain the robustness of malware detectors facing evasion attacks. Our findings shed light on the limitations of current malware detectors, as well as how they can be improved.",Explainability | Malware detectors | Robustness,1,0,repositoryam,Green,,undefined,,FSE Software Engineering
2-s2.0-85163790304,10.1145/3578338.3593552,,,Mean-field Analysis for Load Balancing on Spatial Graphs,cp,Conference Paper,Rutten D.,60019647,Georgia Institute of Technology,Atlanta,United States,2,"Rutten, Daan;Mukherjee, Debankur",57219788931;57190336501,60019647;60019647,2023-06-19,19 June 2023,SIGMETRICS 2023 - Abstract Proceedings of the 2023 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems,,21101162612,,Conference Proceeding,,,,27-28,"A pivotal methodological tool behind the analysis of large-scale load balancing systems is mean-field analysis. The high-level idea is to represent the system state by aggregate quantities and characterize their rate of change as the system size grows large. An assumption for the above scheme to work is that the aggregate quantity is Markovian such that its rate of change can be expressed as a function of its current state. If the aggregate quantity is not Markovian, not only does this technique break down, the mean-field approximation may even turn out to be highly inaccurate. In load balancing systems, if servers are exchangeable, then the aggregate quantity is indeed Markovian. However, the growing heterogeneity in the types of tasks processed by modern data centers has recently motivated the research community to consider systems beyond the exchangeability assumption. The main reason stems from data locality, i.e., the fact that servers need to store resources to process tasks of a particular type locally and have only limited storage space. An emerging line of work thus considers a bipartite graph between task types and servers [2, 3, 5-7]. In this compatibility graph, an edge between a server and a task type represents the server's ability to process these tasks. In practice, storage capacity or geographical constraints force a server to process only a small subset of all task types, leading to sparse network topologies. This motivates the study of load balancing in systems with suitably sparse bipartite compatibility graphs.",data locality | load balancing on network | many-server asymptotics | meanfield approximation | power-of-d | queueing theory | stochastic coupling,0,0,repositoryam,Green,NSF,CIF-2113027,National Science Foundation,SIGMETRICS Performance
2-s2.0-85174067832,10.1145/3603269.3604864,,,Memory Management in ActiveRMT: Towards Runtime-programmable Switches,cp,Conference Paper,Das R.,60030612,"University of California, San Diego",La Jolla,United States,2,"Das, Rajdeep;Snoeren, Alex C.",57211783139;10142863200,60030612;60030612,2023-09-10,10 September 2023,SIGCOMM 2023 - Proceedings of the ACM SIGCOMM 2023 Conference,,21101182756,,Conference Proceeding,,,,1043-1059,"A wide variety of in-network services have been developed for RMT-based switching hardware, almost exclusively through the P4 language and ecosystem. Many of these applications maintain state in switch memory, a scarce shared resource. As with any other network resource, varying traffic demands necessitate reallocations, yet the P4 ecosystem is not well suited for dynamic resource management: Modifying the set of services deployed on a switch using P4 requires the network operator to prepare a new binary image and re-provision the switch, disrupting all existing traffic. We present an alternate approach - -using techniques from capsule-based active networking - -to programming RMT devices that enables non-disruptive (re)allocation of switch memory at time scales that are much faster than P4 compilation without operator intervention. We use P4 to implement a single, shared runtime on commodity RMT hardware that interprets instructions received via the switch data plane to deliver a variety of exemplar services including caching, load balancing, and network telemetry. Our prototype implementation is able to dynamically provision dozens-to-hundreds of instances of simultaneous stateful services at the timescale of seconds.",active networking | network function virtualization | P4 | RMT,0,1,publisherhybridgold,Hybrid Gold,USDOE,ARPA-E DE-AR000084,U.S. Department of Energy,SIGCOMM Networking
2-s2.0-85167980342,,,,Misspecification in Inverse Reinforcement Learning,cp,Conference Paper,Skalse J.,60026851,University of Oxford,Oxford,United Kingdom,2,"Skalse, Joar;Abate, Alessandro",57219525715;56819871700,60026851;60026851,2023-06-27,27 June 2023,"Proceedings of the 37th AAAI Conference on Artificial Intelligence, AAAI 2023",,21101170618,,Conference Proceeding,37,,,15136-15143,"The aim of Inverse Reinforcement Learning (IRL) is to infer a reward function R from a policy π. To do this, we need a model of how π relates to R. In the current literature, the most common models are optimality, Boltzmann rationality, and causal entropy maximisation. One of the primary motivations behind IRL is to infer human preferences from human behaviour. However, the true relationship between human preferences and human behaviour is much more complex than any of the models currently used in IRL. This means that they are misspecified, which raises the worry that they might lead to unsound inferences if applied to real-world data. In this paper, we provide a mathematical analysis of how robust different IRL models are to misspecification, and answer precisely how the demonstrator policy may differ from each of the standard models before that model leads to faulty inferences about the reward function R. We also introduce a framework for reasoning about misspecification in IRL, together with formal tools that can be used to easily derive the misspecification robustness of new IRL models.",,1,0,,,,undefined,,AAAI Artificial Intelligence
2-s2.0-85171621476,10.1109/INFOCOM53939.2023.10228919,,,More than Enough is Too Much: Adaptive Defenses against Gradient Leakage in Production Federated Learning,cp,Conference Paper,Wang F.,60016849,University of Toronto,Toronto,Canada,3,"Wang, Fei;Hugh, Ethan;Li, Baochun",57853294000;58604591900;57216996445,60016849;60016849;60016849,2023-01-01,2023,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2023-May,,,,"With increasing concerns on privacy leakage from gradients, a variety of attack mechanisms emerged to recover private data from gradients at an honest-but-curious server, which challenged the primary advantage of privacy protection in federated learning. However, we cast doubt upon the real impact of these gradient attacks on production federated learning systems. By taking away several impractical assumptions that the literature has made, we find that gradient attacks pose a limited degree of threat to the privacy of raw data.Through a comprehensive evaluation on existing gradient attacks in a federated learning system with practical assumptions, we have systematically analyzed their effectiveness under a wide range of configurations. We present key priors required to make the attack possible or stronger, such as a narrow distribution of initial model weights, as well as inversion at early stages of training. We then propose a new lightweight defense mechanism that provides sufficient and self-adaptive protection against time-varying levels of the privacy leakage risk throughout the federated learning process. As a variation of gradient perturbation method, our proposed defense, called Outpost, selectively adds Gaussian noise to gradients at each update iteration according to the Fisher information matrix, where the level of noise is determined by the privacy leakage risk quantified by the spread of model weights at each layer. To limit the computation overhead and training performance degradation, Outpost only performs perturbation with iteration-based decay. Our experimental results demonstrate that Outpost can achieve a much better tradeoff than the state-of-the-art with respect to convergence performance, computational overhead, and protection against gradient attacks.",,2,0,,,,undefined,,INFOCOM Networking
2-s2.0-85162065788,10.1145/3591236,,,Mosaic: An Interoperable Compiler for Tensor Algebra,ar,Article,Bansal M.,60012708,Stanford University,Stanford,United States,4,"Bansal, Manya;Hsu, Olivia;Olukotun, Kunle;Kjolstad, Fredrik",58315953400;57499741300;35615042200;37117054100,60012708;60012708;60012708;60012708,2023-06-06,6 June 2023,Proceedings of the ACM on Programming Languages,,21101020042,24751421,Journal,7,,122,,"We introduce Mosaic, a sparse tensor algebra compiler that can bind tensor expressions to external functions of other tensor algebra libraries and compilers. Users can extend Mosaic by adding new functions and bind a sub-expression to a function using a scheduling API. Mosaic substitutes the bound sub-expressions with calls to the external functions and automatically generates the remaining code using a default code generator. As the generated code is fused by default, users can productively leverage both fusion and calls to specialized functions within the same compiler. We demonstrate the benefits of our dual approach by showing that calling hand-written CPU and specialized hardware functions can provide speedups of up to 206× against fused code in some cases, while generating fused code can provide speedups of up to 3.57× against code that calls external functions in other cases. Mosaic also offers a search system that can automatically map an expression to a set of registered external functions. Both the explicit binding and automatic search are verified by Mosaic. Additionally, the interface for adding new external functions is simple and general. Currently, 38 external functions have been added to Mosaic, with each addition averaging 20 lines of code.",automated search | compilation | external functions | sparse tensor algebra,1,1,publisherfree2read,Bronze,,undefined,,PLDI Programming Languages
2-s2.0-85180552042,10.1145/3611643.3616337,,,NeuRI: Diversifying DNN Generation via Inductive Rule Inference,cp,Conference Paper,Liu J.,60033100;60030162;60000745,Nanjing University;Columbia University;University of Illinois Urbana-Champaign,Nanjing;New York;Urbana,China;United States;United States,4,"Liu, Jiawei;Peng, Jinjun;Wang, Yuyao;Zhang, Lingming",57219762550;58727761600;58106124600;57203347002,60000745;60030162;60033100;60000745,2023-11-30,30 November 2023,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101194128,,Conference Proceeding,,,,657-669,"Deep Learning (DL) is prevalently used in various industries to improve decision-making and automate processes, driven by the ever-evolving DL libraries and compilers. The correctness of DL systems is crucial for trust in DL applications. As such, the recent wave of research has been studying the automated synthesis of test-cases (i.e., DNN models and their inputs) for fuzzing DL systems. However, existing model generators only subsume a limited number of operators, lacking the ability to pervasively model operator constraints. To address this challenge, we propose NeuRI, a fully automated approach for generating valid and diverse DL models composed of hundreds of types of operators. NeuRI adopts a three-step process: (i) collecting valid and invalid API traces from various sources; (ii) applying inductive program synthesis over the traces to infer the constraints for constructing valid models; and (iii) using hybrid model generation which incorporates both symbolic and concrete operators. Our evaluation shows that NeuRI improves branch coverage of TensorFlow and PyTorch by 24% and 15% over the state-of-the-art model-level fuzzers. NeuRI finds 100 new bugs for PyTorch and TensorFlow in four months, with 81 already fixed or confirmed. Of these, 9 bugs are labelled as high priority or security vulnerability, constituting 10% of all high-priority bugs of the period. Open-source developers regard error-inducing tests reported by us as ""high-quality""and ""common in practice"".",Compiler Testing | Deep Learning Compilers | Fuzzing,0,0,repositoryam,Green,NSF,CCF-2131943,National Science Foundation,FSE Software Engineering
2-s2.0-85162790486,10.1109/SP46215.2023.10179306,,,Not Yet Another Digital ID: Privacy-Preserving Humanitarian Aid Distribution,cp,Conference Paper,Wang B.,60117087;60028186;100887097,CISPA - Helmholtz Center for Information Security;École Polytechnique Fédérale de Lausanne;International Committee of the Red Cross,Saarbrucken;Lausanne;Geneva,Germany;Switzerland;Switzerland,5,"Wang, Boya;Lueks, Wouter;Sukaitis, Justinas;Narbel, Vincent Graf;Troncoso, Carmela",58179906100;55579785200;58180311100;58179769300;23398216400,60028186;60117087;100887097;100887097;60028186,2023-01-01,2023,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2023-May,,,645-663,"Humanitarian aid-distribution programs help bring physical goods to people in need. Traditional paper-based solutions to support aid distribution do not scale to large populations and are hard to secure. Existing digital solutions solve these issues, at the cost of collecting large amount of personal information. This lack of privacy can endanger recipients' safety and harm their dignity. In collaboration with the International Committee of the Red Cross, we build a safe digital aid-distribution system. We first systematize the requirements such a system should satisfy. We then propose a decentralized solution based on the use of tokens that fulfills the needs of humanitarian organizations. It provides scalability and strong accountability, and, by design, guarantees the recipients' privacy. We provide two instantiations of our design, on a smart card and on a smartphone. We formally prove the security and privacy properties of these solutions, and empirically show that they can operate at scale.",humanitarian aid distribution | privacy engineering | privacy-preserving technologies,1,0,,,EPFL,undefined,École Polytechnique Fédérale de Lausanne,S&P Security and Privacy
2-s2.0-85185871911,10.1109/ICCV51070.2023.00747,,,Passive Ultra-Wideband Single-Photon Imaging,cp,Conference Paper,Wei M.,60016849,University of Toronto,Toronto,Canada,5,"Wei, Mian;Nousias, Sotiris;Gulve, Rahul;Lindell, David B.;Kutulakos, Kiriakos N.",57194857841;57200613390;57207995977;57201292322;58904284400,60016849;60016849;60016849;60016849;60016849,2023-01-01,2023,Proceedings of the IEEE International Conference on Computer Vision,15505499,110561,,Conference Proceeding,,,,8101-8112,"We consider the problem of imaging a dynamic scene over an extreme range of timescales simultaneously - seconds to picoseconds - and doing so passively, without much light, and without any timing signals from the light source(s) emitting it. Because existing flux estimation techniques for single-photon cameras break down in this regime, we develop a flux probing theory that draws insights from stochastic calculus to enable reconstruction of a pixel's time-varying flux from a stream of monotonically-increasing photon detection timestamps. We use this theory to (1) show that passive free-running SPAD cameras have an attainable frequency bandwidth that spans the entire DC-to-31 GHz range in low-flux conditions, (2) derive a novel Fourier-domain flux reconstruction algorithm that scans this range for frequencies with statistically-significant support in the timestamp data, and (3) ensure the algorithm's noise model remains valid even for very low photon counts or non-negligible dead times. We show the potential of this asynchronous imaging regime by experimentally demonstrating several never-seen-before abilities: (1) imaging a scene illuminated simultaneously by sources operating at vastly different speeds without synchronization (bulbs, projectors, multiple pulsed lasers), (2) passive non-line-of-sight video acquisition, and (3) recording ultra-wideband video, which can be played back later at 30 Hz to show everyday motions - but can also be played a billion times slower to show the propagation of light itself.",,0,0,,,NSERC,undefined,Natural Sciences and Engineering Research Council of Canada,ICCV Computer Vision
2-s2.0-85160019211,10.1145/3544548.3581101,,,Paying the Price: When Intimate Partners Use Technology for Financial Harm,cp,Conference Paper,Bellini R.,60007776,Cornell University,Ithaca,United States,1,"Bellini, Rosanna",57202047155,60007776,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,872,,"Financial abuse - the control of a survivor's access to and use of financial resources - is highly prevalent in intimate partner violence (IPV) cases. Based on the reports of 158 survivors of IPV and 16 financial advocates, we present a comprehensive investigation into how abusers exploit technologies to harm survivors financially through various technical attacks and deceptive strategies. In doing so, we identify four motivations for abusers who use these harmful attacks and how these acts exploit, monitor, restrict, and sabotage a survivor's financial well-being and independence. As each dimension of these financial harms warrants a tailored approach, we highlight potential directions for practice and research to protect survivors from technology-enabled financial harms. Broadly, we call for the financial technology sector to consider designing for intimate threats through adversarial thinking, recommend strategies for detecting financially abusive activity and provide guidance for how customer service agents may be financially abuse aware.",financial abuse | intimate partner violence | technology-enabled abuse,4,0,,,NSF,1916096,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85051412948,10.4271/2018-01-1587,,,Research on the Development Trend of Brain Controlled Cars,cp,Conference Paper,Bie W.,60029306;113805851,Wuhan University;Dongfeng Motor Corporation,Wuhan;Wuhan,China;China,7,"Bie, Weiwei;Li, Kai;Zhang, Ruilin;Huang, Yi;Fang, Qiang;Hu, Jin;Qian, Jianshu",57203368231;57203373480;57203373275;57203373719;57203372242;57746961800;57203370393,113805851;113805851;113805851;113805851;113805851;113805851;60029306,2018-08-07,7 August 2018,SAE Technical Papers,,21100239259,01487191,Journal,2018-August,August,,,"This paper studies the development trend of the brain controlled cars. A brain controlled car is a new application of the brain-computer interface (BCI) to the on-road motor vehicles. As a new frontier science, the relevant studies are exploratory and still at an early stage. The prospect of the brain controlled cars is also unclear. In this paper, we summarizes the research status of the brain controlled cars based on both the academic articles and publicly released demo cars. The research history, the achievable control functions, the vehicle types that implemented on, the testing scenarios and the technology roadmaps are elaborated. According to the development traces of both the intelligent connected vehicle (ICV) and the artificial intelligence (AI) technologies, we predicted the development trend of the brain controlled cars. This paper is from a novel angel that considering BCI technology as one of the driver assistance methods to make the driving experience more intelligent, more safe and reliable, more comfortable, and more compliant to the driver's intention. The main finding of this paper is that human-computer collaborative driving by the hybrid-augmented intelligence is the irresistible trend of the brain controlled cars. The hybrid-augmented intelligence will mainly act on the environment perception module, the decision-making & planning module and the control & execution module of an autonomous driving car to achieve the full autonomous driving in the open traffic and maximally ensure the driving safety. Additionally, applying BCI technology to the human-computer interface (HMI) in a car makes the driving experiences more ""people oriented"". This paper plays a positive role in promoting the applications of BCI technology to the on-road motor vehicles, accelerating the development of ICV, as well as improving our future driving experiences.",,0,0,,,,undefined,,CVPR Computer Vision
2-s2.0-85160014891,10.1145/3544548.3580662,,,"Playing with Feedback: Unpredictability, Immediacy, and Entangled Agency in the No-input Mixing Desk",cp,Conference Paper,Mudd T.,60027272,The University of Edinburgh,Edinburgh,United Kingdom,1,"Mudd, Tom",56636618500,60027272,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,243,,"Feedback is a process that is common in both acoustic and electronic musical instruments, but rare in digital musical tools or creative digital tools more generally. This paper examines the musical use of the 'no-input mixing desk' - or 'feedback mixer', a sound mixing desk fed back on itself - to explore how and why feedback is appealing for musicians. Twenty interviews were conducted with musicians who have used no-input mixing desk in their practice. Thematic analysis is used to explore the interview data. Results highlight the enjoyment and creative fulfilment of working with systems that can't be fully predicted or understood, a sense of gestural immediacy, sensitivity and tactility often perceived as lacking in digital instruments, and an affinity with acoustic instruments in terms of the scope for surprise and exploration.",creative interaction | feedback | music technology | performance,1,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85173036868,10.1109/SP46215.2023.10351027,,,Practically-exploitable Cryptographic Vulnerabilities in Matrix,cp,Conference Paper,Albrecht M.R.,60020595;60011520;60001881;130605444,"Royal Holloway, University of London;King's College London;The University of Sheffield;Brave Software",Egham;London;Sheffield;,United Kingdom;United Kingdom;United Kingdom;,4,"Albrecht, Martin R.;Celi, Sofía;Dowling, Benjamin;Jones, Daniel",57194093186;57292325600;56417507500;57222232382,60011520;130605444;60001881;60020595,2023-01-01,2023,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,,,,164-181,"We report several practically-exploitable cryptographic vulnerabilities in the Matrix standard for federated real-time communication and its flagship client and prototype implementation, Element. These, together, invalidate the confidentiality and authentication guarantees claimed by Matrix against a malicious server. This is despite Matrix' cryptographic routines being constructed from well-known and -studied cryptographic building blocks. The vulnerabilities we exploit differ in their nature (insecure by design, protocol confusion, lack of domain separation, implementation bugs) and are distributed broadly across the different subprotocols and libraries that make up the cryptographic core of Matrix and Element. Together, these vulnerabilities highlight the need for a systematic and formal analysis of the cryptography in the Matrix standard.",,2,0,,,EPSRC,EP/S021817/1,Engineering and Physical Sciences Research Council,S&P Security and Privacy
2-s2.0-85160020429,10.1145/3544548.3581109,,,Probing a Community-Based Conversational Storytelling Agent to Document Digital Stories of Housing Insecurity,cp,Conference Paper,Halperin B.A.,60015481;60013372,University of Washington;The University of Texas at Austin,Seattle;Austin,United States;United States,5,"Halperin, Brett A.;Hsieh, Gary;McElroy, Erin;Pierce, James;Rosner, Daniela K.",57697646400;23397317600;57194173839;36142259400;23009944700,60015481;60015481;60013372;60015481;60015481,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,304,,"Despite the central role that stories play in social movement-building, they are difficult to sustainably document for many reasons. To explore this challenge, this paper describes the design of a community-based conversational storytelling agent (CSA) to document digital stories of housing insecurity. Building on insights from an ongoing grassroots project, the Anti-Eviction Mapping Project, we share how a study initially focused on CSA-support opened an investigation of the role that artificial intelligence may play in housing justice movements. Drawing from 17 interviews with narrators of housing insecurity experiences and collectors of such stories, we find that collectors perceive opportunities to expand means of documentation with multimedia and multi-language support. Meanwhile, some narrators perceive potential for a CSA to offer therapeutic storytelling experiences and document otherwise unrecorded stories. Yet, CSA encounters also surface perils of machine bias, as well as reduced possibilities of human connections and relations.",City | Community-Based Design | Conversational Interface | Grassroots | Housing | Narrative Systems | Social Movements | Storytelling,1,1,publisherhybridgold,Hybrid Gold,NSF,2142795,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85180547314,10.1145/3611643.3616305,,,Recommending Analogical APIs via Knowledge Graph Embedding,cp,Conference Paper,Liu M.,60009860,Fudan University,Shanghai,China,7,"Liu, Mingwei;Yang, Yanjun;Lou, Yiling;Peng, Xin;Zhou, Zhong;Du, Xueying;Yang, Tianyong",57204696756;57220063936;58827705100;53865467700;58574311100;58546572800;58574112200,60009860;60009860;60009860;60009860;60009860;60009860;60009860,2023-11-30,30 November 2023,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101194128,,Conference Proceeding,,,,1496-1508,"Library migration, which replaces the current library with a different one to retain the same software behavior, is common in software evolution. An essential part of this is finding an analogous API for the desired functionality. However, due to the multitude of libraries/APIs, manually finding such an API is time-consuming and error-prone. Researchers created automated analogical API recommendation techniques, notably documentation-based methods. Despite potential, these methods have limitations, e.g., incomplete semantic understanding in documentation and scalability issues. In this study, we present KGE4AR, a novel documentation-based approach using knowledge graph (KG) embedding for recommending analogical APIs during library migration. KGE4AR introduces a unified API KG to comprehensively represent documentation knowledge, capturing high-level semantics. It further embeds this unified API KG into vectors for efficient, scalable similarity calculation. We assess KGE4AR with 35,773 Java libraries in two scenarios, with and without target libraries. KGE4AR notably outperforms state-of-the-art techniques (e.g., 47.1%-143.0% and 11.7%-80.6% MRR improvements), showcasing scalability with growing library counts.",API Migration | Knowledge Graph | Knowledge Graph Embedding,0,0,repositoryam,Green,NSFC,61972098,National Natural Science Foundation of China,FSE Software Engineering
2-s2.0-85166474084,10.1109/SP46215.2023.10179341,,,Red Team vs. Blue Team: A Real-World Hardware Trojan Detection Case Study Across Four Modern CMOS Technology Generations,cp,Conference Paper,Puschner E.,60277517;60005322;60000874;108184927,Max Planck Institute for Security and Privacy;Ruhr-Universitat Bochum;Université Catholique de Louvain;Bundeskriminalamt,Bochum;Bochum;Louvain-la-Neuve;Wiesbaden,Germany;Germany;Belgium;Germany,6,"Puschner, Endres;Moos, Thorben;Becker, Steffen;Kison, Christian;Moradi, Amir;Paar, Christof",57226880066;57194442621;57205685713;55879864400;57561752900;7004505375,60277517;60000874;60277517-60005322;108184927;60005322;60277517,2023-01-01,2023,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2023-May,,,56-74,"Verifying the absence of maliciously inserted Trojans in Integrated Circuits (ICs) is a crucial task - especially for security-enabled products. Depending on the concrete threat model, different techniques can be applied for this purpose. Assuming that the original IC layout is benign and free of backdoors, the primary security threats are usually identified as the outsourced manufacturing and transportation. To ensure the absence of Trojans in commissioned chips, one straightforward solution is to compare the received semiconductor devices to the design files that were initially submitted to the foundry. Clearly, conducting such a comparison requires advanced laboratory equipment and qualified experts. Nevertheless, the fundamental techniques to detect Trojans which require evident changes to the silicon layout are nowadays well-understood. Despite this, there is a glaring lack of public case studies describing the process in its entirety while making the underlying datasets publicly available. In this work, we aim to improve upon this state of the art by presenting a public and open hardware Trojan detection case study based on four different digital ICs using a Red Team vs. Blue Team approach. Hereby, the Red Team creates small changes acting as surrogates for inserted Trojans in the layouts of 90 nm, 65 nm, 40 nm, and 28 nm ICs. The quest of the Blue Team is to detect all differences between digital layout and manufactured device by means of a GDSII-vs-SEM-image comparison. Can the Blue Team perform this task efficiently? Our results spark optimism for the Trojan seekers and answer common questions about the efficiency of such techniques for relevant IC sizes. Further, they allow to draw conclusions about the impact of technology scaling on the detection performance.",GDSII | Hardware Trojans | Integrated Circuits Verification | Very Large Scale Integration,2,0,,,EC,724725,Waalse Gewest,S&P Security and Privacy
2-s2.0-85166957497,10.1109/ICSE48619.2023.00112,,,Rete: Learning Namespace Representation for Program Repair,cp,Conference Paper,Parasaram N.,60022148,University College London,London,United Kingdom,3,"Parasaram, Nikhil;Barr, Earl T.;Mechtaev, Sergey",57336835600;7005643860;57021983800,60022148;60022148;60022148,2023-01-01,2023,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,1264-1276,"A key challenge of automated program repair is finding correct patches in the vast search space of candidate patches. Real-world programs define large namespaces of variables that considerably contributes to the search space explosion. Existing program repair approaches neglect information about the program namespace, which makes them inefficient and increases the chance of test-overfitting. We propose Rete, a new program repair technique, that learns project-independent information about program namespace and uses it to navigate the search space of patches. Rete uses a neural network to extract project-independent information about variable CDU chains, def-use chains augmented with control flow. Then, it ranks patches by jointly ranking variables and the patch templates into which the variables are inserted. We evaluated Rete on 142 bugs extracted from two datasets, ManyBugs and BugsInPy. Our experiments demonstrate that ReTe generates six new correct patches that fix bugs that previous tools did not repair, an improvement of 31% and 59% over the existing state of the art.",Deep Learning | Patch Prioritisation | Program Repair | Variable Representation,1,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-85160003099,10.1145/3544548.3581308,,,"Rethinking ""Risk"" in Algorithmic Systems Through A Computational Narrative Analysis of Casenotes in Child-Welfare",cp,Conference Paper,Saxena D.,60016849;60015720,University of Toronto;Marquette University,Toronto;Milwaukee,Canada;United States,5,"Saxena, Devansh;Moon, Erina Seh Young;Chaurasia, Aryan;Guan, Yixin;Guha, Shion",57199324793;57549650800;58114651100;58115220400;55439707600,60015720;60016849;60016849;60016849;60016849,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,873,,"Risk assessment algorithms are being adopted by public sector agencies to make high-stakes decisions about human lives. Algorithms model ""risk""based on individual client characteristics to identify clients most in need. However, this understanding of risk is primarily based on easily quantifiable risk factors that present an incomplete and biased perspective of clients. We conducted a computational narrative analysis of child-welfare casenotes and draw attention to deeper systemic risk factors that are hard to quantify but directly impact families and street-level decision-making. We found that beyond individual risk factors, the system itself poses a significant amount of risk where parents are over-surveilled by caseworkers and lack agency in decision-making processes. We also problematize the notion of risk as a static construct by highlighting the temporality and mediating effects of different risk, protective, systemic, and procedural factors. Finally, we draw caution against using casenotes in NLP-based systems by unpacking their limitations and biases embedded within them.",computational narrative analysis | risk prediction | risk work | uncertainty in decision-making,3,1,repositoryam,Green,NSERC,04570,Natural Sciences and Engineering Research Council of Canada,CHI Human-Computer Interaction
2-s2.0-85167927876,,,,SAT-Based PAC Learning of Description Logic Concepts,cp,Conference Paper,Cate B.t.,60032991;60008042;60002483;125736302,Technische Universität Dortmund;Universität Leipzig;Universiteit van Amsterdam;Center for Scalable Data Analytics and Artificial Intelligence (ScaDS.AI),Dortmund;Leipzig;Amsterdam;Leipzig,Germany;Germany;Netherlands;Germany,4,"Cate, Balder ten;Funk, Maurice;Jung, Jean Christoph;Lutz, Carsten",8964763900;57209282329;36166980800;7103325866,60002483;60008042-125736302;60032991;60008042-125736302,2023-01-01,2023,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2023-August,,,3347-3355,"We propose bounded fitting as a scheme for learning description logic concepts in the presence of ontologies. A main advantage is that the resulting learning algorithms come with theoretical guarantees regarding their generalization to unseen examples in the sense of PAC learning. We prove that, in contrast, several other natural learning algorithms fail to provide such guarantees. As a further contribution, we present the system SPELL which efficiently implements bounded fitting for the description logic ELHr based on a SAT solver, and compare its performance to a state-of-the-art learner.",,4,0,,,H2020,57616814,Horizon 2020 Framework Programme,IJCAI Artificial Intelligence
2-s2.0-85160023002,10.1145/3544548.3580991,,,SAWSense: Using Surface Acoustic Waves for Surface-bound Event Recognition,cp,Conference Paper,Iravantchi Y.,60025778;128423669,"University of Michigan, Ann Arbor;Meta Reality Labs",Ann Arbor;Redmond,United States;United States,4,"Iravantchi, Yasha;Zhao, Yi;Kin, Kenrick;Sample, Alanson P.",57209395174;58285517000;35199859600;9235634800,60025778;60025778;128423669;60025778,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,422,,"Enabling computing systems to understand user interactions with everyday surfaces and objects can drive a wide range of applications. However, existing vibration-based sensors (e.g., accelerometers) lack the sensitivity to detect light touch gestures or the bandwidth to recognize activity containing high-frequency components. Conversely, microphones are highly susceptible to environmental noise, degrading performance. Each time an object impacts a surface, Surface Acoustic Waves (SAWs) are generated that propagate along the air-to-surface boundary. This work repurposes a Voice PickUp Unit (VPU) to capture SAWs on surfaces (including smooth surfaces, odd geometries, and fabrics) over long distances and in noisy environments. Our custom-designed signal acquisition, processing, and machine learning pipeline demonstrates utility in both interactive and activity recognition applications, such as classifying trackpad-style gestures on a desk and recognizing 16 cooking-related activities, all with >97% accuracy. Ultimately, SAWs offer a unique signal that can enable robust recognition of user touch and on-surface events.",Acoustics | Activity Recognition | Gesture Interface | Sensing | Surface Acoustic Wave | Touch Detection,1,0,,,,undefined,,CHI Human-Computer Interaction
2-s2.0-85168869897,10.1145/3579371.3589107,,,SCALO: An Accelerator-Rich Distributed System for Scalable Brain-Computer Interfacing,cp,Conference Paper,Sriram K.,60005455,Yale University,New Haven,United States,8,"Sriram, Karthik;Ugur, Muhammed;Pothukuchi, Raghavendra Pradyumna;Ye, Oliver;Gerasimiuk, Michał;Manohar, Rajit;Khandelwal, Anurag;Bhattacharjee, Abhishek",57219272792;57763135200;57191252534;58065695400;57355103400;7004181876;57189265710;7102556898,60005455;60005455;60005455;60005455;60005455;60005455;60005455;60005455,2023-06-17,17 June 2023,Proceedings - International Symposium on Computer Architecture,10636897,145750,,Conference Proceeding,,,,1006-1025,"SCALO is the first distributed brain-computer interface (BCI) consisting of multiple wireless-networked implants placed on different brain regions. SCALO unlocks new treatment options for debilitating neurological disorders and new research into brain-wide network behavior. Achieving the fast and low-power communication necessary for real-time processing has historically restricted BCIs to single brain sites. SCALO also adheres to tight power constraints, but enables fast distributed processing. Central to SCALO’s efficiency is its realization as a full stack distributed system of brain implants with accelerator-rich compute. SCALO balances modular system layering with aggressive cross-layer hardware-software co-design to integrate compute, networking, and storage. The result is a lesson in designing energy-efficient networked distributed systems with hardware accelerators from the ground up.",BCI | Brain-Computer Interfaces | Hardware Accelerators | Low Power,0,1,publisherfree2read,Bronze,NSF,2127309,National Science Foundation,ISCA Architecture
2-s2.0-85167957482,10.1109/ICSE48619.2023.00103,,,'STILL AROUND': Experiences and Survival Strategies of Veteran Women Software Developers,cp,Conference Paper,Van Breukelen S.,60032882;60009512;60002306,Technische Universiteit Eindhoven;The University of Adelaide;University of Calgary,Eindhoven;Adelaide;Calgary,Netherlands;Australia;Canada,4,"Van Breukelen, Sterre;Barcombt, Ann;Baltes, Sebastian;Serebrenik, Alexander",58109924000;58609151500;56241807200;8987563200,60032882;60002306;60009512;60032882,2023-01-01,2023,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,1148-1160,"The intersection of ageism and sexism can create a hostile environment for veteran software developers belonging to marginalized genders. In this study, we conducted 14 interviews to examine the experiences of people at this intersection, primar-ily women, in order to discover the strategies they employed in order to successfully remain in the field. We identified 283 codes, which fell into three main categories: Strategies, Experiences, and Perception. Several strategies we identified, such as (Deliberately) Not Trying to Look Younger, were not previously described in the software engineering literature. We found that, in some compa-nies, older women developers are recognized as having particular value, further strengthening the known benefits of diversity in the workforce. Based on the experiences and strategies, we suggest organizations employing software developers to consider the benefits of hiring veteran women software developers. For example, companies can draw upon the life experiences of older women developers in order to better understand the needs of customers from a similar demographic. While we recognize that many of the strategies employed by our study participants are a response to systemic issues, we still consider that, in the short-term, there is benefit in describing these strategies for developers who are experiencing such issues today.",age | gender | intersectionality | interview study | qualitative research | software development,2,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-85170386139,,,,Safe Reinforcement Learning via Probabilistic Logic Shields,cp,Conference Paper,Yang W.C.,60025063;60008141;60001565,KU Leuven;Örebro Universitet;Stellenbosch University,Leuven;Orebro;Stellenbosch,Belgium;Sweden;South Africa,4,"Yang, Wen Chi;Marra, Giuseppe;Rens, Gavin;De Raedt, Luc",57223722730;57204181546;36716764700;55760010700,60025063;60025063;60001565;60025063-60008141,2023-01-01,2023,IJCAI International Joint Conference on Artificial Intelligence,10450823,19400157504,,Conference Proceeding,2023-August,,,5739-5749,"Safe Reinforcement learning (Safe RL) aims at learning optimal policies while staying safe. A popular solution to Safe RL is shielding, which uses a logical safety specification to prevent an RL agent from taking unsafe actions. However, traditional shielding techniques are difficult to integrate with continuous, end-to-end deep RL methods. To this end, we introduce Probabilistic Logic Policy Gradient (PLPG). PLPG is a model-based Safe RL technique that uses probabilistic logic programming to model logical safety constraints as differentiable functions. Therefore, PLPG can be seamlessly applied to any policy gradient algorithm while still providing the same convergence guarantees. In our experiments, we show that PLPG learns safer and more rewarding policies compared to other state-of-the-art shielding techniques.",,0,0,,,FWO,1239422N,Fonds Wetenschappelijk Onderzoek,IJCAI Artificial Intelligence
2-s2.0-85167865913,10.1109/INFOCOM53939.2023.10228997,,,Scalable Real-Time Bandwidth Fairness in Switches,cp,Conference Paper,MacDavid R.,60003269,Princeton University,Princeton,United States,3,"MacDavid, Robert;Chen, Xiaoqi;Rexford, Jennifer",56928256200;57203514760;7003493334,60003269;60003269;60003269,2023-01-01,2023,Proceedings - IEEE INFOCOM,0743166X,18204,,Conference Proceeding,2023-May,,,,"Network operators want to enforce fair bandwidth sharing between users without solely relying on congestion control running on end-user devices. However, in edge networks (e.g., 5G), the number of user devices sharing a bottleneck link far exceeds the number of queues supported by today's switch hardware; even accurately tracking per-user sending rates may become too resource-intensive. Meanwhile, traditional software-based queuing on CPUs struggles to meet the high throughput and low latency demanded by 5G users.We propose Approximate Hierarchical Allocation of Bandwidth (AHAB), a per-user bandwidth limit enforcer that runs fully in the data plane of commodity switches. AHAB tracks each user's approximate traffic rate and compares it against a bandwidth limit, which is iteratively updated via a real-time feedback loop to achieve max-min fairness across users. Using a novel sketch data structure, AHAB avoids storing per-user state, and therefore scales to thousands of slices and millions of users. Furthermore, AHAB supports network slicing, where each slice has a guaranteed share of the bandwidth that can be scavenged by other slices when under-utilized. Evaluation shows AHAB can achieve fair bandwidth allocation within 3.1ms, 13x faster than prior data-plane hierarchical schedulers.",Admission Control | Fair Queuing | Network Slicing | P4 | Packet Scheduling | Programmable Data Plane,6,0,,,DARPA,HR001120C0107,Defense Advanced Research Projects Agency,INFOCOM Networking
2-s2.0-85174399634,,,,Self-Repellent Random Walks on General Graphs - Achieving Minimal Sampling Variance via Nonlinear Markov Chains,cp,Conference Paper,Doshi V.,60279548;60112142,NC State College of Engineering;IQVIA Inc.,Raleigh;Durham,United States;United States,3,"Doshi, Vishwaraj;Hu, Jie;Eun, Do Young",57217278835;57222095129;6603631181,60112142;60279548;60279548,2023-01-01,2023,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,202,,,8403-8423,"We consider random walks on discrete state spaces, such as general undirected graphs, where the random walkers are designed to approximate a target quantity over the network topology via sampling and neighborhood exploration in the form of Markov chain Monte Carlo (MCMC) procedures. Given any Markov chain corresponding to a target probability distribution, we design a self-repellent random walk (SRRW) which is less likely to transition to nodes that were highly visited in the past, and more likely to transition to seldom visited nodes. For a class of SRRWs parameterized by a positive real α, we prove that the empirical distribution of the process converges almost surely to the the target (stationary) distribution of the underlying Markov chain kernel. We then provide a central limit theorem and derive the exact form of the arising asymptotic co-variance matrix, which allows us to show that the SRRW with a stronger repellence (larger α) always achieves a smaller asymptotic covariance, in the sense of Loewner ordering of co-variance matrices. Especially for SRRW-driven MCMC algorithms, we show that the decrease in the asymptotic sampling variance is of the order O(1/α), eventually going down to zero. Finally, we provide numerical simulations complimentary to our theoretical results, also empirically testing a version of SRRW with α increasing in time to combine the benefits of smaller asymptotic variance due to large α, with empirically observed faster mixing properties of SRRW with smaller α.",,0,0,,,NSF,CNS-1824518,National Science Foundation,ICML Machine Learning
2-s2.0-85160016558,10.1145/3544548.3580767,,,Sensorimotor Simulation of Redirected Reaching using Stochastic Optimal Feedback Control,cp,Conference Paper,Gonzalez E.J.,60012708,Stanford University,Stanford,United States,2,"Gonzalez, Eric J.;Follmer, Sean",25642446000;26430822900,60012708;60012708,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,776,,"Illusory VR interaction techniques such as hand redirection work because humans use vision to adjust their motor commands during movement (e.g., reaching). Existing simulations of redirected reaching are limited, however, and have not yet incorporated important stochastic characteristics like sensorimotor noise, nor captured redirection's effect on movement duration. In this work, we propose adapting a stochastic optimal feedback control (SOFC) model of normal reach to simulate redirection by augmenting sensory feedback at run-time. We present a summary of our simulation and validate it against user data gathered in multiple redirection conditions. We also evaluate the impacts of visual attention on the effectiveness of redirection in real users and replicate the effects in simulation. Our results show that an infinite-horizon SOFC model is able to reproduce key characteristics of redirected reaches and highlight the benefits of SOFC as a tool for simulating, evaluating, and gaining insights about redirection techniques.",Hand Redirection | Modeling | Optimal Control | Sensorimotor Control | Stochastic Simulation | Virtual Reality,1,0,,,APSF,FG-2021-15851,Alfred P. Sloan Foundation,CHI Human-Computer Interaction
2-s2.0-85171738354,10.1109/ICSE48619.2023.00184,,,Sibyl: Improving Software Engineering Tools with SMT Selection,cp,Conference Paper,Leeson W.,60152865;60015150,University of Virginia School of Engineering and Applied Science;Imperial College London,Charlottesville;London,United States;United Kingdom,3,"Leeson, Will;Dwyer, Matthew B.;Filieri, Antonio",57441657800;7005193693;36170481900,60152865;60152865;60015150,2023-01-01,2023,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,2185-2197,"SMT solvers are often used in the back end of different software engineering tools-e.g., program verifiers, test generators, or program synthesizers. There are a plethora of algorithmic techniques for solving SMT queries. Among the available SMT solvers, each employs its own combination of algorithmic techniques that are optimized for different fragments of logics and problem types. The most efficient solver can change with small changes in the SMT query, which makes it nontrivial to decide which solver to use. Consequently, designers of software engineering tools often select a single solver, based on familiarity or convenience, and tailor their tool towards it. Choosing an SMT solver at design time misses the opportunity to optimize query solve times and, for tools where SMT solving is a bottleneck, the performance loss can be significant. In this work, we present Sibyl, an automated SMT selector based on graph neural networks (GNNs). Sibyl creates a graph representation of a given SMT query and uses GNNs to predict how each solver in a suite of SMT solvers would perform on said query. Sibyl learns to predict based on features of SMT queries that are specific to the population on which it is trained - avoiding the need for manual feature engineering. Once trained, Sibyl makes fast and accurate predictions which can substantially reduce the time needed to solve a set of SMT queries. We evaluate Sibyl in four scenarios in which SMT solvers are used: in competition, in a symbolic execution engine, in a bounded model checker, and in a program synthesis tool. We find that Sibyl improves upon the state of the art in nearly every case and provide evidence that it generalizes better than existing techniques. Further, we evaluate Sibyl's overhead and demonstrate that it has the potential to speedup a variety of different software engineering tools.",algorithm selection | graph neural networks | satisfiable modulo theories,1,0,,,NSF,2129824,National Science Foundation,ICSE Software Engineering
2-s2.0-85159296281,10.1145/3543507.3583214,,,Simplistic Collection and Labeling Practices Limit the Utility of Benchmark Datasets for Twitter Bot Detection,cp,Conference Paper,Hays C.,60022195,Massachusetts Institute of Technology,Cambridge,United States,5,"Hays, Chris;Schutzman, Zachary;Raghavan, Manish;Walk, Erin;Zimmer, Philipp",58079267300;57202994239;56410570100;57577767600;58078012200,60022195;60022195;60022195;60022195;60022195,2023-04-30,30 April 2023,"ACM Web Conference 2023 - Proceedings of the World Wide Web Conference, WWW 2023",,21101151800,,Conference Proceeding,,,,3660-3669,"Accurate bot detection is necessary for the safety and integrity of online platforms. It is also crucial for research on the influence of bots in elections, the spread of misinformation, and financial market manipulation. Platforms deploy infrastructure to flag or remove automated accounts, but their tools and data are not publicly available. Thus, the public must rely on third-party bot detection. These tools employ machine learning and often achieve near-perfect performance for classification on existing datasets, suggesting bot detection is accurate, reliable and fit for use in downstream applications. We provide evidence that this is not the case and show that high performance is attributable to limitations in dataset collection and labeling rather than sophistication of the tools. Specifically, we show that simple decision rules - shallow decision trees trained on a small number of features - achieve near-state-of-the-art performance on most available datasets and that bot detection datasets, even when combined together, do not generalize well to out-of-sample datasets. Our findings reveal that predictions are highly dependent on each dataset's collection and labeling procedures rather than fundamental differences between bots and humans. These results have important implications for both transparency in sampling and labeling procedures and potential biases in research using existing bot detection tools for pre-processing.",bot detection | Social media,4,1,repositoryam,Green,,undefined,,WWW World Wide Web
2-s2.0-85180147684,10.1109/SP46215.2023.10351029,,,Space Odyssey: An Experimental Software Security Analysis of Satellites,cp,Conference Paper,Willbold J.,60117087;60005322,CISPA - Helmholtz Center for Information Security;Ruhr-Universitat Bochum,Saarbrucken;Bochum,Germany;Germany,6,"Willbold, Johannes;Schloegel, Moritz;Vögele, Manuel;Gerhardt, Maximilian;Holz, Thorsten;Abbasi, Ali",57948693400;57225171500;58565892500;58771555500;53263832100;57198237842,60005322;60005322-60117087;60005322;60005322;60117087;60117087,2023-01-01,2023,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,,,,,"Satellites are an essential aspect of our modern society and have contributed significantly to the way we live today, most notable through modern telecommunications, global positioning, and Earth observation. In recent years, and especially in the wake of the New Space Era, the number of satellite deployments has seen explosive growth. Despite its critical importance, little academic research has been conducted on satellite security and, in particular, on the security of onboard firmware. This lack likely stems from by now outdated assumptions on achieving security by obscurity, effectively preventing meaningful research on satellite firmware.In this paper, we first provide a taxonomy of threats against satellite firmware. We then conduct an experimental security analysis of three real-world satellite firmware images. We base our analysis on a set of real-world attacker models and find several security-critical vulnerabilities in all analyzed firmware images. The results of our experimental security assessment show that modern in-orbit satellites suffer from different software security vulnerabilities and often a lack of proper access protection mechanisms. They also underline the need to overcome prevailing but obsolete assumptions. To substantiate our observations, we also performed a survey of 19 professional satellite developers to obtain a comprehensive picture of the satellite security landscape.",satellite firmware | satellite security | satellites | software security | space segment | threat taxonomy,0,0,repositoryam,Green,ERC,101045669,European Research Council,S&P Security and Privacy
2-s2.0-85180549431,10.1145/3611643.3616357,,,Speeding up SMT Solving via Compiler Optimization,cp,Conference Paper,Mikek B.,60019647,Georgia Institute of Technology,Atlanta,United States,2,"Mikek, Benjamin;Zhang, Qirun",58071968100;36661677600,60019647;60019647,2023-11-30,30 November 2023,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101194128,,Conference Proceeding,,,,1177-1189,"SMT solvers are fundamental tools for reasoning about constraints in practical problems like symbolic execution and program synthesis. Faster SMT solving can improve the performance and precision of those analysis tools. Existing approaches typically speed up SMT solving by developing new heuristics inside particular solvers, which requires nontrivial engineering efforts. This paper presents a new perspective on speeding up SMT solving. We propose SMT-LLVM Optimizing Translation (SLOT), a solver-agnostic pre-processing approach that utilizes existing compiler optimizations to simplify SMT problem instances. We implement SLOT for the two most application-critical SMT theories, bitvectors, and floating-point numbers. Our extensive evaluation based on the standard SMT-LIB benchmarks shows that SLOT can substantially increase the number of solvable SMT formulas given fixed timeouts and achieve mean speedups of nearly 3× for large benchmarks.",compiler optimization | simplification | SMT Solvers,0,1,publisherhybridgold,Hybrid Gold,NSF,1917924,National Science Foundation,FSE Software Engineering
2-s2.0-85168553424,10.1145/3592110,,,Split-Lohmann Multifocal Displays,ar,Article,Qin Y.,60027950,Carnegie Mellon University,Pittsburgh,United States,4,"Qin, Yingsi;Chen, Wei Yu;O'Toole, Matthew;Sankaranarayanan, Aswin C.",58543044700;57573718200;35987660300;14523223000,60027950;60027950;60027950;60027950,2023-08-01,1 August 2023,ACM Transactions on Graphics,07300301,24972,15577368,Journal,42,4,57,,"This work provides the design of a multifocal display that can create a dense stack of focal planes in a single shot. We achieve this using a novel computational lens that provides spatial selectivity in its focal length, i.e, the lens appears to have different focal lengths across points on a display behind it. This enables a multifocal display via an appropriate selection of the spatially-varying focal length, thereby avoiding time multiplexing techniques that are associated with traditional focus tunable lenses. The idea central to this design is a modification of a Lohmann lens, a focus tunable lens created with two cubic phase plates that translate relative to each other. Using optical relays and a phase spatial light modulator, we replace the physical translation of the cubic plates with an optical one, while simultaneously allowing for different pixels on the display to undergo different amounts of translations and, consequently, different focal lengths. We refer to this design as a Split-Lohmann multifocal display. Split-Lohmann displays provide a large étendue as well as high spatial and depth resolutions; the absence of time multiplexing and the extremely light computational footprint for content processing makes it suitable for video and interactive experiences. Using a lab prototype, we show results over a wide range of static, dynamic, and interactive 3D scenes, showcasing high visual quality over a large working range.",computational displays | lohmann lenses | multifocal displays | vergence-Accomodation conflict,1,1,publisherfree2read,Bronze,,undefined,,SIGGRAPH Graphics
2-s2.0-85179197854,10.1109/FOCS57990.2023.00059,,,Strong Bounds for 3-Progressions,cp,Conference Paper,Kelley Z.,60158506;60027550,"The Grainger College of Engineering;University of California, Los Angeles",Urbana;Los Angeles,United States;United States,2,"Kelley, Zander;Meka, Raghu",57190935892;25027961300,60158506;60027550,2023-01-01,2023,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,,,,933-973,"We show that for some constant β>0, any subset A of integers {1, ⋯, N} of size at least 2-O((log N)β) · N contains a non-trivial three-term arithmetic progression. Previously, three-term arithmetic progressions were known to exist only for sets of size at least N / (log N)1+c for a constant c>0.Our approach is first to develop new analytic techniques for addressing some related questions in the finite-field setting and then to apply some analogous variants of these same techniques, suitably adapted for the more complicated setting of integers.",,1,0,repositoryam,Green,NSF,2047310,National Science Foundation,FOCS Theory
2-s2.0-85162052885,10.1145/3591298,,,Synthesizing MILP Constraints for Efficient and Robust Optimization,ar,Article,Wang J.,60029311;60003269,University of Southern California;Princeton University,Los Angeles;Princeton,United States;United States,3,"Wang, Jingbo;Gupta, Aarti;Wang, Chao",57221357615;7410389613;55647141100,60029311;60003269;60029311,2023-06-06,6 June 2023,Proceedings of the ACM on Programming Languages,,21101020042,24751421,Journal,7,,184,,"While mixed integer linear programming (MILP) solvers are routinely used to solve a wide range of important science and engineering problems, it remains a challenging task for end users to write correct and efficient MILP constraints, especially for problems specified using the inherently non-linear Boolean logic operations. To overcome this challenge, we propose a syntax guided synthesis (SyGuS) method capable of generating high-quality MILP constraints from the specifications expressed using arbitrary combinations of Boolean logic operations. At the center of our method is an extensible domain specification language (DSL) whose expressiveness may be improved by adding new integer variables as decision variables, together with an iterative procedure for synthesizing linear constraints from non-linear Boolean logic operations using these integer variables. To make the synthesis method efficient, we also propose an over-approximation technique for soundly proving the correctness of the synthesized linear constraints, and an under-approximation technique for safely pruning away the incorrect constraints. We have implemented and evaluated the method on a wide range of benchmark specifications from statistics, machine learning, and data science applications. The experimental results show that the method is efficient in handling these benchmarks, and the quality of the synthesized MILP constraints is close to, or higher than, that of manually-written constraints in terms of both compactness and solving time.",Data Science | Machine Learning | Statistics | Syntax Guided Synthesis,0,1,publisherfree2read,Bronze,,undefined,,PLDI Programming Languages
2-s2.0-85160002627,10.1145/3544548.3581415,,,Take My Hand: Automated Hand-Based Spatial Guidance for the Visually Impaired,cp,Conference Paper,Rahman A.,60021918,University of Virginia,Charlottesville,United States,3,"Rahman, Adil;Azim, Md Aashikur Rahman;Heo, Seongkook",57838554000;57703244000;39061511400,60021918;60021918;60021918,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,544,,"Tasks that involve locating objects and then moving hands to those specific locations, such as using touchscreens or grabbing objects on a desk, are challenging for the visually impaired. Over the years, audio guidance and haptic feedback have been a staple in hand navigation based assistive technologies. However, these methods require the user to interpret the generated directional cues and then manually perform the hand motions. In this paper, we present automated hand-based spatial guidance to bridge the gap between guidance and execution, allowing visually impaired users to move their hands between two points automatically, without any manual effort. We implement this concept through FingerRover, an on-finger miniature robot that carries the user's finger to target points. We demonstrate the potential applications that can benefit from automated hand-based spatial guidance. Our user study shows the potential of our technique in improving the interaction capabilities of people with visual impairments.",accessibility | automated guidance | miniature guiding robot | spatial guidance | visual impairment,3,1,publisherfree2read,Bronze,,undefined,,CHI Human-Computer Interaction
2-s2.0-85171792487,10.1109/ICSE48619.2023.00174,,,Testing Database Engines via Query Plan Guidance,cp,Conference Paper,Ba J.,60017161,National University of Singapore,Singapore City,Singapore,2,"Ba, Jinsheng;Rigger, Manuel",57604944800;55901677600,60017161;60017161,2023-01-01,2023,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,2060-2071,"Database systems are widely used to store and query data. Test oracles have been proposed to find logic bugs in such systems, that is, bugs that cause the database system to compute an incorrect result. To realize a fully automated testing approach, such test oracles are paired with a test case generation technique; a test case refers to a database state and a query on which the test oracle can be applied. In this work, we propose the concept of Query Plan Guidance (QPG) for guiding automated testing towards 'interesting' test cases. SQL and other query languages are declarative. Thus, to execute a query, the database system translates every operator in the source language to one of the potentially many so-called physical operators that can be executed; the tree of physical operators is referred to as the query plan. Our intuition is that by steering testing towards exploring a variety of unique query plans, we also explore more interesting behaviors-some of which are potentially incorrect. To this end, we propose a mutation technique that gradually applies promising mutations to the database state, causing the DBMS to create potentially unseen query plans for subsequent queries. We applied our method to three mature, widely-used, and extensively-tested database systems-SQLite, TiDB, and CockroachDB-and found 53 unique, previously unknown bugs. Our method exercises 4.85-408.48× more unique query plans than a naive random generation method and 7.46× more than a code coverage guidance method. Since most database systems-including commercial ones-expose query plans to the user, we consider QPG a generally applicable, black-box approach and believe that the core idea could also be applied in other contexts (e.g., to measure the quality of a test suite).",automated testing | test case generation,5,0,repositoryam,Green,,undefined,,ICSE Software Engineering
2-s2.0-85160016481,10.1145/3544548.3581045,,,The Halting problem: Video analysis of self-driving cars in traffic,cp,Conference Paper,Brown B.,60030840;60028378;60011520;60009358,Københavns Universitet;Stockholms universitet;King's College London;Linköpings Universitet,Copenhagen;Stockholm;London;Linkoping,Denmark;Sweden;United Kingdom;Sweden,3,"Brown, Barry;Broth, Mathias;Vinkhuyzen, Erik",9234195400;23970080000;16231545600,60030840-60028378;60009358;60011520,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,12,,"Using publicly uploaded videos of the Waymo and Tesla FSD self-driving cars, this paper documents how self-driving vehicles still struggle with some basics of road interaction. To drive safely self-driving cars need to interact in traffic with other road users. Yet traffic is a complex, long established social domain. We focus on one core element of road interaction: when road users yield for each other. Yielding - such as by slowing down for others in traffic - involves communication between different road users to decide who will 'go' and who will 'yield'. Videos of the Waymo and Tesla FSD self-driving cars show how these systems fail to both yield for others, as well as failing to go when yielded to. In discussion, we explore how these 'problems' illustrate both the complexity of designing for road interaction, but also how the space of physical machine/human social interactions more broadly can be designed for.",,2,0,,,,RIT15-0046,,CHI Human-Computer Interaction
2-s2.0-85168661467,10.1145/3539618.3591888,,,The Information Retrieval Experiment Platform,cp,Conference Paper,Fröbe M.,60029507;60028637;60008042;60001490;130106904,Friedrich-Schiller-Universität Jena;Bauhaus-Universität Weimar;Universität Leipzig;University of Glasgow;ScaDS.AI,Jena;Weimar;Leipzig;Glasgow;,Germany;Germany;Germany;United Kingdom;,9,"Fröbe, Maik;Deckers, Niklas;Stein, Benno;Reimer, Jan Heinrich;Reich, Simon;Hagen, Matthias;MacAvaney, Sean;Bevendorff, Janek;Potthast, Martin",57214930695;57195962977;23013265500;57218707874;58398339600;16309692700;57202919022;57201362871;23012600600,60029507;60008042-130106904;60028637;60029507;60008042;60029507;60001490;60028637;60008042-130106904,2023-07-19,19 July 2023,SIGIR 2023 - Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval,,21101173008,,Conference Proceeding,,,,2826-2836,"We integrate ir_datasets, ir_measures, and PyTerrier with TIRA in the Information Retrieval Experiment Platform (TIREx) to promote more standardized, reproducible, scalable, and even blinded retrieval experiments. Standardization is achieved when a retrieval approach implements PyTerrier's interfaces and the input and output of an experiment are compatible with ir_datasets and ir_measures. However, none of this is a must for reproducibility and scalability, as TIRA can run any dockerized software locally or remotely in a cloud-native execution environment. Version control and caching ensure efficient (re)execution. TIRA allows for blind evaluation when an experiment runs on a remote server or cloud not under the control of the experimenter. The test data and ground truth are then hidden from public access, and the retrieval software has to process them in a sandbox that prevents data leaks. We currently host an instance of TIREx with 15 corpora (1.9 billion documents) on which 32 shared retrieval tasks are based. Using Docker images of 50 standard retrieval approaches, we automatically evaluated all approaches on all tasks (50 · 32 = 1,600 runs) in less than a week on a midsize cluster (1,620 CPU cores and 24 GPUs). This instance of TIREx is open for submissions and will be integrated with the IR Anthology, as well as released open source.",Reproducibility | Retrieval evaluation | Shared tasks | TIREx,7,0,repositoryam,Green,EC,GA 101070014,European Commission,SIGIR Information Retrieval
2-s2.0-85166233342,10.1109/SP46215.2023.10179311,,,The Leaky Web: Automated Discovery of Cross-Site Information Leaks in Browsers and the Web,cp,Conference Paper,Rautenstrauch J.,60117087,CISPA - Helmholtz Center for Information Security,Saarbrucken,Germany,3,"Rautenstrauch, Jannis;Pellegrino, Giancarlo;Stock, Ben",58519369900;57008821200;36246822400,60117087;60117087;60117087,2023-01-01,2023,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2023-May,,,2744-2760,"When browsing the web, none of us want sites to infer which other sites we may have visited before or are logged in to. However, attacker-controlled sites may infer this state through browser side-channels dubbed Cross-Site Leaks (XS-Leaks). Although these issues have been known since the 2000s, prior reports mostly found individual instances of issues rather than systematically studying the problem space. Further, actual impact in the wild often remained opaque.To address these open problems, we develop the first automated framework to systematically discover observation channels in browsers. In doing so, we detect and characterize 280 observation channels that leak information cross-site in the engines of Chromium, Firefox, and Safari, which include many variations of supposedly fixed leaks. Atop this framework, we create an automatic pipeline to find XS-Leaks in real-world websites. With this pipeline, we conduct the largest to-date study on XS-Leak prevalence in the wild by performing visit inference and a newly proposed variant cookie acceptance inference attack on the Tranco Top10K. In addition, we test 100 websites for the classic XS-Leak attack vector of login detection.Our results show that XS-Leaks pose a significant threat to the web ecosystem as at least 15%, 34%, and 77% of all tested sites are vulnerable to the three attacks. Also, we present substantial implementation differences between the browsers resulting in differing attack surfaces that matter in the wild. To ensure browser vendors and web developers alike can check their applications for XS-Leaks, we open-source our framework and include an extensive discussion on countermeasures to get rid of XS-Leaks in the near future and ensure new features in browsers do not introduce new XS-Leaks.",Browser-Security | Web-Security | XS-Leaks,5,0,,,H2020,101019206,Horizon 2020 Framework Programme,S&P Security and Privacy
2-s2.0-85160011634,10.1145/3544548.3581387,,,The Nuanced Nature of Trust and Privacy Control Adoption in the Context of Google,cp,Conference Paper,Ul Haque E.,60022659,University of Connecticut,Storrs,United States,3,"Ul Haque, Ehsan;Khan, Mohammad Maifi Hasan;Fahim, Md Abdullah Al",58285457100;23397066000;57211760106,60022659;60022659;60022659,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,591,,"This paper investigates how trust towards service providers and the adoption of privacy controls belonging to two specific purposes (control over ""sharing""vs. ""usage""of data) vary based on users' technical literacy. Towards that, we chose Google as the context and conducted an online survey across 209 Google users. Our results suggest that integrity and benevolence perceptions toward Google are significantly lower among technical participants than non-technical participants. While trust perceptions differ between non-technical adopters and non-adopters of privacy controls, no such difference is found among the technical counterparts. Notably, among the non-technical participants, the direction of trust affecting privacy control adoption is observed to be reversed based on the purpose of the controls. Using qualitative analysis, we extract trust-enhancing and dampening factors contributing to users' trusting beliefs towards Google's protection of user privacy. The implications of our findings for the design and promotion of privacy controls are discussed in the paper.",Privacy | Privacy Choices | Privacy Control Adoption | Privacy Controls | Technical Literacy | Trust,3,0,,,NSF,1750908,National Science Foundation,CHI Human-Computer Interaction
2-s2.0-85163120445,10.1145/3564246.3585132,,,The Randomized-Server Conjecture Is False!,cp,Conference Paper,Bubeck S.,60026851;60021726;60007903,University of Oxford;Microsoft Research;Hebrew University of Jerusalem,Oxford;Redmond;Jerusalem,United Kingdom;United States;Israel,3,"Bubeck, Sébastien;Coester, Christian;Rabani, Yuval",26431237900;57195335825;7004138829,60021726;60026851;60007903,2023-06-02,2 June 2023,Proceedings of the Annual ACM Symposium on Theory of Computing,07378017,2300147402,,Conference Proceeding,,,,581-594,"We prove a few new lower bounds on the randomized competitive ratio for the k-server problem and other related problems, resolving some long-standing conjectures. In particular, for metrical task systems (MTS) we asympotically settle the competitive ratio and obtain the first improvement to an existential lower bound since the introduction of the model 35 years ago (in 1987). More concretely, we show: (1) There exist (k+1)-point metric spaces in which the randomized competitive ratio for the k-server problem is ω(log2 k). This refutes the folklore conjecture (which is known to hold in some families of metrics) that in all metric spaces with at least k+1 points, the competitive ratio is (logk). (2) Consequently, there exist n-point metric spaces in which the randomized competitive ratio for MTS is ω(log2 n). This matches the upper bound that holds for all metrics. The previously best existential lower bound was ω(logn) (which was known to be tight for some families of metrics). (3) For all k<n, for all n-point metric spaces the randomized k-server competitive ratio is at least ω(logk), and consequently the randomized MTS competitive ratio is at least ω(logn). These universal lower bounds are asymptotically tight. The previous bounds were ω(logk/loglogk) and ω(logn/loglogn), respectively. (4) The randomized competitive ratio for the w-set metrical service systems problem, and its equivalent width-w layered graph traversal problem, is ω(w2). This slightly improves the previous lower bound and matches the recently discovered upper bound. (5) Our results imply improved lower bounds for other problems like k-taxi, distributed paging, and metric allocation. These lower bounds share a common thread, and other than the third bound, also a common construction.",$k$-server | competitive analysis | lower bounds | metrical task systems | online computing | randomized algorithms,4,0,repositoryam,Green,,2018687,,STOC Theory
2-s2.0-85177736805,10.1109/FOCS57990.2023.00060,,,The Subspace Flatness Conjecture and Faster Integer Programming,cp,Conference Paper,Reis V.,60015481,University of Washington,Seattle,United States,2,"Reis, Victor;Rothvoss, Thomas",57216615659;23991787100,60015481;60015481,2023-01-01,2023,"Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS",02725428,21100474207,,Conference Proceeding,,,,974-988,"In a seminal paper, Kannan and Lovász (1988) considered a quantity μ_K L(Λ, K) which denotes the best volume-based lower bound on the covering radius μ(Λ, K) of a convex body K with respect to a lattice Λ. Kannan and Lovász proved that μ(Λ, K) ≤ n · μ_K L(Λ, K) and the Subspace Flatness Conjecture by Dadush (2012) claims a O(log (2 n)) factor suffices, which would match the lower bound from the work of Kannan and Lovász. We settle this conjecture up to a constant in the exponent by proving that μ(Λ, K) ≤ O(log 3(2 n)) · μ_K L(Λ, K). Our proof is based on the Reverse Minkowski Theorem due to Regev and Stephens-Davidowitz (2017). Following the work of Dadush (2012,2019), we obtain a (log (2 n))O(n)-time randomized algorithm to solve integer programs in n variables. Another implication of our main result is a near-optimal flatness constant of O(n log 3(2 n)).",integer programming,1,0,repositoryam,Green,,undefined,,FOCS Theory
2-s2.0-85160020491,10.1145/3544548.3580986,,,The Walking Talking Stick: Understanding Automated Note-Taking in Walking Meetings,cp,Conference Paper,Haliburton L.,60028717;60027786;60016104;60000990,Ludwig-Maximilians-Universität München;University of St. Gallen;Lodz University of Technology;Chalmers University of Technology,Munich;St Gallen;Lodz;Gothenburg,Germany;Switzerland;Poland;Sweden,5,"Haliburton, Luke;Bartłomiejczyk, Natalia;Schmidt, Albrecht;Woźniak, Paweł W.;Niess, Jasmin",57189976121;57377772800;55596321600;55879280600;57195638917,60028717;60016104;60028717;60000990;60027786,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,431,,"While walking meetings offer a healthy alternative to sit-down meetings, they also pose practical challenges. Taking notes is difficult while walking, which limits the potential of walking meetings. To address this, we designed the Walking Talking Stick - a tangible device with integrated voice recording, transcription, and a physical highlighting button to facilitate note-taking during walking meetings. We investigated our system in a three-condition between-subjects user study with thirty pairs of participants (N=60) who conducted 15-minute outdoor walking meetings. Participants either used clip-on microphones, the prototype without the button, or the prototype with the highlighting button. We found that the tangible device increased task focus, and the physical highlighting button facilitated turn-taking and resulted in more useful notes. Our work demonstrates how interactive artifacts can incentivize users to hold meetings in motion and enhance conversation dynamics. We contribute insights for future systems which support conducting work tasks in mobile environments.",CSCW | Mobile Work | Note-taking | Office Workers | Physical Activity | Walking Meetings,3,1,repositoryam,Green,VR,683008,Vetenskapsrådet,CHI Human-Computer Interaction
2-s2.0-85180548834,10.1145/3611643.3616281,,,TransRacer: Function Dependence-Guided Transaction Race Detection for Smart Contracts,cp,Conference Paper,Ma C.,60020547;60010080,Texas A&amp;M University;Nanjing University of Science and Technology,College Station;Nanjing,United States;China,3,"Ma, Chenyang;Song, Wei;Huang, Jeff",57208102368;56742578700;57013582200,60010080;60010080;60020547,2023-11-30,30 November 2023,ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering,,21101194128,,Conference Proceeding,,,,947-959,"Smart contracts are programs that define rules for transactions running on blockchains. Since any qualified transaction sequence within the same block can be orchestrated by the blockchain miner, unexpected results may occur due to data races between transactions (called transaction races). Surprisingly, transaction races in smart contracts have not been fully investigated. To address this, we propose TransRacer, an automated approach and open-source tool that employs symbolic execution to detect transaction races in smart contracts. TransRacer analyzes function dependencies to identify transaction races hidden in specific contract states. It also generates witness transactions that can trigger such races. The experimental results on 50 real-world smart contracts show the effectiveness and efficiency of TransRacer: it detects 426 races in 255.9 minutes, including 149 race bugs leading to inconsistent states.",data race | Ethereum | smart contract | symbolic execution,0,0,,,NSFC,61761136003,National Natural Science Foundation of China,FSE Software Engineering
2-s2.0-85176951667,10.1145/3600006.3613160,,,TreeSLS: A Whole-system Persistent Microkernel with Tree-structured State Checkpoint on NVM,cp,Conference Paper,Wu F.,60025084;60001604,Shanghai Jiao Tong University;Ministry of Education of the People's Republic of China,Shanghai;Beijing,China;China,4,"Wu, Fangnuo;Dong, Mingkai;Mo, Gequan;Chen, Haibo",57948817000;56697813900;58697832700;55743141500,60025084-60001604;60025084-60001604;60025084;60025084-60001604,2023-10-23,23 October 2023,SOSP 2023 - Proceedings of the 29th ACM Symposium on Operating Systems Principles,,21101186888,,Conference Proceeding,,,,1-16,"Whole-system persistence promises simplified application deployment and near-instantaneous recovery. This can be implemented using single-level store (SLS) through periodic checkpointing of ephemeral state to persistent devices. However, traditional SLSs suffer from two main issues on checkpointing efficiency and external synchrony, which are critical for low-latency services with persistence need.In this paper, we note that the decentralized state of microkernel-based systems can be exploited to simplify and optimize state checkpointing. To this end, we propose TreeSLS, a whole-system persistent microkernel that simplifies the whole-system state maintenance to a capability tree and a failure-resilient checkpoint manager. TreeSLS further exploits the emerging non-volatile memory to minimize checkpointing pause time by eliminating the distinction between ephemeral and persistent devices. With efficient state maintenance, TreeSLS further proposes delayed external visibility to provide transparent external synchrony with little overhead. Evaluation on microbenchmarks and real-world applications (e.g., Memcached, Redis and RocksDB) show that TreeSLS can complete a whole-system persistence in around 100 μs and even take a checkpoint every 1 ms with reasonable overhead to applications.",checkpoint/restore | microkernel | non-volatile memory | single-level store | transparent persistence,0,0,,,NSFC,61925206,National Natural Science Foundation of China,SOSP Operating Systems
2-s2.0-85178360139,,,,Triangulating Python Performance Issues with SCALENE,cp,Conference Paper,Berger E.D.,60014313,University of Massachusetts Amherst,Amherst,United States,3,"Berger, Emery D.;Stern, Sam;Pizzorno, Juan Altmayer",7202374093;58033377600;58032697100,60014313;60014313;60014313,2023-01-01,2023,"Proceedings of the 17th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2023",,21101193953,,Conference Proceeding,,,,51-64,"This paper proposes the SCALENE Python profiler. SCALENE precisely and simultaneously profiles CPU, memory, and GPU usage, all with low overhead. SCALENE’s CPU and memory profilers help Python programmers direct their optimization efforts by distinguishing between inefficient Python and efficient native execution time and memory usage. SCALENE’s memory profiler employs a novel sampling algorithm that lets it operate with low overhead yet high precision. It also incorporates a novel algorithm that automatically pinpoints memory leaks within Python or across the Python/native boundary. SCALENE tracks a new metric called copy volume, which highlights costly copying operations that can occur when Python silently converts between native and Python data representations, or between CPU and GPU. Since its introduction, SCALENE has been widely adopted, with over 675,000 downloads to date. We present experience reports from developers who used SCALENE to achieve significant performance improvements and memory savings.",,1,0,,,NSF,1954830,National Science Foundation,OSDI Operating Systems
2-s2.0-85163187674,10.1109/SP46215.2023.10179418,,,Typing High-Speed Cryptography against Spectre v1,cp,Conference Paper,Shivakumar B.A.,60121727;60104289;60032385;60016529;60004981;124636316,IMDEA Software Institute;Université de Lorraine;Centre Inria Sophia Antipolis - Méditerranée;Radboud Universiteit;École Normale Supérieure Paris-Saclay;MPI-SP,Pozuelo de Alarcon;Nancy;Sophia Antipolis;Nijmegen;Gif-sur-Yvette;Bochum,Spain;France;France;Netherlands;France;Germany,8,"Shivakumar, Basavesh Ammanaghatta;Barthe, Gilles;Grégoire, Benjamin;Laporte, Vincent;Oliveira, Tiago;Priya, Swarn;Schwabe, Peter;Tabary-Maujean, Lucas",57204904823;7004083177;8976190300;55602171300;57190181888;57261900200;24385813500;58519378800,124636316;124636316-60121727;60032385;60104289;124636316;60032385;124636316-60016529;60004981,2023-01-01,2023,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2023-May,,,1094-1111,"The current gold standard of cryptographic software is to write efficient libraries with systematic protections against timing attacks. In order to meet this goal, cryptographic engineers increasingly use high-assurance cryptography tools. These tools guide programmers and provide rigorous guarantees that can be verified independently by library users. However, high-assurance tools reason about overly simple execution models that elide transient execution leakage. Thus, implementations validated by high-assurance cryptography tools remain potentially vulnerable to transient execution attacks such as Spectre or Meltdown. Moreover, proposed countermeasures are not used in practice due to performance overhead.We propose, analyze, implement and evaluate an approach for writing efficient cryptographic implementations that are protected against Spectre v1 attacks. Our approach ensures speculative constant-time, an information flow property which guarantees that programs are protected against Spectre v1. Speculative constant-time is enforced by means of a (value-dependent) information flow type system. The type system tracks security levels depending on whether execution is misspeculating. We implement our approach in the Jasmin framework for high-assurance cryptography, and use it for protecting all implementations of an experimental cryptographic library that includes highly optimized implementations of symmetric primitives, of elliptic-curve cryptography, and of Kyber, a lattice-based KEM recently selected by NIST for standardization. The performance impact of our protections is very low; for example, less than 1% for Kyber and essentially zero for X25519.",,6,0,,,EC,805031,European Commission,S&P Security and Privacy
2-s2.0-85160014997,10.1145/3544548.3581243,,,Understanding Context to Capture when Reconstructing Meaningful Spaces for Remote Instruction and Connecting in XR,cp,Conference Paper,Maddali H.T.,60020304,"University of Maryland, College Park",College Park,United States,2,"Maddali, Hanuma Teja;Lazar, Amanda",57200498178;55660177200,60020304;60020304,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,275,,"Recent technological advances are enabling HCI researchers to explore interaction possibilities for remote XR collaboration using high-fidelity reconstructions of physical activity spaces. However, creating these reconstructions often lacks user involvement with an overt focus on capturing sensory context that does not necessarily augment an informal social experience. This work seeks to understand social context that can be important for reconstruction to enable XR applications for informal instructional scenarios. Our study involved the evaluation of an XR remote guidance prototype by 8 intergenerational groups of closely related gardeners using reconstructions of personally meaningful spaces in their gardens. Our findings contextualize physical objects and areas with various motivations related to gardening and detail perceptions of XR that might affect the use of reconstructions for remote interaction. We discuss implications for user involvement to create reconstructions that better translate real-world experience, encourage reflection, incorporate privacy considerations, and preserve shared experiences with XR as a medium for informal intergenerational activities.",3D reconstruction | contextual capture | Extended Reality | gardening | hobby activities | intergenerational study | metaverse | remote instruction,1,1,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85159427315,10.1109/ICSE48619.2023.00062,,,Understanding and Detecting On-The-Fly Configuration Bugs,cp,Conference Paper,Wang T.,60032356;60024350,Hunan University;National University of Defense Technology China,Changsha;Changsha,China;China,8,"Wang, Teng;Jia, Zhouyang;Li, Shanshan;Zheng, Si;Yu, Yue;Xu, Erci;Peng, Shaoliang;Liao, Xiangke",57203411271;56733791600;55741045700;37119734200;55566298800;54399637600;55756247400;14834355700,60024350;60024350;60024350;60024350;60024350;60024350;60032356;60024350,2023-01-01,2023,Proceedings - International Conference on Software Engineering,02705257,19242,,Conference Proceeding,,,,628-639,"Software systems introduce an increasing number of configuration options to provide flexibility, and support updating the options on the fly to provide persistent services. This mechanism, however, may affect the system reliability, leading to unexpected results like software crashes or functional errors. In this paper, we refer to the bugs caused by on-the-fly configuration updates as on-the-fly configuration bugs, or OCBugs for short. In this paper, we conducted the first in-depth study on 75 real-world OCBugs from 5 widely used systems to understand the symptoms, root causes, and triggering conditions of OCBugs. Based on our study, we designed and implemented Parachute, an automated testing framework to detect OCBugs. Our key insight is that the value of one configuration option, either loaded at the startup phase or updated on the fly, should have the same effects on the target program. Parachute generates tests for on-the-fly configuration updates by mutating the existing tests and conducts differential analysis to identify OCBugs. We evaluated Parachute on 7 real-world software systems. The results show that Parachute detected 75% (42/56) of the known OCBugs, and reported 13 unknown bugs, 11 of which have been confirmed or fixed by developers until the time of writing.",bug detection | metamorphic testing | on-the-fly configuration updates,3,0,,,NSFC,61872373,National Natural Science Foundation of China,ICSE Software Engineering
2-s2.0-85160021963,10.1145/3544548.3581503,,,Understanding the Benefits and Challenges of Deploying Conversational AI Leveraging Large Language Models for Public Health Intervention,cp,Conference Paper,Jo E.,60007278;127182748;126889164,"University of California, Irvine;NAVER AI Lab;NAVER Cloud",Irvine;Seongnam;Seongnam,United States;South Korea;South Korea,4,"Jo, Eunkyung;Epstein, Daniel A.;Jung, Hyunhoon;Kim, Young Ho",57200496212;25645787700;57209303928;57221144687,60007278;60007278;126889164;127182748,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,18,,"Recent large language models (LLMs) have advanced the quality of open-ended conversations with chatbots. Although LLM-driven chatbots have the potential to support public health interventions by monitoring populations at scale through empathetic interactions, their use in real-world settings is underexplored. We thus examine the case of CareCall, an open-domain chatbot that aims to support socially isolated individuals via check-up phone calls and monitoring by teleoperators. Through focus group observations and interviews with 34 people from three stakeholder groups, including the users, the teleoperators, and the developers, we found CareCall offered a holistic understanding of each individual while offloading the public health workload and helped mitigate loneliness and emotional burdens. However, our findings highlight that traits of LLM-driven chatbots led to challenges in supporting public and personal health needs. We discuss considerations of designing and deploying LLM-driven chatbots for public health intervention, including tensions among stakeholders around system expectations.",Chatbot | Check-up calls | Large language model | Open-domain dialog system | Public health | Social isolation,5,1,repositoryvor,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85174871204,10.1145/3600006.3613140,,,Validating JIT Compilers via Compilation Space Exploration,cp,Conference Paper,Li C.,60033100;60025858,Nanjing University;ETH Zürich,Nanjing;Zurich,China;Switzerland,4,"Li, Cong;Jiang, Yanyan;Xu, Chang;Su, Zhendong",57775259100;56006054500;56870592600;7402248744,60033100;60033100;60033100;60025858,2023-10-23,23 October 2023,SOSP 2023 - Proceedings of the 29th ACM Symposium on Operating Systems Principles,,21101186888,,Conference Proceeding,,,,66-79,"This paper introduces the novel concept of compilation space, which facilitates the thorough validation of just-in-time (JIT) compilers in modern language virtual machines (LVMs). The compilation space, even for a single program, consists of an extensive array of JIT compilation choices, which can be cross-validated for the correctness of JIT compilation. To thoroughly explore the compilation space in a lightweight and LVM-agnostic manner, we strategically mutate test programs with JIT-relevant, yet semantics-preserving code structures to trigger diverse JIT compilation choices. We realize our technique in Artemis, a tool for the Java virtual machine (JVM). Our evaluation has led to 85 bug reports for three widely used production JVMs, namely HotSpot, OpenJ9, and the Android Runtime. Among them, 53 have already been confirmed or fixed with many being critical. It is also worth mentioning that all the reported bugs concern JIT compilers, demonstrating the clear effectiveness and strong practicability of our technique. We expect that the generality and practicability of our approach will make it broadly applicable for understanding and validating JIT compilers.",compilers | JIT compilers | JVMs | testing,0,0,,,NSFC,BK20202001,National Natural Science Foundation of China,SOSP Operating Systems
2-s2.0-85173953281,10.1109/CVPR52729.2023.01436,,,Visual Programming: Compositional visual reasoning without training,cp,Conference Paper,Gupta T.,129102071,PRIOR,Allen,United States,2,"Gupta, Tanmay;Kembhavi, Aniruddha",57220671276;57208117160,129102071;129102071,2023-01-01,2023,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,10636919,24212,,Conference Proceeding,2023-June,,,14953-14962,"We present Visprog, a neuro-symbolic approach to solving complex and compositional visual tasks given natural language instructions. Visprog avoids the need for any task-specific training. Instead, it uses the incontext learning ability of large language models to generate python-like modular programs, which are then executed to get both the solution and a comprehensive and interpretable rationale. Each line of the generated program may invoke one of several off-the-shelf computer vision models, image processing subroutines, or python functions to produce intermediate outputs that may be consumed by subsequent parts of the program. We demonstrate the flexibility of VIsPROG on 4 diverse tasks - compositional visual question answering, zero-shot reasoning on image pairs, factual knowledge object tagging, and language-guided image editing. We believe neuro-symbolic approaches like Visprog are an exciting avenue to easily and effectively expand the scope of AI systems to serve the long tail of complex tasks that people may wish to perform.",and reasoning | language | Vision,10,0,repositoryam,Green,,undefined,,CVPR Computer Vision
2-s2.0-85166466400,10.1109/SP46215.2023.10179357,,,WaVe: A verifiably secure WebAssembly sandboxing runtime,cp,Conference Paper,Johnson E.,60030612;130033644;124227311;123976447;123683234,"University of California, San Diego;Fastly Labs;UIUC;Stanford;CMU",La Jolla;;Berkeley;Stanford;Philadelphia,United States;;United States;United States;United States,8,"Johnson, Evan;Laufer, Evan;Zhao, Zijie;Gohman, Dan;Narayan, Shravan;Savage, Stefan;Stefan, Deian;Brown, Fraser",57222380128;58519158100;58519491000;57189873002;57194972516;7103218472;24475695700;57189853657,60030612;123976447;124227311;130033644;60030612;60030612;60030612;123683234,2023-01-01,2023,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2023-May,,,2940-2955,"The promise of software sandboxing is flexible, fast and portable isolation; capturing the benefits of hardwarebased memory protection without requiring operating system involvement. This promise is reified in WebAssembly (Wasm), a popular portable bytecode whose compilers automatically insert runtime checks to ensure that data and control flow are constrained to a single memory segment. Indeed, modern compiled Wasm implementations have advanced to the point where these checks can themselves be verified, removing the compiler from the trusted computing base. However, the resulting integrity properties are only valid for code executing strictly inside the Wasm sandbox. Any interactions with the runtime system, which manages sandboxes and exposes the WebAssembly System Interface (WASI) used to access operating system resources, operate outside this contract. The resulting conundrum is how to maintain Wasm's strong isolation properties while still allowing such programs to interact with the outside world (i.e., with the file system, the network, etc.). Our paper presents a solution to this problem, via WaVe, a verified secure runtime system that implements WASI. We mechanically verify that interactions with WaVe (including OS side effects) not only maintain Wasm's memory safety guarantees, but also maintain access isolation for the host OS's storage and network resources. Finally, in spite of completely removing the runtime from the trusted computing base, we show that WaVe offers performance competitive with existing industrial (yet unsafe) Wasm runtimes.",Software-Fault-Isolation | Verification | WebAssembly,3,0,,,NSF,CCF-1918573,National Science Foundation,S&P Security and Privacy
2-s2.0-85166483286,10.1109/SP46215.2023.10179408,,,Weak Fiat-Shamir Attacks on Modern Proof Systems,cp,Conference Paper,Dao Q.,60027950;60025778;127785570,"Carnegie Mellon University;University of Michigan, Ann Arbor;Trail of Bits",Pittsburgh;Ann Arbor;Trail,United States;United States;Canada,4,"Dao, Quang;Miller, Jim;Wright, Opal;Grubbs, Paul",58312191400;58519167700;58519564800;56022262200,60027950;127785570;127785570;60025778,2023-01-01,2023,Proceedings - IEEE Symposium on Security and Privacy,10816011,84156,,Conference Proceeding,2023-May,,,199-216,"A flurry of excitement amongst researchers and practitioners has produced modern proof systems built using novel technical ideas and seeing rapid deployment, especially in cryptocurrencies. Most of these modern proof systems use the Fiat-Shamir (F-S) transformation, a seminal method of removing interaction from a protocol with a public-coin verifier. Some prior work has shown that incorrectly applying F-S (i.e., using the so-called ""weak""F-S transformation) can lead to breaks of classic protocols like Schnorr's discrete log proof; however, little is known about the risks of applying F-S incorrectly for modern proof systems seeing deployment today.In this paper, we fill this knowledge gap via a broad theoretical and practical study of F-S in implementations of modern proof systems. We perform a survey of open-source implementations and find 30 weak F-S implementations affecting 12 different proof systems. For four of these - Bulletproofs, Plonk, Spartan, and Wesolowski's VDF - we develop novel knowledge soundness attacks accompanied by rigorous proofs of their efficacy. We perform case studies of applications that use vulnerable implementations, and demonstrate that a weak F-S vulnerability could have led to the creation of unlimited currency in a private smart contract platform. Finally, we discuss possible mitigations and takeaways for academics and practitioners.",applied-cryptography | attacks | blockchain | Fiat-Shamir | proof-systems | zero-knowledge,2,0,,,DARPA,HR00112020022,Defense Advanced Research Projects Agency,S&P Security and Privacy
2-s2.0-85160008339,10.1145/3544548.3581019,,,What Do We Mean When We Talk about Trust in Social Media? A Systematic Review,cp,Conference Paper,Zhang Y.,60090654;60028628;60019647;60016114,Universiti Malaysia Pahang Al-Sultan Abdullah;Northeastern University;Georgia Institute of Technology;William &amp; Mary,Pekan;Boston;Atlanta;Williamsburg,Malaysia;United States;United States;United States,8,"Zhang, Yixuan;Gaggiano, Joseph D.;Yongsatianchot, Nutchanon;Suhaimi, Nurul M.;Kim, Miso;Sun, Yifan;Griffin, Jacqueline;Parker, Andrea G.",57202889533;57704796800;57190129228;57207565937;57366796500;57189261706;25521941900;55093650600,60019647;60019647;60028628;60090654;60028628;60016114;60028628;60019647,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,670,,"Do people trust social media? If so, why, in what contexts, and how does that trust impact their lives? Researchers, companies, and journalists alike have increasingly investigated these questions, which are fundamental to understanding social media interactions and their implications for society. However, trust in social media is a complex concept, and there is conflicting evidence about the antecedents and implications of trusting social media content, users, and platforms. More problematic is that we lack basic agreement as to what trust means in the context of social media. Addressing these challenges, we conducted a systematic review to identify themes and challenges in this field. Through our analysis of 70 papers, we contribute a synthesis of how trust in social media is defined, conceptualized, and measured, a summary of trust antecedents in social media, an understanding of how trust in social media impacts behaviors and attitudes, and directions for future work.",social media | systematic review | trust,2,1,repositoryam,Green,,undefined,,CHI Human-Computer Interaction
2-s2.0-85167699497,,,,What the DAAM: Interpreting Stable Diffusion Using Cross Attention,cp,Conference Paper,Tang R.,60025919;60022148;60014171,Comcast;University College London;University of Waterloo,Philadelphia;London;Waterloo,United States;United Kingdom;Canada,9,"Tang, Raphael;Liu, Linqing;Pandey, Akshat;Jiang, Zhiying;Yang, Gefei;Kumar, Karun;Stenetorp, Pontus;Lin, Jimmy;Ture, Ferhan",57204048147;57216692188;57938954000;57216365353;57194471542;58278749300;36663192600;56824507200;25926158000,60025919;60022148;60025919;60014171;60025919;60025919;60022148;60014171;60025919,2023-01-01,2023,Proceedings of the Annual Meeting of the Association for Computational Linguistics,0736587X,21101138302,,Conference Proceeding,1,,,5644-5659,"Diffusion models are a milestone in text-to-image generation, but they remain poorly understood, lacking interpretability analyses. In this paper, we perform a text-image attribution analysis on Stable Diffusion, a recently open-sourced model. To produce attribution maps, we upscale and aggregate cross-attention maps in the denoising module, naming our method DAAM. We validate it by testing its segmentation ability on nouns, as well as its generalized attribution quality on all parts of speech, rated by humans. On two generated datasets, we attain a competitive 58.8-64.8 mIoU on noun segmentation and fair to good mean opinion scores (3.4-4.2) on generalized attribution. Then, we apply DAAM to study the role of syntax in the pixel space across head-dependent heat map interaction patterns for ten common dependency relations. We show that, for some relations, the head map consistently subsumes the dependent, while the opposite is true for others. Finally, we study several semantic phenomena, focusing on feature entanglement; we find that the presence of cohyponyms worsens generation quality by 9%, and descriptive adjectives attend too broadly. We are the first to interpret large diffusion models from a visuolinguistic perspective, which enables future research. Our code is at https://github.com/castorini/daam.",,1,0,,,CIFAR,undefined,Canadian Institute for Advanced Research,ACL Natural Language Processing
2-s2.0-85160014296,10.1145/3544548.3581524,,,Who Do We Mean When We Talk About Visualization Novices?,cp,Conference Paper,Burns A.,60020426;60014313,Bucknell University;University of Massachusetts Amherst,Lewisburg;Amherst,United States;United States,5,"Burns, Alyxander;Lee, Christiana;Chawla, Ria;Peck, Evan;Mahyar, Narges",57211214032;57254450400;57491543400;36170923500;36727821000,60014313;60014313;60014313;60020426;60014313,2023-04-19,19 April 2023,Conference on Human Factors in Computing Systems - Proceedings,,21101153176,,Conference Proceeding,,,819,,"As more people rely on visualization to inform their personal and collective decisions, researchers have focused on a broader range of audiences, including ""novices.""But successfully applying, interrogating, or advancing visualization research for novices demands a clear understanding of what ""novice""means in theory and practice. Misinterpreting who a ""novice""is could lead to misapplying guidelines and overgeneralizing results. In this paper, we investigated how visualization researchers define novices and how they evaluate visualizations intended for novices. We analyzed 79 visualization papers that used ""novice,""""non-expert,""""laypeople,""or ""general public""in their titles or abstracts. We found ambiguity within papers and disagreement between papers regarding what defines a novice. Furthermore, we found a mismatch between the broad language describing novices and the narrow population representing them in evaluations (i.e., young people, students, and US residents). We suggest directions for inclusively supporting novices in both theory and practice.",audience | critical analyses | data visualization | research methodology,3,0,,,,undefined,,CHI Human-Computer Interaction
